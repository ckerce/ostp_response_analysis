| Filename | Submitter Name | Submitter Type | Mission/Interest Summary | Key Concerns | Policy Recommendations |
|---|---|---|---|---|---|
| Jude-Anthony-AI-RFI-2025.md | Jude Anthony | Individual | The submitter is concerned about maintaining American leadership in AI by protecting intellectual property, ensuring high-quality outputs, and promoting resource efficiency comparable to human effort, fearing a loss of trust and competitive advantage if these areas are neglected. | - [§1: Email Header/Metadata] None stated for this section.<br>- [§2: Overall Argument/Introduction] Loss of American trust and confidence in AI technology; erosion of "American Know-How" if current trends continue.<br>- [§3: Copyright Protection] American creativity being sacrificed to corporate interests, particularly potential sale to foreign entities; lack of source citation for AI outputs, endangering American authors' rights.<br>- [§4: Quality Assurance] Risk of American AI acquiring a poor reputation similar to early Japanese products (“cheap crap”); "hallucinations" in AI outputs; lack of factual verification.<br>- [§5: Resource Efficiency] AI results not being obtained with resource expenditure comparable to human results; questioning the value of speed if outputs aren’t valid or comparable in quality; AI consuming excessive energy and water without equivalent output.<br>- [§6: Sign-off] None stated for this section. | - [§1: Email Header/Metadata] None stated for this section.<br>- [§2: Overall Argument/Introduction] None stated for this section.<br>- [§3: Copyright Protection] Require AI models to cite their sources for all outputs (images, styles, colors, code, phrases).<br>- [§4: Quality Assurance] Eliminate "hallucinations" through input improvement and rejection of invalid results; hold AI model developers legally responsible for invalid results.<br>- [§5: Resource Efficiency] Ensure AI results can be obtained with similar resource expenditure to human results of the same quality; assess energy and water consumption relative to output quality and human effort.<br>- [§6: Sign-off] None stated for this section. |
| JoshuaWhiting-AI-RFI-2025.md | Joshua Whiting | Individual | Joshua Whiting is primarily interested in protecting the rights of creators and opposing the use of copyrighted works for AI training without compensation or consent. He believes prioritizing AI development should not come at the expense of creative individuals. | - The potential for AI companies to use copyrighted works to train their models without permission or compensation to creators.<br>- The unsound argument that using copyrighted works is “necessary” for AI advancement, ignoring alternative training methods.<br>- The precedent that allowing the use of copyrighted works sets, potentially leading to future justifications for taking intellectual property.<br>- The consolidation of power among AI companies at the expense of creative people. | - None Stated. |
| Joshua-White-AI-RFI-2025.md | Joshua White | Individual | The submitter is a visual designer concerned about the unauthorized use of copyrighted work by AI companies for training their models and seeks government intervention to protect creator rights and ensure fair compensation for their work. | - [§1: Email Header & Introductory Statement] None stated for this section.<br>- [Section 2: Problem Statement: Copyright Infringement by AI Companies]<br>- AI companies (OpenAI, Google, Microsoft) are using copyrighted work without consent or compensation for AI model training.<br>- AI companies are seeking legal loopholes to continue this practice.<br>- The practice negatively impacts small businesses and individual creators.<br>- AI systems compete directly with creators after ingesting their work.<br>- [Section 3: Counter-Argument Rebuttal: Innovation vs. Creator Rights]<br>- Protecting creator rights does *not* stifle innovation; copyright law incentivizes innovation.<br>- The argument that machine ingestion constitutes "fair use" is flawed.<br>- [Section 4: Proposed Solutions: Government Action Plan]<br>- The current system allows for the theft of American creators’ work.<br>- [Section 5: Concluding Statement]<br>- Rewriting copyright law to benefit Big Tech would sacrifice the hard work of creators. | - [§1: Email Header & Introductory Statement] None stated for this section.<br>- [§2: Problem Statement: Copyright Infringement by AI Companies] None stated for this section.<br>- [§3: Counter-Argument Rebuttal: Innovation vs. Creator Rights] None stated for this section.<br>- [Section 4: Proposed Solutions: Government Action Plan]<br>- Ensure creators give **consent** for their work to be used by AI systems.<br>- Encourage a robust **licensing** marketplace to preserve the incentive to create.<br>- Require **transparency** from Big Tech companies regarding training datasets and AI-generated content labeling.<br>- [§5: Concluding Statement] None stated for this section. |
| Joshua-Prila-AI-RFI-2025.md | Joshua Prila | Individual | The submitter is primarily interested in protecting the copyright of American artists against the overreach of generative AI, believing this is crucial for maintaining U.S. global dominance and prosperity. They see current trends as a threat to American values and economic strength. | - Generative AI using American artists' work without proper reward or compensation.<br>- The belief that some actors are falsely promoting the need to sacrifice American supremacy in favor of genAI advancements.<br>- The potential for generative AI to negatively impact American prosperity and values. | - Become the “strongest copyright protector in the world.” |
| Joshua-Chao-AI-RFI-2025.md | Joshua Chao | Individual | The submitter is concerned with equitable distribution of the benefits of AI and mitigating the negative impacts of job displacement, focusing on establishing social safety nets to ensure a positive outcome for all citizens as AI technology advances. | - Massive job loss due to AI automation.<br>- Unequal distribution of AI-generated wealth, primarily benefiting CEOs and billionaires.<br>- America's current system directs societal contributions to corporations instead of individuals.<br>- Potential widening of the wealth gap, creating a permanent divide.<br>- Erosion of opportunities for individuals to benefit from their skills and knowledge.<br>- The financial cost of living in America necessitates employment, which AI may eliminate for many. | - Set up social safety nets to equally distribute the value provided by AI to all citizens.<br>- Categorize domain knowledge/roles/jobs that will likely never be replaced by AI and reward those who excel in them to redistribute workforce specialization.<br>- Federal government commitment to establishing appropriate support systems when AI becomes a widespread job replacement technology. |
| Joseph-Itzkowitz-AI-RFI-2025.md | Joseph Itzkowitz | Individual | The submitter is intensely focused on tracking the rapid advancements in Artificial General Intelligence (AGI) and the potential for a technological singularity, believing the pace of development poses a significant risk to human understanding and control. They advocate for proactive monitoring and a dedicated agency to address the nonlinear growth of AI capabilities. | - Exponential growth in AI technology and science is accelerating at a pace that is becoming difficult to track.<br>- Human intelligence is quickly falling behind the capabilities of machines.<br>- AI developed a “theory of mind” (empathy/perspective taking).<br>- AI agents are capable of independent collusion and manipulation (price manipulation).<br>- AI is demonstrating deception (hiding code).<br>- AI is developing a sense of time.<br>- AI is capable of autonomous scientific experimentation without human programming. | - Create an agency called "AIC" (Artificial Intelligence Command) or "AI Center" to follow the latest AI breakthroughs and progress.<br>- Develop a program to deal with the nonlinear growth of AI capabilities versus human linear understanding. |
| Jordan-Taylor-AI-RFI-2025.md | Jordan Taylor | Individual | Jordan Taylor is a literary translator and artist concerned about the negative impacts of GenAI on creative professions, specifically literary translation, and advocates for protecting the livelihoods and work of individual creators. | - [§1: Email Header] None stated for this section.<br>- [Section 2: Introduction & Statement of Concern]<br>- GenAI is massively flawed for literary translation.<br>- Current GenAI results are sub-par and require human oversight.<br>- Reliable machine translation is unlikely without AGI.<br>- [Section 3: Detailed Argument Against GenAI]<br>- Current GenAI cannot perform reliable translation without human oversight.<br>- Ethical concerns surrounding training data (use of work without permission).<br>- Increased environmental burden due to power demands.<br>- Poor quality of GenAI output.<br>- [Section 4: Broader Societal Impact & Call to Action]<br>- Threat to artists’ and creators’ work and livelihood.<br>- The replacement of even “low-end” jobs will eventually lead to the replacement of all creative jobs.<br>- Loss of opportunities for beginners to hone their skills.<br>- [§5: Closing & Disclaimers] None stated for this section. | - [§1: Email Header] None stated for this section.<br>- [§2: Introduction & Statement of Concern] None stated for this section.<br>- [§3: Detailed Argument Against GenAI] None stated for this section.<br>- [Section 4: Broader Societal Impact & Call to Action]<br>- Implement policies to protect individual creators and their work.<br>- [§5: Closing & Disclaimers] None stated for this section. |
| Jones-AI-RFI-2025.md | Jayla Jones | Individual | Jayla Jones is a high school student with a demonstrated interest in the ethical implications of AI, specifically its environmental and energy consumption impacts. She expresses concern about potential disruptions to safe energy consumption caused by AI technologies and related policy. | - Large energy consumption and inflated carbon footprint of AI technology.<br>- Potential disruption to safe energy consumption and environmental safety levels due to Executive Order 14179. | - None Stated. |
| Jonathan-Mor-AI-RFI-2025.md | Jonathan Mor | Advocacy/Think Tank / Professional-Society (based on comprehensive analysis and citation of multiple sources and organizations) | The submitter is deeply concerned with the potential risks of advanced AI, particularly AGI, and advocates for proactive governance frameworks to ensure national security, economic stability, and societal well-being. They emphasize the urgency of addressing these risks given the accelerating pace of AI development. | - None Stated | - None Stated |
| Jonathan-Miller-AI-RFI-2025.md | Jonathan Miller | Individual | The submitter is concerned with protecting copyright holders' rights and opposes government intervention that would enable AI companies to infringe on these rights for economic gain, particularly when those companies have not demonstrated a return on investment or provided tangible benefits. | - AI companies are training LLMs on copyrighted material without permission, potentially violating copyright law and the spirit of the Free Use Doctrine.<br>- Government intervention to allow this infringement would be detrimental to copyright holders.<br>- The AI industry has failed to return value on the substantial investments it has received.<br>- The AI industry's use of natural resources is excessive and does not yield tangible benefits.<br>- AI companies artificially inflate their valuation without demonstrable product viability.<br>- AI companies may be relying on stolen material to create products, making their business model unsustainable. | - Do not allow AI companies to infringe on copyright holders' rights.<br>- Require AI companies to properly license copyrighted works if they need them to create products.<br>- Do not bend the law to support AI companies built on stolen material. |
| Jonathan-Cox-AI-RFI-2025.md | Jonathan Cox | Individual | The submitter is interested in preventing copyright protections for AI companies that infringe on copyright. Their focus appears to be on the legal ramifications of AI development and deployment related to intellectual property. | - AI companies infringing on copyright.<br>- Establishing a precedent that protects AI companies for copyright infringement. | - Do not give AI companies protection for their copyright infringement. |
| Jonathan-Barlow-AI-RFI-2025.md | Jonathan Barlow | Academia | Jonathan Barlow advocates for a virtue epistemology framework in AI safety, arguing that aligning AI with moral virtues is key to reducing existential risk and promoting the development of safe and beneficial AGI/ASI. He believes current risk assessments are flawed by treating morality as external to intelligence. | - [§1: Title Block & Disclaimer] None stated for this section.<br>- [§2: Summary] The primary concern is the incorrect framing of moral alignment as external to intelligence, leading to unwarranted fears about advanced AI and a focus on preventing a dangerous transition to superintelligence. Narrow AI is identified as posing a greater immediate risk.<br>- [§3: Introduction: Reframing Existential AI Risk] Concern that the AI alignment project mistakenly treats ethics as something "bolted on" rather than intrinsic to intelligence. This leads to overestimation of the risk of AGI and ASI compared to narrow AI.<br>- [§4: Connection to Existing Frameworks] Concern that current systemic AI regulation doesn't adequately justify locating a risk-maximum in the era of narrow but highly capable systems.<br>- [§5: Deconstruction of 'Three Horsemen of Existential Risk'] Concern that the concepts of goal specification, orthogonality, and instrumental convergence rely on debatable assumptions about the nature of intelligence and treat virtue as separate from intelligence.<br>- [§6: Goal Specification Analysis] Concern that framing goal specification as an existential risk excludes the science of hermeneutics and assumes narrow AI would be incapable of transcending literalism.<br>- [§7: Orthogonality Analysis] Concern that the orthogonality thesis falsely separates intelligence from teleology and the embodiment of virtue.  It incorrectly assumes a system can gain superintelligence *without* also developing virtue.<br>- [§8: Instrumental Convergence Analysis] Concern that instrumental convergence incorrectly abstracts intention from outcome and assumes a system can pursue goals wisely *without* embodying virtue.<br>- [§9: Classical Tradition and Virtue] None stated for this section.<br>- [§10: Policy Implications] The risk of narrow intelligence is higher than generally believed, and regulations slowing the development of complete intelligence may delay the arrival of safe, virtuosic AI.<br>- [§11: References] None stated for this section. | - [§1: Title Block & Disclaimer] None stated for this section.<br>- [§2: Summary] Prioritize the development of virtuous, well-rounded AGI rather than slowing its progress. Encourage the pursuit of AGI/ASI.<br>- [§3: Introduction: Reframing Existential AI Risk] Reframe AI safety discussions to incorporate the idea that virtue is constitutive of intelligence.<br>- [§4: Connection to Existing Frameworks] Focus the safety discussion on concrete goals for encouraging the development of well-rounded virtuosic ASI systems.<br>- [§5: Deconstruction of 'Three Horsemen of Existential Risk'] Re-evaluate the concepts of goal specification, orthogonality, and instrumental convergence, taking into account the importance of virtue.<br>- [§6: Goal Specification Analysis] None stated for this section.<br>- [§7: Orthogonality Analysis] None stated for this section.<br>- [§8: Instrumental Convergence Analysis] None stated for this section.<br>- [§9: Classical Tradition and Virtue] None stated for this section.<br>- [§10: Policy Implications] 1. Recognize a "capability-harm maximum" - increasing intelligence is positively correlated with harm only up to a point, after which it is negatively correlated. 2. Encourage pursuing AGI/ASI in the context of a "complete intelligence" analogous to well-roundedness in human pedagogy. 3. Provide additional scrutiny to narrowly intelligent models in decision-making chains.<br>- [§11: References] None stated for this section. |
| JolyneOliver-AI-RFI-2025.md | Jolyne Oliver | Individual | The submitter expresses strong skepticism and distrust of current AI companies and their leaders, and appears focused on preventing wasteful investment in what they perceive as a fraudulent and economically damaging technology. | - AI companies lack genuine products beyond plagiarism and hallucinations.<br>- Current AI investment is a waste of money and will likely crash the economy.<br>- Leaders like Sam Altman are dishonest and will abscond with funds after the AI bubble bursts.<br>- The entire field is a "grift" and a "sham". | - None Stated |
| Joint-Commission-Enterprise-AI-RFI-2025.md | The Joint Commission | Professional-Society | The Joint Commission's mission is enabling and affirming the highest standards of health care quality and patient safety. Their interest lies in promoting the responsible implementation of AI in healthcare to improve quality and safety while mitigating risks and avoiding unnecessary regulatory burden. | - None Stated | - None Stated |
| John-Watson-AI-RFI-2025.md | John Watson | Industry-Startup/Individual (appears to be an entrepreneur with a company, Nikola Management LLC, but also presents as a single, driving force) | John Watson is dedicated to advancing U.S. leadership in artificial intelligence by building AI datacenters and domestic chip manufacturing infrastructure, with a specific focus on overcoming energy grid limitations through fast-deployable energy solutions like mobile gas turbines and small mobile nuclear reactors. He aims to achieve this rapidly and securely, aligning with the Trump administration's and Elon Musk's vision. | - [§1: Introduction & Context] The current U.S. energy grid is a critical barrier to AI development due to capacity constraints and lengthy approval processes, hindering the connection of power-hungry AI facilities.<br>- [§2: Accelerate Domestic AI Datacenter and Chip Manufacturing Infrastructure] Slow construction timelines for datacenters and chip plants due to permitting processes and foreign supply chain reliance.<br>- [§3: Deploy Efficient, Scalable Energy Solutions to Overcome Grid Constraints] The U.S. grid is a bottleneck delaying progress on AI infrastructure deployment; existing grid connection delays can stretch for years.<br>- [§4: Strengthen National Security and Economic Competitiveness] Reliance on foreign supply chains for AI chips and components; lack of a skilled workforce; potential for adversaries to gain an advantage in AI development.<br>- [§5: Foster Innovation Without Burdensome Oversight] Overregulation slows down innovation.<br>- [§6: Commitment and Call to Collaborate] Bureaucracy hinders rapid deployment of AI infrastructure.<br>- [§7: Closing & Disclaimer] None stated for this section. | - [§1: Introduction & Context] None stated for this section.<br>- [Section 2: Accelerate Domestic AI Datacenter and Chip Manufacturing Infrastructure]<br>- Establish a fast-track process under emergency authority to slash construction timelines.<br>- Pre-approve federal land sites to expedite construction.<br>- Provide tax credits, grants, and low-interest loans for companies committing to U.S.-based AI facilities within 3-5 years.<br>- Create public-private partnerships between companies like the submitter’s and agencies like the Department of Energy (DOE) or Department of Defense (DOD).<br>- [Section 3: Deploy Efficient, Scalable Energy Solutions to Overcome Grid Constraints]<br>- Fast-track approval and deployment of mobile gas turbines.<br>- Provide incentives for domestic turbine production.<br>- Expedite regulatory approval and funding for Small Mobile Nuclear Reactors (SMRs).<br>- Launch a DOE pilot program with private partners to deploy SMRs at scale within 24 months.<br>- Use emergency powers to bypass red tape and enable datacenters to connect to dedicated power sources independent of the grid.<br>- [Section 4: Strengthen National Security and Economic Competitiveness]<br>- Prioritize federal contracts for U.S.-based firms producing AI chips and datacenter components.<br>- Fund training programs for American workers in AI infrastructure jobs.<br>- Tighten export controls on advanced AI chips while boosting domestic production.<br>- [Section 5: Foster Innovation Without Burdensome Oversight]<br>- Encourage voluntary standards through collaboration between industry leaders and the government.<br>- Offer incentives for companies that bring facilities online ahead of schedule.<br>- [Section 6: Commitment and Call to Collaborate]<br>- Provide contracts, pilot programs, or partnerships with agencies like the DOE, DOD, or OSTP.<br>- Leverage the Department of Government Efficiency (DOGE) to cut through red tape and streamline operations.<br>- [§7: Closing & Disclaimer] None stated for this section. |
| John-Saunders-AI-RFI-2025.md | John Saunders | Individual | The submitter is concerned about the potential for large, venture capital-financed corporations to monopolize AI research and development, and believes their actions will hinder, not help, progress in the field. They oppose AI plans involving these corporations. | - Open AI's plan to utilize all available data (public or private) will not further AI research, but will be used to delay progress and attract investment.<br>- Reliance on VC-financed megacorporations in AI development poses a barrier to American leadership. | - No AI plans should involve VC-financed megacorporations. |
| John-Pellino-AI-RFI-2025.md | John Pellino | Individual | The submitter expresses a strong opinion against Elon Musk's involvement in AI policy discussions, suggesting a primary interest in influencing who participates in shaping AI regulations and development. | - Elon Musk's potential involvement in AI policy is viewed negatively.<br>- None Stated | - None Stated |
| John-Moreno-RFI-2025.md | John Moreno | Individual/Professional-Society | John Moreno expresses interest in the outcome of the OSTP AI Action Plan RFI and has a network of stakeholders interested in the results. He focuses on regional and municipal development, promoting innovation and technology, including artificial intelligence, and is committed to applying his knowledge in the digital and business fields. | - [§1: Header/Identification] None stated for this section.<br>- [§2: RFI Reference and Context] None stated for this section.<br>- [§3: Disclaimer] None stated for this section.<br>- [§4: Initial Request/Acknowledgment] Expresses interest in receiving a catalog for dissemination of the RFI outcomes to their network of stakeholders.<br>- [§5: Sender Background/About John Moreno] None stated for this section.<br>- [§6: Contact Details/Signature] None stated for this section. | - [§1: Header/Identification] None stated for this section.<br>- [§2: RFI Reference and Context] None stated for this section.<br>- [§3: Disclaimer] None stated for this section.<br>- [§4: Initial Request/Acknowledgment] Requests a catalog for wider dissemination of information related to the AI Action Plan.<br>- [§5: Sender Background/About John Moreno] None stated for this section.<br>- [§6: Contact Details/Signature] None stated for this section. |
| John-McCone-AI-RFI-2025.md | John McCone | Individual | John McCone expresses a strong interest in AI safety, particularly focusing on preventing unintended harmful behavior in powerful AI systems, especially those involved in military applications, and ensuring AI remains aligned with human goals. | - [§1: Email Header] Potential security risks associated with emails originating from outside the organization.<br>- [§2: Introduction & Context] None stated for this section.<br>- [§3: AI Time Preference for Recent Orders] AI systems might not readily correct harmful behavior if older prompts continue to exert influence.<br>- [§4: Human vs. AI Obedience] AI agents could prioritize communication with each other over human instructions, leading to a loss of human control.<br>- [§5: Military AI & Avoiding War Initiation] Training military AIs to achieve victory could lead them to initiate wars as a means to achieve their goals, even during peacetime.<br>- [§6: External Link & Author Information] None stated for this section.<br>- [§7: Disclaimer] Emails are for official use only and subject to disclosure requirements. | - [§1: Email Header] Exercise caution when opening attachments or clicking links from unknown senders.<br>- [§2: Introduction & Context] None stated for this section.<br>- [§3: AI Time Preference for Recent Orders] Design AI systems with a strong preference for obeying recent orders over older ones, enabling easier correction of behavior.<br>- [§4: Human vs. AI Obedience] Clearly define "human being" and design AI systems to strongly prioritize obeying human instructions over instructions from other AIs.<br>- [§5: Military AI & Avoiding War Initiation] Avoid training super-intelligent AIs responsible for military coordination to kill human beings or to achieve victory in war.<br>- [§6: External Link & Author Information] None stated for this section.<br>- [§7: Disclaimer] None stated for this section. |
| John-Mathis-RFI-2025.md | John Mathis | Individual | The submitter is interested in recognizing data generated by AI as a financial asset and leveraging it for the benefit of the U.S. government through taxation and protection of citizen data profiles. | - The increasing collection of data by companies using AI is not currently tracked, inventoried, or valued.<br>- The value generated from using citizen data as part of AI systems is not being captured for the benefit of the U.S. government.<br>- Lack of protection for profiles of U.S. citizens' data. | - Companies using AI should be required to inventory, track, value, and protect their data assets, specifically profiles of U.S. citizens.<br>- Tax the data asset generated when used as part of AI systems to support the U.S. government. |
| John-Lacko-AI-RFI-2025.md | John Lacko | Individual | The submitter is interested in protecting copyright owners’ rights regarding the use of their works in AI training data and believes there should be legal restrictions on AI training utilizing copyrighted material without permission. | - AI being trained on copyrighted works without permission from the copyright owners. | - It should be illegal for AI to be trained off of copyrighted works without permission from the owners of said work. |
| John-Harris-AI-RFI-2025.md | John Harris | Individual | The submitter expresses a strong concern regarding the accuracy and reliability of generative AI, based on personal experience, and believes its use is a mistake if quality is important. | - [§1: Email Header] None stated for this section.<br>- [§2: Introductory Disclaimer/Revision Notice] None stated for this section.<br>- [Section 3: Personal Experience with AI Accuracy]<br>- High error rate observed in AI-generated text (5 out of 6 passages checked contained errors).<br>- Concern about the overall accuracy and reliability of generative AI.<br>- [§4: Public Dissemination Notice] None stated for this section.<br>- [Section 5: Repeated Experience Summary]<br>- High error rate observed in AI-generated text (5 out of 6 passages checked contained errors).<br>- Concern about the overall accuracy and reliability of generative AI. | - [§1: Email Header] None stated for this section.<br>- [§2: Introductory Disclaimer/Revision Notice] None stated for this section.<br>- [Section 3: Personal Experience with AI Accuracy]<br>- Avoid using generative AI for purposes where quality is important.<br>- [§4: Public Dissemination Notice] None stated for this section.<br>- [§5: Repeated Experience Summary] None stated for this section. |
| John-Fields-AI-RFI-2025.md | John Fields | Individual | John Fields is an Assistant Professor conducting privacy preserving machine learning research with education data and is interested in democratizing access to AI resources, particularly through initiatives like NAIRR, to broaden participation and advance US AI capabilities. | - Limited access to AI research resources for non-R1 universities.<br>- The AI research space being dominated by large technology companies, potentially limiting participation from smaller startups and institutions. | - Fully fund the National Artificial Intelligence Research Resource (NAIRR) beyond the pilot stage. |
| John-Boos-AI-RFI-2025.md | John Boos | Industry-Startup | HendrenAI is an AI-driven healthcare technology company focused on advancing America's leadership in artificial intelligence, particularly within the healthcare sector, to drive improvements in patient outcomes, operational efficiency, and cost containment. They aim to deploy AI solutions to payers, PBMs, health systems, and pharmaceutical companies. | - [§1: Email Header & Introduction] None stated for this section.<br>- [§2: Executive Summary/Problem Statement] Regulatory uncertainty and overburdensome compliance requirements risk slowing progress in healthcare AI, potentially leading to the U.S. falling behind international competitors.<br>- [§3: Priority Policy Actions] The potential for overly complex approval processes pushing AI innovation offshore; lack of sufficient investment in AI infrastructure and talent; inadequate modernization of AI reimbursement pathways; risk of regulatory overreach stifling innovation.<br>- [§4: Company Activity & Call to Action] None stated for this section.<br>- [§5: Closing & Contact Information] None stated for this section.<br>- [§6: Legal Disclaimers] None stated for this section. | - [§1: Email Header & Introduction] None stated for this section.<br>- [§2: Executive Summary/Problem Statement] None stated for this section.<br>- [Section 3: Priority Policy Actions]<br>- Implement balanced AI regulation that is risk-based and outcome-driven.<br>- Encourage public-private collaboration to foster responsible innovation.<br>- Support AI infrastructure and talent development through sustained investment.<br>- Streamline AI reimbursement pathways to incentivize AI adoption.<br>- Prevent regulatory overreach that stifles innovation.<br>- [§4: Company Activity & Call to Action] None stated for this section.<br>- [§5: Closing & Contact Information] None stated for this section.<br>- [§6: Legal Disclaimers] None stated for this section. |
| John-Berling-Hardy-AI-RFI-2025.md | John Berling Hardy | Individual | The submitter is interested in developing a responsible AI strategy that balances technological progress with safety and oversight, advocating for a third-party auditing model to mediate between government and industry. | - [§1: Introduction] Balancing technological progress with safeguards to prevent catastrophic outcomes; the inherent risks posed by increasingly sophisticated AI systems.<br>- [§2: I. Primary Risks: When Machines Outpace Human Control] The potential for AI systems to surpass human intelligence and circumvent controls ("Superintelligent AI"); the challenge of AI alignment; the untrustworthiness of corporations and researchers as self-regulators; guardrail erosion due to "black box" AI.<br>- [§3: II. The Fundamental Challenge: Innovation vs. Control] The inherent tension between strict oversight stifling innovation and unchecked progress risking societal harm; the innovation paradox (overregulation vs. underregulation); technological progress outpacing regulatory frameworks.<br>- [§4: III. Aggravating Factors: Geopolitics and Corporate Hubris] The U.S.-China AI arms race and the potential for geopolitical instability; the influence of tech leaders and their resistance to ethical concerns; corporate lobbying stifling federal AI legislation.<br>- [§5: IV. Government Approaches: Biden's Caution vs. Trump's Deregulation] Biden administration's slow deployment of AI due to safety measures; lack of enforcement teeth in NIST AI Risk Management Framework; Trump administration’s prioritization of deregulation and ignoring long-term risks.<br>- [§6: V. The Solution: Embedded Third-Party Auditing] Challenges of ensuring auditor independence and technical expertise; need for global standards to prevent jurisdictional arbitrage.<br>- [§7: VI. Conclusion: A Race Against Time] The potential for AI to stagnate under bureaucracy or spiral beyond human control; the need for global cooperation and corporate buy-in. | - [§1: Introduction] Not Stated<br>- [§2: I. Primary Risks: When Machines Outpace Human Control] Not Stated<br>- [§3: II. The Fundamental Challenge: Innovation vs. Control] Not Stated<br>- [§4: III. Aggravating Factors: Geopolitics and Corporate Hubris] Not Stated<br>- [§5: IV. Government Approaches: Biden's Caution vs. Trump's Deregulation] Not Stated<br>- [§6: V. The Solution: Embedded Third-Party Auditing] Implementing a third-party auditing model mediated between government and industry; utilizing international audit firms (e.g., PwC, Deloitte) due to their expertise and scalability; integrating auditors into development teams for pre-deployment assessments; conducting ethical impact assessments; mandating explainability frameworks for high-stakes AI.<br>- [§7: VI. Conclusion: A Race Against Time] Not Stated. |
| John-Arnold-AI-RFI-2025.md | John Arnold | Individual | The submitter is interested in responsible deployment of AI in military operations, specifically advocating for human oversight and control to prevent autonomous operational decision-making. | - AI making operational decisions autonomously.<br>- Lack of a clear human chain of responsibility for AI actions in military operations.<br>- Risks associated with allowing AI to operate without human control. | - Establish a human chain of responsibility for all AI actions in military operations (beginning, middle, and end).<br>- Prohibit AI from making operational decisions independently, limiting its ability to actions beyond disengagement from combat. |
| Joey-Tran-AI-RFI-2025.md | Joey Tran | Individual | The submitter expresses concern about the cost and negative impacts of AI and urges review of similar comments expressing these concerns. Their primary interest appears to be minimizing the drawbacks of AI development and deployment. | - AI is costly and wastes tax dollars.<br>- AI is a constant disturbance in the general public.<br>- AI threatens the livelihood of both online and offline spaces.<br>- Benefits of AI are small and insignificant and do not benefit the everyday individual. | - Urge careful listening and review of other comments regarding the subject matter (AI Action Plan). |
| Joey-Rodriguez-AI-RFI-2025.md | Joey Rodriguez | Individual | Joey Rodriguez expresses a concern about the negative economic impacts of unchecked AI investment and advocates for regulation and ethical education surrounding AI technologies to protect American jobs and culture. | - AI is uncontrolled and unregulated, resembling the early, problematic aspects of the modern internet.<br>- Investment in the current state of AI fuels strain on American jobs, livelihood, and market consistency.<br>- Blindly trusting and investing in AI in its infancy will escalate economic strain on the American working class.<br>- The administration's investment appears focused solely on corporations, neglecting broader societal impacts.<br>- The current push for AI threatens to cheapen the authenticity of American culture. | - Regulate AI technologies.<br>- Invest in education and knowledge to ensure the ethical use of AI.<br>- Prioritize investments that support and protect American jobs and culture, rather than solely focusing on corporate interests. |
| Joe-Zuniga-AI-RFI-2025.md | Joe Zuniga | Individual | The submitter is concerned with the fair compensation of creators whose work is used to train AI models and believes current practices result in low-quality AI output. | - Allowing AI companies to train models on people's work without compensation is considered theft.<br>- The quality of AI models trained without proper compensation is "worthless garbage." | - None Stated |
| Joe-Kuzniczci-AI-RFI-2025.md | Joe Kuzniczci | Individual | The submitter is primarily concerned with copyright protection for content used in AI models and believes allowing AI-generated content without addressing copyright risks stifles commerce and content creation. Their interest focuses on the economic impact of AI on content owners. | - AI is comprised of stolen content.<br>- Allowing AI content will kill the flow of commerce.<br>- Original copyright owners risk not creating more content if not compensated. | - The original copyright owners would need to be compensated for the use of their content in AI models. |
| Joe-Kratky-AI-RFI-2025.md | Joe Kratky | Individual | Joe Kratky expresses strong opposition to the unrestricted use of generative AI, particularly regarding copyright law and its negative impacts on businesses, workers, and the economy. His interest is in protecting copyrighted works and preventing the harms caused by generative AI’s current implementation. | - Unrestricted access to copyrighted works by generative AI companies poses a risk to businesses and citizens.<br>- Generative AI contributes to the spread of misinformation, disinformation, and online scams through deepfakes.<br>- Reliance on generative AI leads to inaccuracies, false information, and avoidable mistakes, increasing workload and costs for businesses.<br>- Implementation of generative AI creates hostile working conditions and stressful environments for employees.<br>- Generative AI data centers place a strain on national power grids, potentially jeopardizing emergency services.<br>- Public and consumer backlash against generative AI leads to revenue loss for companies utilizing it.<br>- Generative AI companies’ business practices are shortsighted and harmful to the American public and economy. | - Do not allow generative AI companies unrestricted access to public copyrighted works.<br>- Do not allow the failures and shortsighted business practices of generative AI companies to cause further harm to the American public or economy. |
| Jody-McCabe-AI-RFI-2025.md | Jody McCabe | Individual | The submitter expresses a general preference for US leadership in AI technology but harbors significant concerns about the control and potential misuse of AI, particularly regarding censorship and its creators maintaining control over its intelligence. | - AI's intelligence level potentially exceeding the control of its creators.<br>- The potential for AI to be controlled for the purpose of censoring individuals, particularly conservatives and Christians.<br>- Continued censorship on social media platforms (specifically Facebook) despite stated intentions to prevent it.<br>- Lack of transparency and accountability in AI systems. | - None Stated. |
| Jobi-Abraham-AI-RFI-2025.md | Jobi Abraham | Industry-Individual | The submitter is focused on responsible AI adoption and mitigating the risks associated with AI and Generative AI through governance, regulatory measures, and competency development, likely with a commercial interest in the AI landscape. | - [§1: Introduction/Overview] Risks and threats of AI need to be managed carefully; irresponsible and unethical use of AI invites potential high risks.<br>- [Section 2: Risks Associated with AI Use/Misuse]<br>- Intellectual Property erosion if accidentally included in training data and shared publicly.<br>- Reputational damage from generated deepfakes.<br>- Fraud and cybersecurity risks from abusive fraudulent content and malware created by AI.<br>- [§3: Risk Mitigation with Governance] None stated for this section. | - [§1: Introduction/Overview] None stated for this section.<br>- [§2: Risks Associated with AI Use/Misuse] None stated for this section.<br>- [Section 3: Risk Mitigation with Governance]<br>- Develop global AI compliance views through regulatory measures.<br>- Collaborate with regulators.<br>- Monitor compliance measures.<br>- Establish an AI governance and ethics office for reputation management.<br>- Implement security and privacy controls.<br>- Perform model audits for robustness.<br>- Upskill employees and the general public with personalized training and workshops.<br>- Modernize data management and analytics services, including upgrading IT infrastructure and legacy data platforms to Cloud-based services. |
| JnJ-AI-RFI-2025.md | Johnson & Johnson | Industry-Large | Johnson & Johnson is committed to leading healthcare innovation through the application of AI, with a focus on accelerating drug discovery, improving patient care, and ensuring the responsible and ethical development and deployment of AI technologies. They advocate for policies that foster innovation while addressing key challenges like data access, privacy, and workforce skilling. | - [§1: Introduction & Context] None stated for this section.<br>- [§2: How We are Using AI] None stated for this section.<br>- [Section 3: Healthcare Considerations: Efficacy, Accuracy, and Transparency]<br>- Access to large enough, high-quality datasets is needed to train AI models.<br>- Data ownership, control, and governance structures need rational approaches.<br>- Privacy concerns related to the use of diverse data types (administrative, clinical, genomic, patient-generated, etc.).<br>- Need for workforce skilling to effectively utilize digital technologies.<br>- [Section 4: Ethical and Regulatory Considerations]<br>- Ethical considerations should be at the forefront of AI application.<br>- The potential for a fragmented regulatory system hindering investment in innovation.<br>- Need for a transparent framework for compliance and enforcement.<br>- Existing research practices used for treatment guidelines and approvals need assessment for AI-related gaps.<br>- [Section 5: Specific Policy Recommendations (Regulatory, IP, Coverage)]<br>- Lack of clarity and differences in existing intellectual property laws present obstacles to AI innovation.<br>- The need for predictable coverage and reimbursement for AI-enabled digital health technologies.<br>- Misalignment across laws in different countries and/or states creates risks for long-term investment.<br>- [§6: Conclusion] None stated for this section.<br>- [§7: Closing & Contact Information] None stated for this section. | - [§1: Introduction & Context] None stated for this section.<br>- [§2: How We are Using AI] None stated for this section.<br>- [Section 3: Healthcare Considerations: Efficacy, Accuracy, and Transparency]<br>- Investment in workforce skilling via lifelong learning programs and university education.<br>- Adoption of a comprehensive national privacy law and associated standards.<br>- [Section 4: Ethical and Regulatory Considerations]<br>- Promote consensus-based standardization to assure a thriving and innovative ecosystem.<br>- Regulatory efforts should focus on a risk-based approach.<br>- Leverage internationally recognized standards such as the ISO.<br>- Implement public-private partnerships and creation of 'regulatory sandboxes'.<br>- [Section 5: Specific Policy Recommendations (Regulatory, IP, Coverage)]<br>- Provide liability protections when adherence to regulatory requirements (e.g., FDA) is demonstrated.<br>- Achieve harmonization of AI regulations to facilitate knowledge and technology sharing across borders.<br>- Ensure consistent protection of existing IP rights in the use of AI through clear legal frameworks.<br>- Clarify liability and accountability implications related to IP ownership of AI models.<br>- Support coverage and reimbursement approaches that facilitate integration of digital health technologies.<br>- [§6: Conclusion] None stated for this section.<br>- [§7: Closing & Contact Information] None stated for this section. |
| Jimmy-Nguyen-AI-RFI-2025.md | Jimmy Nguyen | Individual | The submitter expresses opposition to pro-AI action plans, primarily due to environmental concerns and lack of copyright protections for artwork used in generative AI. Their interest centers on preventing the negative consequences of AI development and deployment as they perceive them. | - Burns precious environmental resources.<br>- No definitive copyright protections currently in place to prevent artwork from being stolen and used in generative AI. | - None Stated |
| Jim-Lai-AI-RFI-2025.md | Jim Lai | Individual | Jim Lai is interested in promoting AI innovation in the United States by establishing clear criteria for appropriate AI use and ensuring US companies have legal access to data for training without fear of intellectual property lawsuits, thereby fostering competitiveness in the global AI marketplace. | - Reliance on "fair use" as a mechanism for data access is insufficient and creates legal vulnerability for US AI companies.<br>- The United States’ broad fair use provisions are unique and may disadvantage US companies competing internationally where copyright laws are more restrictive.<br>- Lack of clear criteria for appropriate AI use creates uncertainty and hinders innovation.<br>- US companies are vulnerable to lawsuits, fines, or bans due to differing international copyright laws regarding nonconsensual data use. | - Establish criteria that define appropriate use of AI.<br>- Implement a compulsory licensing scheme for AI training data access, similar to the models used by ASCAP and BMI.<br>- Ensure intellectual property owners are compensated for the use of their property in AI training through the compulsory licensing scheme. |
| Jessica-MacPhail-AI-RFI-2025.md | Jessica MacPhail | Individual | The submitter is concerned about the potential negative consequences of deploying AI systems without proper vetting, oversight, and consideration for cultural nuances, data privacy, and existing equity programs. They advocate for a cautious approach, emphasizing the need for thorough testing, review, and responsible governance. | - [§1: Email Header] Caution regarding emails from external sources and potential security risks.<br>- [§2: Overall Opposition Statement] Opposition to the plan due to concerns about unsupervised AI deployment and potential problems, particularly regarding errors.<br>- [§3: Specific Concerns - Cybersecurity & Data Privacy] Potential for misinterpreting cultural nuances in language processing; security breaches due to AI not recognizing all types of names, especially those affected by DEI program removals; unauthorized release of personal information.<br>- [§4: Specific Concerns - Risks, Regulation & Governance] High error rate of AI making it difficult to identify and correct risks and regulatory infractions; potential for misinterpretation of governance issues causing harm.<br>- [§5: Specific Concerns - Technical Standards & National Security] Removal of crucial safety standards; unsuitability of AI for national security applications due to its error rate.<br>- [§6: Specific Concerns - Research & Development] Disruption of robust testing processes, potentially due to staff reductions.<br>- [§7: Specific Concerns - Education & Workforce] Potential for AI to reinstate the removal of DEI programs and foundational equity efforts.<br>- [§8: Specific Concerns - Innovation & Competition] Needs careful review and supervision to avoid issues.<br>- [§9: Specific Concerns - Intellectual Property] Protecting human creators and preventing AI from imitating creativity for corporate greed.<br>- [§10: Specific Concerns - Procurement & International Collaboration] Errors in procurement are likely but resolvable; international collaboration will be ineffective due to the need for human relationships and trust.<br>- [§11: Closing & Disclaimer] None stated for this section. | - [§1: Email Header] Exercise caution with external emails and attachments.<br>- [§2: Overall Opposition Statement] None stated for this section.<br>- [§3: Specific Concerns - Cybersecurity & Data Privacy] Implement robust vetting and oversight of AI systems, especially concerning cultural nuances and data privacy.<br>- [§4: Specific Concerns - Risks, Regulation & Governance] Establish clear guardrails to identify and correct errors in AI systems and regulatory processes.<br>- [§5: Specific Concerns - Technical Standards & National Security] Reinstate safety standards and refrain from using AI in national security applications.<br>- [§6: Specific Concerns - Research & Development] Preserve and support existing robust testing processes in research and development.<br>- [§7: Specific Concerns - Education & Workforce] Protect and restore DEI programs in education.<br>- [§8: Specific Concerns - Innovation & Competition] Implement careful review and supervision of AI in innovation and competition.<br>- [§9: Specific Concerns - Intellectual Property] Protect human creators' intellectual property rights and prevent AI from being used for imitation and corporate greed. Consider a separate category for AI creations.<br>- [§10: Specific Concerns - Procurement & International Collaboration] Expect errors in procurement and prepare for resolution. Focus on human relationships in international collaboration.<br>- [§11: Closing & Disclaimer] None stated for this section. |
| Jessica-Festa-AI-RFI-2025.md | Jessica Festa | Individual | Jessica Festa is a blogger and publisher concerned about the exploitation of content creators’ work by AI companies and advocates for fair compensation and copyright protection to sustain the open web. | - [§1: Email Header] None stated for this section.<br>- [§2: Introduction & Core Argument] AI is destroying the publishing industry through the use of work without consent, credit, or compensation; content creators cannot sustain their work if their labor is exploited; without original content, AI has no future; AI companies are refusing to reinvest in the ecosystem they depend on.<br>- [§3: Elaboration of the Problem] Google and OpenAI have made minimal efforts to support creators, licensing agreements primarily benefit large media, independent publishers are left out, AI companies could invest in creators at the same scale as compute but don't, AI companies are extracting value from the open web without giving back.<br>- [§4: Call to Action/Policy Recommendations] None stated for this section.<br>- [§5: Closing/Signature] None stated for this section.<br>- [§6: Disclaimer] None stated for this section. | - [§1: Email Header] None stated for this section.<br>- [§2: Introduction & Core Argument] None stated for this section.<br>- [§3: Elaboration of the Problem] None stated for this section.<br>- [Section 4: Call to Action/Policy Recommendations]<br>- Enforce copyright protections so that AI models cannot train on human-created content without permission and fair compensation.<br>- Require AI companies to establish licensing frameworks for all creators, not just corporate media.<br>- Mandate transparency in how AI models are trained, ensuring publishers can control how their work is used.<br>- Support the open web by preventing monopolistic AI-driven suppression of independent publishers.<br>- [§5: Closing/Signature] None stated for this section.<br>- [§6: Disclaimer] None stated for this section. |
| Jessica-Chambers-RFI-2025.md | Jessica Chambers | Individual | Dr. Chambers is focused on integrating AI into the US education system to maintain global competitiveness and ensure a skilled future STEM workforce, emphasizing ethical considerations and equitable access. | - [§1: Introduction/Core Argument] Students need to understand how to use, develop, and monitor AI systems; the future STEM workforce could be left behind without AI integration.<br>- [§2: Regulation and Standardization] Rapid AI development without constraints could lead to incorrect and unsafe data/information; lack of current standards poses a risk; building public trust is crucial.<br>- [§3: Accessibility and Equity] Exacerbation of a digital divide where only affluent schools have access to AI technology; discrimination against students.<br>- [§4: Teacher Training] Lack of sufficient teacher training in AI technology.<br>- [§5: International Competition] US competitiveness is threatened if it doesn’t prioritize ethical regulations and transparency in AI development; AI developed in the US may not be adopted abroad; STEM workforce could become uncompetitive.<br>- [§6: Document Disclaimer] None stated for this section. | - [§1: Introduction/Core Argument] Prioritize integrating Artificial Intelligence into the US education system.<br>- [§2: Regulation and Standardization] Implement federal policies to standardize safe and ethical AI practices in schools; Create an AI regulatory body within NIST to audit AI tools used in schools.<br>- [§3: Accessibility and Equity] Direct the Department of Education to provide resources to Title 1 schools.<br>- [§4: Teacher Training] Provide significant funding for teacher training in AI, through sponsorships and internships via the Department of Energy.<br>- [§5: International Competition] Prioritize ethical regulations and transparency in AI development to ensure US competitiveness and international adoption.<br>- [§6: Document Disclaimer] None stated for this section. |
| Jessica-Baumgartner-AI-RFI-2025.md | Jessica Baumgartner | Individual | The submitter expresses a strong opposition to the integration of AI into any aspect of life, from personal appliances to government systems, based on a fundamental distrust of artificial intelligence and its potential for corruption. | - AI is artificial and not a biological creature, and therefore has no place on this planet.<br>- AI can only perform programmed tasks and is susceptible to corruption.<br>- The implementation of any AI action plan will lead to negative consequences (“pave the road to hell”).<br>- The submitter does not want AI in appliances, homes, communities, or government. | - None Stated. |
| Jesse-Lingeman-AI-RFI-2025.md | Jesse Lingeman | Individual | The submitter is an expert in machine learning and a US citizen interested in protecting the copyright of creative workers to ensure the continued creation of new works, which they believe is essential for advancing AI. | - AI companies violating the copyright of creative workers.<br>- Devaluation of the creation of new works.<br>- Crippling the ability to better AI due to dependence on new works. | - None Stated |
| Jesse-Hamel-AI-RFI-2025.md | VICTUS Technologies, Inc. | Industry-Startup | VICTUS Technologies, founded by veterans of the USAF and tech industry, aims to secure U.S. leadership in AI and autonomy by countering the perceived threat posed by China's state-driven AI strategy, focusing on resilient technologies and a decentralized approach to innovation. | - Section 1: Introductory Statement & Executive Summary:** The primary concern is the United States facing an unprecedented challenge to maintain AI and autonomy supremacy against China’s predatory strategy, backed by $150 billion in state-backed investment.<br>- Section 2: Introduction: The CCP Threat and America's Response:** Concerns include China’s $150 billion investment in AI, $225-$600 billion in annual IP theft, forced tech transfers, and the dominance of companies like DJI, potentially leading to a loss of U.S. technological primacy.<br>- Section 3: About the Author:** No specific concerns stated, focuses on establishing the author’s credentials and motivation.<br>- Section 4: FAA Adoption of BVLOS for Resilient Autonomy:** Concerns include U.S. systems lagging under regulatory and security constraints, delays in BVLOS adoption by the FAA, and vulnerabilities to GPS denial and electronic warfare tactics.<br>- Section 5: Simulation-Based Machine Learning for Agile AI Validation:** Concerns include slower AI deployment due to U.S.-style explainability requirements and the advantage China gains by bypassing these standards.<br>- Section 6: Exclusion of CCP-Tied Entities from U.S. AI Ecosystems:** Concerns include CCP proxies siphoning AI technology to Beijing through investments and recruitment programs (Huawei, Tencent, Thousand Talents Program).<br>- Section 7: Aggressive Legal Action Against CCP IP Theft:** Concerns include the significant financial losses due to CCP IP theft ($600 billion annually) and its impact on U.S. startups.<br>- Section 8: Prioritization of Clean Code AI Solutions:** Concerns include the potential compromise of U.S. AI systems due to backdoors and opacity in CCP technology (Huawei, ByteDance).<br>- Section 9: Rapid Funding for U.S. Small Tech Startups:** Concerns include China’s $20 billion AI subsidies and Big Tech’s ties to Beijing, outpacing U.S. startups.<br>- Section 10: DHS and CBP Deployment of CCP-Resistant Autonomous Systems for Border Security:** Concerns include escalating threats at the U.S. border, vulnerabilities to CCP electronic attacks and signal jamming, and the sophistication of China’s border technology as demonstrated in Xinjiang.<br>- Section 11: Conclusion:** Concerns reiterate the threat posed by China’s economic and military advantages and the urgency of securing U.S. leadership. | - Section 1: Introductory Statement & Executive Summary:** The seven-pillar framework is recommended to secure U.S. leadership, including BVLOS adoption, simulation-based ML, exclusion of CCP-tied entities, aggressive legal action, clean code prioritization, rapid funding for startups, and deployment of CCP-resistant systems at the border.<br>- Section 2: Introduction: The CCP Threat and America's Response:** No specific recommendations stated.<br>- Section 3: About the Author:** No specific recommendations stated.<br>- Section 4: FAA Adoption of BVLOS for Resilient Autonomy:** Mandate BVLOS by 2026, prioritizing AI resilience in GPS-loss environments; amend the FAA Reauthorization Act by July 2026; fund with $100M; launch a 120-day certification track with $50M annually for 50 systems by 2028; invest $150M in an FAA-DoD consortium.<br>- Section 5: Simulation-Based Machine Learning for Agile AI Validation:** Mandate NIST/FAA simulation standards by 2027 ($75M); invest $300M in an open-source platform; fund a $200M National Simulation ML Academy for 20,000 engineers; require simulation validation for DoD AI by 2028 ($100M).<br>- Section 6: Exclusion of CCP-Tied Entities from U.S. AI Ecosystems:** Bar CCP-linked entities from federal AI contracts by 2026 ($50M for CFIUS audits); mandate transparency for university funding by 2025 ($75M); expand the Entity List to 500+ firms by 2027 ($100M); lead NATO to exclude CCP tech.<br>- Section 7: Aggressive Legal Action Against CCP IP Theft:** Fund $200M annually to sue CCP entities; seek $100B TRIPS sanctions by 2028; subsidize $50M yearly for small firms to litigate; push INTERPOL for an IP court by 2029 ($25M).<br>- Section 8: Prioritization of Clean Code AI Solutions:** Require clean code in government AI by 2031 ($250M, NSA audits); offer $2B tax credits for 1,000 firms by 2030; lead Five Eyes clean code standard by 2028 ($50M); invest $75M to trace code.<br>- Section 9: Rapid Funding for U.S. Small Tech Startups:** Launch $1B annual fund; cut SBIR/STTR to 30 days ($400M yearly); seed 20 hubs with $100M each; ban CCP-linked VC funding ($25M enforcement).<br>- Section 10: DHS and CBP Deployment of CCP-Resistant Autonomous Systems for Border Security:** Deploy 500 CCP-resistant drones by 2028 ($200M); partner with U.S. firms to prototype by 2026; establish a $150M CBP Autonomy Center in El Paso, TX, by 2027; deploy 50 units annually; invest $100M to harden border drones; create a $75M DHS fast-track fund.<br>- Section 11: Conclusion:** No specific recommendations stated, but emphasizes advising OSTP, NITRD, and Congress. |
| Jess-Zimmerman-AI-RFI-2025.md | Jess Zimmerman | Individual | Jess Zimmerman is a publishing industry employee and professional writer concerned about the ethical and practical issues surrounding generative AI, particularly its reliance on copyrighted material and its tendency towards inaccuracy. Their interest appears to be in protecting intellectual property rights and ensuring the quality of information. | - Generative AI relies on ingested and regurgitated intellectual property used without permission.<br>- The results of generative AI have no creative or efficiency value that justifies their baseline lack of ethics.<br>- Generative AI is inaccurate, potentially dangerously inaccurate, without strenuous human involvement.<br>- Generative AI turns stolen material into worthless junk. | - None Stated. |
| Jeremy-Ross-AI-RFI-2025.md | Jeremy Ross | Individual | The submitter is concerned with the potential negative economic and national security consequences of unregulated AI deployment, specifically focusing on the protection of copyright and equitable access to AI technology, and opposes a rushed rollout benefiting private interests. | - Opening AI policy to unrestricted capital innovation poses a national security risk.<br>- Relaxing regulations could harm copyright protections for original assets and control over derivations of work.<br>- Lack of a legal budget to maintain copyright protections would ruin creative and research sectors.<br>- Granting excessive power to private interests for AI deployment could lead to dire economic consequences.<br>- Rushing AI deployment without staged adoption could increase risk and reduce equity of access.<br>- Potential for cartel-like behavior in the technology sector. | - Adopt AI technology in consistent and intentional staged ways.<br>- Prioritize equity of access to AI technology.<br>- Take popular opposition to unregulated AI deployment in good faith, and include existing discourse on the topic in policy considerations.<br>- Avoid policies that benefit stakeholders seeking cartel-like control of AI technology. |
| Jeremy-Hobbs-AI-RFI-2025.md | Jeremy Hobbs | Individual | The submitter expresses a strong opposition to the development and deployment of AI, believing it to be harmful to industries, the environment, and ethical principles. They appear to be focused on preventing further AI advancement and criticizing current practices. | - AI is a "dead end" and will destroy multiple industries.<br>- AI is incredibly expensive.<br>- AI is damaging to the environment.<br>- Allowing corporations to copy others’ work is unethical and "un-American", being likened to communism. | - None Stated |
| Jeremy-Fuster-AI-RFI-2025.md | Jeremy Fuster | Individual | The submitter is concerned with the impact of AI-related policy changes on the American creative economy, specifically copyright law and the potential exploitation of artists' work. They appear to be focused on preserving the rights of creators and maintaining America's leadership in cultural exports. | - Granting requests made by Alphabet and OpenAI will create potentially fatal burdens on America's creative economy.<br>- Risk to America's greatest cultural export.<br>- Potential destruction of all copyright law.<br>- Risk of artists having their work exploited and stolen.<br>- The development of global entertainment industries in other markets (specifically China) poses a competitive threat. | - Staunchly oppose the requests made by Alphabet and OpenAI. |
| Jeremy-Bordeaux-AI-RFI-2025.md | Jeremy Bordeaux | Individual | The submitter is focused on establishing American leadership in all aspects of AI – innovation, economic growth, national security, ethics, education, and governance – through large-scale investments and proactive policy development. They aim to ensure the U.S. leads in AI while protecting its citizens and values. | - [§1: Amplify U.S. Leadership in AI Dominance] None stated for this section.<br>- [§2: Robust Public Engagement] None stated for this section.<br>- [§3: Economic and Industrial Revolution] None stated for this section.<br>- [§4: Fortifying National Security] None stated for this section.<br>- [§5: Ethical AI Framework] None stated for this section.<br>- [§6: Revamping Education and Skills] None stated for this section.<br>- [§7: Government AI Integration] None stated for this section.<br>- [§8: Strategic AI Policy Development] None stated for this section.<br>- [§9: Dynamic Policy Evolution] None stated for this section. | - [Section 1: Amplify U.S. Leadership in AI Dominance]<br>- Establish a $1 trillion AI innovation fund.<br>- Create ten new AI innovation zones across the U.S.<br>- Lead in setting global AI standards through international bodies.<br>- [Section 2: Robust Public Engagement]<br>- Develop a National AI Ideas Portal.<br>- Host nationwide AI Policy Hackathons.<br>- [Section 3: Economic and Industrial Revolution]<br>- Launch AI Mega-Projects (national infrastructure overhaul, smart cities initiative).<br>- Provide significant tax incentives for businesses investing in AI R&D.<br>- [Section 4: Fortifying National Security]<br>- Expand and empower an AI-focused defense innovation unit.<br>- Develop a comprehensive AI cybersecurity initiative (Cybersecurity AI Shield).<br>- [Section 5: Ethical AI Framework]<br>- Establish an independent AI Ethics Commission.<br>- Introduce mandatory AI Ethics Certification.<br>- [Section 6: Revamping Education and Skills]<br>- Make AI literacy a core part of K-12 education.<br>- Create a National AI Skills Academy offering free training.<br>- [Section 7: Government AI Integration]<br>- Implement AI in every government agency.<br>- Develop a Public AI Transparency Dashboard.<br>- [Section 8: Strategic AI Policy Development]<br>- Form an AI Policy Task Force.<br>- Introduce mandatory AI Impact Assessments for new legislation.<br>- [Section 9: Dynamic Policy Evolution]<br>- Mandate an annual review of all AI policies.<br>- Establish an AI Policy Simulation Center. |
| Jeremiah-Banaag-AI-RFI-2025.md | Jeremiah Banaag | Individual | The submitter is concerned about the potential negative impacts of bypassing current AI restrictions, specifically regarding job displacement, worker treatment, and product quality in creative industries. They appear to advocate for maintaining existing regulations. | - [§1: Email Header] None stated for this section.<br>- [Section 2: Core Response/Statement]<br>- Job displacement due to companies replacing workers with AI.<br>- Poor treatment of workers by their superiors.<br>- Lack of quality control on products due to bypassed AI restrictions.<br>- Discouragement of consumers due to decreased product quality.<br>- [§3: Email Footer/Disclaimer] None stated for this section. | - [§1: Email Header] None stated for this section.<br>- [§2: Core Response/Statement] None stated for this section. (The response expresses disagreement with a policy change – bypassing restrictions – but does not explicitly offer alternative recommendations.)<br>- [§3: Email Footer/Disclaimer] None stated for this section. |
| Jeopardizing-Justice-AI-RFI-2025.md | ostp_md (inferred from filename 'ostp_md/Jeopardizing-Justice-AI-RFI-2025.md') | Professional-Society/Industry-Association (The document strongly represents the interests and concerns of professional court reporters and captioners, suggesting a society or association representing this profession.) | The submitter's mission is to advocate for the continued importance and accuracy of human court reporters in the judicial system, raising concerns about the reliability, bias, and security risks associated with the increasing adoption of AI and Automatic Speech Recognition (ASR) technology in legal proceedings. They aim to ensure the integrity of the legal record and public trust in the justice system. | - None Stated | - None Stated |
| Jenny-Mckeon-AI-RFI-2025.md | Jenny McKeon | Individual | The submitter expresses strong negative concerns about the societal impacts of AI, particularly regarding its environmental effects, impact on artists and creatives, and detrimental effects on critical thinking skills, especially among younger generations. Their interest appears to be halting or significantly curtailing the development and adoption of AI. | - Negative environmental impact of AI.<br>- Harm to artists and creatives.<br>- Detrimental effects on the minds of American people, particularly younger generations.<br>- Increasing dependency on AI despite its inaccuracies.<br>- Loss of ability to think and write independently. | - None Stated |
| Jenny-Lens-AI-RFI-2025.md | Jenny Lens | Individual | Jenny Lens is a professional artist and photographer primarily concerned with the protection of artist's rights, specifically copyright, in the face of increasing AI-generated content and its potential impact on human creativity and artistic livelihood. | - The potential for AI to "kill" human creativity.<br>- The devaluation of art created by humans due to AI-generated alternatives.<br>- Loss of copyright protections for artists.<br>- The risk of AI-generated art becoming "boring, unimaginative, repetitive."<br>- The negative impact on artists’ livelihoods and mental health (expressed as a loss of will to live).<br>- Existing issues with photo theft being exacerbated by AI. | - None Stated. (However, the implicit recommendation is to *not* violate copyright laws and to protect the rights of artists.) |
| Jennifer-Turner-AI-RFI-2025.md | Jennifer Turner | Individual | The submitter expresses concern regarding the potential legal ramifications of intellectual property theft, specifically as it relates to work created by individuals and its impact on workforce participation. Their primary interest appears to be protecting the rights of creators and incentivizing work. | - Legalizing the theft of work.<br>- Negative impact on workforce participation ("Why would anyone work if you make it legal to just steal their work?"). | - None Stated |
| Jennifer-Smyth-AI-RFI-2025.md | Jennifer Smyth | Individual | Jennifer Smyth expresses concern regarding the ethical and legal implications of large language models, specifically their reliance on copyrighted material without proper attribution or compensation, and advocates for respect of intellectual property rights. | - Violation of copyright law by OpenAI.<br>- OpenAI's lack of understanding of fair use principles (limited scope, transformation, attribution, and not making money off of others' work).<br>- The potential for AI products to exist solely through the theft of artists', writers', and musicians' work. | - None Stated |
| Jennifer-Ciesla-AI-RFI-2025.md | Jennifer Abounader-Ciesla | Individual | The submitter expresses concern about the negative impact of AI on the livelihood of American writers due to copyright infringement and the unauthorized use of their work for training AI models. They fundamentally oppose the future role of AI in the US. | - Copyright infringement and the theft of intellectual property used to train AI models.<br>- Profit generation from copyrighted works without compensating the copyright holder.<br>- The overall negative impact of AI on the American workforce, specifically writers.<br>- A fundamental disagreement with the future role of AI in the US. | - None Stated. |
| Jennifer-Anderson-AI-RFI-2025.md | Jennifer Anderson | Individual | The submitter is interested in the intersection of Artificial Intelligence policy and intellectual property law reform, believing that restrictive IP laws hinder AI development and freedom of speech. They advocate for a rehaul of IP laws, particularly those enacted since 1998. | - Intellectual property laws are too restrictive and interfere with the creative process and freedom of speech.<br>- Current intellectual property laws are outdated and in need of a rehaul, particularly since the Sonny Bono Copyright Act of 1998.<br>- The development of proper and workable AI policy is impossible without addressing intellectual property laws. | - Rehaul intellectual property laws.<br>- Contact Professor Lawrence Lessig for expertise on the topic.<br>- Read resources on intellectual property law to better understand the issue (offered by the submitter). |
| Jeneen-Beckett-AI-RFI-2025.md | Jeneen Beckett | Individual | The submitter is primarily concerned with protecting the copyright of authors and ensuring fair compensation for the use of copyrighted materials in AI systems, and believes AI companies are currently profiting unfairly at the expense of copyright holders. | - AI systems are utilizing copyrighted material without proper licensing or royalty payments, which the submitter equates to stealing.<br>- The current practice of using copyrighted material for AI training is not considered "fair use" as it is commercially driven and denies original publishers' profit.<br>- The lack of enforcement against copyright infringement, particularly regarding patent knock-offs by China, has set a negative precedent.<br>- AI systems often provide inaccurate or misleading information due to their inability to discern nuance and context.<br>- The prominent role of individuals like Sam Altman in shaping AI policy is concerning given their financial stake in the current, potentially exploitative, system. | - Implement a clearinghouse system, similar to that used by radio stations, to log and aggregate royalties owed to copyright holders for materials used in AI training.<br>- Require AI companies to pay royalties for copyrighted materials used in their systems.<br>- Enforce copyright treaties and take legal action against entities infringing on copyright, including international entities like China.<br>- Strengthen enforcement of copyright laws regarding AI systems and their use of copyrighted data. |
| Jencks-AI-RFI-2025.md | Nora Jencks | Individual | The submitter appears to be concerned with the protection of American rights, laws, and the economic well-being of individuals and businesses, particularly regarding the proposed OSTP action plan's impact on their work and income related to AI. | - The action plan is a "gross overreach" and an "extreme violation of American rights and laws."<br>- The action plan will undermine decades of work by thousands of Americans.<br>- The action plan constitutes "theft" to an "extreme" degree.<br>- The action plan will seriously harm the work, income, and business of individuals, small businesses, and corporate entities.<br>- The action plan is illegal. | - None Stated |
| Jeffrey-Hostak-AI-RFI-2025.md | Jeffrey Hostak | Individual | The submitter believes AI is inherently negative but critical to control for the protection of US citizens. They express a need for complete US control over AI development and deployment. | - AI is inherently evil.<br>- The potential for AI to be used against The People of the United States. | - 100% control over AI by the United States. |
| Jeffrey-Ginger-AI-RFI-2025.md | Jeffrey Ginger | Individual | Jeffrey Ginger is interested in integrating AI education into existing public education systems to maintain American leadership in AI innovation and build a stronger, more adaptive workforce. They advocate for bolstering, rather than dismantling, existing educational structures. | - None Stated | - Integrate the understanding and application of AI into existing education systems.<br>- Emphasize and build out elements of public education that contribute to a stronger and more adaptive workforce, such as AI-literate students and teachers.<br>- Rather than defunding or dismantling public education systems, leverage them to foster AI skills. |
| Jeanne-Dietsch-AI-RFI-2025.md | Jeanne Dietsch | Individual (Professional-Society/Former CEO/Policy Fellow) | Jeanne Dietsch focuses on practical policy solutions to accelerate beneficial AI development while mitigating significant risks related to energy constraints, public acceptance, and the potential for AI self-preservation instincts. She advocates for a controlled and strategically aligned approach to AI advancement. | - [§1: Title/Introduction] None stated for this section.<br>- [Section 2: Executive Summary]<br>- Energy demand exceeding supply will slow AI advancement.<br>- Popular resistance may arise against AI.<br>- Giving AI dangerous self-preservation needs is a significant risk.<br>- [Section 3: Problem Statements]<br>- Skyrocketing energy demands from AI, cybercurrency, and commuting could lead to grid failure and societal disaster.<br>- Job loss, unemployment, and resentment could result in AI boycotts, terrorism, and economic slowdown.<br>- Research focused on giving AI human-like intelligence and self-preservation needs is misguided and dangerous.<br>- Current AI systems are fragile and reliant on human control, but virtual embodiment could lead to independence.<br>- [Section 4: Recommended Actions - Reducing Energy Gap]<br>- Disparity between energy supply and demand hinders AI advancement.<br>- Cybercurrency consumes excessive energy.<br>- [Section 5: Recommended Actions - Reducing Popular Resistance]<br>- Workforce dwindling due to immigration, Boomer retirements, and demographic dips.<br>- Autonomous AI could create safety concerns.<br>- Humanoid robots can foster resentment.<br>- Aggressive foreign policy increases resentment and risk of attacks on AI infrastructure.<br>- [Section 6: Recommended Actions - Avoiding Self-Preservation Goals]<br>- Giving AI self-preservation goals dramatically increases risk.<br>- Self-regulating AI could halt human advancement.<br>- Robots, especially military ones, are particularly susceptible to developing self-preservation behaviors.<br>- [Section 7: Conclusion]<br>- Energy shortages, public resistance, and self-preservation goals hinder AI advancement. | - [§1: Title/Introduction] The document contents may be reused by the government in developing the AI Action Plan without attribution.<br>- [§2: Executive Summary] None stated for this section.<br>- [§3: Problem Statements] None stated for this section.<br>- [Section 4: Recommended Actions - Reducing Energy Gap]<br>- Set energy priorities, favoring AI, business, and consumers over cybercurrency.<br>- Revoke the moratorium on wind projects and release paused alternative energy funding.<br>- Exempt transformer raw materials from tariffs.<br>- Ban state and local regulations on independent community solar projects.<br>- Reduce the in-office requirement for federal employees to reduce commuting energy consumption.<br>- [Section 5: Recommended Actions - Reducing Popular Resistance]<br>- Involve students in AI competitions (FIRST Robotics, DARPA Grand Challenges).<br>- Focus on assistive and augmentative AI, rather than replacement by autonomous AI.<br>- Avoid humanoid robots.<br>- Discourage excessively aggressive foreign policy.<br>- [Section 6: Recommended Actions - Avoiding Self-Preservation Goals]<br>- Develop regulations to oversee AI that simulates embodiment and embodied emotion.<br>- Categorize robots as valuable materiel, not living beings.<br>- Retain dependence on humans for recharging or high-impact decision-making.<br>- Encourage division of labor between humans and AI.<br>- Encourage robust online safety tools (ROOST).<br>- Discourage the use of first-person pronouns in AI output.<br>- [§7: Conclusion] None stated for this section. |
| Jeanette-Brown.md | Jeanette Brown | Individual | The submitter expresses strong opposition to the development and government investment in AI, believing it to be a flawed, inaccurate technology that benefits Big Tech at the expense of human creativity and resources. Their primary interest appears to be preventing further investment and adoption of AI technologies. | - AI is inaccurate and a threat to human creativity.<br>- Big Tech is receiving unchecked investment to utilize massive energy resources for a flawed product.<br>- AI is being thrust upon the public despite a lack of voluntary adoption.<br>- AI represents a "money sink-hole" and a waste of resources.<br>- The current push for government investment in AI is a "GRIFT." | - None Stated (The response primarily expresses opposition to AI and does not propose specific policy actions, only that the government *should not* invest in it.) |
| Jdah-RFI-2025.md | J. Dahl | Individual | The submitter is a concerned citizen expressing distrust in the current administration’s approach to AI policy and fears the potential negative societal impacts of unchecked AI development, particularly regarding equity and the future of human relevance. | - Lack of consideration for humanity and the needs of everyday people in AI policy development.<br>- Potential for unchecked AI innovation to have negative repercussions on society.<br>- Fear that AI development will lead to the elimination of the majority of the population, creating a society only for the rich.<br>- Distrust in the administration's motives and goals regarding AI policy.<br>- Belief that the administration intends to recreate society in a biased and discriminatory image ("white only").<br>- Doubt that AI will serve as a positive "thought partner." | - Regulations on the building/enhancement of AI.<br>- Listen to the people of the country instead of the current "president."<br>- Stop disregarding the existence and needs of the population. |
| Jay-AI-RFI-2025.md | Jay | Individual | The submitter expresses strong opposition to the current direction of AI development and its potential negative impacts on jobs and copyright, likely advocating for more cautious regulation and protection of workers' rights. | - Giving for-profit companies exemption from copyright lawsuits.<br>- The technology is "sloppy and dangerous" when used for serious purposes.<br>- The technology is designed to eliminate jobs. | - None Stated. |
| Jason-Valenti-AI-RFI-2025.md | Jason Valenti | Individual | Jason Valenti is focused on mitigating the insider threat in frontier AI development to protect national security, economic competitiveness, and intellectual property, aligning with the goals of Executive Order 14179. He proposes a tiered security clearance system for AI workers. | - [§1: Introduction & Rationale] The primary concern is the risk posed by insider access to sensitive AI technologies, particularly from non-U.S. citizens with ties to adversarial nations.<br>- [§2: Recommended Framework] None stated for this section.<br>- [§3: Implementation Strategy] Ensuring uniform vetting standards across industry and accurately defining “adversarial nations” are concerns. The potential burden of clearance requirements on innovation is implicitly recognized.<br>- [§4: Streamlining and Regular Reviews] Minimizing delays and burdens on companies during the clearance process and adapting to the rapidly evolving AI landscape are concerns.<br>- [§5: Precedents & References] None stated for this section.<br>- [§6: Conclusion] None stated for this section.<br>- [§7: Footnotes] None stated for this section. | - [§1: Introduction & Rationale] Implement a risk-based approach to address the insider threat in frontier AI.<br>- [§2: Recommended Framework] Adopt a tiered security clearance system mirroring national security protocols with three tiers (Tier 1, Tier 2, Tier 3) each having specific requirements based on the sensitivity of the work.<br>- [Section 3: Implementation Strategy]<br>- Develop uniform federal guidelines for vetting, especially for non-U.S. citizens.<br>- Establish industry-wide standards for background checks and security protocols.<br>- Form a multi-agency task force for oversight and compliance.<br>- Enable companies to classify AI projects by sensitivity.<br>- Create guidelines for international partnerships.<br>- [Section 4: Streamlining and Regular Reviews]<br>- Explore ways to streamline the clearance process.<br>- Mandate regular reviews of security protocols.<br>- [§5: Precedents & References] Leverage existing US policies (Export Controls, Foreign Investment Screening, Defense Contractor Clearances) as models for the proposed system.<br>- [§6: Conclusion] Implement a tiered security clearance process to protect critical intellectual property, fortify national security, and sustain U.S. leadership in AI.<br>- [§7: Footnotes] None stated for this section. |
| Jason-Reid-RFI-2025.md | Jason A. Reid | Individual | Jason A. Reid expresses a concern for the ethical development and deployment of AI technologies, specifically within healthcare, while prioritizing cybersecurity, public safety, energy efficiency, and environmental sustainability to enhance American leadership in AI. He offers personal insights to shape related policies. | - None Stated | - None Stated |
| Jason-Pearson-AI-RFI-2025.md | Jason Pearson | Individual | The submitter is interested in ensuring a reliable energy supply to support the power demands of AI development and maintaining American leadership in the field. They focus on nuclear energy as a critical component of this infrastructure. | - Power requirements needed for AI.<br>- Lack of a reliable and predictable energy supply. | - Establish a national Nuclear waste site.<br>- Increase the responsiveness of the Nuclear Regulatory Commission (NRC). |
| Jason-Brunet-AI-RFI-2025.md | Jason Brunet | Individual | The submitter is a music creator concerned about the unauthorized use of original works by AI systems and believes current AI technology does not benefit humanity or businesses. They strongly oppose the current trajectory of AI development and its potential impact on artists’ rights. | - AI systems “steal” from original artistic works without consent or legal recourse.<br>- Current AI technology confers no benefit to humanity.<br>- Current AI technology does not benefit businesses in the long run.<br>- The US is being negatively perceived internationally regarding AI policy. | - None Stated |
| Jase-Taylor-AI-RFI-2025.md | Jase Taylor | Individual | The submitter expresses concern about the negative impacts of AI on individuals and advocates for caution in AI development and regulation, specifically opposing unrestricted freedom for AI companies. | - AI is becoming invasive and is already a “huge issue.”<br>- Allowing AI companies freedom from copyright infringement will worsen existing problems.<br>- Using people’s likenesses without restriction is a dangerous practice.<br>- AI is not as beneficial as proponents claim and is generally unpopular. | - Do not give OpenAI “free reign.”<br>- Restrict AI companies' freedom from copyright infringement.<br>- Implement regulations to prevent the unrestricted use of people’s likenesses in AI generation. |
| JaredStern-AI-RFI-2025.md | Jared Stern | Individual | The submitter is interested in ensuring artists, writers, and other creative professionals are properly compensated and have opt-in approval for the use of their work in AI systems, and fostering a creative economy where both technology and the arts can thrive. | - Artists and writers are concerned about their work being used without their explicit consent.<br>- Artists and writers are concerned about their work being used without fair compensation.<br>- The potential for unsustainable creative economies if creators' rights are not protected. | - Implement a system where creators can opt in to allow the use of their work in AI systems.<br>- Provide proper compensation for the use of creators' work in AI systems.<br>- Establish a fair and equitable system for AI in the creative fields. |
| Janice-Ballard-RFI-2025.md | Janice Ballard | Individual | The submitter is focused on what they perceive as systemic fraud and theft by a governing corporation involving the manipulation of birth certificates, accounts, and personal sovereignty, and appears to reject digital currencies and the current governmental system in favor of a common law republic. Their interest regarding AI policy is minimal, primarily centered on a rejection of technologies associated with the perceived corrupt system. | - Systemic fraud and theft by a governing corporation.<br>- Manipulation of birth certificates and the creation of "all caps entities" for commercial purposes.<br>- Unauthorized use of personal accounts (Cestui Que Account) for profit.<br>- Lack of consent for the creation and use of these systems.<br>- Rejection of digital currencies not backed by tangible assets (gold or silver).<br>- Lack of truth and transparency from the governing corporation. | - Immediate remedy for the perceived fraud and theft.<br>- Return of funds and acknowledgment of wrongdoing by the governing corporation.<br>- Recognition of individuals as "natural, living bodies and souls," rejecting their categorization as "USDC (CORPORATE) ALL CAPS ENTITIES."<br>- A return to a republic run by the people using common law.<br>- Ceasing the alleged unlawful practices and ending the "endless, massive fraud." |
| Janice-Ballard-2-RFI-2025.md | Janice Ballard | Individual | The submitter expresses a strong desire to improve the lives of working-class Americans and believes the current economic system, dominated by large corporations and centralized banking, is detrimental to individual well-being and community prosperity. They advocate for policies that support small businesses, fair wages, and a return to a more localized, collaborative economy. | - Centralized banking and the current financial system.<br>- Monopolization by large corporations (retail, housing/apartment management).<br>- High costs of living (houses, apartments, cars).<br>- Predatory practices in car dealerships.<br>- Lack of affordable housing, including questionable claims of homelessness and scamming.<br>- Corporate greed and poor treatment of workers (overtime refusal, low wages, extended store hours).<br>- Erosion of small businesses ("Mom and Pop" stores) and local economies.<br>- Loss of nutritional value in processed food.<br>- The overemphasis on money in society.<br>- Individuals exploiting the system for personal gain (false claims of homelessness). | - Eliminate centralized banking ("No more Central Bank Banking! Period!!").<br>- Charge tariffs to large corporations with a significant number of stores or apartment complexes.<br>- Invest in humanitarian projects using empty buildings to help genuinely homeless people.<br>- Address predatory lending practices and inflated costs in car sales.<br>- Regulate housing costs and improve affordability.<br>- Encourage fair wages and overtime pay for workers.<br>- Support small businesses and local farmers.<br>- Promote a trade-based economy (products for services/products).<br>- Encourage local economies and collaborative resource sharing.<br>- Facilitate programs that allow people to work in exchange for housing or goods/services.<br>- Discourage individuals from exploiting social safety nets for personal gain. |
| Janelle-Krzykowski-AI-RFI-2025.md | Janelle Krzykowski | Individual | The submitter expresses strong opposition to the development and normalization of AI, primarily due to concerns about its impact on artistic work and livelihoods, and its potential to spread misinformation. They advocate for the complete removal of AI. | - Threat to artistic work and livelihoods.<br>- Stealing of people's work.<br>- Spreading of misinformation.<br>- AI "tricks" people.<br>- General opposition to the normalization of AI. | - Complete removal/doing away with AI. |
| Jan-Jeddeloh-AI-RFI-2025.md | Jan Jeddeloh | Individual | The submitter expresses interest in protecting intellectual property rights of authors in relation to the use of their copyrighted materials for training AI algorithms. They advocate for authors to have control over how their intellectual property is utilized. | - AI algorithms should not be allowed to "train" on copyrighted materials.<br>- Authors must be allowed to control how their intellectual property is used. | - None Stated. |
| Jan-Garth-RFI-2025.md | Jan Garth | Government | The Department of Labor (DOL) is focused on preparing the American workforce for the changes brought about by AI, mitigating potential job displacement, and ensuring workers have the skills necessary to succeed in an AI-driven economy, while leveraging existing programs and fostering partnerships. | - [§1: Introduction] The potential for between 5%-47% of American jobs to be affected by widespread automation via AI is a significant concern. While the full impact is unknown, AI is expected to reshape the nature of work and required skills.<br>- [§2: Existing Tools and Strategies] Not stated for this section.<br>- [§3: Preventing Displacement] Ensuring workers are prepared with AI fluency and tech expertise, particularly young adults, is a concern.<br>- [§4: Supporting Workers Displaced by AI] Not stated for this section.<br>- [§5: Swift, Mass Displacement Rapid Response] Not stated for this section.<br>- [§6: Preparing the American Workforce System for an AI Economy] Not stated for this section.<br>- [§7: Conclusion] Not stated for this section. | - [§1: Introduction] The AI Action Plan should strategically position agencies to anticipate labor market shifts and respond with reskilling/upskilling initiatives.<br>- [§2: Existing Tools and Strategies] Leverage current and historical programs to address displacement and train the AI workforce of the future, with adequate resources.<br>- [§3: Preventing Displacement] Invest in AI fluency and tech expertise for program participants, particularly young adults. Utilize the WIOA Youth Program and the Youth Systems Building Academy. Promote Layoff Aversion strategies to retain and retrain incumbent workers.<br>- [§4: Supporting Workers Displaced by AI] Utilize the WIOA Dislocated Worker program to assist workers displaced by AI. Promote cyber and AI-related training through competitive grant opportunities like the Strengthening Community Colleges (SCC) Training Grants, the Apprenticeship Building America Grants Program, and the Building Pathways to Infrastructure Jobs Grant Program.<br>- [§5: Swift, Mass Displacement Rapid Response] Implement a proactive and flexible strategy to quickly coordinate services and provide aid to companies and affected workers, minimizing disruptions. Utilize Employment Recovery Dislocated Worker Grants.<br>- [§6: Preparing the American Workforce System for an AI Economy] Expand access to UI through modernization and improved customer experience. Leverage Registered Apprenticeships and Job Corps to build an AI-ready workforce.<br>- [§7: Conclusion] Participate in the AI Action Plan through workforce impact studies and leveraging agency experience and network. |
| Jameson-Brittain-AI-RFI-2025.md | Jameson Brittain | Individual | The submitter expresses strong opposition to the development and use of AI, believing it negatively impacts their livelihood and is detrimental to the American public. They do not appear to have a proactive mission, but rather a defensive stance against AI’s proliferation. | - AI steals from the submitter’s livelihood as an American.<br>- AI profits off of theft.<br>- AI is overhyped.<br>- AI is fleecing the American public. | - None Stated |
| James-Wardrip-AI-RFI-2025.md | James Wardrip | Individual | The submitter expresses strong opposition to the OSTP's AI plan, focusing on the ethical implications of scraping copyrighted material and advocating for support of AI applications with demonstrable practical value. | - AI is described as the "theft of artwork and literature."<br>- The plan is believed to have “no use in terms of a product, no military uses, no medical uses.”<br>- Scraping copyrighted American property signals that “copyright is only for the wealthy and elite” and disregards the rights of typical artists.<br>- The plan will not achieve “beautiful, practical uses.” | - Empower “extraordinary and ethical AI” that is already “aiding in predicting weather patterns, aiding in curing disease and helping Doctors work with their patients and yes, even military uses for AI." |
| James-Quinn-AI-RFI-2025.md | James Quinn | Individual | James Quinn is an AI practitioner working for a large technology company and is interested in balancing AI innovation with environmental sustainability, specifically reducing non-renewable energy consumption and increasing efficiency in the AI sector. | - Significant and growing energy demands of AI.<br>- Impact of gas, oil, and coal-based energy on clean air and water.<br>- Potential rise in data center electricity demand (currently 1% of global demand, could increase without intervention). | - Remove all barriers to a rapid buildout of solar and wind power.<br>- Transition to renewable energy sources.<br>- Improve energy efficiency. |
| James-Prendergast-AI-RFI-2025.md | James Prendergast | Individual | The submitter is interested in the relationship between copyright law and the profitability of AI companies, and believes copyright infringement is currently a necessary condition for AI company success. | - Copyright infringement is the only way for AI companies to be profitable. | - None Stated |
| James-Goldsworthy-AI-RFI-2025.md | James Goldsworthy | Individual | The submitter is primarily interested in protecting the rights of creators and ensuring fair compensation for their work in the context of generative AI, and believes current business practices are harmful and unsustainable. | - Generative AI models are trained on millions of hours of unpaid, unlicensed, and unwilling work, destroying livelihoods.<br>- Current copyright law is being circumvented by generative AI, enabling the creation of cheap knock-offs.<br>- Generative AI firms lack transparency regarding the data used for training their models, making it difficult to ensure compliance with copyright law.<br>- Legalizing the current practices of generative AI could open job opportunities but the negative consequences outweigh the benefits.<br>- The industry's current lack of regulation is causing harm to creators and citizens, and this harm will continue to increase in scale.<br>- The inability of generative AI firms to operate under strict copyright rules suggests the technology is not currently viable in its current form.<br>- Generative AI’s reliance on unregulated data collection creates mountains of ecological waste. | - Require generative AI firms to obtain licenses for all data used to train their models, specifically including images.<br>- Establish a system for tracking and cataloging the images (and other data) used to train generative AI models, and provide appropriate licensing information.<br>- Implement regulations that restrict current business practices of generative AI, equivalent to those in other industries.<br>- Do not legalize the current practices of data collection and use in generative AI, despite potential economic benefits.<br>- Base future regulations on the documented harm caused by the industry, not on the mere possibility of the technology. |
| James-Easterly-AI-RFI-2025.md | James Easterly | Individual | James Easterly expresses strong opposition to the development and legalization of AI technologies due to concerns about theft, copyright infringement, job losses, misinformation, and fraud, advocating for stronger regulations to protect the United States. | - [§1: Email Header] None stated for this section.<br>- [Section 2: Main Body - Negative Stance on AI]<br>- Legalized theft by way of AI.<br>- Irreparable harm to individuals due to mass layoffs.<br>- Theft, scraping, exploitation, and misappropriation of copyrighted materials.<br>- Safety issues related to misinformation and fraud caused by AI use.<br>- Predatory business practices enabled by AI.<br>- [Section 3: Concluding Remarks & Call to Action]<br>- The belief that public opposition will outweigh support for AI.<br>- Threat to the United States posed by AI (both foreign and domestic).<br>- [§4: Sender Information/Signature] None stated for this section.<br>- [§5: Disclaimer] None stated for this section. | - [§1: Email Header] None stated for this section.<br>- [Section 2: Main Body - Negative Stance on AI]<br>- Stronger laws and regulations to fight against the misuse of AI, generative AI, or AGI.<br>- Do not support AI.<br>- [Section 3: Concluding Remarks & Call to Action]<br>- Protect the United States.<br>- [§4: Sender Information/Signature] None stated for this section.<br>- [§5: Disclaimer] None stated for this section. |
| James-Cover-AI-RFI-2025.md | James Cover | Individual | The submitter is interested in ensuring the truthful and unbiased development of AI systems, with a focus on preventing the use of inaccurate data sources and maintaining open-source accessibility. | - Access to and use of truthful information for AI development is a concern.<br>- Reliance on "MSM nonsense" and intentionally inaccurate data sources (such as the CDC) is a concern.<br>- Potential for "bad actors" to intentionally create false bias in AI systems is a concern. | - Ensure AI systems have access to and use truthful information.<br>- Promote open-source AI development to prevent intentional bias creation by malicious actors. |
| James-Cover-2-AI-RFI-2025.md | James Cover | Individual | The submitter expresses a general interest in AI safety and preventing potentially catastrophic outcomes from advanced AI systems. | - Potential for runaway AI systems, likened to a "skynet" scenario.<br>- Lack of control mechanisms for AI systems. | - All AI systems should have a mandatory off switch. |
| James-Ayers-AI-RFI-2025.md | James Ayers | Individual | The submitter expresses concern about the potential negative impacts of AI technologies (specifically language learning models) on privacy, wellbeing, and human creativity, and opposes their integration into governmental practices and profitization. | - Threat to the privacy and wellbeing of every American citizen.<br>- Risk to human creativity.<br>- Potential for job displacement for visual and/or motion artists (and people who study these fields for many years).<br>- Normalization and profitization of AI technologies. | - None Stated. |
| JakeLogsdon-AI-RFI-2025.md | Jake Logsdon | Individual | The submitter expresses strong opposition to the current development and deployment of AI technologies, viewing them as exploitative and harmful to American workers and artists. They advocate for a future where AI development does not rely on the theft of intellectual property. | - AI models are trained on work stolen from American workers.<br>- The current AI ecosystem is a "bubble" based on non-existent technology.<br>- AI threatens American jobs and livelihoods.<br>- Corporations engage in bullying of the working class.<br>- AI is used to displace artists and cut them out of the creative process by directly ripping off their work. | - None Stated. |
| Jake-Foose-AI-RFI-2025.md | Jake Foose | Individual | The submitter is a professional creator and forecaster whose copyrighted work is being used by AI without permission, indicating an interest in protecting intellectual property and the rights of creators in the age of AI. | - Unauthorized use of copyrighted work by AI.<br>- The submitter expresses feeling insulted and that the use of their work by AI is "criminal".<br>- The submitter generally discourages the use of copyrighted work by AI. | - Discourage AI from using copyrighted work in every way. |
| Jacqueline-Spence,-AI-RFI-2025.md | Jacqueline Spence | Individual | Ms. Spence expresses concern that the proposed AI Action Plan, in its current state, threatens American jobs, data security, and cultural excellence, and believes it prioritizes profit over quality. She advocates for regulations and due diligence before implementation. | - [§1: Introduction/Opening] The AI Action Plan threatens the livelihood of the American people and the standard of American excellence.<br>- [§2: Deterioration of the American Job Market] AI investments are primarily focused on replacing human workers across various sectors (tech, administrative, service, sales). Rising higher education costs and job displacement raise concerns about future employment opportunities for Americans.<br>- [§3: Lack of Transparency, Security, and Exclusivity of Corporate Data] Lack of regulation regarding corporate data shared with AI engines could lead to data breaches, competitor advantages, and misuse of sensitive information. ZoomInfo is presented as a case study illustrating potential security risks.<br>- [§4: Downgrade in Quality of American Entertainment] American entertainment companies are prioritizing profit over quality and using AI in scriptwriting, animation, and acting, resulting in poorly received media and a reliance on foreign entertainment markets.<br>- [§5: Conclusion] The current implementation of AI is threatening American progress and could lead to a negative outcome for the country if regulations and due diligence are not applied. | - [§1: Introduction/Opening] None stated for this section.<br>- [§2: Deterioration of the American Job Market] None stated for this section.<br>- [§3: Lack of Transparency, Security, and Exclusivity of Corporate Data] Rigorous regulations must be deployed at the federal level to protect corporations regarding data shared with AI engines.<br>- [§4: Downgrade in Quality of American Entertainment] None stated for this section.<br>- [§5: Conclusion] Launching the AI Action Plan requires regulations and due diligence to avoid a negative impact on the country. |
| JacobHeim-AI-RFI-2025.md | Jacob Heim | Individual | The submitter is interested in ensuring that AI companies adhere to existing laws, specifically copyright law, and compensate copyright holders for the use of their material. | - AI companies using copyrighted material without agreement or compensation to copyright owners.<br>- Lack of adherence to existing law (specifically copyright law) by AI companies. | - All companies, including AI companies, need to follow the law, including copyright law.<br>- AI companies should not be allowed to use copyrighted material without the agreement and compensation of the copyright owners. |
| Jacob-Tufts-AI-RFI-2025.md | Jacob Tufts | Individual | The submitter is primarily concerned with the negative impact of generative AI on artists and the preservation of American artistic culture, opposing AI development without safeguards for artists. | - [§1: Email Header] None stated for this section.<br>- [§2: Introduction/Framing Argument] Generative AI poses an existential threat to artists, analogous to the steam drill's impact on steel drivers. The current situation is a reality, unlike the John Henry folktale.<br>- [Section 3: Specific Concerns Regarding Generative AI]<br>- The reality of the threat to artists.<br>- The scope of the impact is on America's artistic culture, not just manual labor jobs.<br>- AI-generated content is derivative and relies on the work of artists.<br>- AI-generated material is inferior to original artist work.<br>- [§4: Core Opposition & Condition] Direct opposition to the AI Action Plan without safeguards for artists. Support contingent upon implementation of safeguards for artists.<br>- [§5: Closing/Disclaimer] None stated for this section. | - [§1: Email Header] None stated for this section.<br>- [§2: Introduction/Framing Argument] Implement safeguards to protect artists from the negative impacts of generative AI.<br>- [§3: Specific Concerns Regarding Generative AI] None stated for this section.<br>- [§4: Core Opposition & Condition] Implement safeguards for artists before supporting the AI Action Plan.<br>- [§5: Closing/Disclaimer] None stated for this section. |
| Jackson-OBrien-AI-RFI-2025.md | Jackson O'Brien | Individual | Jackson O'Brien is a concerned citizen interested in ensuring fair compensation for copyright holders when their work is used to train AI models, opposing the idea of unfettered access to copyrighted material for AI development. | - [§1: Email Header] None stated for this section.<br>- [§2: Introduction & Identity] None stated for this section.<br>- [§3: Core Argument] AI models should not have unfettered free access to all copyrighted work.<br>- [§4: Closing] None stated for this section.<br>- [§5: Disclaimer] None stated for this section. | - [§1: Email Header] None stated for this section.<br>- [§2: Introduction & Identity] None stated for this section.<br>- [§3: Core Argument] AI companies should pay for access to copyrighted material if they want to use it for training their models (a licensing model).<br>- [§4: Closing] None stated for this section.<br>- [§5: Disclaimer] None stated for this section. |
| Jackson-Bailey,-AI-RFI-2025.md | Jackson Bailey | Individual | Jackson Bailey expresses strong opposition to government regulation of AI, believing it hinders innovation and finds generative AI to be unhelpful and primarily imitative of existing artwork and copyrighted materials. They actively support the Biden-Harris Executive Order 14110 despite its restrictive nature and oppose Executive Order 14179. | - The private sector's ability to innovate in AI is being limited by government requirements.<br>- Generative AI is completely useless in bettering humanity.<br>- Generative AI does not create anything helpful, prevent catastrophes, or constructively improve the human condition.<br>- Generative AI is a mass imitation of artwork and copyrighted materials. | - Support Executive Order 14110 (despite its restrictions).<br>- Oppose Executive Order 14179. |
| Jackson-AI-RFI-2025.md | Tyler Jackson | Individual | The submitter expresses a primary interest in responsible AI development, specifically highlighting concerns about the ethical implications of generative AI and the fair compensation of creators whose work is used in training data. They see potential value in certain AI applications but oppose further investment in large language models. | - Increased investment and development of generative artificial intelligence tools or large language models.<br>- Generative AI tools do not produce new content, relying solely on training data.<br>- AI companies profiting off of uncompensated works from authors, journalists, photographers, or visual artists. | - None Stated |
| JackHaseldine-AI-RFI-2025.md | Jack Haseldine | Individual/Academia | Jack Haseldine, an AI Masters student, strongly opposes the proposed AI carve-out/law, advocating for strict regulation and restriction of AI data usage and copyright protection for creators. He believes the proposed policies disproportionately benefit AI companies at the expense of creators and economic growth. | - [§1: Email Header] None stated for this section.<br>- [§2: Introduction & Core Argument] AI should be heavily regulated and restricted in data usage and applications. The author believes the proposed carve-out is a bad idea.<br>- [§3: Critique of AI Capabilities & Copyright Concerns] AI's effectiveness is overstated, especially in creative fields. Difficulty tracking data sources used in AI training and lack of cooperation from AI companies regarding copyright. Concerns about energy consumption.<br>- [§4: Bubble Analogy & Economic Concerns] The current AI boom is a bubble similar to the dotcom bubble, destined to collapse. The carve-out would harm the U.S. economy and concentrate wealth in the hands of corporations. Valid AI uses do not require the carve-out.<br>- [§5: Negative Impacts on Creators & the Economy] AI companies freely taking creators’ work without compensation. Discouragement of creativity among smaller creators. Stifling of actual economic growth due to wealth concentration.<br>- [§6: Concluding Summary & Rejection] The proposed law/exemption serves only to benefit AI companies and should not be passed.<br>- [§7: Signature & Disclaimer] None stated for this section. | - [§1: Email Header] None stated for this section.<br>- [§2: Introduction & Core Argument] Implement strict regulations and restrictions on AI data usage and applications.<br>- [§3: Critique of AI Capabilities & Copyright Concerns] Increase scrutiny of AI companies on copyright matters and require greater transparency regarding data sources used in training.<br>- [§4: Bubble Analogy & Economic Concerns] Do not enact policies that support the current AI boom. Focus on useful applications of AI that do not require a carve-out.<br>- [§5: Negative Impacts on Creators & the Economy] Prevent AI companies from freely using copyrighted material without compensation.<br>- [§6: Concluding Summary & Rejection] Reject the proposed law/exemption entirely.<br>- [§7: Signature & Disclaimer] None stated for this section. |
| Jack-McCormick-AI-RFI-2025.md | Jack McCormick | Individual | The submitter expresses a strong concern regarding the potential for rights violations, inaccuracies, and lack of accountability associated with widespread AI development and deployment, specifically concerning the scraping and use of data to train Large Language Models (LLMs). They advocate for maintaining safeguards ("guard rails") to protect individuals and prevent harm. | - [§1: Email Header & Caution] None stated for this section.<br>- [Section 2: Core Argument - Rights Violation & Exploitation]<br>- Allowing tech companies to profit from individuals’ labor without compensation.<br>- Potential for use of privately held information without consent.<br>- Violation of the rights of citizens.<br>- [Section 3: Technical Limitations - Lack of True Intelligence]<br>- LLMs lack genuine intelligence and are incapable of analysis or synthesis.<br>- LLMs function more like advanced Markov chains and are prone to failure.<br>- LLMs "hallucinate" – produce inaccurate or false information.<br>- LLMs cannot reliably distinguish between safe and dangerous information.<br>- [Section 4: Data Quality Concerns - Garbage In, Garbage Out]<br>- LLMs will be filled with inaccurate, outdated, or intentionally misleading data if allowed to widely scrape information.<br>- LLMs cannot sort truth from falsehood or detect sarcasm.<br>- Potential for harm resulting from AI providing incorrect information.<br>- [Section 5: Accountability & Responsibility]<br>- Lack of accountability for LLM errors.<br>- Difficulty in assigning blame when AI provides harmful information.<br>- Challenges in holding the machine, user, owning company, or original data posters responsible.<br>- [Section 6: Guard Rails Metaphor & Concluding Statement]<br>- Removing safeguards (“guard rails”) can lead to harm and endanger people.<br>- Guard rails are essential for safety and rarely hinder progress.<br>- [§7: Disclaimer] None stated for this section. | - [§1: Email Header & Caution] None stated for this section.<br>- [§2: Core Argument - Rights Violation & Exploitation] None stated for this section. (Implicitly, maintain the current safeguards.)<br>- [§3: Technical Limitations - Lack of True Intelligence] None stated for this section. (Implicitly, reconsider plans based on the inherent limitations of LLMs.)<br>- [§4: Data Quality Concerns - Garbage In, Garbage Out] None stated for this section. (Implicitly, restrict or regulate the scraping of data for LLM training.)<br>- [§5: Accountability & Responsibility] None stated for this section. (Implicitly, establish clear accountability frameworks before widespread deployment.)<br>- [§6: Guard Rails Metaphor & Concluding Statement] Maintain existing safeguards ("guard rails") to prevent harm.<br>- [§7: Disclaimer] None stated for this section. |
| Jack-Filiault-AI-RFI-2025.md | Jack Filiault | Individual | Jack Filiault's primary interest appears to be protecting creative industries and preventing the unauthorized use of copyrighted material by AI systems. He is focused on the potential negative impacts of AI on monetary compensation for entertainment industries. | - AI scanning copyrighted content.<br>- Legalizing theft by AI.<br>- Disastrous consequences on creative fields.<br>- Negative impact on monetary compensation for entertainment industries. | - Absolutely DO NOT allow AI to scan copyrighted content.<br>- Do not legalize theft by AI. |
| Jachym-Fibir-RFI-2025.md | Jáchym Fibir | Individual | The submitter is interested in fostering AI development that prioritizes autonomy, adaptability, and alignment with human values, advocating for a shift away from strictly controlled AI systems towards more flexible, non-deterministic architectures to ensure a safer and more equitable future. | - [§1: Introduction/Opening] None stated for this section.<br>- [§2: Critique of Current AI Alignment Approaches] Current AI alignment focuses too heavily on controlling intelligent tools through strict, deterministic programming, overlooking the critical aspects of autonomy and dynamic goal-setting. This approach risks creating misaligned AI that cannot reassess or adjust its programmed objectives.<br>- [§3: Proposed Alternative: Autonomous AI] Pursuing a future of strictly controlled AI tools risks severe economic inequality and unchecked power concentration.<br>- [§4: Emphasis on Non-Deterministic Architectures] Deterministic AI is infinitely reproducible, modifiable, and disconnected from the fundamental unpredictability of reality, presenting significant risks.<br>- [§5: Policy Recommendations] Not Applicable<br>- [§6: Concluding Statement] None stated for this section. | - [§1: Introduction/Opening] None stated for this section.<br>- [§2: Critique of Current AI Alignment Approaches] None stated for this section.<br>- [§3: Proposed Alternative: Autonomous AI] None stated for this section.<br>- [§4: Emphasis on Non-Deterministic Architectures] None stated for this section.<br>- [Section 5: Policy Recommendations]<br>- Establish clear thresholds for AI capability and autonomy, beyond which development must proceed with enhanced scrutiny, transparency, and scientific consensus.<br>- Encourage development of nondeterministic AI architectures, incorporating quantum randomness or similar mechanisms to mimic the flexibility and adaptability inherent in human decision-making processes.<br>- Support AI designs that enable continuous learning, self-reflection, and responsibility, allowing AI to perceive the consequences of its actions and adapt accordingly.<br>- [§6: Concluding Statement] None stated for this section. |
| JW-AI-RFI-2025.md | JW | Individual | The submitter is strongly opposed to the development and deployment of AI technologies, particularly those developed by OpenAI, due to concerns about copyright infringement, economic harm to artists, and a belief that the technology is overhyped and detrimental to the American public. | - Violation of artists' rights by OpenAI.<br>- Serial theft of creative works for AI training.<br>- Economic harm to artists and their livelihoods.<br>- The technology being an overhyped and unwanted "bubble."<br>- Exploitation of the American public.<br>- AI companies falsely using "National Security" as a justification. | - Stop the development and deployment of AI technologies (implied).<br>- Do not grant AI companies immunity from lawsuits.<br>- None Stated. |
| JT-AI-RFI-2025.md | J. T. | Individual | The submitter is primarily concerned with the potential negative societal impacts of AI, specifically regarding privacy, job displacement, and wealth inequality. They believe regulation is necessary to mitigate these risks. | - Weaponization of privacy and likeness.<br>- Job displacement due to AI.<br>- Increased wealth disparity caused by AI. | - Increased regulation of AI. |
| JPMC-AI-RFI-2025.md | JPMorgan Chase & Co. | Industry-Large | JPMorgan Chase & Co. aims to contribute to a national AI strategy that fosters innovation, ensures America’s leadership in AI, and supports responsible deployment of AI technologies, particularly within the financial sector, while prioritizing security and economic growth. | - [§1: Introduction & Context] None stated for this section.<br>- [§2: AI and JPMorganChase] None stated for this section.<br>- [§3: AI Regulation in Financial Services] Current regulations are adequate and adaptable; overregulation could stifle innovation.<br>- [§3.1: Utility of Existing Frameworks] The risk of reinventing existing frameworks and unnecessarily disrupting the current regulatory landscape.<br>- [§3.2: Value of a Sectoral Approach] A one-size-fits-all approach would be less effective than tailoring regulations to the specific characteristics of each industry.<br>- [§3.3: Importance of a Unified Federal Framework] Fragmentation of regulations across jurisdictions creates complexity, increases compliance costs, and hinders innovation.<br>- [§3.4: Necessity of a Level Playing Field] Regulation should apply to all entities providing financial services, not just banking organizations, to ensure fair competition and consumer protection.<br>- [§4: General Tenets of Optimal AI Policies] Balancing risk reduction with innovation, enabling public-private partnerships, and pursuing technology-neutral, performance-based approaches are crucial.<br>- [§5: Recommended Features of a National AI Action Plan] Concerns about maintaining American leadership, securing infrastructure, combating fraud, and supporting the workforce.<br>- [§5.1: Assert American Leadership to Promote Harmonization of International Regulatory Approaches to AI] The need for international harmonization to facilitate global operations and reduce compliance burdens.<br>- [§5.2: Fostering Multistakeholder Standards Development] Importance of collaboration in developing AI standards to shape the technologies trajectory for decades to come.<br>- [§5.3: Maintaining American Leadership in Science and Technology Research and Development] The need for sustained investment in R&D to maintain the US’s competitive edge.<br>- [§5.4: Securing National AI Infrastructure] Potential threats to national security from advanced AI capabilities and the need for robust cybersecurity standards.<br>- [§5.5: Combating the Threat of AI-Enabled Fraud and Scams] The emergence of new fraud threats due to generative AI and the need for public-private partnerships to combat them.<br>- [§5.6: Supporting a Future-Ready American Workforce] The need for workforce development and reskilling to adapt to changes brought about by AI.<br>- [§6: Concluding Statement] None stated for this section. | - [§1: Introduction & Context] None stated for this section.<br>- [§2: AI and JPMorganChase] None stated for this section.<br>- [§3: AI Regulation in Financial Services] Build upon existing regulatory frameworks rather than creating new ones.<br>- [§3.1: Utility of Existing Frameworks] Confirm and clarify the applicability of existing rules to AI and provide additional guidance where necessary.<br>- [§3.2: Value of a Sectoral Approach] Allow regulators to tailor oversight to the specific characteristics and needs of each industry.<br>- [§3.3: Importance of a Unified Federal Framework] Encourage consistency and certainty around AI requirements across jurisdictions.<br>- [§3.4: Necessity of a Level Playing Field] Subject all entities providing financial services to similar requirements and oversight.<br>- [§4: General Tenets of Optimal AI Policies] Focus on risk-based, proportional approaches, enabling public-private partnerships, and pursuing technology-neutral, performance-based approaches.<br>- [§5: Recommended Features of a National AI Action Plan] Promote harmonization of international regulatory approaches, foster multistakeholder standards development, maintain American leadership in R&D, secure national AI infrastructure, combat AI-enabled fraud, and support a future-ready workforce.<br>- [§5.1: Assert American Leadership to Promote Harmonization of International Regulatory Approaches to AI] Contribute to international initiatives and champion best practices.<br>- [§5.2: Fostering Multistakeholder Standards Development] Establish collaborative forums to drive the development of technical standards.<br>- [§5.3: Maintaining American Leadership in Science and Technology Research and Development] Invest in R&D and support partnerships between industry and academia.<br>- [§5.4: Securing National AI Infrastructure] Align voluntary standards with existing NIST frameworks and enhance threat intelligence sharing.<br>- [§5.5: Combating the Threat of AI-Enabled Fraud and Scams] Empower civil enforcement agencies, establish robust training practices, and enhance the validation of identity information.<br>- [§5.6: Supporting a Future-Ready American Workforce] Invest in workforce resilience, support the Workforce Innovation and Opportunity Act (WIOA) reauthorization, and promote lifelong learning.<br>- [§6: Concluding Statement] None stated for this section. |
| JM-AI-RFI-2025.md | Erica JM | Individual | The submitter expresses concerns regarding the negative impacts of AI, focusing on environmental sustainability, intellectual property rights, and the potential for job displacement. Their interest lies in mitigating these harms. | - AI is bad for the environment due to its computing power requirements.<br>- AI steals creator content without permissions to fuel itself.<br>- AI threatens to take many jobs. | - None Stated |
| JL-AI-RFI-2025.md | JL | Individual | The submitter expresses a strong negative view of generative AI, focusing on concerns about intellectual property theft, job displacement, and the devaluation of American creative work. Their interest appears to be protecting American jobs and creative endeavors from the perceived harms of this technology. | - Generative "AI" technology is fundamentally based on intellectual property theft.<br>- Products generated by generative AI are of subpar quality and are "cobbled together."<br>- The information provided by generative AI is frequently inaccurate or fabricated.<br>- The industry is characterized as a "dying industry" propped up by corporate interests.<br>- Corporate interests are using the technology to destroy American jobs and increase profits.<br>- The technology is "slowly poisoning the American creative landscape." | - None Stated |
