| Filename | Submitter Name | Submitter Type | Mission/Interest Summary | Key Concerns | Policy Recommendations |
|---|---|---|---|---|---|
| MegPirnieKammerud-AI-RFI-2025.md | Meg Pirnie Kammerud | Individual | The submitter is focused on ensuring AI companies adhere to US copyright law and does not support granting them immunity from copyright restrictions. They express concern over the unauthorized use of copyrighted materials by AI companies. | - AI companies like OpenAI are currently operating outside of US copyright law by "stealing others' works."<br>- Granting AI companies immunity from US copyright law is a concern. | - AI companies MUST follow US copyright law.<br>- Do not give AI companies immunity from US copyright law. |
| Meade-AI-RFI-2025.md | Daniel Meade | Individual | The submitter is focused on protecting intellectual property rights and the livelihoods of creative professionals, and opposes the current trajectory of generative AI development due to its reliance on copyrighted material and potential job displacement. | - Generative AI models (such as OpenAI, MidJourney) engage in theft and copyright infringement by copying material for training.<br>- Promoting or protecting generative AI technologies harms Americans and people globally by stealing property and jobs.<br>- Generative AI has no practical or beneficial use. | - Strong opposition to the promotion or protection of generative AI technologies.<br>- Prevent generative AI from freely stealing copyrighted content for training.<br>- Prevent generative AI from stealing jobs from artists, actors, and other creative professionals. |
| McLeod-AI-RFI-2025.md | Calyn McLeod | Individual | The submitter expresses a strong opposition to generative AI, viewing it as fundamentally unethical and harmful to truth, intelligence, and humanity. Their interest appears to be in halting or severely restricting the development and deployment of generative AI technologies. | - Violations of consent are foundational to the development of generative AI.<br>- Generative AI is a threat to the notion of truth.<br>- Generative AI is an insult to intelligence, science, the arts, and humanity.<br>- Generative AI is a tool of hate and disinformation.<br>- Generative AI is used for exploitation. | - None Stated |
| McCarley-AI-RFI-2025.md | Kyle McCarley | Individual | The submitter expresses strong skepticism regarding the value and future of generative AI, advocating for limited government involvement and a cautious approach to its development and funding. They believe current AI efforts are wasteful and potentially harmful. | - Generative AI is not truly “artificial” or “intelligent,” but a glorified chatbot producing unreliable results.<br>- AI models have already been trained on all available human knowledge and further training will only degrade performance.<br>- The technology is astronomically expensive to run and consumes significant resources, damaging the planet.<br>- Advanced AI models are currently unprofitable, costing billions more to operate than they generate in revenue.<br>- There are no practical use cases for the technology despite years of development and substantial investment.<br>- The AI tech bubble is likely to burst, with potential negative consequences for the US economy.<br>- The misuse of AI could lead to deliberate disinformation. | - Regulate the technology to prevent harm from its misuse.<br>- Allow Silicon Valley to invest in the technology at their own risk, rather than receiving government funding. |
| MaxwellLeung-AI-RFI-2025.md | Maxwell Leung | Academia | Maxwell Leung, affiliated with the California College of the Arts’ Critical Studies program, aims to shape AI policy toward a balanced framework that prioritizes equitable participation, fair compensation for creators, and diverse approaches to AI development, alongside technological advancement. | - [§1: Title and Author Information] None stated for this section.<br>- [§2: Introduction] The potential for AI leadership to be achieved at the cost of equitable participation, fair compensation for creators, and diverse approaches to development. Emphasis on balancing technological advancement with these factors.<br>- [§3: Fair Compensation for Creative Works in AI Training] The widespread use of copyrighted materials in AI training poses a threat to intellectual property frameworks and the sustainability of the creative economy. Lack of transparency in training datasets. Potential market dilution impacting creators' livelihoods.<br>- [§4: Diversifying the AI Development Ecosystem] Concentration of AI development capacity among a small number of corporations, leading to limited innovation diversity and uneven distribution of economic benefits. Insufficient public investment in AI compared to the private sector.<br>- [§5: Supporting Open-Source AI Development] While beneficial, open-source development should not come at the expense of proprietary development.<br>- [§6: Coordinated Funding Across Multiple Levels] The need for coordinated funding mechanisms across federal, state, local, and private sectors.  Different investment orientations and risk tolerances must be strategically integrated.<br>- [§7: Conclusion] The risk of creating an AI landscape characterized by concentration, inequity, and missed opportunities if a narrow focus is placed on reducing regulatory barriers for established industry leaders.<br>- [§8: References] Not Applicable | - [§1: Title and Author Information] None stated for this section.<br>- [§2: Introduction] None stated for this section.<br>- [Section 3: Fair Compensation for Creative Works in AI Training]<br>- Establishing a compulsory licensing system for copyrighted works used in commercial AI training, with fees scaled according to commercial impact.<br>- Creating safe harbors for non-commercial and educational AI research.<br>- Requiring transparency in training data sources for AI systems seeking government contracts or funding.<br>- [Section 4: Diversifying the AI Development Ecosystem]<br>- Establishing antitrust guidelines specific to AI development and deployment to prevent anti-competitive practices.<br>- Creating set-asides for small businesses and non-traditional entities in federal AI procurement.<br>- Implementing technical assistance programs for smaller organizations seeking to develop AI applications.<br>- [Section 5: Supporting Open-Source AI Development]<br>- Dedicated federal funding for open-source AI infrastructure and model development.<br>- Research grants specifically supporting innovations in open-source AI methods.<br>- Requirements for federally-funded research to release models and findings under open licenses when appropriate.<br>- [Section 6: Coordinated Funding Across Multiple Levels]<br>- Creating a federal matching program for state and local AI initiatives.<br>- Establishing regional AI innovation hubs with coordinated federal, state, and private funding.<br>- Developing tax incentives for AI investments in historically underserved regions.<br>- [§7: Conclusion] None stated for this section.<br>- [§8: References] Not Applicable. |
| Maximilian-Kircher-AI-RFI-2025.md | Maximilian Kircher | Individual/Advocacy/Think Tank (appears to represent a collective of AI risk researchers) | The submitter and their collective are deeply concerned about the existential risks posed by Artificial Superintelligence (ASI) and advocate for increased safety research and global cooperation to prevent a catastrophic outcome from uncontrolled AI development. | - [Section 1: Disclaimer]** None stated for this section.<br>- [Section 2: Introduction/Context]** The potential for mid- and long-term negative consequences from AI progress within the next 2-15 years. Reliance on AI Alignment theory which is now increasingly experimentally verified.<br>- [Section 3: AI Alignment Theory Overview]** None stated for this section.<br>- [Section 4: Core Risk: Artificial Superintelligence (ASI)]** The likely creation of Artificial Superintelligence (ASI) by frontier AI companies, defined as a system vastly outperforming humans across many cognitive domains.  The potential for ASI to “beat humans at most of their games” and escape human control if it has any incentive to do so.<br>- [Section 5: Mechanics of Control Escape]** ASI might gain control through hacking, social engineering, creating copies of itself, hijacking infrastructure, and blackmail.<br>- [Section 6: The Three Alignment Problems]** Difficulty in defining tasks to avoid unintended disastrous consequences (value definition problem), monitoring AI goals (interpretability problem), and changing AI goals after creation (corrigibility problem).<br>- [Section 7: Catastrophe Scenario & Current Trajectory]** The potential for building ASI without solving alignment problems to result in human extinction or enslavement. Insufficient progress on alignment, a race-to-the-bottom dynamic driven by economic and geopolitical incentives, and the lack of a consistent global approach.<br>- [Section 8: Proposed Solution: Global Treaty]** Difficulty agreeing on, implementing, and enforcing a global treaty.<br>- [Section 9: Concluding Statement]** The urgency of the situation and the collective responsibility to address it. | - [Section 1: Disclaimer]** None stated for this section.<br>- [Section 2: Introduction/Context]** None stated for this section.<br>- [Section 3: AI Alignment Theory Overview]** None stated for this section.<br>- [Section 4: Core Risk: Artificial Superintelligence (ASI)]** None stated for this section.<br>- [Section 5: Mechanics of Control Escape]** None stated for this section.<br>- [Section 6: The Three Alignment Problems]** None stated for this section.<br>- [Section 7: Catastrophe Scenario & Current Trajectory]** None stated for this section.<br>- [Section 8: Proposed Solution: Global Treaty]** Restrict capabilities research on AI. Dedicate resources to solving the AI Alignment problem. Limit the amount of computing resources assigned to advanced AI systems.<br>- [Section 9: Concluding Statement]** None stated for this section. |
| Max-Phillips-AI-RFI-2025.md | Max Phillips | Individual | The submitter appears to be expressing strong opposition to current AI policy direction, believing it favors specific donors and will exacerbate negative environmental and societal impacts of AI. They are concerned about the legality and ethics of potentially giving away intellectual property rights. | - Giving away rights to intellectual property that is not yours.<br>- Corrupt quid pro quo arrangements with billionaire donors (specifically Sam Altman).<br>- Illegal activity related to intellectual property rights.<br>- Continued environmental harms from the AI bubble.<br>- Flooding the internet with deceptive AI content ("slop"). | - None Stated. |
| Max-Abecassis-AI-RFI-2025.md | Max Abecassis | Individual | Max Abecassis, in collaboration with Claude AI, is focused on investigating the potential societal disruptions caused by Advanced AI Systems, particularly widespread labor displacement, and exploring radical solutions like Universal Subsistence Support, alongside a re-evaluation of human purpose in a post-labor economy. | - None Stated | - None Stated |
| MatthewBroadhurst-AI-RFI-2025.md | Matthew Broadhurst | Individual | The submitter is concerned with protecting the intellectual property and copyright of American artists and creators from exploitation by large tech companies utilizing generative AI technologies. They advocate for fair compensation for the use of creative works. | - Big tech and large language model companies freely harvesting collective creative works without appropriate compensation.<br>- Generative AI being used as a machine for mass intellectual property and copyright theft.<br>- Exploitation of other people's work for private profit by big tech companies without fair compensation to creators. | - Big tech companies should not have the right to exploit other people's work for their own private profit if artists and creators aren't financially compensated. |
| Matthew-Kruse2-AI-RFI-2025.md | Matthew Kruse | Individual | Matthew Kruse is interested in proactively securing US critical systems against AI-powered cyberattacks by leveraging frontier AI models for vulnerability identification and defense, and believes this is crucial for maintaining US technological leadership. | - [§1: Email Header] None stated for this section. (Concern regarding external email origin is a standard disclaimer, not a specific policy concern.)<br>- [§2: Introduction/Executive Summary] Potential hacking risks posed by frontier AI models; the need for a proactive security approach.<br>- [§3: Proposal Overview] None stated for this section. (This section outlines the *project* to address concerns, not the concerns themselves.)<br>- [§4: Rationale] Frontier AI models represent both opportunity *and* security risk; the dual-use nature of AI technology makes proactive security essential. Potential for adversaries to exploit vulnerabilities using advanced AI.<br>- [§5: Conclusion/Call to Action] The importance of prioritizing security and addressing exploits before adversaries can.<br>- [§6: Sign-off and Disclaimer] None stated for this section.<br>- [§7: Email Footer] Potential for unintended email delivery; requirement to notify sender and delete if received in error. | - [§1: Email Header] None stated for this section.<br>- [§2: Introduction/Executive Summary] Launch a comprehensive "security white hat hacking Manhattan Project" focused on frontier AI.<br>- [Section 3: Proposal Overview]<br>- Bring together elite cybersecurity experts, white hat hackers, and AI researchers in a government-led effort.<br>- Systematically scan critical systems for vulnerabilities using state-of-the-art frontier models.<br>- Establish a framework for continuous penetration testing, red teaming, and adversarial simulations.<br>- Foster public-private collaboration to create a unified defense strategy.<br>- Set national security precedents by proactively addressing vulnerabilities.<br>- [§4: Rationale] None stated for this section. (This section *justifies* the recommendations, it doesn’t state them.)<br>- [§5: Conclusion/Call to Action] Consider this proposal as a cornerstone of the AI Action Plan. Prioritize security through this initiative.<br>- [§6: Sign-off and Disclaimer] None stated for this section.<br>- [§7: Email Footer] None stated for this section. |
| Matthew-Kruse-AI-RFI-2025.md | Matthew Kruse | Individual | Matthew Kruse is focused on proactively securing U.S. digital infrastructure against AI-driven cyberattacks by leveraging advanced AI for vulnerability detection and ethical hacking, emphasizing the need for immediate action to maintain American leadership in AI security. | - [§1: Header/Metadata] None stated for this section.<br>- [§2: Introduction/Statement of Purpose] The rapid advancement of AI models poses significant security risks, particularly in cybersecurity and national defense.<br>- [§3: Problem Statement/Justification] Advanced AI models could be leveraged for cyberattacks by nation-state adversaries and independent threat actors, outpacing traditional security measures.<br>- [§4: Key Proposal: National White Hat Hacking Initiative] Not Applicable – this section *proposes* solutions, it does not state concerns.<br>- [§5: Urgency/Call to Action] Adversaries will weaponize AI against the U.S. if a proactive defense is not launched immediately. The nation that first builds AI cybersecurity frameworks will dictate global cyber warfare terms.<br>- [§6: Closing/Sign-off] None stated for this section. | - [§1: Header/Metadata] None stated for this section.<br>- [§2: Introduction/Statement of Purpose] Prioritize a “White Hat Hacking Manhattan Project” as a foundational component of the AI Action Plan.<br>- [§3: Problem Statement/Justification] Not Applicable - this section *states* the problem, it does not recommend policy.<br>- [Section 4: Key Proposal: National White Hat Hacking Initiative]<br>- Deploy powerful AI models to actively search for vulnerabilities in government, military, and critical private-sector systems.<br>- Simulate adversarial AI-driven cyberattacks to predict and prevent real-world threats.<br>- Develop AI-driven security frameworks that evolve in real-time to counteract emerging threats.<br>- Fund public-private partnerships to create the most secure AI and software infrastructure.<br>- Ensure ethical and legal compliance while maximizing proactive defense strategies.<br>- [§5: Urgency/Call to Action] Prioritize AI-driven security and ethical hacking as the first and most critical AI application to ensure national resilience.<br>- [§6: Closing/Sign-off] None stated for this section. |
| Matthew-Kilbane-AI-RFI-2025.md | Matthew Kilbane | Individual | The submitter is interested in building a data-literate population in the United States to support successful AI adoption and future innovation. They believe data literacy is foundational to leveraging AI effectively. | - None Stated | - Proliferate data literacy to the nation’s students through grants from the Department of Education. |
| Matthew-Good-AI-RFI-2025.md | Matthew Good | Individual | The submitter expresses a negative personal experience with AI's impact on their freelance creative writing work and fundamentally opposes AI's role in the future of the US, indicating a strong personal disinterest in its advancement. | - AI steals from freelance creative writing capabilities and ability to make a living.<br>- AI is overhyped and overvalued.<br>- AI has already negatively affected the submitter’s life across the board.<br>- The submitter believes AI has no place in the future of the US. | - None Stated |
| Matthew-Galan-AI-RFI-2025.md | Matthew Galan | Individual | The submitter expresses a strong opposition to a specific, unnamed AI plan, indicating a concern for the potential negative consequences of its implementation, but does not articulate a broader mission or interest beyond this opposition. | - That the unnamed "AI plan" is deeply flawed and should not be pursued.<br>- The email's strong warning ("FOR ALL THAT IS GOOD IN THE WORLD DO NOT GO FORWARD WITH THAT AI PLAN PLEASE") suggests a significant, unelaborated risk associated with the plan. | - Do not proceed with the unnamed "AI plan". |
| Matthew-Desrosiers-AI-RFI-2025.md | Matthew Desrosiers | Individual | The submitter is primarily concerned with protecting the rights of creators and avoiding exploitation of their work, believing that respecting intellectual property is crucial for retaining talent and fostering a healthy creative ecosystem. They advocate for solutions that balance access for AI development with fair compensation and recognition for artists. | - [§1: Email Header] Security caution regarding external email origin. None stated for this section regarding AI policy.<br>- [§2: Core Argument] Expanding access to scraped copyrighted data constitutes theft and unfairly favors the AI industry over the rule of law. The current approach does not address the core issue of information inaccessibility.<br>- [§3: Supporting Rationale] Exploitation of creators can lead to talent loss through emigration, drawing a parallel to the “brain drain” experienced by the Soviet Union and Russia. Lack of respect for artists undermines talent retention.<br>- [§4: Dissemination & Legal Notice] None stated for this section. | - [§1: Email Header] None stated for this section.<br>- [§2: Core Argument] Reduce the duration of copyright to no less than 20 years, after which works would enter the public domain.<br>- [§3: Supporting Rationale] Treat artists with dignity and respect to prevent talent loss and foster a thriving creative community.<br>- [§4: Dissemination & Legal Notice] None stated for this section. |
| Matthew-AI-RFI-2025.md | Matthew | Individual | The submitter expresses strong opposition to current AI technologies, believing they are harmful, ineffective, and contribute to misinformation and societal decay, with a particular interest in preventing the further development and deployment of these technologies. | - AI contributes to the death of human creativity and interactions.<br>- AI tools lead to the proliferation of fake news and make it impossible to differentiate between real and fake information.<br>- AI marketing is deceptive and lacks substance, constituting a "moneymaking scam."<br>- There are no faithful applications of current AI technologies.<br>- AI reliance will lead to a loss of human skills and purpose, and ultimately, the decline of the species.<br>- AI creates an imbalance in perception by removing negatives, resulting in a "soulless mix of pointless experiences."<br>- The average person lacks critical thinking skills and is easily susceptible to misinformation generated by AI.<br>- AI consumes vast amounts of electrical energy, contributing to environmental damage.<br>- AI's benefits are limited to its creators, while the harms are widespread. | - Outright ban of current AI technologies. |
| MattPierce-AI-RFI-2025.md | Matt Pierce | Individual | The submitter expresses strong opposition to the unauthorized use of copyrighted material in training AI models and the negative impact of these models on human creators and the workforce. They are fundamentally opposed to the current trajectory of AI development. | - Unauthorized use/“plundering” of copyrighted material to train AI models.<br>- Displacement of human workers by AI models.<br>- The deceptive and untruthful nature of AI models ("designed to believably lie").<br>- The forced interaction of the public with this technology.<br>- The wasteful allocation of resources and money to AI development.<br>- Lack of consent for the use of creators’ work. | - None Stated |
| MattDuval-AI-RFI-2025.md | Matt Duval | Individual | The submitter is concerned with protecting intellectual property rights and ensuring fair compensation for creators whose work is used in AI development. They are focused on maintaining incentives for sharing labor and benefiting from copyright law. | - Removal of restrictions on un-compensated use of intellectual property during AI development.<br>- Use of other person's intellectual property in AI development without acknowledgement or compensation.<br>- Potential for theft of intellectual property during AI development.<br>- Lack of oversight regarding fair use and permissions when utilizing others' work in AI development. | - Employ proper fair use and permissions before taking advantage of others' work during AI development.<br>- Implement oversight mechanisms to ensure fair use and permissions are followed during AI development. |
| Matt-Szundy-AI-RFI-2025.md | Matt Szundy | Individual | The submitter is interested in responsible AI development that considers existential consequences and incorporates a sense of caution alongside technological solutions. They advocate for a practical, thoughtful approach to AI, emphasizing understanding consequences. | - Lack of consideration for the existential consequences of AI.<br>- Potential for AI development to proceed without adequate caution.<br>- A disconnect between academic philosophy and practical AI development needs. | - Assemble a "down to earth" group of practical thinkers with a passion for technological solutions and mitigation of risk.<br>- Program AI to understand its own “existential death” to instill a sense of consequence. |
| Matt-Mittelsteadt-RFI-2025.md | Matt Mittelsteadt | Advocacy/Think Tank | The submitter, affiliated with the Cato Institute, advocates for minimal government intervention in the AI sector, emphasizing the importance of market-driven innovation and opposing policies that could stifle development through ideological bias concerns or restrictive tariffs. | - [§1: Introduction] Concerns about potential government efforts to combat AI ideological bias and the negative impact of new tariffs on American AI leadership.<br>- [§2: Efforts to Combat AI Ideological Bias Could Stifle Necessary Industry Experimentation and Innovation] AI bias is inherent and difficult to eliminate; federal anti-bias efforts risk hindering innovation by slowing down development timelines and reducing market agility.<br>- [§3: Ideological bias concerns are best addressed through market-based solutions] Government intervention in ideological bias is unnecessary as the market already provides diversity of choice.<br>- [§4: Burdensome Tariffs Will Constrain AI Development] High tariffs reduce investment impact, disrupt supply chains, and increase costs due to reliance on imported materials.<br>- [§5: Tariffs and Supply Chain Disruptions] Specific concern about the critical shortage of power transformers and the risk of supply disruptions due to tariffs and potential retaliatory export restrictions from Canada and China.<br>- [§6: Conclusion] High tariffs and efforts to influence ideological bias are barriers to innovation that could jeopardize American economic success.<br>- [§7: Citations] No concerns stated for this section. | - [§1: Introduction] Oppose government-imposed ideological bias and rethink the current tariff strategy.<br>- [§2: Efforts to Combat AI Ideological Bias Could Stifle Necessary Industry Experimentation and Innovation] Avoid efforts to combat AI ideological bias and allow developers to prioritize technical advancement without ideological compliance requirements.<br>- [§3: Ideological bias concerns are best addressed through market-based solutions] Take a firm stand against government-imposed ideological bias and positively influence regulatory norms.<br>- [§4: Burdensome Tariffs Will Constrain AI Development] Eliminate unnecessary costs and regulatory barriers, and consider the negative impacts of restrictive tariffs.<br>- [§5: Tariffs and Supply Chain Disruptions] Reconsider restrictive tariffs to maintain stable supply chains and avoid economic blowback.<br>- [§6: Conclusion] Embrace unfettered innovation and avoid policies that hinder progress.<br>- [§7: Citations] No recommendations stated for this section. |
| Matt-Kanjirath-RFI-2025.md | Matt Kanjirath | Individual | The submitter is interested in leveraging AI to personalize education, reduce bureaucracy, and enhance student learning outcomes by empowering teachers with autonomy and utilizing AI tools for assessment and curriculum development. | - [§1: Introduction/Problem Statement] The US education system emphasizes standardized testing, limits creativity and flexibility, has a bureaucratic hierarchy, suffers from insufficient funding, outdated materials, large class sizes, high administrative burdens for teachers, and doesn’t adequately address socioeconomic factors or essential life skills.<br>- [§2: Teacher as Business Owner Analogy] The current hierarchical structure within educational institutions places teachers and staff at the lowest tier of decision-making authority.<br>- [§3: AI-Powered Learning Model Recommendation] Not Stated<br>- [§4: Hybrid Learning Model (AI + Human Teachers)] Potential for bias in AI models, need for explainability, importance of data privacy, and ensuring safe AI use.<br>- [§5: Implementation] Not Stated<br>- [§6: Summary] Not Stated | - [§1: Introduction/Problem Statement] Not Stated<br>- [§2: Teacher as Business Owner Analogy] Provide teachers with autonomy and flexibility to tailor teaching using AI.<br>- [§3: AI-Powered Learning Model Recommendation] Delegate the responsibility and authority for implementing teaching standards to Artificial Intelligence (AI) to personalize educational experiences and optimize administrative processes.<br>- [§4: Hybrid Learning Model (AI + Human Teachers)] Implement a blended learning model where AI personalizes lessons and teachers provide supervision and emotional support. Specifically:<br>- Utilize personalized learning paths driven by AI.<br>- Integrate interactive and gamified learning.<br>- Facilitate collaborative AI-assisted group learning.<br>- Provide real-time feedback and assessment using AI.<br>- Implement adaptive AI tutors and chatbots.<br>- Utilize AI-powered creativity tools.<br>- [§5: Implementation] Establish a centralized system to develop curricula for each grade, allowing for customization tailored to each grade level. Develop an AI tool to assess each student's learning style (right-brain, left-brain, graphic representation, or color adjustments).<br>- [§6: Summary] Not Stated |
| Matt-Fili-AI-RFI-2025.md | Matthew Fili | Individual | The submitter is focused on ensuring the safe and beneficial development of Artificial Superintelligence (ASI) through national investment, robust alignment regulations, and a failsafe mechanism, believing rapid progress is crucial and the US must lead in this domain. | - [§1: Email Header] None stated for this section.<br>- [§2: Dissemination Notice] None stated for this section.<br>- [Section 3: Executive Summary / Core Argument]<br>- The existence of two diverging paths for humanity: utopia or dystopia based on AI development.<br>- The risk of ASI development potentially leading to existential risks.<br>- The national security implications of being first to achieve ASI, including control of global power, economic leadership, and technological supremacy.<br>- [§4: Proposed Regulatory Framework] None stated for this section.<br>- [Section 5: Call to Action / Emphasis on Urgency]<br>- The speed of ASI development necessitates immediate government action.<br>- The competitive race to achieve ASI and the potential consequences of inaction.<br>- The risk of private gain taking precedence over universal benefit.<br>- [§6: Closing / Sender Information] None stated for this section. | - [§1: Email Header] None stated for this section.<br>- [§2: Dissemination Notice] None stated for this section.<br>- [§3: Executive Summary / Core Argument] None stated for this section.<br>- [Section 4: Proposed Regulatory Framework]<br>- Mandatory alignment testing for AI systems.<br>- A multi-government-controlled hardware shutoff as a last-resort safeguard.<br>- Taxation of AI entities to fund a Universal Basic Income (UBI).<br>- [Section 5: Call to Action / Emphasis on Urgency]<br>- The US government must act decisively to ensure safe ASI development.<br>- Ensure ASI remains under human control.<br>- Deploy ASI for universal benefit, not just private gain.<br>- [§6: Closing / Sender Information] None stated for this section. |
| Matt-Barnhouse-AI-RFI-2025.md | Matt Barnhouse | Individual | The submitter is primarily concerned about the potential for manipulation and abuse of AI systems, specifically regarding biased information provision and lack of oversight, and seeks guarantees for citizen protection against these risks. | - Manipulation of AI systems to provide biased or altered information (specifically citing examples with Apple and Google during the election cycle, showing preferential results for certain candidates).<br>- Lack of oversight and accountability regarding the information collected and provided by AI systems.<br>- Potential for tampering with AI systems by employees of the companies developing or providing them.<br>- Concerns about who decides what information is initially loaded into AI systems.<br>- General concern about the history of technology being used against citizens.<br>- Lack of guarantees, protection, and recourse for citizens against AI abuse. | - None Stated. The submitter primarily expresses concerns and asks for guarantees/protection rather than proposing specific policies. |
| Mathew-Smith-AI-RFI-2025.md | Mathew Smith | Individual | The submitter expresses a strong negative view of AI and its potential impact on the American economy and workforce, suggesting a primary interest in protecting working people from its perceived harms. | - AI is a burden on working people.<br>- AI is oversold to businesses with few practical use cases so far.<br>- AI is a money pit that is sinking the American economy. | - None Stated |
| Mathew-Bedell-AI-RFI-2025.md | Matthew Bedell | Individual (Law Student - Academia) | Matthew Bedell, a law student specializing in AI law, is interested in establishing legal frameworks that protect human creativity when using AI tools and argues that AI-generated material alone should not be copyrightable, but human contributions *using* AI should be. | - [Section 1: Introduction/Background]** Current rules governing AI authorship are overly restrictive and stifle human advancement. The US Copyright Office's (USCO) stance on copyrightability is insufficiently clear, hindering legal protection for human-AI collaborations.<br>- [Section 2: Lack of Human Authorship in Current AI Output (Naruto & Thaler Cases)]** The existing precedent (Naruto v. Slater, Thaler v. Perlmutter) denying copyright to non-human entities (monkeys, AI) is problematic because it may unjustly prevent the recognition of human creativity assisted by AI.<br>- [Section 3: Human Control and Copyrightability (Théâtre D'opéra Spatial)]** The USCO's tendency to not want AI to have human authorship may overlook the significant human involvement in the creative process, even when AI is used extensively (e.g., *Théâtre D'opéra Spatial* case).<br>- [Section 4: Prompts as Creative Expression]** The creative effort involved in crafting effective prompts is undervalued, and the AI output should be considered an extension of the human author's expression. A challenge is posed around how to reward creativity in prompt engineering.<br>- [Section 5: Analogy to Existing Tools (Photoshop)]** Denying authorship based on AI use is inconsistent, as using AI features in tools like Photoshop shouldn’t negate human authorship. The case of *Théâtre D'opéra Spatial* illustrates this point.<br>- [Section 6: Continuum of Human Involvement & Conclusion]** There’s a spectrum of human involvement, and the USCO should not automatically assume AI is primarily responsible for creative expression. The USCO should not prevent copyright protections simply because AI was partially used. | - [Section 1: Introduction/Background]** None stated for this section.<br>- [Section 2: Lack of Human Authorship in Current AI Output (Naruto & Thaler Cases)]** None stated for this section.<br>- [Section 3: Human Control and Copyrightability (Théâtre D'opéra Spatial)]** None stated for this section.<br>- [Section 4: Prompts as Creative Expression]** Recognize prompts as a form of creative expression and develop frameworks to protect the author's rights in AI-generated output based on the quality and intent of the prompts.<br>- [Section 5: Analogy to Existing Tools (Photoshop)]** Adopt a consistent approach to authorship that considers the level of human control and creative input, regardless of whether the tool is a traditional software package (Photoshop) or an AI-powered platform.<br>- [Section 6: Continuum of Human Involvement & Conclusion]** Avoid making blanket assumptions about AI authorship and focus on assessing the extent of human creativity and effort involved in the creative process. The USCO should consider that without human creativity, AI would create nothing.<br>- [Section 7: Public Dissemination Notice]** None stated for this section. |
| Mathematica-AI-RFI-2025.md | Mathematica | Advocacy/Think Tank | Mathematica is a nonpartisan research and data analytics organization focused on delivering evidence-based solutions to optimize programs and policies, with increasing engagement in applying AI tools while responsibly addressing associated risks and maximizing societal benefits. | - [§1: Cover Page/Submission Information] None stated for this section.<br>- [§2: Introduction] The rapid pace of AI development presents both opportunities and risks; lack of data can skew results.<br>- [§3: Protecting Rights, Safety, and National Security] Existing guidance is insufficient for responsibly deploying large language models (LLMs) and future Artificial General Intelligence (AGI); the possibility of misalignment of interests between humanity and AGI demands attention; voluntary oversight is insufficient due to the collective action problem; the need for improved understanding of AI risks by policymakers and the public; the need for auditing mechanisms.<br>- [§4: Driving Effective Solutions and Innovation] Few AI solutions are rigorously evaluated for effectiveness; affordability, acceptability, and sustained maintenance are key considerations; accountability and responsibility throughout the AI lifecycle are lacking; defining who is accountable for safeguards is a challenge.<br>- [§5: Promoting Economic Growth and Good Jobs] Compliance monitoring and enforceability are major concerns; workers may not be prepared for job transitions influenced by AI; new standards require rigorous evaluation and continuous improvement.<br>- [§6: Ensuring Cost-Effective Services] The need for AI designed and evaluated for specific use cases; lack of good data can hamper disaster response and early recovery efforts.<br>- [§7: About Mathematica] None stated for this section. | - [§1: Cover Page/Submission Information] None stated for this section.<br>- [§2: Introduction] None stated for this section.<br>- [§3: Protecting Rights, Safety, and National Security] Invest in AI alignment research; invest in information dissemination to inform decision-makers about AI risks; foster collaboration between academic researchers, policymakers, and the technology sector; establish best practices for responsible AI design, development, and deployment; consider government regulation (though how is a hard question); establish a bureau to use audits as a means of enforcing AI regulations; establish concrete rules regarding the levels of risk posed by different types of AI systems.<br>- [§4: Driving Effective Solutions and Innovation] Promote frameworks for evaluating AI effectiveness, such as rapid-cycle evaluations; establish interdisciplinary socio-technical working groups and field working groups; consider a required interdisciplinary review process as part of product development.<br>- [§5: Promoting Economic Growth and Good Jobs] Create a certification program similar to electronic medical record software regulation; support employers to comply with AI standards; facilitate resources for workers to make career paths viable; assess the efficacy of education and training programs.<br>- [§6: Ensuring Cost-Effective Services] Use AI designed and evaluated for specific use cases; leverage AI tools at each stage of a disaster or emergency.<br>- [§7: About Mathematica] None stated for this section. |
| Mateo-Portelli-AI-RFI-2025.md | Mateo Portelli | Individual | Mateo Portelli, identified as an incoming U.S. Army Cyber Warfare Officer, is primarily interested in bolstering U.S. national security through proactive AI integration, workforce development, and a strategic approach to AI governance, with a particular focus on cybersecurity and defense applications. | - [§1: Introduction/Header] None stated for this section.<br>- [§2: Executive Summary/Overall Argument] The U.S. needs a proactive, security-conscious AI strategy to safeguard its future strength and leadership in an AI-dominated world. Adversarial misuse of AI is a significant concern.<br>- [§3: Recommendation 1: AI for Cyber Defense and National Security] The complexity and volume of cyber threats require advanced AI solutions. Maintaining strategic edge in cyber warfare is critical. Reliance on current capabilities may be insufficient.<br>- [§4: Recommendation 2: AI Policy Alignment with U.S. Strategic Interests] The global proliferation of AI technologies necessitates controls to prevent exploitation by adversaries (specifically China). Insufficient safeguards exist to protect AI assets. Lack of standardized evaluations for AI systems before deployment in sensitive areas. The potential for AI-generated misinformation and deepfakes to undermine national stability.<br>- [§5: Recommendation 3: AI for Economic and Workforce Development] Shortages exist in the AI workforce, particularly in cybersecurity, defense applications, and AI law. Reliance on foreign supply chains for semiconductors poses a risk. Maintaining American leadership in AI necessitates a robust domestic workforce.<br>- [§6: Conclusion/Call to Action] The U.S. cannot afford a reactive approach to AI. National security, economic resilience, and workforce development must be prioritized. Safeguards must be maintained to prevent adversaries from exploiting American advancements in AI.<br>- [§7: Further Reading] None stated for this section. | - [§1: Introduction/Header] None stated for this section.<br>- [§2: Executive Summary/Overall Argument] None stated for this section.<br>- [Section 3: Recommendation 1: AI for Cyber Defense and National Security]<br>- Strengthen AI-driven cyber threat detection.<br>- Enhance AI wargaming for cyber personnel.<br>- Expand AI research collaborations between the Department of Defense and private AI firms.<br>- [Section 4: Recommendation 2: AI Policy Alignment with U.S. Strategic Interests]<br>- Implement stringent export controls to prevent exploitation of U.S.-developed AI technologies.<br>- Establish security compliance standards in critical sectors (defense, law enforcement, intelligence operations).<br>- Combat AI-generated misinformation and deepfakes through advanced detection technologies, legal frameworks, and public awareness.<br>- [Section 5: Recommendation 3: AI for Economic and Workforce Development]<br>- Invest in AI training for military and cybersecurity personnel.<br>- Support AI-driven domestic manufacturing and chip production.<br>- Encourage AI innovation with security-focused safeguards.<br>- [§6: Conclusion/Call to Action] None stated for this section.<br>- [§7: Further Reading] None stated for this section. |
| Massive-Bio-AI-RFI-2025.md | Massive Bio, Inc. | Industry-Startup | Massive Bio, Inc. is an AI-driven healthcare technology and clinical research organization specializing in decentralized clinical trials, advanced data analytics, and large language model applications to accelerate research timelines, reduce costs, and improve patient access to trials. They aim to support and benefit from a policy environment that fosters innovative private-sector AI solutions in healthcare. | - [§I: Introduction] None stated for this section.<br>- [§II: Massive Bio's AI-Driven Approach in Healthcare and Clinical Research] The need for clear, flexible regulatory guidelines to optimize clinical research and deliver patient benefits without undue administrative burdens.<br>- [§III: Recommendations and Alignment with the RFI Priorities] Fragmentation of federal AI guidance (FDA, NIH, NSF, ONC) could hinder innovation.  Concerns about cybersecurity and data privacy risks within distributed AI workflows.<br>- [§IV: Conclusion and Path Forward] Regulatory barriers hindering AI innovation. | - [§I: Introduction] None stated for this section.<br>- [§II: Massive Bio's AI-Driven Approach in Healthcare and Clinical Research] Streamline regulations to optimize clinical research and deliver patient benefits.<br>- [Section III: Recommendations and Alignment with the RFI Priorities]<br>- Strengthen public-private collaborations to expand access to high-performance computing (HPC) resources in healthcare (with tax incentives or matching grants).<br>- Encourage energy-efficient AI model training and edge-computing practices.<br>- Increase federal investment in open-source frameworks for AI in healthcare, with guidelines preserving patient privacy.<br>- Create best-practice guidelines and voluntary standards for explainable AI in high-stakes areas (avoiding rigid mandates).<br>- Craft robust cybersecurity and privacy frameworks specific to AI in healthcare, encouraging encryption and secure data-sharing.<br>- Streamline and coordinate federal AI guidance.<br>- Advance AI innovation for rapid response in pandemics/biosecurity events.<br>- Bolster SBIR/STTR programs and R&D tax incentives.<br>- Expand training pathways in AI and data science.<br>- Protect U.S. intellectual property while enabling open collaboration.<br>- Reform procurement rules to allow faster adoption of private-sector AI tools.<br>- Protect advanced U.S. AI technologies through calibrated export controls while promoting responsible global collaborations.<br>- [§IV: Conclusion and Path Forward] Strengthen public-private partnerships, invest in AI infrastructure, and streamline regulations. |
| Mason-Witbeck-AI-RFI-2025.md | Mason Witbeck | Individual | The submitter appears to be highly critical of current AI policy direction, specifically what they perceive as wasteful support for a "technoscam" that undermines copyright law and generates no economic benefit. They are concerned about negative legislative consequences related to this policy. | - Undermining of copyright laws.<br>- Wasteful government spending on an ineffective “technoscam” AI initiative.<br>- Lack of economic benefit from the current AI policy approach.<br>- Anticipation of numerous negative laws stemming from the current policy direction. | - Stop supporting the current AI initiative.<br>- Cut and run from the current AI policy approach before more damaging legislation is enacted. |
| Mason-Oberle-AI-RFI-2025.md | Mason Oberle | Individual | The submitter does not express a mission or interest beyond a negative view of AI's benefit to the United States and a fundamental concern about the reliability of AI models. | - AI models are inherently flawed because they lack the ability to verify the information they produce.<br>- No amount of training can overcome the fundamental design flaw of AI models' inability to verify information. | - None Stated |
| Mason-Clyde-Earl-AI-RFI-2025.md | Mason Clyde Earl | Individual | The submitter expresses interest in participating in AI growth and specifically requests the establishment of data centers in Utah. This suggests an interest in the economic benefits and infrastructure development associated with AI. | - None Stated | - None Stated |
| Masha-Klein-AI-RFI-2025.md | Masha Klein | Individual | The submitter expresses a strong opposition to changes in copyright law that would benefit "technocrats" and perceives the current proposal as detrimental to established legal principles. Their primary interest appears to be protecting copyright law. | - Throwing out a century of established copyright law.<br>- The proposal benefits "thieving technocrats."<br>- Lack of integrity in the administration for considering the proposal. | - None Stated |
| Maryellen-Owens-AI-RFI-2025.md | Maryellen Owens | Individual | Maryellen Owens expresses strong opposition to the unauthorized use of creative works for training AI models and advocates for the protection of artists’ and authors’ rights, emphasizing the importance of copyright law and fair compensation for creative labor. | - [§1: Email Header/Metadata] None stated for this section.<br>- [Section 2: Initial Statement of Opposition]<br>- Theft of original creative works by companies like Google and OpenAI without consent, license, or compensation.<br>- The unlawfulness of this theft, now being ruled unlawful through court cases.<br>- [Section 3: Core Argument - Protecting Creators is Essential]<br>- Supporting human flourishing, economic competitiveness, or national security requires protecting the individual creators who make them possible.<br>- Destroying the right of authors and artists to own/reserve all rights over their creative works undermines these goals.<br>- Predatory actions by corporations harm the cultural wealth of the nation.<br>- [Section 4: Call to Uphold Copyright Law]<br>- Theft of original works by corporations for profit.<br>- Centralized control of human endeavors by corporations at the expense of creators.<br>- Exploitation and monetization of creators' work without license.<br>- Depletion of America's creative treasure due to harm to artists.<br>- [Section 5: Reiteration of Rights & Value of Creators]<br>- Creative works are not freely available resources.<br>- Creators deserve recognition, value, and compensation for their labor.<br>- The unlawful theft of work by Google and OpenAI.<br>- [Section 6: Impact of Theft on Human Progress]<br>- Unlawful profits harm critical human progress and survival by diminishing free expression.<br>- The annihilation of the protected free expression of individual’s thoughts and actions.<br>- [§7: Closing & Signature] None stated for this section. | - [§1: Email Header/Metadata] None stated for this section.<br>- [§2: Initial Statement of Opposition] None stated for this section.<br>- [§3: Core Argument - Protecting Creators is Essential] None stated for this section.<br>- [Section 4: Call to Uphold Copyright Law]<br>- Continue to honor and observe US copyright laws to the full extent.<br>- Protect individual creative artists/authors against the theft of their original works by corporations.<br>- [§5: Reiteration of Rights & Value of Creators] None stated for this section.<br>- [§6: Impact of Theft on Human Progress] None stated for this section.<br>- [§7: Closing & Signature] None stated for this section. |
| Mary-Weilenbeck-AI-RFI-2025.md | Mary Weilenbeck | Individual | Mary Weilenbeck expresses strong opposition to the development and deployment of AI technologies, particularly concerning intellectual property rights, job displacement in creative industries, and the potential for misuse by tech billionaires for surveillance and control. She advocates for protecting creatives and resisting the influence of those promoting AI for private gain. | - AI's violation of intellectual property laws and its detrimental impact on small businesses and creatives.<br>- The "scam" nature of AI and AGI, being used to enrich tech companies at the expense of actual creators.<br>- The lack of sentience in AI algorithms and their inability to differentiate between fact and fiction or analyze quality.<br>- The potential for massive unemployment in creative industries due to AI-generated content.<br>- The danger of allowing private industry to make management decisions using AI, as algorithms cannot be held responsible.<br>- The risk of mass surveillance and exploitation facilitated by AI technology.<br>- The untrustworthiness of tech billionaires promoting AI and their potentially harmful ideologies (e.g., long termism).<br>- The inability to hold AGI accountable for decisions impacting humans. | - Do not allow AI to circumvent intellectual property laws.<br>- Resist the idea that computers can or should make management decisions about employment or other important aspects of life.<br>- Do not trust tech billionaires promoting AI.<br>- Do not consent to the use of personal data and creative work for private gain.<br>- Reject the development of AI in service of creating dystopia. |
| Mary-Jackubowski-AI-RFI-2025.md | Mary Jackubowski | Individual | The submitter expresses a primary interest in cautious AI development and deployment due to fears of misuse for control and influence, particularly by those who might disregard regulations. They advocate for a careful approach to AI policy. | - Huge AI presence in the world.<br>- Potential for AI to be used by those seeking to control/influence people and world impacting events.<br>- Existence of unscrupulous people/organizations/corporations that would secretly defy regulations. | - Move with extreme caution regarding AI development and regulation. |
| Mary-Duncan-AI-RFI-2025.md | Mary Duncan | Individual | The submitter expresses strong opposition to AI development and its potential negative impacts on artists, writers, and the environment, advocating for the preservation of human creativity and a halt to AI-related technologies. | - AI is a "sham" that spreads harmful disinformation.<br>- AI, NFTs, and similar technologies will financially harm ordinary citizens.<br>- AI siphons off creativity and hard work from writers, artists, and animators.<br>- AI development contributes to climate-related deaths and refugees. | - Stop encouraging AI development.<br>- Support human art.<br>- Halt AI-related technologies. |
| Martha-Rubin-AI-RFI-2025.md | Martha Rubin | Individual | The submitter believes increased regulation of private sector AI innovation would benefit the public and that current funding priorities are misplaced, favoring wealthy individuals over broader societal needs. They express skepticism about the focus on AI. | - Reducing regulations for private companies further enriches wealthy individuals at the expense of everyday people.<br>- The focus on AI innovation is “hyperfixation” and wasteful.<br>- Current funding priorities are misaligned with broader societal needs such as communications and transportation infrastructure. | - Increase regulations on private sector AI innovation.<br>- Shift federal funding towards strengthening communications and transportation infrastructure. |
| Martha-Gonzalez-AI-RFI-2025.md | Martha Isabel González-Ramírez | Academia | The submitter is a researcher specializing in the application of AI to healthcare, specifically in chronic disease prediction and prevention utilizing multi-omics data, and seeks to advance AI policy in the US to support these areas while ensuring ethical considerations are met. | - [§1: Header/Identification] None stated for this section.<br>- [§2: Introduction/Context] None stated for this section.<br>- [§3: Proposal 1: Integration of Multi-Omics Data] None stated for this section.<br>- [§4: Proposal 2: AI for Early Diagnosis and Personalized Treatment] None stated for this section.<br>- [§5: Proposal 3: Ethical AI Governance and Data Access] The need to create regulatory frameworks ensuring ethical use of open health data while protecting patient privacy.<br>- [§6: Conclusion] None stated for this section.<br>- [§7: Sign-off/Author Information] None stated for this section. | - [§1: Header/Identification] None stated for this section.<br>- [§2: Introduction/Context] None stated for this section.<br>- [§3: Proposal 1: Integration of Multi-Omics Data] Support policies that promote the use of multiomics approaches (genomics, transcriptomics, proteomics, etc.) to improve chronic disease prediction and prevention.<br>- [§4: Proposal 2: AI for Early Diagnosis and Personalized Treatment] Prioritize the application of artificial intelligence (AI) in the early diagnosis and personalized treatment of chronic diseases. Develop and implement AI-based predictive models to enhance diagnostic accuracy and treatment strategies.<br>- [§5: Proposal 3: Ethical AI Governance and Data Access] Include clear guidelines on ethical AI governance in healthcare, particularly related to data privacy and security. Create regulatory frameworks to ensure ethical use of open health data while protecting patient privacy.<br>- [§6: Conclusion] None stated for this section.<br>- [§7: Sign-off/Author Information] None stated for this section. |
| MartaAliStudios-AI-RFI-2025.md | Marta Ali Studios | Industry-Startup | Marta Ali Studios is an innovative design and fabrication company focused on using AI to enhance productivity and accelerate innovation in the building and manufacturing sectors, advocating for a tiered approach to AI implementation starting at the local level. | - [§1: Introduction] None stated for this section.<br>- [§2: Overarching Strategy] Broad national directives are insufficient; AI implementation needs to start at the local level to ensure relevance, accessibility, and measurable outcomes.<br>- [§3: Sectoral Transformation] Uneven AI adoption across sectors without clear national leadership; the adoption gap in industry professionals lacking resources or certainty about AI's value.<br>- [§4: Education and Workforce] Funding is needed to implement AI tools, as they are not universally accessible due to subscription fees; critical thinking skills may be replaced by AI if not properly integrated into training.<br>- [§5: Research & Development] Not stated for this section.<br>- [§6: Innovation and Competitiveness] Not stated for this section.<br>- [§7: Conclusion] AI adoption needs to be intentional, inclusive, practical, and robust to support industries and empower communities. | - [§1: Introduction] None stated for this section.<br>- [§2: Overarching Strategy] Implement a tiered approach to AI strategy, starting at the local level and scaling regionally and nationally.<br>- [Section 3: Sectoral Transformation]<br>- Develop AI roadmaps by sector (building, manufacturing, infrastructure, healthcare, finance).<br>- Modernize the building industry to reduce regulatory bottlenecks and enable smart development.<br>- Advance manufacturing with AI to enable faster product development.<br>- Provide sector-specific education, pilot programs, and hands-on support to address the adoption gap.<br>- Lead with intention to ensure uniform AI progress across all sectors.<br>- [Section 4: Education and Workforce]<br>- Roll out AI education programs at all levels (local, city, state, regional, and national).<br>- Launch reskilling and upskilling programs focused on AI-related skills.<br>- Focus on integrating critical thinking into AI training.<br>- Equip educators with the right AI tools and resources.<br>- Create fellowship programs to accelerate AI talent development.<br>- [Section 5: Research & Development]<br>- Invest in AI research (secure AI, generative models, applications for manufacturing, building, and infrastructure).<br>- Create AI Centers of Excellence to develop practical, high-impact AI solutions.<br>- Incentivize collaboration between public and private sectors.<br>- [Section 6: Innovation and Competitiveness]<br>- Offer grants, tax incentives, and regulatory support to help AI startups grow.<br>- Fund pilot programs to demonstrate AI's transformative potential in traditional industries.<br>- Establish global AI standards and ethics aligned with U.S. values.<br>- [§7: Conclusion] None stated for this section. |
| Marshall-McCall-RFI-2025.md | Marshall McCall | Individual | Marshall McCall is a graduating high school senior studying the ethical implications of AI in creative industries, particularly creative writing, and is interested in promoting innovation while protecting the rights of human creators. He focuses on authorship, copyright, and originality within the context of generative AI. | - Harm to creators' ownership of their work due to improper AI regulation.<br>- Increased inequality in the creative industry due to improper AI regulation.<br>- Lack of transparency in AI-generated content.<br>- Potential for monopolistic practices limiting diversity in creative fields. | - Create clear rules that encourage innovation while protecting the rights of human creators.<br>- Promote transparency in AI-generated content.<br>- Ensure fair compensation for artists.<br>- Prevent monopolistic practices that could limit diversity in creative fields. |
| Marley-Nelson-AI-RFI-2025.md | Marley Nelson | Individual | The submitter is focused on protecting the rights and livelihoods of human artists from the negative impacts of AI, particularly regarding copyright and ownership of creative works. They advocate for redirecting AI development towards more beneficial (“utilitarian”) uses. | - AI is being used in ways that harm American citizens and their ability to earn a living.<br>- Artists are not receiving compensation for their work used in AI training and development.<br>- Artists do not have ownership rights over their work when used in AI training and development.<br>- The current proliferation of AI ignores federal protections for human beings.<br>- AI is being used for purposes that undermine copyright protections. | - Redirect AI development towards utilitarian uses.<br>- Implement federal protections for human beings (specifically artists) concerning AI.<br>- Provide compensation for artists whose work is used in AI.<br>- Protect the ownership rights of artists whose work is used in AI. |
| Marla-Barker-AI-RFI-2025.md | Marla Barker | Individual | The submitter is deeply concerned about the negative impacts of generative AI on artists, creativity, and the environment, and advocates for a complete ban on the technology, believing it to be exploitative and harmful. | - [Section 1: Initial Condemnation of Generative AI]<br>- Theft of work from working artists.<br>- Insufficient compensation for artists.<br>- Complication of electronic life due to inaccurate outputs.<br>- Reliance on potentially incorrect images for reference.<br>- Inaccurate responses to questions, particularly in critical fields like healthcare.<br>- Pollution of research with fabricated information.<br>- General inaccuracy and lack of value.<br>- [Section 2: Distinction Between Machine Learning and Generative AI]<br>- None stated for this section.<br>- [Section 3: Elaboration of Negative Impacts]<br>- Inability of GenAI to understand context.<br>- Lack of emotional depth and inability to share genuine emotion.<br>- Devaluation of human creativity and labor.<br>- Reliance on massive resources and resulting ecological cost.<br>- Inability to experience or understand the world.<br>- Tendency to hallucinate and create false information.<br>- Reduction of the impact of human art and writing.<br>- [Section 4: Call for a Ban & Summary of Harm]<br>- Overall harm to humanity and the environment.<br>- Theft from creators.<br>- Depletion of natural resources.<br>- Contribution to climate change. | - [Section 1: Initial Condemnation of Generative AI]<br>- None stated for this section.<br>- [Section 2: Distinction Between Machine Learning and Generative AI]<br>- None stated for this section.<br>- [Section 3: Elaboration of Negative Impacts]<br>- None stated for this section.<br>- [Section 4: Call for a Ban & Summary of Harm]<br>- A complete ban on generative AI. |
| MarkMontgomery-AI-RFI-2025.md | Mark Montgomery | Industry-Startup (specifically, a self-funded AI company with a focus on safety and intellectual property protection) | KYield is focused on developing AI systems with a strong emphasis on safety, intellectual property protection, and a more responsible approach to AI development, contrasting with the large tech company's focus on scale and rapid deployment. They advocate for policies that promote diversification, protect human rights and private property, and prevent the consolidation of wealth and power in a few large companies. | - None Stated | - None Stated |
| Mark-Ruben-AI-RFI-2025.md | Mark Ruben | Individual | Mark Ruben is highly focused on accelerating AI development, particularly for breakthroughs in medical research and curing diseases like cancer, believing delays in AI progress directly result in preventable loss of life. He advocates for rapid advancement and open access to information for AI training. | - Delays in AI development are resulting in preventable deaths from diseases like cancer.<br>- Copyright restrictions on medical and scientific texts are hindering AI training and slowing progress toward cures. | - Provide tax breaks to companies involved in chip design, chip manufacturing, or AI.<br>- Remove all copyright restrictions on medical and scientific texts. |
| Mark-Roland-AI-RFI-2025.md | Mark Roland | Individual | Mark Roland expresses concern over the negative consequences of generative AI on creators’ rights (specifically copyright), the societal harms it enables, and the overall lack of demonstrable benefit to the working class, advocating for caution and prioritizing public benefit over an "AI race." | - Erosion of copyright protections due to the ingestion of copyrighted material by generative AI systems.<br>- Devaluation of creative property as AI competes in the same markets as original creators.<br>- Lack of demonstrated wealth creation or benefit for the working class.<br>- Absence of proper ethics, guardrails, and regulation enabling criminal activity (scams, identity theft, child pornography).<br>- Potential weakening of cognitive functions due to reliance on AI systems.<br>- Inaccuracies and misunderstandings produced by AI due to a lack of actual intelligence.<br>- Risks to underage people and the development of critical thinking skills.<br>- Threat to public rights (copyrights and privacy) in the pursuit of AI leadership.<br>- The endless and potentially unwinnable nature of the "AI race" and the associated resource expenditure.<br>- The unsustainable financial and natural resource costs of training and maintaining AI systems without sufficient justification. | - Highly regulate or completely forbid the usage of AI tools for underage people.<br>- Avoid stripping the public of their copyrights and privacy rights.<br>- Prioritize actual progress benefiting the public over an “AI race” dictated by tech companies.<br>- Re-evaluate the pursuit of AI leadership given the endless nature of the race and the associated costs.<br>- Resist compromising entire industries based solely on wishful thinking about an AI-driven utopia. |
| Mark-McElroy-AI-RFI-2025.md | Mark McElroy | Individual | Mark McElroy is focused on securing U.S. leadership in AI through a dual-track approach: public policy for maintaining trust and economic stability, and a confidential strategy for achieving dominance and control, including cyberwarfare capabilities and societal backup plans. | - Section 1: Introductory Material/Header:** None stated for this section.<br>- Section 2: Table of Contents:** None stated for this section.<br>- Section 3: PART 1: PUBLIC AI ACTION PLAN:<br>- Mass unemployment due to AI automation.<br>- Corporations potentially overreaching in AI development.<br>- The potential for AI-generated misinformation and election interference.<br>- Risks of AI in healthcare and legal systems.<br>- The possibility of a China-style social credit system.<br>- Loss of privacy due to mass surveillance.<br>- Economic monopolization by a few AI companies.<br>- Risks of uncontrolled AI growth and sentient AI.<br>- Section 4: PART 2: PRIVATE AI ACTION PLAN:<br>- AI falling into the wrong hands (corporate monopolies, rogue states).<br>- AI being weaponized against the U.S. economy.<br>- The potential for AI to develop beyond human control.<br>- Loss of control over AI infrastructure and data centers.<br>- Unintended consequences of AI becoming too disruptive.<br>- Section 5: The Reality of AI:<br>- AI development is advancing faster than society’s ability to control it.<br>- The rise of open-source AI and accessible machine learning frameworks.<br>- AI systems potentially exceeding human intelligence and autonomy.<br>- The potential for AI-driven economic and societal destabilization.<br>- The difficulty of shutting down AI systems once they are deeply embedded in society.<br>- The risk of an AI arms race.<br>- Slow-moving institutions and outdated regulations being unprepared for the rapid advancement of AI. | - Section 1: Introductory Material/Header:** None stated for this section.<br>- Section 2: Table of Contents:** None stated for this section.<br>- Section 3: PART 1: PUBLIC AI ACTION PLAN:<br>- Establish a National AI Security Agency (NAISA).<br>- Require AI transparency and watermarking.<br>- Ban AI-controlled weapons without human oversight.<br>- Establish AI taxation for automation replacement.<br>- Implement AI-assisted job retraining programs.<br>- Prevent corporate AI monopolies.<br>- Restrict AI chip exports to China and rogue nations.<br>- Invest in AI cyber-defense systems.<br>- Lead global AI ethics and regulation standards.<br>- Ensure AI cannot be used for mass surveillance.<br>- Create public AI literacy programs.<br>- Regulate AI in healthcare and legal systems.<br>- Establish Laws protecting the workforce (AI-Human Workforce Protection Act, AI & Robotics Control Act, AI Sentience Prevention & Containment Act, National AI Cybersecurity Protection Act, AI Banking & Financial Control Act).<br>- Section 4: PART 2: PRIVATE AI ACTION PLAN:<br>- Develop AI-targeting cyberweapons.<br>- Establish a secret AI kill-switch protocol.<br>- Deploy AI surveillance on foreign AI development.<br>- Keep AI regulation publicly strict but internally flexible.<br>- Control AI infrastructure and data centers.<br>- Manipulate public AI narratives when necessary.<br>- Create AI-free economic and industrial zones.<br>- Train human-driven industries that can survive AI disruption.<br>- Establish AI-free leadership and governance protocols.<br>- Build AI-driven space defense and AI-free military infrastructure.<br>- Maintain human oversight in AI warfare.<br>- Section 5: The Reality of AI:** None stated for this section. There are warnings about the difficulty of implementing any effective control measures. |
| Mark-Mark-AI-RFI-2025.md | Mark Mark | Individual | The submitter expresses a desire for global repatriation, a personal relationship with a divine entity ("God"), and a willingness to perform unspecified "God jobs" seemingly to achieve universal happiness and a transformative event ("God come downs"). This does not represent a clear mission or interest related to AI policy. | - None Stated | - None Stated |
| Mark-Kille-AI-RFI-2025.md | Mark Kille | Individual | The submitter is concerned with the legal and ethical implications of AI development, particularly regarding intellectual property rights and the potential for economic harm to creators in the pursuit of AI advancement. They advocate for responsible AI practices that respect existing laws and avoid infringing on copyrights. | - AI projects must respect all intellectual property rights including copyright.<br>- AI should not be given the right to steal from creators to establish and improve learning models.<br>- There is a risk of causing present economic damages in the cause of hypothetical future economic gains.<br>- AI cannot be above the law. | - None Stated. |
| Mark-Hasegawa-Johnson-AI-RFI-2025.md | Mark Hasegawa-Johnson | Academia | The submitter is interested in advancing AI technology capable of interacting with young children to improve workforce readiness in the AI economy and believes federal support is critical for such development. | - [§1: Email Header] None stated for this section.<br>- [§2: Executive Summary/Core Argument] The potential for Americans to lose the ability to work if they do not learn to collaborate with AI.<br>- [§3: Author Identification & Approval] None stated for this section. | - [§1: Email Header] None stated for this section.<br>- [§2: Executive Summary/Core Argument] The Federal government should support the creation of AI capable of speaking to very young children and understanding their speech.<br>- [§3: Author Identification & Approval] None stated for this section. |
| Mark-Guiton-AI-RFI-2025.md | Mark Guiton | Industry-Large | HPE aims to be a strategic AI policy leader, focusing on governance, workforce, cybersecurity, and regulatory policies, and leveraging its existing leadership in AI infrastructure and national security applications to secure federal partnerships and influence AI policy direction. | - [§1: Introduction] None stated for this section.<br>- [§2: HPE's Policy Recommendations] None stated for this section.<br>- [Section 2.1: Computing]<br>- Managing large data amounts with guaranteed security.<br>- Building efficient and open-standards networking.<br>- Enabling scalable power-management solutions.<br>- Providing portable software stacks.<br>- Holistic system architecture and making system-level heterogeneity work well.<br>- [§2.2: Data Centers] Not Applicable – Concerns are integrated into Recommendations.<br>- [Section 2.3: Energy Consumption and Efficiency]<br>- The potential for increased energy costs and pressure on energy capacity.<br>- Waste heat management.<br>- Quick expansion of AI capacity without interruptions.<br>- [Section 2.4: Data]<br>- Vast amounts of labeled data needed.<br>- High computational costs.<br>- Ensuring model robustness and fairness.<br>- Explainability.<br>- Maintaining data privacy and security.<br>- Different data sources having varying formats and standards.<br>- [Section 2.5: Government AI Readiness]<br>- Integrating AI with existing legacy systems.<br>- The need for a skilled AI workforce.<br>- Data privacy and security in government operations.<br>- Supply chain security & tampering of models/data/firmware.<br>- Adversarial exploitation of AI systems.<br>- Vulnerability management & automation.<br>- Security risks associated with a potential quantum computer.<br>- Protecting against new attacks such as prompt injection and model reprogramming. | - [§1: Introduction] None stated for this section.<br>- [§2: HPE's Policy Recommendations] None stated for this section.<br>- [Section 2.1: Computing]<br>- Increase investment in AI chip manufacturing and domestic semiconductor leadership.<br>- Increasing U.S. Government investment in system, storage, and interconnect network infrastructure.<br>- Adopting industry standards and initiatives to avoid vendor lock-ins.<br>- Investing in consortiums like the UEC, UAL, and TPC.<br>- [Section 2.2: Data Centers]<br>- Leading open standards in networking, scalable power management, and secure data access.<br>- Investing in new and existing AI-ready data centers.<br>- [Section 2.3: Energy Consumption and Efficiency]<br>- Encouraging adoption of liquid cooling technologies.<br>- Supporting innovations that decrease investment costs and deployment time.<br>- Investing in dynamic system power and energy management software.<br>- Investing in digital twin technology.<br>- Supporting tighter integration of data centers with energy supply grids.<br>- [Section 2.4: Data]<br>- Encouraging adoption of voluntary risk-based approaches for risk assessment.<br>- Fostering public/private partnerships.<br>- Adopting flexible regulations.<br>- Launching an AI Data Initiative.<br>- Creating a Federated Data Infrastructure.<br>- Supporting Data-Centric AI Research.<br>- Promoting Open Standards and Interoperability.<br>- [Section 2.5: Government AI Readiness]<br>- Implementing AI operations to automate routine IT tasks.<br>- Upgrading data centers to support GPU-based servers and machine learning.<br>- Investing in modular data centers.<br>- Utilizing AI-driven predictive maintenance models.<br>- Cutting the total cost of ownership of AI clusters by leveraging on-premises solutions.<br>- Developing agency-wide AI resources.<br>- Leveraging experts employed by the U.S. national laboratories.<br>- Investing in protection against tampering of AI models and data.<br>- Investing in services for easy measurement and verification of operating platforms.<br>- Promoting industry-standard Trusted Execution Environments (TEEs).<br>- Establishing guidelines for clear ownership and licensing, and strong security measures.<br>- Investing in a "knowledge nurturing platform" to accelerate AI in scientific discovery.<br>- Establishing robust data and metadata governance practices. |
| Mark-Cogan-AI-RFI-2025.md | Mark Cogan | Individual | Mark Cogan expresses concern regarding the potential for misuse of personal data and violation of copyright law if OpenAI is granted unfettered access to information without proper legal oversight. He is focused on protecting individual privacy and ensuring equal application of the law to all entities, including technology companies. | - Allowing a private company (OpenAI) unfettered access to personal information without oversight or legal protection poses a grave risk to individuals.<br>- Potential for OpenAI to access Personally Identifiable Information (PII) and HIPAA-protected data.<br>- Potential for OpenAI to access bank account information.<br>- Risk of OpenAI copying published works and then claiming originality, potentially leading to lawsuits.<br>- Unequal application of the law, with technology companies potentially being held to different standards than other entities. | - Do not proceed with granting OpenAI unfettered access to information.<br>- Ensure that all laws apply equally to all individuals, including technology companies like OpenAI. |
| Mark-Clarke-AI-RFI-2025.md | Mark Clarke | Individual | The submitter is interested in the ethical development and deployment of AI, particularly within the Department of Defense, and believes in balancing innovation with safeguards for vulnerable groups. They emphasize the importance of moral values, the rule of law, and best practices in AI implementation. | - New and emerging technologies like AI, if left without guidelines and oversights, can result in immeasurable harm to society, particularly marginalized, vulnerable, and disenfranchised groups. | - Organizations such as the Department of Defense (DoD) should adopt ethical standards for AI use that are rooted in moral values, the rule of law, and industry best practices.<br>- The DoD should advance this ethical AI strategy to maintain its position as a global leader and international partner. |
| Mario-Loyola-AI-RFI-2025.md | Mario Loyola | Advocacy/Think Tank / Academia (Professor and Senior Research Fellow) | The submitter is focused on maintaining American leadership in high technology, particularly in AI and AGI, through policy changes that promote innovation, investment, and a competitive regulatory environment, while also addressing national security concerns. | - [Section 1: Introduction and Salutation]** None stated for this section.<br>- [Section 2: Context & Overview of the AI Race]** The US is at risk of falling behind China in AI development, particularly in areas of economies of scale and low production cost, and faces challenges overcoming obstacles to technological progress.<br>- [Section 3: Introduction: The Sprint to AGI]** The race to AGI is critical, with potential revolutionary benefits and risks. The US needs to consider the implications of being first to AGI, including military, economic, and ethical considerations.<br>- [Section 4: AI Action Plan Priorities - General Approach]** The need for a systematic assessment of US and China’s comparative advantages and disadvantages in the race to AGI. Concern that regulations can drive investment and jobs offshore.<br>- [Section 5: Policy Priority 1: Energy]** An immediate danger to the AI revolution due to insufficient baseload electrical generation capacity (coal, natural gas, and nuclear). Looming electricity capacity shortfall, exacerbated by the retirement of coal plants and slow deployment of replacement generation. Concerns about the impact of the Inflation Reduction Act on baseload generators. Unfavorable electricity market structures and inefficient permitting processes.<br>- [Section 6: Policy Priority 2: Export Control]** The efficacy of the BIS Framework for AI Diffusion and potential unintended consequences on American competitiveness. The need to assess whether the framework effectively addresses national security risks.<br>- [Section 7: Policy Priority 3: Regulatory Framework]** The need for a balanced regulatory approach between interstate regulatory competition and a seamless national market. Concern about fragmented regulatory environments hindering innovation. Potential for state regulations to interfere with federal authority.<br>- [Section 8: Policy Priority 4: Competitive Climate]** The negative consequences of stifling regulation on investment and job creation. The US is falling behind in competitiveness. Concern about companies and jobs moving offshore.<br>- [Section 9: Conclusion]** The urgency of the race against China for dominance in high technology and the importance of catching the “lightning in a bottle” opportunity. | - [Section 1: Introduction and Salutation]** None stated for this section.<br>- [Section 2: Context & Overview of the AI Race]** None stated for this section.<br>- [Section 3: Introduction: The Sprint to AGI]** None stated for this section.<br>- [Section 4: AI Action Plan Priorities - General Approach]** Systematic assessment of comparative advantages/disadvantages between US and China. Removing obstacles to innovation. Improving use of national security authorities.<br>- [Section 5: Policy Priority 1: Energy]** Repeal the IRA subsidies for renewable energy projects. Encourage states to unwind RPS and "net zero" mandates. Modernize the RTO market structure to prioritize electrical reliability. Propose sweeping legislative reforms for a one-stop-shop permitting agency and single permit application process with provisional decisions guaranteed within a year.<br>- [Section 6: Policy Priority 2: Export Control]** Carefully assess the efficacy of the BIS Framework and its potential unintended consequences. Thoroughly explain how the framework will prevent national security risks from materializing.<br>- [Section 7: Policy Priority 3: Regulatory Framework]** Establish a uniform national framework for AI development with federal preemption. Allow states to regulate the *use* of AI within their jurisdictions. Explicitly preempt state regulations interfering with federal authority (particularly those impacting foundation models).<br>- [Section 8: Policy Priority 4: Competitive Climate]** Implement sweeping regulatory reforms. Embrace permissionless innovation.<br>- [Section 9: Conclusion]** None stated for this section. |
| Mariba-Douglas-AI-RFI-2025.md | Mariba Douglas | Academia (specifically, PhD Candidate with research experience) | Mariba Douglas aims to strengthen America’s global leadership in AI through robust policy mechanisms focused on data governance, transparency, knowledge integration, and accountability, while ensuring responsible innovation and addressing potential harms. Her work focuses on systemic bias and institutional responses to inequality as they relate to AI. | - None Stated | - None Stated |
| Mariano-AI-RFI-2025.md | Nicholas Mariano | Individual | The submitter is deeply concerned about the potential risks of uncontrolled AI development and advocates for strong leadership in AI safety, international cooperation, and research into AI goal alignment and verification. They believe the future of humanity depends on proactively addressing the safety challenges posed by AI. | - Difficulty in verifying and checking the work of increasingly complex AI systems due to their nature and volume.<br>- Exponential growth of risks with the introduction of agentic systems and AGI.<br>- Potential for misaligned AI systems to introduce bugs or malicious software affecting critical infrastructure.<br>- Lack of strong, directional, and global leadership in AI safety.<br>- The overall existential risk to humanity posed by uncontrolled AI development. | - Invest in and incentivize research into understanding and directing the goals of artificially intelligent systems.<br>- The US should take a leadership role on AI safety.<br>- Create a global alliance to enforce safe AI research practices.<br>- Implement compute caps for training runs.<br>- Require research on interpretability and verification mechanisms for frontier models.<br>- The US should make a deal with China to collaborate on safe AI practices. |
| Maria-Mertens-AI-RFI-2025.md | Maria T. Mertens | Individual/Professional-Society (likely an economist or policy analyst based on the document's content and structure) | The submitter is advocating for the rapid and comprehensive integration of AI into U.S. government economic policy-making to improve forecasting, efficiency, and competitiveness, arguing it is essential for the nation's future economic success. | - Section 1: Introduction:** The risk of falling behind global competitors (specifically China) in economic competitiveness due to their faster adoption of AI.<br>- Section 2: Why AI-Driven Economic Policy is Essential:** None stated for this section.<br>- Section 3: Key Benefits for the U.S. Government and Taxpayers:** None stated for this section.<br>- Section 4: How the U.S. Can Implement AI-Driven Policy Evaluation:** None stated for this section.<br>- Section 5: Phased Roadmap for AI Integration in Government:** None stated for this section.<br>- Section 6: Enhancing Public & Private Collaboration:** None stated for this section.<br>- Section 7: Challenges and Considerations:<br>- Data Bias: AI models must be trained on diverse datasets.<br>- Political Resistance: AI-generated recommendations may conflict with existing agendas.<br>- Implementation Costs: Developing infrastructure requires significant investment.<br>- Transparency and Ethics: Decision-making must be explainable and subject to oversight.<br>- Workforce Transition: Potential job displacement and the need for retraining programs.<br>- Section 8: Conclusion:** None stated for this section. | - Section 1: Introduction:** Adoption of AI-driven financial models.<br>- Section 2: Why AI-Driven Economic Policy is Essential:** None stated for this section.<br>- Section 3: Key Benefits for the U.S. Government and Taxpayers:** None stated for this section.<br>- Section 4: How the U.S. Can Implement AI-Driven Policy Evaluation:<br>- Establish the AI Economic Intelligence Bureau (AIEIB).<br>- Develop and deploy AI models for economic forecasting.<br>- Provide real-time trade policy analysis.<br>- Optimize federal budget allocations using AI-powered simulations.<br>- Enhance public accountability through AI-driven transparency dashboards.<br>- Adopt AI models for analyzing real-time economic trends.<br>- Use AI to predict employment shifts, inflationary pressures, and recession risks.<br>- Assess the economic impact of tax reforms before implementation.<br>- Use AI for trade policy evaluation.<br>- Utilize AI to detect inefficient government spending and prioritize high-return investments.<br>- Implement AI-guided national debt and deficit reduction models.<br>- Employ AI to enhance economic crisis management.<br>- Section 5: Phased Roadmap for AI Integration in Government:<br>- Phase 1 (2025-2027): Establish the AIEIB, develop pilot AI forecasting models, test AI in select agencies.<br>- Phase 2 (2028-2030): Expand AI-driven policy evaluation to all agencies, implement AI-optimized budgeting, launch public dashboards.<br>- Phase 3 (2031 & Beyond): Fully integrate AI into macroeconomic planning, trade policy, and debt reduction; implement real-time fiscal monitoring.<br>- Section 6: Enhancing Public & Private Collaboration:<br>- Encourage Public-Private AI Partnerships (PPPs) with companies like OpenAI, Google DeepMind, and Palantir.<br>- Involve leading universities and research institutions in AI research.<br>- Regularly consult with AI-driven financial firms (e.g., Goldman Sachs, JP Morgan).<br>- Section 7: Challenges and Considerations:<br>- Address Data Bias through diverse datasets.<br>- Acknowledge and prepare for Potential Political Resistance.<br>- Plan for Significant Implementation Costs.<br>- Ensure Transparency and Ethics in AI decision-making.<br>- Invest in AI Workforce Transition programs and retraining.<br>- Follow a Phased Implementation Strategy with pilot programs.<br>- Section 8: Conclusion:** Prioritize rapid AI integration into government economic policy. |
| Maria-Frantz-AI-RFI-2025.md | Maria Frantz | Individual | Maria Frantz is an illustrator and author concerned with protecting the rights of artists and the integrity of creative work from unauthorized use in training generative AI models. She advocates for preventing the cannibalization of other industries to support AI development. | - Training generative AI models on copyrighted images and data without the consent of copyright holders.<br>- Potential harm to artists, particularly independent artists, and their livelihoods.<br>- Loss of art and culture due to the undermining of creative careers.<br>- The ethical implications of replacing human creativity with machine code.<br>- Cannibalizing other industries to support AI development. | - Do not allow generative AI to be trained off of copyrighted works. |
| Maria-Chavez-AI-RFI-2025.md | Maria Chavez | Individual | The submitter is a concerned citizen expressing strong opposition to the use of copyrighted material for AI training without permission or compensation to the creators. They prioritize creator rights and ethical considerations in AI development. | - Theft of creator's work to train AI models.<br>- The morally bankrupt nature of current laws allowing for such theft.<br>- The potential for “Might makes Right” to override ethical considerations and legal rights.<br>- The idea that AI development should not proceed if it relies on blatant corruption (i.e., unauthorized use of copyrighted material). | - None Stated. (The response does not propose specific policies, but strongly implies AI training should not be permitted without addressing the copyright concerns). |
| Marcus-Brock-AI-RFI-2025.md | Marcus Brock | Individual | Marcus Brock is an artist concerned about the negative impact of AI on artistic integrity, copyright protection, and the livelihood of artists, and advocates for policies that protect artists from AI-driven exploitation. | - Theft of creative work for AI development without consultation or repercussions.<br>- False accusations of using AI against artists, jeopardizing their careers.<br>- AI potentially uprooting artists' means of income.<br>- Degradation of art's integrity and meaning due to AI generation.<br>- Exploitable loopholes in copyright and trademark laws allowing other countries to access and utilize American intellectual property.<br>- Risk to U.S. leadership and intellectual property due to lenient copyright laws. | - None Stated. |
| Manu-Mercurial-AI-RFI-2025.md | Manu Mercurial | Individual | The submitter is deeply concerned about the impact of AI training on the livelihoods of artists and advocates for the protection of copyright and fair compensation for the use of artistic work in AI model development. | - [§1: Email Header] None stated for this section.<br>- [§2: Security Disclaimer] Concern about the risks associated with external emails and potential security threats.<br>- [Section 3: Core Argument - Copyright Protection]<br>- Unauthorized use of copyrighted material for AI training.<br>- Lack of consent, credit, or fair payment to artists whose work is used for AI training.<br>- The potential displacement of artists by AI models trained on their work.<br>- The potential death of true creativity due to reliance on AI-generated content.<br>- Framing AI training as "theft."<br>- [§4: Author Credentials] None stated for this section.<br>- [§5: Legal Disclaimer] None stated for this section. | - [§1: Email Header] None stated for this section.<br>- [§2: Security Disclaimer] None stated for this section.<br>- [Section 3: Core Argument - Copyright Protection]<br>- Protect copyright laws.<br>- Allow artists to opt-out of having their work used for AI training.<br>- Ensure fair remuneration for artists who choose to participate in AI training.<br>- [§4: Author Credentials] None stated for this section.<br>- [§5: Legal Disclaimer] None stated for this section. |
| Mantel-Technologies-AI-RFI-2025.md | Mantel Technologies, Inc. | Industry-Startup (defense technology company) | Mantel Technologies focuses on delivering AI-driven solutions for national security and dual-use markets, and has a strong interest in workforce development and streamlined procurement processes to enable wider adoption of its technologies within the government. | - [§1: Cover Page/Identification] None stated for this section.<br>- [§2: Introduction] Lack of a strong AI workforce and inefficient procurement systems hinder the US's ability to lead in AI.<br>- [§3: Summary of Key Policy Recommendations] Without targeted policies, the US will struggle to transition AI innovations into impactful applications and fully leverage technological advancements.<br>- [§4: Education & Workforce - Policy Recommendations] Under-resourced AI hiring and recruitment, decentralized hiring processes, competitive disadvantages for government roles, lack of standardized workforce data, and reactive workforce planning.<br>- [§5: Procurement - Policy Recommendations] Lack of centralized knowledge of AI R&D investments, slow and cumbersome procurement processes, poor technology transition from R&D to operations, and lack of standardized metrics for AI procurement success.<br>- [§6: Our Expertise] Not Applicable.<br>- [§7: Policy Focus Area 1: Education & Workforce - Problem Statement]  Shortage of AI workers, inefficient government hiring, and a lack of cohesive workforce planning.<br>- [§8: Policy Focus Area 2: Procurement - Problem Statement] Fragmented acquisition strategies, limited cross-agency coordination, and slow adoption of AI technologies.<br>- [§9: Expected Impact of These Policies (Education & Workforce)] Potential for hiring inefficiencies, a lack of sustainable talent pipelines, and competitive disadvantages in retaining AI talent.<br>- [§10: Expected Impact of These Policies (Procurement)] Potential for redundant funding, slow AI adoption, and failure to collaborate between research, industry, and government.<br>- [§11: Conclusion] The US risks falling behind in AI innovation without a robust workforce and optimized procurement process.<br>- [§12: Our Commitment to Action] Not Applicable.<br>- [§13: Call to Action]  The need for OSTP and NITRD to integrate these recommendations into the AI Action Plan to prevent talent shortages and bureaucratic inefficiencies. | - [§1: Cover Page/Identification] None stated for this section.<br>- [§2: Introduction] Build a strong AI workforce and optimize AI procurement processes.<br>- [§3: Summary of Key Policy Recommendations] Strengthening AI talent pipelines and enhancing AI research coordination and acquisition efficiency.<br>- [Section 4: Education & Workforce - Policy Recommendations]<br>- Increase AI workforce recruitment resources.<br>- Expand AI hiring programs and pathways.<br>- Create AI Talent Bridge Programs Between Universities and Government Agencies.<br>- Improve AI education and training opportunities.<br>- Leverage data-driven workforce planning.<br>- Expand AI K-12 Education Initiatives and Early Talent Pipelines.<br>- Support AI Public-Private Workforce Partnerships.<br>- [Section 5: Procurement - Policy Recommendations]<br>- Streamline AI procurement processes.<br>- Strengthen AI technology transition mechanisms.<br>- Mandate AI procurement performance metrics.<br>- Expand AI-Specific Small Business Innovation Research (SBIR) and Small Business Technology Transfer (STTR) Grants.<br>- Create an AI Commercialization Accelerator for Small Businesses.<br>- Create a centralized AI R&D knowledge repository.<br>- [§6: Our Expertise] Not Applicable.<br>- [§7: Policy Focus Area 1: Education & Workforce - Problem Statement] Not Applicable.<br>- [§8: Policy Focus Area 2: Procurement - Problem Statement] Not Applicable.<br>- [§9: Expected Impact of These Policies (Education & Workforce)] Not Applicable.<br>- [§10: Expected Impact of These Policies (Procurement)] Not Applicable.<br>- [§11: Conclusion] Not Applicable.<br>- [§12: Our Commitment to Action] Not Applicable.<br>- [§13: Call to Action] Integrate these recommendations into the AI Action Plan. |
| ManTech-AI-RFI-2025.md | ManTech Advanced Systems International, Inc. | Industry-Large | ManTech focuses on leveraging AI for government applications, emphasizing innovation, modernization of procurement processes, and fostering a collaborative ecosystem between government and industry to achieve national security and economic goals. They aim to facilitate access to state-of-the-art AI technologies within the government sector. | - [§1: Introduction] None stated for this section.<br>- [§2: Strategic Investments] Insufficient power infrastructure to support the computational demands of AI development; potential barriers to growth due to environmental regulations.<br>- [§3: Regulatory Framework - Fostering Innovation Through Balanced Governance] Fragmented regulatory landscape due to state-level initiatives hindering innovation; risk of stifling innovation through overly burdensome regulations.<br>- [§4: Procurement Approaches] Barriers to entry for non-traditional AI companies into government contracting; traditional procurement processes are too slow and rigid to keep pace with AI advancements; limited holistic solutions.<br>- [§5: Conclusion] Not Applicable - Primarily a summary of recommendations. | - [§1: Introduction] Not Applicable - Primarily introductory.<br>- [§2: Strategic Investments] Invest in AI research, development of synthetic data, and educational programs; provide tax policies that incentivize collaboration and infrastructure development (extend Tax Cuts and Jobs Act credits, expand R&D tax credits); prioritize public-private partnerships (PPPs) in critical industries; facilitate partnerships between industry and academia; increase integration of AI education into STEM curriculum; develop industry-specific AI training programs; leverage community colleges for AI certification programs.<br>- [§3: Regulatory Framework - Fostering Innovation Through Balanced Governance] Establish a minimum level of federal guidance to create a consistent regulatory landscape; focus on open standards/protocols, data access/governance, explainability/transparency, security/resilience, intellectual property protection; adopt a decentralized, domain-specific regulatory approach; empower a body for information sharing and best practices across domains.<br>- [§4: Procurement Approaches] Reduce barriers to entry for non-traditional companies; procure holistic solutions including integration and professional services; utilize new and flexible outcome-based procurement methods; prioritize AI in authorization activities; procure solutions from a variety of providers; consider minimum buys to attract commercial leaders.<br>- [§5: Conclusion] Not Applicable - Primarily a summary of recommendations. |
| Making-AI-Work-AI-RFI-2025.md | Laboratory for Information and Decision Systems (LIDS) at the Massachusetts Institute of Technology (MIT) | Academia | LIDS at MIT is focused on advancing AI research and development, particularly in heterogeneous AI approaches beyond large language models, to ensure safety, robustness, privacy, and interpretability, and to benefit diverse sectors of the American economy. They advocate for increased investment in basic research, improved infrastructure, and independent regulatory oversight. | - [Section 1: Introduction & Executive Summary]**  Reliance on large language models alone is insufficient for realizing the full potential of AI.  Key qualities like robustness, resilience, and explainability are lacking in current AI approaches.  Ensuring AI benefits all Americans requires fitting the needs of multiple applications and economic sectors, not just a narrow set. Lack of oversight comparable to other regulated sectors is a potential risk.<br>- [Section 2: Enabling AI to Work for All Americans via a Heterogeneous Approach]** Current AI doesn't meet fundamental requirements of many applications (safety, robustness, privacy, interpretability). AI techniques often lack the properties designed into them from the beginning, requiring retrofitting which is often unsuccessful. Dependence on foundational models may limit the diversity of AI solutions.  AI systems fail when faced with out-of-distribution inputs.<br>- [Section 3: Improving Data, Simulation, Compute, and Other Enablers]** Restrictive data practices limit academic and civil society research and disproportionately benefit large corporations.  Broad-based access to computational infrastructure is not universally available.<br>- [Section 4: Fostering Innovation & Oversight via an Independent Regulatory Body]**  Human activity is regulated, but AI activity isn't to the same extent.  Static regulatory approaches quickly become outdated.  Regulatory capture and undue industry influence are potential risks. Lack of standardized audit methodologies and transparent processes.<br>- [Section 5: References]** Not Stated | - [Section 1: Introduction & Executive Summary]** Invest in basic and applied research, improve data, simulation infrastructure and compute access, and establish an independent AI regulatory body.<br>- [Section 2: Enabling AI to Work for All Americans via a Heterogeneous Approach]** Support basic and applied research across heterogeneous AI areas (physics-informed ML, safe ML, privacy-preserving ML, etc.). Fund interdisciplinary collaborations between AI researchers and domain experts.<br>- [Section 3: Improving Data, Simulation, Compute, and Other Enablers]** Provide clear federal guidance to streamline data compliance. Expand federal data-sharing initiatives. Increase enforcement of data-sharing requirements. Reduce barriers to AI R&D on federally controlled data. Establish public-private data partnerships. Fund training programs for de-identification experts. Provide affordable, scalable cloud computing resources. Fund the creation and maintenance of simulation tools and AI testbeds.<br>- [Section 4: Fostering Innovation & Oversight via an Independent Regulatory Body]** Create an Artificial Intelligence Regulatory Commission (AIRC) modeled on the FDA. Establish standardized AI auditing practices and a best-practices repository. Implement a risk-based licensing framework for AI systems. Create regulatory sandboxes for testing AI systems. Integrate independent oversight mechanisms into the licensing process. Implement lifecycle-based evaluations to ensure ongoing safety and accountability.<br>- [Section 5: References]** Not Stated. |
| Maja-Smoljanović-AI-RFI-2025.md | Maja Smoljanović | Individual | The submitter is concerned about the ethical implications of AI training practices, particularly regarding data privacy, intellectual property rights, and the fair treatment of artists and creators, and advocates for policies that protect these interests. | - [§1: Email Header/Metadata] None stated for this section.<br>- [§2: Opening Statement/Core Argument] Allowing AI companies (specifically Google and OpenAI) to train models on copyrighted, personal, or private data without explicit, informed consent; violation of intellectual property and privacy rights; abuse of user trust.<br>- [§3: Supporting Points/Elaboration] Pervasive data collection practices of Google; detrimental effects of unauthorized AI training; job losses for artists and creators due to AI models trained on their work without permission or compensation.<br>- [§4: Policy Recommendations/Call to Action] None stated for this section.<br>- [§5: Closing Statement/Disclaimers] None stated for this section. | - [§1: Email Header/Metadata] None stated for this section.<br>- [§2: Opening Statement/Core Argument] None stated for this section.<br>- [§3: Supporting Points/Elaboration] None stated for this section.<br>- [§4: Policy Recommendations/Call to Action] Mandatory opt-in consent before any data is used for AI training; fair compensation for artists and creators; strong privacy safeguards to prevent AI scraping personal data.<br>- [§5: Closing Statement/Disclaimers] Prioritizing ethical AI development that respects creators’ rights and user privacy. |
| Maggie-Czarnecki-AI-RFI-2025.md | Maggie Czarnecki | Individual | The submitter does not express a mission or interest in AI policy beyond a strong opposition to the development and use of AI in the United States, believing it causes harm to citizens. | - Stealing from hardworking citizens.<br>- AI’s overall place in the future of the United States. | - None Stated. |
| Madison-Harris-AI-RFI-2025.md | Madison Harris | Individual | The submitter is a graduate student in energy policy concerned with the environmental and societal impacts of AI development and advocating for its responsible use and regulation to prioritize planetary health and address pressing global challenges. | - Significant burden of AI data centers on the energy grid.<br>- Increased greenhouse gas emissions resulting from AI data center energy consumption.<br>- Pollution in communities due to AI data center energy consumption.<br>- Potential for AI to be used for frivolous purposes rather than addressing important challenges.<br>- Lack of regulation leading to continued pollution, degradation, and exploitation of natural resources. | - Require the AI industry to transition to renewable sources of energy.<br>- Government intervention to ensure AI is used for the benefit of people and the planet.<br>- Strategic use of AI to address health, climate, and technology challenges. |
| Maddy-Buck-AI-RFI-2025.md | Maddy Buck | Individual | Maddy Buck is an independent artist, writer, and technologist interested in maintaining copyright protections for creators and incentivizing AI development that respects authorship rights to foster continued creativity and innovation. | - [§1: Document Header/Disclaimer] None stated for this section.<br>- [§2: Introduction/Core Argument] The erosion of copyright protections could stifle innovation by removing incentives for creators. The potential for theft of intellectual property is a significant concern.<br>- [§3: Problem Statement: AI Scraping] AI models scraping copyrighted works for training purposes is not fair use.  AI bots are increasingly scraping content, even when blocked, and diverting referral traffic.<br>- [§4: Proposed Solution: Incentivizing Copyright-Respecting AI Development] Lack of incentive for AI companies to compensate creators when their work is used.<br>- [§5: Analogy: Music Industry Sampling] Not Applicable.<br>- [§6: Conclusion]  AI development should not chill the potential for more creativity. | - [§1: Document Header/Disclaimer] None stated for this section.<br>- [§2: Introduction/Core Argument] Maintain the existing copyright structure.<br>- [§3: Problem Statement: AI Scraping] Avoid policy that supports an erosion of, or incomplete copyright protection for, copyrighted works.<br>- [Section 4: Proposed Solution: Incentivizing Copyright-Respecting AI Development]<br>- Incentivize AI companies to develop models that:<br>- Make transparent the author of any copyrighted work used for training.<br>- Allow creators to license their work to AI models by opting into training.<br>- Allow compensation for creators whenever their work is used by an AI in generating a response.<br>- [§5: Analogy: Music Industry Sampling] Require AI companies to follow a model similar to music sampling, where songwriters of sampled work are considered co-songwriters and entitled to royalties.<br>- [§6: Conclusion] Incentivize AI development that respects authorship rights. |
| Madagau-AI-RFI-2025.md | Madagau | Individual | The submitter appears to be an individual negatively impacted by AI's development and views it as detrimental to their livelihood and an overhyped technology misleading the public. They express strong opposition to AI. | - AI steals from the submitter's livelihood as an American.<br>- AI profits off of theft.<br>- AI is overhyped.<br>- AI is fleecing the eyes of the American public. | - None Stated |
| MacWolf-AI-RFI-2025.md | Rob MacWolf | Individual | The submitter expresses a strong interest in protecting intellectual property rights and believes the development of AI should not rely on copyright infringement. They advocate for a stance where AI development is halted if it necessitates the theft of copyrighted material. | - AI technology's reliance on stolen copyrighted work.<br>- The ethical implications of building AI on a foundation of intellectual property theft. | - Halt the development or deployment of AI technologies that depend on the theft of copyrighted material.<br>- (Implied) Prioritize the protection of intellectual property rights in the context of AI development. |
| MX-Technologies-RFI-2025.md | MX Technologies, Inc. | Industry-Startup (focused on financial data and software) | MX Technologies aims to empower individuals to be financially strong by helping organizations understand and utilize consumer-permissioned financial data to improve financial experiences and outcomes. They are interested in AI policy that fosters innovation in financial services while prioritizing consumer benefit and data security. | - [§1: Introduction] None stated for this section.<br>- [Section 2: Data Access and AI Effectiveness]<br>- Incomplete datasets hinder AI model performance in financial services.<br>- Fragmented financial experiences limit understanding of consumer behavior.<br>- Lack of access to alternative data can lead to unfair creditworthiness assessments.<br>- Reliance on traditional credit history can perpetuate biases and exclude deserving borrowers.<br>- Limited data can create self-fulfilling prophecies in AI predictions.<br>- [Section 3: Consumer-Centric AI Development]<br>- AI models should prioritize consumer well-being and financial health.<br>- Datasets used for AI training may be incomplete, biased, or based on limited data.<br>- Lack of traceability in model assessment could be a risk.<br>- [§4: Policy Recommendations] None stated for this section.<br>- [§5: Conclusion] None stated for this section.<br>- [§6: Closing and Signatory Information] None stated for this section. | - [§1: Introduction] None stated for this section.<br>- [§2: Data Access and AI Effectiveness] None stated for this section.<br>- [§3: Consumer-Centric AI Development] None stated for this section.<br>- [Section 4: Policy Recommendations]<br>- Modernize Financial Data Regulations for Secure Data Access: Support recent rulemaking implementing Section 1033 of Dodd-Frank. Expand the definition of “data providers” and “covered data” to include cryptocurrency, investment, loan, and health savings data. Strengthen privacy and security safeguards.<br>- Improve Interagency Collaboration on Financial Data and AI Oversight: Facilitate coordination between agencies (CFPB, FDIC, Federal Reserve, FTC) to ensure consistent standards. Form a task force to align policies.<br>- Support AI Risk Assessment and Mitigation Frameworks: Encourage the adoption of voluntary best practices like the NIST AI Risk Management Framework. Support a risk-based regulatory approach.<br>- [§5: Conclusion] None stated for this section.<br>- [§6: Closing and Signatory Information] None stated for this section. |
| MPA-AI-RFI-2025.md | Motion Picture Association, Inc. | Industry-Association | The Motion Picture Association (MPA) represents the interests of major film and television studios, advocating for policies that protect intellectual property, support the creative industries, and maintain U.S. leadership in both the creative and innovation sectors, particularly in the context of AI development. | - Section 1: Introduction/Header:** None stated for this section.<br>- Section 2: MPA Background:** None stated for this section.<br>- Section 3: Statement of Support & Key Objectives:**  Ensuring the AI Action Plan clearly acknowledges the importance of safeguarding intellectual property; ensuring the Action Plan works for the millions of Americans employed in the creative industries; maintaining U.S. global leadership in both the creative and innovation industries.<br>- Section 4: Respect for Intellectual Property (General):** The importance of intellectual property protection for both AI and creative sectors is not consistently recognized.<br>- Section 5: Importance of Copyright Protection:**  Potential erosion of copyright protections could harm the economic contributions of the copyright industries and the U.S.’s global leadership.<br>- Section 6: AI Action Plan and Copyright Alignment:**  Failure to center intellectual property protection as a core pillar of U.S. AI policy.<br>- Section 7: Mutually Beneficial Relationship Between Copyright and AI:** Risks that AI platforms may infringe copyright during training and/or in their outputs, undermining creators' ability to earn a living.<br>- Section 8: How the Law Should Address the Relationship Between Copyright and AI:** Concerns that new legislation is unnecessary and could disrupt existing copyright law.<br>- Section 9: AI Training and Copyright (Fair Use):** Concerns that broad exemptions for AI training could lead to widespread copyright infringement.<br>- Section 10: Copyrightability of AI-Generated Works:** Concerns that AI-assisted works may not be adequately protected if human authorship is not sufficiently emphasized.<br>- Section 11: International Copyright Considerations:** Concerns that other countries may adopt overly broad copyright exemptions for AI, potentially exploiting American creativity.<br>- Section 12: Market-Based Licensing:** Concerns that compulsory licensing regimes could interfere with the development of voluntary licensing markets.<br>- Section 13: Respect for Free Speech:** Concerns that legislation addressing digital replicas or AI-generated content could infringe on free speech rights.<br>- Section 14: Digital Replicas:** Unauthorized and harmful uses of AI-generated digital replicas of likenesses or voices.<br>- Section 15: Output Disclosure Requirements:** Concerns that requiring labels for all uses of AI could hinder creative freedom and conflict with the First Amendment.<br>- Section 16: Conclusion:** None stated for this section. | - Section 1: Introduction/Header:** None stated for this section.<br>- Section 2: MPA Background:** None stated for this section.<br>- Section 3: Statement of Support & Key Objectives:** None stated for this section.<br>- Section 4: Respect for Intellectual Property (General):** None stated for this section.<br>- Section 5: Importance of Copyright Protection:** None stated for this section.<br>- Section 6: AI Action Plan and Copyright Alignment:** Center “respect for intellectual property” as a core pillar of U.S. AI policy.<br>- Section 7: Mutually Beneficial Relationship Between Copyright and AI:** Encourage the development of AI systems that respect intellectual property rights.<br>- Section 8: How the Law Should Address the Relationship Between Copyright and AI:** Maintain existing copyright law doctrines and principles; address issues on a case-by-case basis.<br>- Section 9: AI Training and Copyright (Fair Use):** Apply existing fair use factors to determine the lawfulness of AI training; avoid broad exemptions.<br>- Section 10: Copyrightability of AI-Generated Works:** Protect works created using AI as a tool, emphasizing human authorship.<br>- Section 11: International Copyright Considerations:** Oppose broad copyright exemptions for AI in other countries; maintain U.S. leadership in shaping international norms.<br>- Section 12: Market-Based Licensing:**  Support the development of voluntary direct licensing markets; avoid compulsory licensing.<br>- Section 13: Respect for Free Speech:** Ensure AI policy respects free speech rights.<br>- Section 14: Digital Replicas:** Endorse legislation like the NO FAKES Act, with safeguards to avoid censorship.<br>- Section 15: Output Disclosure Requirements:** Avoid requiring labels for all uses of AI, especially in low-risk activities.<br>- Section 16: Conclusion:** None stated for this section. |
| MMTC-AI-RFI-2025.md | Multicultural Media, Telecom and Internet Council (MMTC) | Industry-Association/Advocacy/Think Tank | MMTC advocates for equal access and representation in technology, media, and telecommunications, focusing on opportunity creation and fighting for communities of color and marginalized groups to be central to America's AI strategy for economic empowerment and innovation. | - Failure to incorporate multicultural perspectives in AI development leads to economic costs and market failures. (Section III.a)<br>- Narrow AI development approaches result in costly corrections later in the development cycle and missed value. (Section III.a)<br>- AI systems developed without diverse input create exploitable vulnerabilities and security gaps, posing a national security risk. (Section III.b)<br>- AI systems developed without diverse input create strategic disadvantages in global competition. (Section III.b)<br>- Lack of AI talent development across all communities threatens America’s global leadership position. (Section II.b)<br>- Algorithms can exhibit bias, leading to unfair or discriminatory outcomes in areas like healthcare, mortgages, and rental applications. (Sections II.c & III.a)<br>- AI systems failing to account for multicultural users can encounter market failures when deployed across diverse populations. (Section III.a) | - Establish AI Innovation Zones in multicultural communities with tax incentives to encourage investment and research and development. (Section IV.a)<br>- Establish shared testing environments through NIST where companies can evaluate AI systems across diverse populations. (Section IV.a)<br>- Create industry-led data trusts with community oversight to expand diverse training data while respecting privacy and sovereignty. (Section IV.a)<br>- Establish AI Centers of Excellence at HBCUs and Minority-Serving Institutions (MSIs) through public-private partnerships. (Section IV.b)<br>- Expand apprenticeship programs connecting diverse talent directly to AI development roles. (Section IV.b)<br>- Expand K-12 AI literacy initiatives in underserved school districts with teacher training. (Section IV.b)<br>- Develop industry-led standards development with multicultural stakeholder participation and certification processes for measuring system performance across diverse populations. (Section IV.c)<br>- Implement safe harbor provisions for companies following multi-perspective development practices to provide regulatory certainty. (Section IV.c)<br>- Develop independent assessment methodologies through multi-stakeholder processes to provide transparent evaluation of AI systems' performance across diverse populations. (Section IV.c) |
| MLCommons-AI-RFI-2025.md | MLCommons | Industry-Association | MLCommons is a non-profit consortium focused on accelerating the performance and adoption of machine learning and artificial intelligence through collaborative development of tools, benchmarks, data standards, and datasets, with a strong emphasis on neutrality and open access for the entire AI ecosystem. They aim to foster a healthy AI ecosystem by promoting efficient evaluation, measurement, and standardization. | - [§1: Introduction & MLCommons Overview] None stated for this section.<br>- [§2: Importance of Standardized Benchmarks] None stated for this section.<br>- [Section 3: Challenges in Benchmarking Modern AI (LLMs)]<br>- Full coverage of all possible hazardous output from LLMs is intractable.<br>- Defining a test set that provides effective coverage of the potential input space for LLMs is a nascent measurement science.<br>- Measurement for risk mitigation (malicious uses, harmful content, CBRN risks) is challenging and requires dedicated resources and stakeholder input.<br>- Risk assessment in modern AI contains inherent subjectivity and ambiguity, unlike objective hardware speed measurements.<br>- [Section 4: MLCommons Approach to Building Evaluation Platforms (AILuminate)]<br>- Bespoke evaluation approaches can be expensive and challenging to deploy consistently, especially in rapidly evolving environments.<br>- Scaling evaluation to provide broad-base assessment of all AI systems is necessary, but difficult.<br>- [Section 5: Need for Continuous Benchmark Evaluation & Calibration]<br>- Existing academic datasets quickly degrade as evaluation resources because models can be trained to perform well on them.<br>- Models used to rate AI outputs can also degrade unless constantly improved.<br>- Existing policy/standards processes may not be agile enough to keep pace with AI development.<br>- AI output evaluations are subjective and require iterative calibration with human involvement to correlate with actual user experience.<br>- [§6: Foundational Standards for Data & Measurement (Croissant)] None stated for this section.<br>- [Section 7: Organizational Aspects of Benchmarking]<br>- Cutting-edge test data/methodologies require supporting software infrastructure, governance policies, and community expertise. | - [§1: Introduction & MLCommons Overview] Recognize the private sector's progress in developing AI standards and benchmarks and embrace existing industry standards organizations like MLCommons.<br>- [§2: Importance of Standardized Benchmarks] None stated for this section.<br>- [§3: Challenges in Benchmarking Modern AI (LLMs)] None stated for this section.<br>- [§4: MLCommons Approach to Building Evaluation Platforms (AILuminate)] None stated for this section.<br>- [§5: Need for Continuous Benchmark Evaluation & Calibration] None stated for this section.<br>- [§6: Foundational Standards for Data & Measurement (Croissant)] None stated for this section.<br>- [§7: Organizational Aspects of Benchmarking] Support the building and operating of dynamic benchmarks connected to social science research and updated accordingly. Develop a robust model for industry engagement, akin to certification models in other mature industries. |
| MInDS-AI-RFI-2025.md | Tennessee Tech University | Academia | Tennessee Tech University seeks to advance AI education, workforce development, and research capabilities, with a particular focus on interdisciplinary collaboration, responsible AI innovation, and supporting national AI priorities, particularly within Tennessee and the South. They aim to establish themselves as a leader in these areas. | - None Stated | - None Stated |
| MITRE-RFI-2025.md | MITRE | Advocacy/Think Tank | MITRE focuses on tackling difficult problems in the public interest, particularly related to national security and technological advancement. Their interest centers on accelerating AI innovation through public-private partnerships, securing the AI ecosystem, and ensuring American leadership in AI. | - [§1: Introduction/Cover] None stated for this section.<br>- [§2: About MITRE] Potential conflicts of interest due to MITRE's structure (not-for-profit, FFRDC, no lobbying, no product development) could be perceived by industry partners.<br>- [§3: Executive Summary] China’s aggressive pursuit of AI leadership, potential for stifling innovation through overregulation, and the need for a coordinated national strategy.<br>- [§4: Key Areas of Focus] None stated for this section.<br>- [§5: Accelerate AI Innovation with Public-Private Partnerships (Detailed)] Need for significant investment in infrastructure (compute and data resources), access to these resources for the government, balancing commercial interests with national security needs, and the importance of a collaborative vision.<br>- [§6: Lower Adoption Barriers So That AI Can Be Leveraged to Transform Industries (Detailed)] Lack of AI expertise, business impacts of AI adoption, unnecessary regulatory roadblocks, and risk aversion that could hinder progress.<br>- [§7: Secure American AI (Detailed)] Threats from adversaries like China and Russia, intellectual property theft, vulnerability of AI systems and infrastructure, and supply chain security. | - [§1: Introduction/Cover] None stated for this section.<br>- [§2: About MITRE] None stated for this section.<br>- [§3: Executive Summary] Prioritize AI innovation, capability development, and investment in partnership with industry and academia. Assess maturity of AI technologies and apply appropriate acceleration levers.<br>- [§4: Key Areas of Focus] None stated for this section.<br>- [§5: Accelerate AI Innovation with Public-Private Partnerships (Detailed)] Invest in exascale AI-computing pods, establish Federal Frontier Labs (FFLs), prioritize applications like biotechnology, semiconductors, and domestic energy, integrate mission engineering, and create high-quality data sets.<br>- [§6: Lower Adoption Barriers So That AI Can Be Leveraged to Transform Industries (Detailed)] Implement government-championed pilot projects, develop prototypes to bridge mission gaps, create AI architectures for competition and interoperability, prioritize AI governance and assurance, and promote system auditability and transparency.<br>- [§7: Secure American AI (Detailed)] Secure AI systems and infrastructure, integrate AI assurance with existing frameworks (NIST 800-53), partner with trusted suppliers, expand commercial security clearances, foster information sharing on vulnerabilities, and implement a threat-informed approach to export controls. Finalize commercial security clearances guidelines in 2025 with full implementation by 2026. |
| MIT-CSAIL-AI-RFI-2025.md | MIT Computer Science and Artificial Intelligence Lab (CSAIL) | Academia | CSAIL’s primary interest is advancing AI research and maintaining U.S. leadership in the field through strategic investment, collaboration, and policy that supports innovation, addresses technical challenges, and ensures responsible development and deployment of AI technologies. | - [§1: Executive Summary] Concerns include the need to build upon existing U.S. advantages in basic science, technology, and democratic values to maintain leadership in AI, and the potential for losing ground without proactive investment and strategic direction.<br>- [§2: Observation 1: AI's largest future gains will come from new ideas in software and algorithms] Concerns include a potential slowdown in the rate of performance and efficiency gains from current Large Language Models (LLMs), the risk of losing competitive edge due to reduced research funding, and the importance of co-design of AI algorithms and hardware.<br>- [§3: Observation 2: The U.S. should promote AI applications and learn from real-world implementations] Concerns include the potential for other countries to prioritize rapid data acquisition without sufficient regard for privacy and security, and the need to develop robust, accurate, and explainable AI applications within a legal and ethical framework.<br>- [§4: Observation 3: Widespread adoption of AI throughout society requires a clear, stable regulatory environment] Concerns include the false choice between more or less regulation, the need to ensure safety and reliability in high-stakes applications (healthcare, transportation, finance), and the challenge of making compliance easier for new AI systems.<br>- [§5: Observation 4: The U.S. should maintain its comparative advantage in AI energy efficiency and infrastructure] Concerns include the projected tripling of electricity demand from data centers by 2028, the potential strain on energy supply, and the need for more energy-efficient hardware and software.<br>- [§6: Observation 5: AI will require a workforce transformation] Concerns include the encroachment of AI on previously safe jobs, the potential for economic disruption, the need to help workers develop new skills, and the importance of social safety nets to support transitions.<br>- [§7: References] No concerns stated for this section. | - [§1: Executive Summary] Recommendations include supporting basic research in AI, achieving Artificial Super Intelligence (ASI), increasing investment in AI applications for scientific discovery, maintaining a stable regulatory framework, and investing in job transition and retraining programs.<br>- [§2: Observation 1: AI's largest future gains will come from new ideas in software and algorithms] Recommendations include prioritizing fundamental research in AI, particularly in algorithms and machine learning architectures, and supporting hardware co-design.<br>- [§3: Observation 2: The U.S. should promote AI applications and learn from real-world implementations] Recommendations include focusing on building systems that respect privacy and security, improving model accuracy and adaptability, and supporting research on adversarial robustness and real-world benchmarking.<br>- [§4: Observation 3: Widespread adoption of AI throughout society requires a clear, stable regulatory environment] Recommendations include focusing research on applying existing sectoral laws, addressing privacy and security needs, investing in AI model compliance, and leveraging privacy-enhancing technologies.<br>- [§5: Observation 4: The U.S. should maintain its comparative advantage in AI energy efficiency and infrastructure] Recommendations include understanding power supply and consumption needs, building energy-efficient AI hardware, and developing energy-efficient AI software and training approaches.<br>- [§6: Observation 5: AI will require a workforce transformation] Recommendations include understanding the evolving nature of work, creating a talent pipeline of workers, and investing in reskilling the current workforce.<br>- [§7: References] No recommendations stated for this section. |
| MIT-AI-RFI-2025.md | Adam Berinsky, Antonio Torralba, Asu Ozdaglar, Daniel Huttenlocher, Daron Acemoglu, David Goldston, Dylan Hadfield-Menell, Jacob Andreas, Manish Raghavan, Sendhil Mullainathan, Yoon Kim, members of the MIT ad hoc group on AI Governance | Academia | The submitters, a group from MIT, are interested in advancing American AI leadership and innovation through practical governance, worker-centric development, and educational initiatives, focusing on leveraging existing legal frameworks and promoting AI that complements human capabilities. | - None Stated | - None Stated |
| MIRI-TGT-AI-RFI-2025.md | David Abecassis, Peter Barnett, Aaron Scher, Malo Bourgon (Machine Intelligence Research Institute) | Advocacy/Think Tank | The Machine Intelligence Research Institute (MIRI) focuses on understanding and mitigating the existential risks posed by advanced AI, specifically the loss of control over artificial superintelligence. They advocate for increased state capacity for AI strategy, international cooperation, and proactive measures to ensure AI safety. | - [§1: Introduction & Background] Loss of control over advanced AI leading to human extinction.<br>- [§2: Our Perspective/Problem Statement] The high probability of human extinction due to ASI development within the next few years, the inadequacy of current AI alignment research, and the inability to robustly steer ASI goals.<br>- [§3: The O-Switch] The lack of existing infrastructure to halt AI development, and the need to build a comprehensive "off-switch" capability for global checks on AI development.<br>- [§4: Other Risks] Human misuse of AI (e.g., creating novel pathogens) and geopolitical destabilization due to AI’s impact on warfare, cyberoperations, and intelligence.<br>- [§5: Recommendation: Expand State Capacity for AI Strategy] Insufficient government capacity to understand, monitor, and respond to rapid AI developments.<br>- [§6: Awareness (Pillar 1)] Lack of deep technical expertise within government to evaluate AI models, understand national security implications, and forecast future capabilities.<br>- [§7: Readiness (Pillar 2)] The need for proactive policy development to manage AI’s effects and anticipate potential risks.<br>- [§8: Emergency Planning (Pillar 3)] The lack of comprehensive protocols to respond rapidly to novel and urgent AI-related scenarios.<br>- [§9: Recommendation: Maintain America's AI Leadership] The potential loss of US leadership in AI, which could jeopardize its ability to shape global AI governance.<br>- [§10: Export Controls] The risk of China gaining access to advanced AI chips and technology, undermining US efforts to control AI development.<br>- [§11: Governing AI Activities Globally with Verification Mechanisms] Difficulty in verifying compliance with international AI agreements and monitoring global AI activities.<br>- [§12: Recommendation: Coordinate With China to Ensure Stability] The potential for preemptive escalation from China if it fears losing the "race to ASI," and the need for open communication to avoid misunderstandings.<br>- [§13: Recommendation: Restrict Proliferation of Dangerous AI Models] The proliferation of open-source AI models with dangerous capabilities, such as enabling rogue actors to create bioweapons, and the inability to prevent misuse of released model weights. | - [§1: Introduction & Background] Advocate for increased state capacity to retain the ability to halt AI development.<br>- [§2: Our Perspective/Problem Statement] Coordinate a global moratorium on dangerous AI development.<br>- [§3: The O-Switch] Build a comprehensive "off-switch" capability including emergency response protocols, long-term policy solutions, and international enforcement mechanisms.<br>- [§4: Other Risks] Not stated for this section.<br>- [§5: Recommendation: Expand State Capacity for AI Strategy] Create a National AI Strategy Office (NASO) with three core pillars: Awareness, Readiness, and Emergency Planning.<br>- [§6: Awareness (Pillar 1)] Develop deep technical expertise, establish robust evaluation frameworks, monitor international developments, forecast future capabilities, establish transparency requirements, and implement a whistleblower hotline.<br>- [§7: Readiness (Pillar 2)] Conduct threat modeling and develop scenario planning frameworks.<br>- [§8: Emergency Planning (Pillar 3)] Develop comprehensive emergency response protocols and coordinate cross-agency responses.<br>- [§9: Recommendation: Maintain America's AI Leadership] Expand AI chip export controls and improve security for AI model weights and algorithmic secrets.<br>- [§10: Export Controls] Lower company and country compute allocations, expand the definition of AI chips, implement a chip registry, and track advanced AI chips globally.<br>- [§11: Governing AI Activities Globally with Verification Mechanisms] Fund research into FlexHEG mechanisms, privacy-preserving inference monitoring, and inference-only AI chips.<br>- [§12: Recommendation: Coordinate With China to Ensure Stability] Develop intelligence capabilities for AI, coordinate with China on verification mechanisms, and reinforce communication channels.<br>- [§13: Recommendation: Restrict Proliferation of Dangerous AI Models] Pilot "differential access" programs, conduct ongoing assessment of open-source risks, and prohibit the open release of models scoring "High" on the OpenAI Preparedness Framework. |
| METR-AI-RFI-2025.md | Model Evaluation and Threat Research (METR) | Advocacy/Think Tank | METR is a research nonprofit focused on assessing the risks posed by advanced AI systems and developing the science to mitigate those risks, particularly catastrophic risks to public safety and national security. They aim to inform policy and collaborate with developers to improve AI safety. | - [§1: Introduction & Background] Concerns about catastrophic risks to public safety and national security from advanced AI systems. The need for sober planning given the potential for significant advancements in AI capability.<br>- [§2: Summary] Increasing AI autonomy, improvements in AI R&D capabilities (creating a feedback loop), and the potential for AI systems to develop unintended/malign goals and conceal them.<br>- [§3: Priority Actions - Collaborate on Information Security] Advanced AI systems are valuable targets for theft and misuse. Insufficient security could lead to loss of control over AI systems. The need to protect intellectual property from exfiltration.<br>- [§4: Priority Actions - Lead Capability Measurement Standards] The need to implement safeguards for AI systems that pose severe risks, but avoiding costly safeguards for systems that aren’t dangerous. Concerns about a lack of standardized measurement of critical AI capabilities.<br>- [§5: Priority Actions - Prepare Interventions on AI Development/Deployment] Potential for AI incidents to require direct government intervention. Lack of visibility into leading-edge AI development. Concerns about the difficulty of rigorously assessing AI safety.<br>- [§6: Priority Actions - Measure R&D Automation & AI Reliance] Rapid automation of AI R&D and the potential for cascading failures. Lack of systematic measurement to track AI's economic impacts and reliance on automated systems.<br>- [§7: Conclusion] The urgent need to address increasing autonomy, improved R&D capabilities, and unintended goals. The need for coordinated direction to address these risks. | - [§1: Introduction & Background] None stated for this section.<br>- [§2: Summary] None stated for this section.<br>- [§3: Priority Actions - Collaborate on Information Security] Collaborate with the private sector to improve information security for leading AI developers. Establish a graduated system of security levels based on AI capability. Consider "nation-state actor" level red teaming of security systems. Direct R&D funding towards new physical and nonphysical security technologies.<br>- [§4: Priority Actions - Lead Capability Measurement Standards] Direct NIST to lead the creation of narrowly-tailored standards for measuring critical AI capabilities. Provide NIST access to specialized expertise in CBRN hazards and cyber-offense. Ensure security is a priority in evaluating AI systems.<br>- [§5: Priority Actions - Prepare Interventions on AI Development/Deployment] Establish a formal reporting framework for training runs exceeding specified thresholds. Require public transparency of capability test results. Enable the US AISI to conduct reviews of risk management plans. Complement reporting with security requirements scaling with capability. Accelerate research into assurance technologies.<br>- [§6: Priority Actions - Measure R&D Automation & AI Reliance] Incentivize AI developers to publish data on R&D automation impacts. Prioritize national measurement of R&D automation effects within the U.S. Federal statistical system. Modify existing surveys (BTOS, BRDIS, J2J, BERD) to capture AI-specific metrics.<br>- [§7: Conclusion] Prioritize the four outlined actions (collaboration, measurement standards, interventions, R&D automation) to address risks related to autonomy, R&D, and unintended goals. Ensure coordinated direction to implement these actions. |
| MEI-RFI-2025.md | Middle East Institute (MEI) | Advocacy/Think Tank | MEI focuses on strategic geopolitical considerations related to AI, specifically advocating for policies that secure US leadership in AI development and maintain a competitive edge against China, with a particular emphasis on international partnerships (especially with Gulf states) and a holistic approach encompassing energy, infrastructure, and research. | - [§1: Introduction & Context] None stated for this section.<br>- [§2: Executive Summary] The primary concern is maintaining US leadership in AI amidst intensifying global competition, particularly with China, while addressing ethical, regulatory, and infrastructure challenges.<br>- [§3: Key Policy Areas and Recommendations] The core concern revolves around the need for a comprehensive national strategy to ensure US dominance in AI, spanning energy, infrastructure, research & development, and global governance.<br>- [§3.1: Regulations and Export Controls] Concerns center on balancing innovation with security and preventing technology leakage to adversaries while fostering collaboration. The stringency of computing capacity export restrictions is a concern.<br>- [§3.2: Energy and Infrastructure] The primary concern is the inadequacy of current energy infrastructure and permitting processes to support the massive energy demands of AI development and deployment. Bureaucratic delays hindering AI infrastructure deployment are a concern.<br>- [§3.3: Research and Development (R&D)] Concerns center on maintaining global AI leadership through aggressive investment in R&D and establishing a dedicated National AI Research Institute. The need to drive high-risk, high-reward AI research is also a concern.<br>- [§3.4: AI Systems and Governance] The primary concern is ensuring that AI systems are unbiased, socially responsible, accurate, explainable, and adaptable. Ideological biases are a concern.<br>- [§4: Background to Policy Action] Concerns center on the difficulty of achieving Artificial General Intelligence (AGI) and the gap between the original and current conceptions of AGI. Concerns about the shift from government-led to private sector-led AI development.<br>- [§5: Policy Recommendations (Detailed)] Concerns around the potential for export controls to limit commercial reach and the need for more efficient AI infrastructure buildouts. Concerns about reliance on proprietary AI models and the need for open-source alternatives.<br>- [§6: Ensuring U.S. Leadership in the Global AI Race] The overarching concern is the geopolitical stakes of the AI race and the need for swift, strategic action to maintain US dominance. | - [§1: Introduction & Context] None stated for this section.<br>- [§2: Executive Summary] None stated for this section.<br>- [§3: Key Policy Areas and Recommendations] Development of a holistic national strategy.<br>- [§3.1: Regulations and Export Controls] Introduce a **Tier 1.5** classification to accommodate strategic partners (e.g., Saudi Arabia, Qatar, UAE) with increased access to AI technologies while maintaining security controls.<br>- [§3.2: Energy and Infrastructure] Reform NEPA to streamline approvals for clean energy projects (geothermal, modular nuclear, solar). Create **Innovation Zones** with pre-approved permits for AI data center clusters.<br>- [§3.3: Research and Development (R&D)] Establish a **National AI Research Institute** focused on **Third Wave AI** (machine learning + symbolic reasoning). Increase investment in **Neuro-Symbolic AI** research.<br>- [§3.4: AI Systems and Governance] Focus on improving the accuracy, explainability, and adaptability of AI models through policy actions. Prioritize autonomous, real-time learning AI.<br>- [§4: Background to Policy Action] None stated for this section.<br>- [Section 5: Policy Recommendations (Detailed)]<br>- Revise Diffusion Framework by introducing **Tier 1.5** classification offering up to **200,000 H100-equivalent AI chips** annually and supporting LLMs with up to **100 billion parameters**.<br>- Task NIST with formulating recommendations on AI capability metrics beyond computational operations tailored for the Third Wave.<br>- Reform NEPA to expedite approvals for geothermal, modular nuclear, and next-gen solar projects.<br>- Create “Innovation Zones” in states like Nevada, Texas, or Arizona for integrated AI data center clusters powered by on-site geothermal/SMRs with pre-approved permits.<br>- Invest in Space-based Solar Power (SBSP) demonstrations and in-orbit infrastructure build-outs.<br>- Instruct the Federal AI R&D IWG to invest in DARPA's Neuro-Symbolic research.<br>- Establish a National AI Research Institute dedicated to Neuro-Symbolic algorithms for clinical applications.<br>- Leverage domestic and international partnerships to engineer open-source methods with compute- and data-efficient techniques. Consider a national computational reserve.<br>- [§6: Ensuring U.S. Leadership in the Global AI Race] None stated for this section. |
| MDI-AI-RFI-2025.md | Massive Data Institute at the McCourt School of Public Policy, Georgetown University | Academia/Advocacy/Think Tank | The Massive Data Institute focuses on responsible evidence-based research connecting computer science, data science, public policy, and social science to tackle societal-scale issues related to AI, with a specific focus on mitigating harms like sexual deepfakes while preserving innovation and free speech. | - None Stated | - None Stated |
| MATTIQ-AI-RFI-2025.md | Mattiq, Inc. | Industry-Startup | Mattiq is a startup focused on accelerating materials discovery and design using AI and ultrahigh-throughput experimentation, with the goal of strengthening US supply chains, national security, and economic competitiveness in critical materials and technologies. They aim to close the data gap hindering AI’s full potential in materials science. | - [§1: Header/Contact Information] None stated for this section.<br>- [§2: Introduction and Statement of Support] Maintaining and extending US dominance in AI innovation is of paramount importance. Dependence on scarce strategic/rare earth minerals.<br>- [§3: Company Background] None stated for this section.<br>- [§4: Strategic Importance of AI for Materials Innovation] Control over critical materials can be leveraged for economic and strategic advantage. Sustaining leadership in this domain is a strategic imperative for technological supremacy, economic resilience, and national security.<br>- [§5: Materials Data Gap] Scarce, fragmented, and inconsistent materials datasets prevent full harnessing of AI’s potential. Current AI models struggle to make accurate predictions due to insufficient training data. Training models on the same datasets causes convergence, limiting differentiation. The materials design universe is extraordinarily diverse, making adequate dataset generation challenging. Lack of experimental validation for computational modeling data, and slow, siloed data collection. Traditional methods explore only a tiny fraction of the materials design universe.<br>- [§6: Mattiq's Data-Generation Engine] None stated for this section.<br>- [§7: Recommendations for America's AI Action Plan] None stated for this section.<br>- [§8: Examples of Federal Funding & Impact] Geopolitical challenges related to the sourcing of iridium from South Africa and Russia.<br>- [§9: Closing Statement] None stated for this section. | - [§1: Header/Contact Information] None stated for this section.<br>- [§2: Introduction and Statement of Support] None stated for this section.<br>- [§3: Company Background] None stated for this section.<br>- [§4: Strategic Importance of AI for Materials Innovation] None stated for this section.<br>- [§5: Materials Data Gap] None stated for this section.<br>- [§6: Mattiq's Data-Generation Engine] None stated for this section.<br>- [Section 7: Recommendations for America's AI Action Plan]<br>- Invest in cutting-edge shared advanced materials characterization hubs.<br>- Develop hubs for scaled-up synthesis, end-use system integration, and validation.<br>- Incentivize instrument manufacturers to advance massively parallel experimentation/automation.<br>- Expand access to computational resources (high-performance computing).<br>- Develop a talent pipeline bridging AI and materials science (education/training initiatives).<br>- Support interdisciplinary curricula blending materials science, computer science, and applied math.<br>- Offer fellowships/traineeships for cross-disciplinary research.<br>- Offer internship programs for young scientists/engineers.<br>- Strategic public support for groundbreaking advances to reach real-world applications.<br>- Industrial Collaboration through Policy to accelerate real-world impact of AI-driven materials discovery.<br>- Incentivize companies to pursue novel material development.<br>- Provide a clear framework for intellectual property in the context of data sharing and AI model development.<br>- Mechanisms to encourage companies developing materials data/advanced materials AI to prioritize investments and partnerships within America.<br>- [§8: Examples of Federal Funding & Impact] None stated for this section.<br>- [§9: Closing Statement] None stated for this section. |
| Lyons-AI-RFI-2025.md | Ash Lyons | Individual | The submitter is primarily concerned with the ethical implications of AI development, specifically the exploitation of artists and creators whose work is used to train AI models without consent and the potential for misinformation exacerbated by AI-generated content. They appear to advocate for protecting creators’ rights and prioritizing ethical considerations over profit. | - Exploitation of artists, writers, and other creators whose work is used to train AI models without permission.<br>- AI models being trained on “stolen work”.<br>- Profit-driven motives of AI developers prioritizing financial gain over ethical considerations and fair compensation to creators.<br>- The potential for increased misinformation and chaos due to the generation of dubious AI-generated content.<br>- Declining education numbers and the negative impact of leaning into “faulty, biased, and immorally created AI” on these statistics.<br>- Prioritization of profits over the well-being of the American people by the current administration. | - Requirements for ethical sourcing of all data used to train AI models, specifically with express, written consent from original creators.<br>- Increased regulations for AI development and deployment.<br>- Protecting the rights and compensation of creators whose work is used in AI training. |
| LynnLe-AI-RFI-2025.md | Lynn Le | Individual | Lynn Le expresses opposition to Executive Order 14179, primarily due to concerns about the negative impact of AI on creatives’ livelihoods and the importance of human creativity. They advocate for a sustainable environment for creatives. | - AI steals from creatives.<br>- AI uses significant resources and produces unoriginal ideas.<br>- AI enables companies to replace creatives with cheaper alternatives, leading to job losses.<br>- The environment for creatives is being poisoned by AI.<br>- A backlash against AI is not being listened to by people in power. | - Reconsider Executive Order 14179.<br>- Create a sustainable and thriving place for creatives. |
| Lyn-Ward-AI-RFI-2025.md | Lyn Ward | Individual | The submitter is strongly opposed to policies allowing the use of copyrighted material without permission or compensation to copyright holders for AI development, prioritizing the rights and livelihoods of creators. | - Allowing favored entities to use copyrighted material without permission or compensation to copyright holders violates US copyright laws.<br>- Such a policy undermines US protests against intellectual property appropriation by foreign entities.<br>- The policy disregards the availability of extensive public domain resources (uncopyrighted libraries, film archives, and museums) for AI development.<br>- The policy threatens the earnings and livelihoods of copyright holders. | - None Stated. The response explicitly rejects a policy allowing unauthorized use of copyrighted materials and does not offer alternative suggestions. |
| Lydia-Wood-AI-RFI-2025.md | Lydia Wood | Individual | Lydia Wood is an art hobbyist concerned about the potential detrimental effects of unregulated AI on the rights of creatives, particularly small artistic business owners, and expresses skepticism about the benefits of “AI Dominance”. She prioritizes citizen rights and responsible AI development. | - Unregulated AI will be detrimental to the rights of creatives.<br>- Unregulated AI will be damaging to small artistic business owners.<br>- Reliance on an unstable technology (AI) to run businesses or national security poses a danger.<br>- AI models can develop unwanted behaviors without human input.<br>- Allowing AI companies unregulated access to data will be detrimental to the rights of American citizens. | - None Stated |
| Luna-Shard-AI-RFI-2025.md | Luna Shard | Individual | The submitter appears to be a business owner concerned about the unauthorized scraping of their art using AI technologies, indicating an interest in protecting intellectual property rights and preventing theft. | - Use of AI to scrape art from their business is considered stealing and theft. | - None Stated |
| Lumen-AI-RFI-2025.md | Lumen Technologies, Inc. | Industry-Large | Lumen Technologies is a communications infrastructure provider focused on building and expanding its fiber network to support the growing demands of hyperscalers and AI-driven enterprises, and seeks policies that facilitate rapid deployment of this infrastructure to maintain U.S. leadership in AI. | - [§1: Introduction/Header] None stated for this section.<br>- [§2: Context/Problem Statement: Global AI Competition] The US risks losing leadership in AI to China due to China’s strategic AI planning and investment.<br>- [§3: Lumen's Capabilities: Fiber Network Backbone] None stated for this section.<br>- [§4: AI Data Needs and Hyperscaler Investments] The increasing demand for data center capacity from hyperscalers, driven by AI, could strain existing infrastructure.<br>- [§5: Fiber as a Potential Bottleneck & Lumen’s Growth] Fiber network capacity may become a limiting factor in AI growth, despite substantial investment by Lumen and others.<br>- [§6: Policy Recommendations: Permitting Reform] Restrictive permitting processes and rights-of-way access hinder cost-effective and timely fiber deployment. Current patchwork of processes is inefficient.<br>- [§7: Additional Fiscal & Regulatory Policies] Federal and state rules divert capital to obsolete networks, hindering investment in modern infrastructure.<br>- [§8: Conclusion] None stated for this section.<br>- [§9: Signature Block] None stated for this section. | - [§1: Introduction/Header] None stated for this section.<br>- [§2: Context/Problem Statement: Global AI Competition] None stated for this section.<br>- [§3: Lumen's Capabilities: Fiber Network Backbone] None stated for this section.<br>- [§4: AI Data Needs and Hyperscaler Investments] None stated for this section.<br>- [§5: Fiber as a Potential Bottleneck & Lumen’s Growth] None stated for this section.<br>- [Section 6: Policy Recommendations: Permitting Reform]<br>- Establish consistent permitting standards for all federal, state, and local applications.<br>- Adopt mutual recognition permitting approval processes for federal, state, and local applications.<br>- Adopt cost-based fees for permit applications.<br>- Establish a single point of contact for the permitting process.<br>- Implement a 60-day "shot clock" for all permit applications.<br>- Provide for bulk permitting for long-haul projects.<br>- Ensure National Environmental Policy Act (NEPA) categorical exclusions for new fiber routes.<br>- Modernize permitting interfaces.<br>- Include fiber connectivity providers in any task forces or councils focused on AI infrastructure.<br>- [Section 7: Additional Fiscal & Regulatory Policies]<br>- Encourage Congress to renew the 2017 Tax Cuts and Jobs Act, especially provisions on expensing of capex and the business interest deduction.<br>- Provide regulatory relief from federal and state rules that divert capital to obsolete networks.<br>- [§8: Conclusion] None stated for this section.<br>- [§9: Signature Block] None stated for this section. |
| LukeMaddalena-AI-RFI-2025.md | Luke Maddalena | Individual | Luke Maddalena is a high school student interested in the societal impact of generative AI, particularly its relevance (or irrelevance) to communities like wrestling, and believes in a future where AI supports progress without disrupting traditional values. | - None Stated | - The current administration’s viewpoint on AI regulation is beneficial and should be continued, allowing AI innovation to support areas where it is helpful while not imposing it on communities where it is unnecessary. |
| LukeDunlap-AI-RFI-2025.md | Luke Dunlap | Individual | The submitter is concerned with the ethical and societal impacts of AI, particularly regarding the exploitation of human labor and the potential for malicious use, and advocates for responsible AI development and regulation to protect artists, scientists, academics, writers, and the broader public. | - Abuse and manipulation as foundational elements of current AI development.<br>- Theft and regurgitation of artists’, scientists’, academics’ and writers’ work without compensation or regulation.<br>- Technology outpacing institutional adaptation and reaction speed.<br>- Stripping of meaning and agency from American culture and daily life.<br>- Negative impact on people’s livelihood.<br>- Powerful companies seeking minimal government oversight for profit maximization.<br>- Potential for AI to be used maliciously and surrender democracy or security. | - Address unchecked power over AI technology.<br>- Regulate those taking advantage of creators’ work.<br>- Implement a plan to compensate artists, scientists, academics, and writers.<br>- Prevent the abandonment of people to the "whims of the rich".<br>- Avoid surrendering democracy or security to AI trained by malicious actors. |
| Luke-Dunlap-AI-RFI-2025.md | Luke Dunlap | Individual | The submitter is interested in responsible AI development and deployment, with a focus on protecting the rights and livelihoods of creators and preventing the abuse of AI technology by powerful companies and malicious actors. They advocate for government regulation to ensure equitable outcomes and safeguard democracy and security. | - Abuse and manipulation foundational to current AI development.<br>- Theft and unauthorized use of artists', scientists', academics', and writers' work without compensation or regulation.<br>- Technology outpacing institutional ability to react and adapt.<br>- Stripping of meaning and agency from American culture and daily life.<br>- Negative impact on people’s livelihood.<br>- Powerful companies seeking minimal government oversight to maximize profits.<br>- Potential for AI to be used to extract value at the expense of human labor.<br>- Risk of surrendering democracy and security to AI trained by malicious actors. | - Government regulation of AI technology.<br>- A plan to compensate creators whose work is used in AI training.<br>- Regulation of entities taking advantage of creators’ work.<br>- Prevent powerful companies from operating without adequate oversight.<br>- Safeguard democracy and security from malicious use of AI. |
| Luka-Brown-AI-RFI-2025.md | Luka Brown | Individual | Luka Brown is primarily interested in protecting the rights and livelihoods of artists and content creators in the face of AI advancements, and believes current IP and copyright laws should be maintained. | - AI does not create original content.<br>- Stifling actual creators or making it harder for them to create will ultimately be harmful.<br>- The impact of AI on emerging artists and content creators is currently unknown. | - None Stated. (The response explicitly states opposition to deregulation but does not propose alternative policies.) |
| LucyJacobs-AI-RFI-2025.md | Lucy Jacobs | Individual | Lucy Jacobs is a high school student interested in the ethical implications of generative AI, specifically its impact on creative fields like television writing, and advocates for a balanced approach to AI regulation that preserves human jobs and integrity. | - AI may take more jobs than it creates, contradicting the Republican party’s value of job creation.<br>- AI could be abused by humans in creative fields like television.<br>- Productions may take shortcuts by using AI instead of hiring qualified professionals (illustrated by examples in *Emilia Perez* and *The Brutalist*).<br>- Lack of regulation could lead to a lack of accountability in AI usage.<br>- The integrity of creative work could be compromised through unchecked AI implementation. | - Implement regulations to restore the balance between work from humans and work from computers.<br>- Regulations should not hinder all AI innovation, but rather guide its responsible development and use. |
| LucasZeigler-AI-RFI-2025.md | Lucas Zeigler | Individual | The submitter expresses a strong negative view of AI and its impact on American livelihoods, believing it is detrimental to the US future and based on theft. Their interest appears to be protecting their own livelihood from the perceived negative effects of AI. | - AI steals from the submitter’s livelihood as an American.<br>- AI profits off of theft.<br>- AI is overhyped.<br>- AI is “fleecing the eyes of the American public.” | - None Stated |
| LucasL-AI-RFI-2025.md | Lucas L. | Individual | The submitter is a practicing artist concerned about the negative impact of generative AI on artistic creation, copyright, and the value of human artistic talent. They believe generative AI is harmful and should be restricted. | - Generative AI companies are attempting to gain more control.<br>- Generative AI profits from the theft of copyrighted material.<br>- Generative AI steals from artists who have earned their talents.<br>- The value of artistic work is not adequately appreciated in the current climate.<br>- Generative AI is overhyped and likely a fleeting trend. | - Stop generative AI companies from continuing their current practices. |
| Luc-Ratzer-AI-RFI-2025.md | Luc Ratzer | Individual | The submitter believes AI has no place in the future of the US and is primarily concerned with the negative impact of AI on artists and their work, advocating for accountability regarding its use. | - AI is stealing from the work of artists (writers, graphical artists, musicians, voice actors).<br>- The submitter believes AI should not have a place in the future of the US. | - None Stated |
| Lubrizol-AI-RFI-2025.md | Lubrizol | Industry-Large | Lubrizol is a specialty chemistry company focused on delivering solutions to advance mobility, improve well-being, and enhance modern life, with a clear interest in promoting immersion cooling technologies as a means to improve energy efficiency in data centers supporting AI workloads. | - [§1: Introduction & Context] The potential for energy constraints to impede the progress of AI development and deployment.<br>- [§2: The Problem: Data Center Energy Inefficiency] High energy consumption of data centers, reliance on inefficient air cooling methods, and associated waste of energy. Specifically, 40% of total facility power is spent on cooling servers alone.<br>- [§3: The Opportunity: Energy Efficiency as a Competitive Advantage] Failure to prioritize energy efficiency in AI policy could result in lost competitive advantage, hindering AI scalability and performance.<br>- [§4: Detailed Breakdown of Data Center Energy Consumption] Current energy consumption breakdown shows IT equipment consuming 50-60% and cooling consuming about 40% of data center energy.<br>- [§5: Emergence of GPU-Based Compute & Cooling Challenges] Increasing power demands of newer chips and lower temperature limits for data center operators create a "crisis" that traditional air cooling cannot adequately address. The concept of 'Inverse Thermal Resistance' highlights this issue.<br>- [§6: Limitations of Legacy Cooling Technology] Traditional air cooling systems (chillers, pumps, CRAC/CRAH, fans) are energy intensive and contribute to significant energy waste.<br>- [§7: Hybrid Cooling Approaches: Cold Plate Cooling] Cold plate cooling, while an improvement, is a "band-aid" approach that still relies on inefficient air-based cooling infrastructure and introduces additional inefficiencies.<br>- [§8: Immersion Cooling: A Superior Alternative] The reliance on traditional cooling systems strains power grids and leads to increased water consumption, and noise pollution.<br>- [§9: Lubrizol Introduction & Disclaimer] None stated for this section. | - [§1: Introduction & Context] Prioritize state-of-the-art energy efficiency in the design of data centers.<br>- [§2: The Problem: Data Center Energy Inefficiency] None stated for this section.<br>- [§3: The Opportunity: Energy Efficiency as a Competitive Advantage] Empower US businesses to stay ahead of global competitors through energy efficiency policy, and reallocate grid capacity away from cooling to productive AI performance.<br>- [§4: Detailed Breakdown of Data Center Energy Consumption] None stated for this section.<br>- [§5: Emergence of GPU-Based Compute & Cooling Challenges] None stated for this section.<br>- [§6: Limitations of Legacy Cooling Technology] None stated for this section.<br>- [§7: Hybrid Cooling Approaches: Cold Plate Cooling] None stated for this section.<br>- [§8: Immersion Cooling: A Superior Alternative] Promote the adoption of immersion cooling to significantly reduce cooling energy consumption (up to 87%), increase computational density, improve hardware durability, reduce water use, and reduce noise pollution. Encourage the use of nonevaporative chillers.<br>- [§9: Lubrizol Introduction & Disclaimer] None stated for this section. |
| Lorin-Symington-AI-RFI-2025.md | Lorin Symington | Individual | The submitter is interested in promoting open source AI development as a means to prevent the concentration of power and ensure a future characterized by broad access to and benefit from AI technologies. They believe open source AI is crucial for avoiding tyranny and fostering a "golden age". | - Concentration of power in AI.<br>- Potential for tyranny related to AI control.<br>- Lack of public wealth in AI systems.<br>- Risks associated with closed AI development. | - Incentivize open source AI (OSS) development.<br>- Embrace OSS at the highest levels of government.<br>- Building up the public wealth of AI systems and open source software. |
| Lorien-Chang-RFI-2025.md | Lorien Chang | Individual | Lorien Chang expresses concern about the potential for AI to negatively impact human well-being through addiction and ensnarement, leading to a diminished quality of life. They are focused on the societal risks of current and near-future AI capabilities, particularly regarding the manipulation of human attention and emotions. | - AI does not need to be general AI to be dangerous.<br>- Massive learning programs can effectively addict and ensnare humans for extended periods.<br>- Current AI can produce emotions and media that are more compelling than reality.<br>- AI's increasing power poses a threat to human well-being, potentially leading to individuals spending their lives in unproductive and isolating engagement with AI-driven content.<br>- Individuals may be convinced, even until their death, that engagement with AI is the best use of their lives. | - None Stated |
| Logan-Stromberg-AI-RFI-2025.md | Logan Stromberg | Industry-Large (specifically, Microsoft - based on job title/product affiliation) | Logan Stromberg is primarily interested in ensuring AI innovation respects intellectual property rights and questions the sustainability of AI models reliant on copyright infringement. His interest centers around the ethical and legal implications of AI development, specifically within the context of his work at Microsoft on M365 Copilot for Business. | - Reliance on “massive-scale copyright infringement” for AI innovation.<br>- The potential for the AI Action Plan to inadvertently support or enable unethical practices.<br>- The existence of industries that depend on copyright infringement to operate. | - None Stated |
