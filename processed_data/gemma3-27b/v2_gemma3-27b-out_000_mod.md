| Filename | Submitter Name | Submitter Type | Mission/Interest Summary | Key Concerns | Policy Recommendations |
|---|---|---|---|---|---|
| 1Day-Sooner-RFI-2025.md | 1Day Sooner | Advocacy/Think Tank | 1Day Sooner is a non-profit organization focused on accelerating medical innovation to combat disease, and is interested in leveraging AI to improve healthcare outcomes and streamline regulatory processes within the Department of Health and Human Services. | - None stated for Introduction/Executive Summary.<br>- None stated for About 1Day Sooner.<br>- The current federal workforce lacks specialized AI expertise, which is causing adoption delays and potentially hindering American AI leadership.<br>- Current initiatives (HHS AI Council, AI Community of Practice) lack the capacity for hands-on, agency-level implementation.<br>- Review delays and limited interactions with the FDA are significant bottlenecks in drug approval processes.<br>- FDA internal data systems may not be organized with robust access and permission hierarchies, which could hinder AI training and utilization. Data security and privacy concerns exist.<br>- None stated for Conduct an FDA Reviewer Benchmark Test.<br>- Gaps may exist in the accessibility of advanced AI tools (such as LLMs) for FDA reviewers. Streamlining AI procurement is necessary.<br>- Reviewers may lack familiarity with emerging AI technologies and there's a need for collaboration between AI experts and regulatory staff.<br>- None stated for Document Metadata/Disclaimer. | - Focus on strengthening the Department of Health and Human Services, particularly the Food and Drug Administration, to maximize AI's benefits and support American AI leadership.<br>- None stated for About 1Day Sooner.<br>- Workforce development, data readiness, and regulatory refinement are crucial for realizing AI's potential within HHS.<br>- Create an AI Corps within HHS to provide specialized expertise across its ten agencies, modeled after the Department of Homeland Security's AI Corps.<br>- Improve the FDA's efficiency through AI to expedite reviews, reduce costs, and increase patient access to innovative therapies.<br>- Prioritize organizing internal data systems with robust access and permission hierarchies to ensure data is properly structured, accessible, and secure.<br>- Conduct a benchmark test led by the FDA's Office of Digital Transformation and CERSI to evaluate AI-assisted reviews against human reviewers.<br>- Publish a report on AI procurement practices, specifying accessibility of advanced AI tools for FDA reviewers.<br>- Engage reviewers in structured AI workshops and training sessions to familiarize them with emerging technologies.<br>- None stated for Document Metadata/Disclaimer. |
| 3C-AI-RFI-2025.md | Connected Commerce Council (3C) | Industry-Association | The Connected Commerce Council (3C) is a nonprofit organization dedicated to ensuring small businesses have the digital tools they need to thrive, with a specific focus on promoting access to and adoption of AI-powered technologies for small businesses. | - Small businesses may not understand how to use AI tools and may lack access to them, hindering their ability to compete.<br>- None stated for Key Recommendations.<br>- Many small business owners and employees may not know how to effectively harness AI tools.<br>- Overly burdensome "one-size-fits-all" regulations on AI could disproportionately impact small businesses and hinder innovation. Costly compliance requirements could limit AI access to larger businesses.<br>- The patchwork of state laws creates complexity, cost, and legal risk for small businesses, hindering AI adoption. Restrictions on AI inputs could slow development and innovation.<br>- None stated for Conclusion. | - Prioritize policies that will ensure small businesses' ongoing access to and adoption of AI-powered tools.<br>- Promote AI literacy and training to help small businesses effectively adopt and utilize AI technologies.<br>- Avoid overly burdensome regulations that disproportionately impact small businesses and hinder innovation.<br>- Establish a federal AI privacy framework to avoid a patchwork of state laws, simplifying compliance and encouraging adoption of AI tools by small businesses.<br>- Invest in small business-focused AI literacy and training programs.<br>- Establish partnerships among government agencies, universities, and technology companies.<br>- Focus on regulating AI-powered applications in sensitive contexts (healthcare, finance, law enforcement).<br>- Focus regulations on AI outputs rather than inputs.<br>- Avoid making all users of AI models liable for potential misuse or flaws.<br>- Develop a comprehensive federal AI privacy framework that supersedes state laws.<br>- Balance privacy protection with the need for publicly available data for training AI models.<br>- Encourage a fair use-based approach to copyright questions and text- and data-mining exemptions.<br>- Develop a federal standard that provides a smart alternative to overly restrictive European AI privacy laws.<br>- Continue to foster tools that allow America's businesses and economy to flourish. Work with policymakers to ensure U.S. innovation, leadership, and small-business success. |
| A-King-RFI-2025.md | A. King | Academia (Student) | The submitter is a student of AI Policy and Management who advocates for prioritizing consumer protection, transparency, and ethical governance in AI development alongside U.S. leadership in AI innovation, opposing deregulation that could compromise these values. | - Lack of safeguards exposes consumers to risks such as discrimination, misinformation, fraud, and privacy violations.<br>- Revocation of the Biden-Harris AI Executive Order 14110 removes critical consumer protections, particularly regarding explainability, accountability, and safety.<br>- Lack of clear liability and accountability structures for AI developers and deployers.<br>- AI systems inherently reflect biases in training data, potentially embedding structural discrimination and reinforcing societal inequalities.<br>- AI’s data processing capabilities pose significant privacy risks, and the elimination of regulations could weaken privacy rights. Raises serious ethical concerns related to surveillance and deepfake technology.<br>- Hasty deregulation could lead to unintended consequences. The government typically moves slower than the pace of AI development.<br>- Reducing regulatory oversight without strong governance, transparency, and ethical safeguards could lead to harmful, biased, and privacy-invading AI deployments. | - Prioritize consumer protection, transparency, and ethical governance.<br>- None stated for Critique of Deregulation & Revocation of Executive Order 14110.<br>- Establish clear liability and accountability structures for AI developers and deployers. Require mandatory risk assessments for high-impact AI applications.<br>- Make AI decision-making auditable with mechanisms to detect and correct biases. Mandate diverse and representative training datasets. Encourage third-party AI audits for transparency and compliance.<br>- Implement stronger data privacy protections. Require ethical AI impact assessments before deploying AI in public sector/critical infrastructure. Establish a government advisory board on AI ethics.<br>- Pursue smart, adaptive AI policies allowing for agility without sacrificing oversight. Create a federal AI oversight task force with authority to adapt regulations in real-time. Promote public-private collaboration. Align AI policy with international best practices.<br>- Develop a balanced AI Action Plan prioritizing consumer protection, accountability, and responsible innovation. |
| AAAI-AI-RFI-2025.md | AAAI (Association for the Advancement of Artificial Intelligence) | Industry-Association/Professional-Society | AAAI aims to advance understanding of artificial intelligence through research and collaboration, promote responsible AI use, and inform policy directions to ensure US leadership in AI innovation, security, and global competitiveness. | - None stated for Introduction/AAAI Overview.<br>- Insufficient support for fundamental AI research could hinder future innovation and the US's ability to maintain AI leadership. The importance of supporting a wide range of AI approaches, not just the most prominent, is highlighted to maximize overall advancement.<br>- Lack of secure AI systems poses a risk to deployment and effectiveness. Insufficient workforce or burdensome requirements could hinder development of secure systems.<br>- Failing to collaborate with allies and global partners could weaken national security and impede technological advancements.<br>- None stated for Conclusion/AAAI Offer of Support.<br>- None stated for Appendix: AI Innovations Enabled by Federal Funding. | - None stated for Introduction/AAAI Overview.<br>- Increase federal investment in AI R&D in the President's Budget Request each year.<br>- Support the NSF NAIRR and publicize its benefits.<br>- Establish a national award to incentivize and recognize AI technology advances.<br>- Request funding for graduate student research fellowships to attract, cultivate, and promote AI talent.<br>- Request funding for partnerships between universities and industry to increase the real-world impact of academic innovations.<br>- Request increased funding in the NIST AI Safety Institute and grow its workforce by 10% each year.<br>- Solicit input from industry, academia, non-profits, government agencies, and international collaborators to inform standards development while addressing both security and feasibility.<br>- Convene public, periodic international meetings of experts to discuss challenges and questions raised by AI advancements.<br>- Incentivize and encourage open-source releases of AI advances and data sets.<br>- None stated for Conclusion/AAAI Offer of Support.<br>- None stated for Appendix: AI Innovations Enabled by Federal Funding. |
| AABA-RFI-2025.md | Association for the Advancement of Business AI (AABA) | Industry-Association/Advocacy/Think Tank | AABA aims to advance AI-driven innovation and policy in the US, prioritizing national competitiveness and security interests, with a focus on practical implementation and cost-effective solutions. They advocate for a strategic approach to AI development, framing it as a national asset and emphasizing resilience over purely ethical considerations. | - None stated for Introduction/Cover Page.<br>- Previous Executive Order 14110 lacked actionable content to advance American AI leadership.<br>- Insufficient funding commitments for AI research and development.<br>- Lack of concrete success metrics for implementation.<br>- Overemphasis on regulation rather than innovation.<br>- Limited expansion of critical AI computing infrastructure.<br>- Lack of clear research domain prioritization.<br>- Insufficient incentives to retain top AI talent.<br>- Slow implementation timelines.<br>- Complex agency coordination structure.<br>- None stated for Priority Policy Recommendations.<br>- Risks of delivering crucial data to online services (privacy breaches, IP exposure, insufficient retention controls, lack of transparency, data repurposing, etc.).<br>- Dependency on centralized AI providers.<br>- Ambiguity in the definition of "open-source AI."<br>- Lack of interoperability.<br>- Vendor lock-in.<br>- Rapid advancements in AI require continuous recalibration of policies.<br>- Risk of regulatory stagnation.<br>- Need to avoid overregulation.<br>- Failure to maintain technological and strategic dominance in AI.<br>- Potential for compromised infrastructure and economic manipulation by adversaries.<br>- Risk of losing advantage in key AI domains.<br>- Prioritizing ethical ideals over strategic supremacy.<br>- Rigid ethical frameworks stifling innovation.<br>- Overregulation disadvantaging American AI firms.<br>- Failure to leverage dual-use AI technologies.<br>- Adversarial exploitation of AI.<br>- None stated for Conclusion.<br>- None stated for About the Association for the Advancement of Business AI (AABA). | - None stated for Introduction/Cover Page.<br>- None stated for Executive Summary.<br>- None stated for Priority Policy Recommendations.<br>- Establish federal tax incentives for on-premise AI infrastructure.<br>- Create a national certification program for sovereign AI solutions.<br>- Develop a tiered classification system for business data.<br>- Fund research into lightweight AI models.<br>- Establish procurement preferences for sovereignty-preserving AI solutions.<br>- Direct NIST to establish open interoperability standards for AI model exchange.<br>- Create safe harbor provisions for businesses adopting officially recognized AI standards.<br>- Fund open-source reference implementations of key AI security controls.<br>- Establish baseline requirements for model versioning and change management.<br>- Implement testing frameworks for AI system resilience against adversarial attacks.<br>- 18-24 month review cycles for all AI regulations.<br>- Establishment of "innovation sandboxes" allowing controlled testing with regulatory flexibility.<br>- Create sector-specific governance approaches.<br>- Develop implementation guidelines that scale with organization size.<br>- Establish a public-private oversight committee.<br>- Establish dual-use development programs benefiting both defense and commercial sectors.<br>- Create frameworks for responsible information sharing between business and government.<br>- Fund competitive intelligence programs to track international AI developments.<br>- Provide targeted investment in strategic AI domains (quantum computing, autonomous systems, AGI).<br>- Establish a National AI Reserve Corps.<br>- Prioritize strategic supremacy over ethical ideals.<br>- Adopt an adaptive ethics framework.<br>- Implement competitive flexibility in regulations.<br>- Leverage dual-use AI development.<br>- Establish preemptive advantage in strategic domains.<br>- Counter-adversarial exploitation.<br>- Use ethics as geopolitical leverage.<br>- Establish a dynamic regulatory environment.<br>- None stated for Conclusion.<br>- None stated for About the Association for the Advancement of Business AI (AABA). |
| AAN-AI-RFI-2025.md | American Academy of Nursing | Professional-Society | The American Academy of Nursing represents nursing leaders and aims to create solutions that improve health care delivery and outcomes, with a focus on leveraging AI while mitigating potential risks to patient safety, access, and the nursing workforce. They aim to shape AI policy solutions. | - Potential for AI to exacerbate access to care issues.<br>- Risks to patient safety.<br>- Privacy breaches related to data used in AI systems.<br>- Potential for AI to disrupt the health care workforce and replace nurses’ roles.<br>- Threat to the quality of care if AI replaces human connection and interpersonal skills.<br>- Data limitations impacting trust and potentially harming patients.<br>- Lack of data accuracy, validity, and reliability.<br>- Potential for abuse or misuse of AI systems. | - Consider ethical issues associated with AI as the AI Action Plan is developed.<br>- Ensure patients have access to information, education, and secure privacy related to their health care and AI use.<br>- Consider patient, provider, and system burden when developing AI policies.<br>- Support efforts to reduce regulatory burdens while balancing patient privacy protections.<br>- Seek public input from patients, nurses, and systems on how to promote AI benefits while reducing burdens of use.<br>- Invest in research and postmarket surveillance to monitor the impact of deployed AI.<br>- Support continued federally funded work on data and health information technology standards.<br>- Invest in research being conducted at the National Institutes of Health to support AI use in health care.<br>- Support development of comprehensive data sources, inter-professional clinical data, and patient-reported outcomes for AI solutions. |
| AANA-RFI-2025.md | American Association of Nurse Anesthesiology (AANA) | Professional-Society | The AANA represents Certified Registered Nurse Anesthetists (CRNAs) and advocates for their role in healthcare, particularly concerning the safe and effective integration of Artificial Intelligence (AI) technologies into anesthesia care, emphasizing patient safety and the continued importance of CRNA expertise. | - None stated for Header/Submission Information.<br>- None stated for Introduction/Purpose.<br>- None stated for AANA Background.<br>- Potential for system failures.<br>- Risk of algorithmic biases.<br>- Over-reliance on automation leading to reduced human oversight.<br>- Ensuring AI tools complement, rather than replace, clinical judgment and hands-on expertise.<br>- None stated for Recommendations for AI Action Plan.<br>- None stated for Concluding Statement.<br>- None stated for Closing/Contact Information. | - None stated for Header/Submission Information.<br>- None stated for Introduction/Purpose.<br>- None stated for AANA Background.<br>- None stated for AI in Healthcare & Safety Concerns.<br>- AI should enhance CRNAs' ability to deliver safe, high-quality care, not replace their expertise.<br>- Robust patient safety standards, including rigorous validation and continuous monitoring of AI systems.<br>- AI tools must function under the direct supervision of CRNAs and other healthcare professionals.<br>- AI decision-making processes should be evidence-based, transparent, and interpretable.<br>- AI models should be trained on diverse, representative datasets to minimize bias.<br>- Appropriate regulatory safeguards and accountability measures for the development and deployment of AI in anesthesia care.<br>- Utilize AI for facility operations optimization, like OR case scheduling and staffing.<br>- Include the voices of CRNAs in the design, testing, and implementation of AI technologies.<br>- Integrate the principles of patient safety and CRNA expertise into the AI Action Plan.<br>- None stated for Closing/Contact Information. |
| AAP-AI-RFI-2025.md | American Academy of Pediatrics | Professional-Society/Advocacy/Think Tank | The American Academy of Pediatrics (AAP) is a professional organization dedicated to the health, safety, and well-being of infants, children, adolescents, and young adults. Their primary interest in AI policy is ensuring that AI systems used in pediatric healthcare are safe, equitable, and protect the unique vulnerabilities of children. | - None Stated | - None Stated |
| AAU-AI-RFI-2025.md | Association of American Universities (AAU) | Industry-Association (representing Academia) | The Association of American Universities advocates for its member universities and promotes the advancement of research and discovery, with a strong interest in securing federal investment and policies to accelerate AI-enabled scientific progress. They aim to maintain U.S. leadership in AI through focused initiatives, infrastructure development, and workforce training. | - None stated for Introduction & Context.<br>- None stated for Overarching Recommendation: AI for Discovery Initiative.<br>- The need to ensure AI tools are effectively deployed discipline-by-discipline.<br>- A significant compute gap exists between universities and industry. Lack of sufficient computational resources for universities.<br>- Lack of sufficient support for basic and applied AI research. Need for secure and responsible access to anonymized federal data. Ensuring reliability and validation of scientific models.<br>- Need for a skilled workforce in AI across multiple disciplines. Maintaining awareness of needs and technology trajectories between universities and industry. Global competition for scientific talent.<br>- High energy costs affect research universities and may inhibit AI-driven discovery.<br>- The potential for missing a crucial opportunity to establish U.S. leadership in AI-enabled science.<br>- None stated for Document Approval & Reuse Statement. | - None stated for Introduction & Context.<br>- Pursue a focused initiative to accelerate AI for discovery, aligning government investments with industry, universities, and other stakeholders. Focus on computational access, basic/applied research, data platforms, and education/training.<br>- None stated for AI's Role in Scientific Research.<br>- Build support for public compute in the FY 2026 Budget Request. Expand support for the National AI Research Resource (NAIRR). Continue/expand support for existing federal infrastructure investments (NSF, NIH, DOE). Initiate an assessment of current investments and needs.<br>- Build support for basic and applied AI research in the FY 2026 Budget Request. Support projects at multiple scales. Incentivize partnering among universities, industry, and national labs. Support biomedical data platforms. Establish "data observatory" teams to map data inventories and resources.<br>- Build support for AI training and education in the FY 2026 Budget Request. Support mobility between academia and industry. Attract the best AI talent from across the globe.<br>- Reduce energy costs and improve grid reliability. Invest in novel energy-efficient techniques for AI.<br>- Develop an action plan for AI.<br>- None stated for Document Approval & Reuse Statement. |
| ABA-AI-RFI-2025.md | American Bankers Association (ABA) | Industry-Association | The American Bankers Association represents the banking industry and is interested in fostering responsible AI innovation within the financial sector while avoiding overly burdensome regulations that could hinder American leadership in AI. They advocate for leveraging existing bank risk management frameworks as a model for broader AI governance. | - Concern that without meaningful standards, companies developing AI will be scrambling for dominance and hindering interconnectedness of the ecosystem. Also concerned about LLM developers potentially violating website terms of service through screen scraping, which could disincentivize content creation.<br>- Concern that a patchwork of state requirements for AI would be burdensome to national companies and adverse to American dominance. Concern over overly prescriptive regulations like the EU AI Act and the vetoed California bill SB 1047.<br>- None stated for How Banks Use AI.<br>- Concern about the potential for cybersecurity breaches, privacy violations, bias in AI models, risks associated with third-party AI vendors, and the potential for illicit finance activities leveraging AI. Also, concern that field examiners might focus on granular matters rather than true risk areas, stifling innovation.<br>- Concern about the need for clear regulatory outcomes, the ability of regulated entities to deploy effective risk management techniques, and the importance of transparency from governmental agencies regarding their own AI usage.<br>- None stated for Conclusion. | - Recommend that policymakers extend similar standards used by banks to nonbank participants in the AI ecosystem.<br>- None stated for Current State of AI Regulation.<br>- None stated for How Banks Use AI.<br>- None stated for Risk Management of AI.<br>- Congress should pass comprehensive laws establishing an AI risk management framework with strong preemptions.<br>- Regulators should identify clear regulatory outcomes and objectives and enable entities to deploy effective risk management techniques.<br>- Regulators should leverage existing authorities to focus on third-party nonbank AI models and require them to furnish credible information.<br>- Update model risk management guidance to be more reflective of bank operations and AI usage, with a notice and comment period.<br>- Field examiners should focus on inputs, outputs, and outcomes, not granular details of code.<br>- Encourage voluntary strategies like standardized disclosure templates (model cards) and industry certifications.<br>- Develop an approach to explainability leveraging NIST frameworks.<br>- Promote cooperation between industry and government via public/private partnerships.<br>- None stated for Conclusion. |
| ACC-AI-RFI-2025.md | American Chemistry Council | Industry-Association | The American Chemistry Council (ACC) advocates for policies supporting the U.S. chemistry industry, emphasizing its foundational role in the U.S. economy and its critical importance for innovation, manufacturing, and securing American leadership in AI, particularly by ensuring a robust domestic chemical supply chain and smart chemical regulation. | - None stated for Introductory Information.<br>- None stated for American Chemistry Council Overview.<br>- The potential for reliance on foreign chemical supplies and the need to maintain a strong domestic chemical industry.<br>- The backlog of new chemicals awaiting TSCA review is impeding investment in new chemical production in the US; seventy percent of member companies reported choosing to introduce new chemicals outside the U.S. due to EPA challenges.<br>- Concerns about security and bias with open-source development and the potential for higher risk with government AI applications due to more stakeholders.<br>- Loss of safety (AI causing danger or damage).<br>- Loss of security and resiliency (loss of integrity, confidentiality, inability to function).<br>- Instability, unreliability, and invalidity.<br>- AI becoming unexplainable and uninterpretable.<br>- AI becoming unaccountable and untransparent.<br>- AI being unfair and biased.<br>- Loss of privacy.<br>- Potential for “hallucinations” in AI models.<br>- Risks associated with proprietary data being submitted to regulatory agencies.<br>- The need for human oversight during AI development and for model outputs to identify and avoid issues. | - None stated for Introductory Information.<br>- None stated for American Chemistry Council Overview.<br>- None stated for American Chemistry's Importance for AI.<br>- Support the production of chemistries needed to develop new technologies and make new electronics; address the backlog of new chemicals awaiting TSCA review and improve the efficiency of EPA’s New Chemicals Program.<br>- Limit open-source AI development to lower-risk applications; include subject-matter experts in the development of AI models; start with smaller, lower-risk projects before expanding into higher-risk areas.<br>- Involve subject-matter experts in AI model development.<br>- Require additional review for open-source AI models prior to deployment.<br>- Ensure explainability and transparency of AI models used in government activities, including documenting policies and assumptions.<br>- Implement cybersecurity measures for federal regulatory agencies that handle proprietary data.<br>- Provide notice to regulated communities if their proprietary data is processed using AI.<br>- Implement a risk governance structure for AI, including risk mapping, measurement, and management.<br>- Require human oversight by trained personnel.<br>- Validate AI models with test data differing from training data.<br>- Conduct peer review of AI models and their outputs, especially consequential models.<br>- Make references and data used to develop consequential models available for external validation.<br>- Track model outputs over time and maintain initial training data to identify drift.<br>- Include subject matter experts during R&D.<br>- Protect industry intellectual property when agencies require the submission of confidential business information.<br>- Integrate international expert groups to provide input in the development of AI. |
| ACE-AI-RFI-2025.md | Adaptive Computing | Industry-Startup | Adaptive Computing, through its Heidi AI platform, aims to provide accessible supercomputing resources to K-12 and higher education institutions, enabling students to gain hands-on experience with HPC and AI technologies and preparing them for STEM-focused careers. They focus on affordability and ease of integration for schools. | - None stated for Heidi AI Overview.<br>- None stated for ParaTools Pro for E4S™.<br>- None stated for Features & Benefits of Heidi AI.<br>- None stated for Use Cases.<br>- None stated for About Adaptive Computing. | - None stated for Heidi AI Overview.<br>- None stated for ParaTools Pro for E4S™.<br>- None stated for Features & Benefits of Heidi AI.<br>- None stated for Use Cases.<br>- None stated for About Adaptive Computing. |
| ACHP-AI-RFI-2025.md | Alliance of Community Health Plans (ACHP) | Industry-Association | ACHP promotes payer-provider aligned healthcare models and advocates for affordable, coordinated, and comprehensive coverage, with a particular interest in the responsible implementation of AI to improve patient outcomes, privacy, and safety. | - None Stated | - None Stated |
| ACLA-AI-RFI-2025.md | American Clinical Laboratory Association (ACLA) | Industry-Association | ACLA represents leading clinical laboratories and advocates for policies that expand access to high-quality clinical laboratory services, improve patient outcomes, and advance personalized care through the use of innovative technologies like AI. They focus on ensuring AI adoption doesn't hinder access to care or stifle innovation in the clinical laboratory space. | - None stated for Introduction/Cover Letter.<br>- None stated for ACLA's Position on AI in Clinical Laboratories.<br>- None stated for Policy Recommendations.<br>- The use of AI by third-party organizations (Laboratory Benefit Managers - LBMs) to apply front-end proprietary coding edits that lead to automatic denials of claims before plans review for medical necessity.<br>- Significant number of inappropriate claim denials resulting from front-end edits.<br>- Administrative burden on laboratories and providers from resubmitting claims.<br>- Concern that AI/automated systems are being used to automatically deny or impede patient access to necessary services.<br>- Lack of human evaluation in coverage decisions potentially denying medically necessary care.<br>- None stated for Concluding Remarks/Signature.<br>- None stated for Enclosure Information. | - None stated for Introduction/Cover Letter.<br>- None stated for ACLA's Position on AI in Clinical Laboratories.<br>- Regulatory Clarity: Clear and transparent oversight of AI tools.<br>- Flexibility: Policies that are adaptable to the rapid development of AI and consider benchmarks from the AI research community.<br>- Risk-Based Approach: Sector-specific regulation balancing risks and benefits, avoiding overregulation. Leverage existing frameworks and avoid duplication.<br>- Transparency: AI systems should provide clarity regarding validity, reliability, and trustworthiness.<br>- Federal Preemption: Explicit and strong federal preemption to avoid a patchwork of inconsistent state laws.<br>- Privacy: Safeguarding patient data while enabling the use of deidentified data for AI innovation.<br>- Reimbursement: Stable and predictable reimbursement reflective of the value of diagnostics. PAMA reform to prevent payment reductions. Appropriate reimbursement for beneficial AI uses in healthcare.<br>- None stated for Specific Concerns: AI in Coverage Decisions.<br>- None stated for Concluding Remarks/Signature.<br>- None stated for Enclosure Information. |
| ACLI-2-RFI-2025.md | American Council of Life Insurers | Industry-Association | The American Council of Life Insurers (ACLI) represents life insurance companies and advocates for policies promoting financial security and retirement security through life insurance, annuities, and related products. They are interested in responsible AI adoption that enhances these goals while maintaining existing regulatory frameworks and consumer protection. | - None Stated | - None Stated |
| ACLI-RFI-2025.md | American Council of Life Insurers (ACLI) | Industry-Association | The ACLI advocates for policies that promote financial security and retirement security for American families through life insurance, annuities, and related products. They are interested in ensuring the continued growth and responsible implementation of AI within the life insurance sector. | - None stated for Header/Identification.<br>- None stated for Disclaimer.<br>- None stated for Introduction/Context.<br>- None stated for ACLI Overview/Industry Position.<br>- The industry is already well-regulated by state insurance commissioners, and the NAIC AI Model Bulletin is a key component of this regulation.<br>- Potential for redundant federal regulation of an already well-regulated sector.<br>- None stated for Closing. | - None stated for Header/Identification.<br>- None stated for Disclaimer.<br>- None stated for Introduction/Context.<br>- None stated for ACLI Overview/Industry Position.<br>- Continued adoption of the NAIC AI Model Bulletin nationwide.<br>- The federal government should defer to the NAIC and state insurance departments regarding the regulation of life insurers and their products related to AI.<br>- None stated for Closing. |
| ACM-AI-RFI-2025.md | Association for Computing Machinery (ACM) / U.S. Technology Policy Committee (USTPC) | Professional-Society / Industry-Association / Academia | The ACM/USTPC seeks to promote the responsible development and deployment of AI through policy recommendations, research advocacy, and standardization efforts, with a focus on maintaining U.S. leadership in AI innovation and ensuring ethical and beneficial AI applications. | - None Stated | - None Stated |
| ACR-AI-RFI-2025.md | American College of Radiology | Professional-Society | The American College of Radiology (ACR) aims to advance safe, effective, and clinically useful radiology AI innovations and advocates for policies that support the responsible implementation and funding of AI in medical imaging to enhance patient care. | - None Stated | - None Stated |
| ACS-AI-RFI-2025.md | American Chemical Society (ACS) | Professional-Society | The American Chemical Society is interested in the responsible development, deployment, and regulation of artificial intelligence, specifically as it relates to the chemical sciences and broader societal impacts, while fostering innovation and leadership in the field. They emphasize safety, privacy, fairness, and accessibility. | - Potential for harm to human life, health, or the environment; respect for intellectual property rights.<br>- Responsible handling of individual’s data; potential for discrimination, fraud, and privacy invasions emerging from AI use.<br>- Lawful access to training data and obtaining prior authorization for intellectual property use; identification of content and sources used to train AI systems; user awareness of AI presence; accountability for AI system functioning and output.<br>- Ensuring AI literacy; addressing the digital divide; privacy, data security, and student safety in educational AI systems; the need for human intervention and approval in AI-supported decision-making; mechanisms to override or decommission AI systems.<br>- Reinforcement of inequality; disproportionate harm to people or groups; lack of stakeholder engagement.<br>- Rapidly changing laws, regulations, and technology; energy usage and sustainability of AI infrastructure.<br>- Cost and resource dependence of AI technology giving an advantage to large companies; accessibility of infrastructure and data for universities and smaller companies. | - None stated for Principles.<br>- Allow individuals the ability to opt-in/out of data use in AI depending on the use-case; handle sensitive information securely during training and use.<br>- Ensure AI systems are trained on lawfully accessed data with prior authorization for intellectual property; publicly identify content and sources used for training; make users aware of AI presence and use; hold AI actors accountable for system functioning, output, and respecting privacy/dignity.<br>- Promote AI literacy; support educators with workforce training; ensure privacy and data security in educational AI systems; allow for human intervention in decision-making; establish mechanisms to override/decommission problematic AI systems.<br>- Intentionally engage multiple stakeholders when developing and regulating AI; design and deploy AI technologies in a way that does not harm the environment or human life/health/dignity.<br>- Regularly review and update AI guidance to comply with changing laws and technology; consider grid resiliency, energy source variety, efficiency, sustainability, and security as AI infrastructure expands.<br>- Make infrastructure accessible to universities and companies of all sizes; support the development of publicly accessible databases of non-proprietary content and data. |
| ADI-AI-RFI-2025.md | Alliance for Digital Innovation (ADI) | Industry-Association | ADI advocates for the removal of institutional and bureaucratic barriers to the operation of a modern digital government and supports the adoption of innovative commercial technologies, including AI, by the Federal Government. They represent companies providing critical technologies to the government. | - None stated for Introduction.<br>- Unnecessary constraints on low-risk, enterprise-level AI uses could hinder agility and effectiveness.<br>- Current procurement processes may be too slow and inflexible to allow for swift acquisition of innovative AI solutions and engagement with emerging tech providers.<br>- Need to defend against sophisticated cyber-attacks, including those powered by generative AI.<br>- Lack of standardized security practices for AI technology.<br>- Need for stronger partnership between public and private sectors for AI advancement.<br>- Lack of a skilled workforce to sustain AI leadership.<br>- Government data may not be clean, organized, appropriately tagged, or formatted for digital use; paper-based data exists.<br>- None stated for Conclusion.<br>- None stated for Closing. | - None stated for Introduction.<br>- Focus governance on specific risks associated with AI applications.<br>- Identify high-risk AI applications.<br>- Exempt routine enterprise functions (cybersecurity, network management, software development in low-risk environments, data storage) from high-risk classifications.<br>- Increase micro-purchase and simplified acquisition thresholds.<br>- Encourage engagement with emerging tech providers by simplifying procurement procedures.<br>- Support AI-driven cyber defense mechanisms.<br>- Adopt security-forward postures, exempting routine enterprise IT functions from unnecessary constraints.<br>- Work with industry on standards and best practices for AI security.<br>- Drive standards adoption, leveraging NIST.<br>- Establish public-private partnerships.<br>- Facilitate knowledge exchange through forums and workshops.<br>- Develop educational programs and training.<br>- Provide reskilling and upskilling initiatives.<br>- Develop policies to drive good data practices (clean, organized, tagged, formatted, digitized).<br>- Prioritize leveraging existing government data to train AI models.<br>- Develop standard service level agreements for data privacy and security.<br>- Adopt a risk-based approach, modernize procurement, prioritize AI in cybersecurity, foster collaboration, and invest in workforce development.<br>- None stated for Closing. |
| AFB-AI-RFI-2025.md | American Foundation for the Blind (AFB) | Advocacy/Think Tank | The American Foundation for the Blind (AFB) advocates for equal opportunities for people who are blind, have low vision, or are deafblind through advocacy, thought leadership, and strategic partnerships, with a growing focus on ensuring AI technologies benefit and do not harm this population. | - None stated for Introduction/Header.<br>- None stated for AFB Background.<br>- None stated for AI Benefits for People with Disabilities.<br>- Inaccessibility of software applications and website interfaces.<br>- Lack of accessibility in educational technology.<br>- Potential for discrimination or bias in job screening applications (gaps in employment, explicit bias, testing limitations, image/video recognition biases).<br>- Potential for denial of care in healthcare/insurance due to AI biases.<br>- Need for consistent accuracy and quality in AI applications used by blind individuals (high stakes when independent verification is difficult).<br>- Risks of automation bias when accuracy can't be independently assessed.<br>- None stated for Government Recommendations - Research, Innovation, Oversight and Workforce Development.<br>- Potential for false information and improper flagging of individuals in algorithmic decision-making systems.<br>- Biased data and opaque disclosures in child welfare risk assessment models.<br>- Incorrect accusations and hardships resulting from flawed unemployment insurance systems.<br>- Lack of opportunity for blind students to participate in science lessons due to inaccessible materials.<br>- Delays in providing basic computer and assistive technology skills training.<br>- None stated for Government Recommendations - AI Literacy and Upskilling.<br>- None stated for Conclusion/Closing. | - None stated for Introduction/Header.<br>- None stated for AFB Background.<br>- None stated for AI Benefits for People with Disabilities.<br>- None stated for AI Risks for People with Disabilities.<br>- Enact proactive AI regulations that account for harms of algorithmic bias and include strong privacy and accessibility provisions.<br>- Build federal uses of AI on inclusive datasets, properly weighted models, auditing, testing, and risk mitigation.<br>- Ensure consistently accurate information from AI models, supported by citations.<br>- Ensure algorithmic decision-making systems do not produce false information or improperly flag individuals.<br>- Ensure blind students are able to learn science, technology, and mathematics from an early age.<br>- Enforce the Individuals with Disabilities Education Act, the Americans with Disabilities Act, and Section 504 of the Rehabilitation Act.<br>- Make AI literacy and upskilling courses accessible to people with disabilities regardless of the provider.<br>- Adopt a comprehensive AI action plan that promotes benefits for and use by people with disabilities.<br>- Implement a coordinated whole-of-government approach to accessibility, data representation, and workforce development. |
| AFP-AI-RFI-2025.md | Americans for Prosperity | Advocacy/Think Tank | Americans for Prosperity aims to promote policies that foster economic growth, innovation, and individual liberty, with a strong interest in ensuring the US maintains global leadership in AI through a limited regulatory approach and expansion of energy infrastructure. | - None Stated | - None Stated |
| AFRICA4DEV-AI-RFI-2025.md | Africa Tech for Development Initiative - Africa4dev | Advocacy/Think Tank | Africa4Dev is committed to fostering responsible AI development, ethical AI policy, and inclusive technological advancement, particularly benefiting communities in the Global South, with a focus on data representation, ethical standards, and sustainable policies. They aim to ensure AI benefits all communities and aligns with human rights and equitable global participation. | - None Stated | - None Stated |
| AHCapitalManagement-AI-RFI-2025.md | AH Capital Management, LLC (also referenced as Andreessen Horowitz or a16z) | Industry-Startup (focus on venture capital investing in AI startups, with a strong emphasis on "Little Tech") | AH Capital Management advocates for policies that foster American leadership in AI, particularly by supporting startups ("Little Tech") and reducing barriers to competition, while emphasizing the importance of government investment in infrastructure and talent. They believe a national policy is needed to secure US competitiveness and national security in the AI landscape. | - None stated for Introduction.<br>- Current US leadership is threatened by foreign competition, particularly from China. The regulatory environment could stifle innovation if it favors larger platforms over startups.<br>- Failure to establish a national AI policy could slow American AI development and allow other countries to surpass the US.<br>- A patchwork of state-specific regulations creates compliance burdens that hinder AI development. The AI market requires a national approach.<br>- Restrictions on AI model development stifle competition and innovation. Burdening developers with pre-emptive regulations is detrimental. Regulations should focus on misuse of AI, not on the models themselves.<br>- Burdening AI development is less effective than punishing misuse. New, AI-specific prohibitions are largely unnecessary.<br>- Aggressive interpretations of copyright law could hinder AI training and put US developers at a disadvantage compared to those in other countries.<br>- Startups often lack the resources for model development and may be at a competitive disadvantage.<br>- Startups need access to reliable, affordable infrastructure, including compute power and data.<br>- A shortage of qualified AI talent could hinder US competitiveness.<br>- Open-source models promote innovation and competition but may be disadvantaged without support.<br>- None stated for Conclusion. | - None stated for Introduction.<br>- None stated for Introduction to Key Arguments.<br>- Establish a federal leadership role in regulating the AI model market.<br>- The federal government should take the lead in regulating the AI model market, preempting state-specific restrictions.<br>- Focus on regulating the *use* of AI, not the models themselves. Punish harms caused by AI misuse.<br>- Enforce existing laws against misuse of AI rather than creating new regulations. Issue guidance clarifying that existing laws apply to AI-related harms.<br>- Clarify that existing copyright law protects the ability of developers to train models even using copyrighted works. The Department of Justice should file statements of interest in pending copyright litigation.<br>- Invest in AI infrastructure and talent.<br>- Establish a National AI Competitiveness Institute (NAICI) to provide access to infrastructure, data, and benchmark resources. Develop a national "AI-Ready Data Initiative." Explore regional AI hubs. Support public-private partnerships for infrastructure access.<br>- Support workforce development initiatives, including improving STEM education and expanding research programs. Modernize the National Apprenticeship Act. Establish public-private partnerships for AI training.<br>- Continue support for open-source models.<br>- Urge the Office of Science and Technology Policy to set out a National AI Action Plan that enables "Little Tech" to thrive. |
| AHIMA-AI-RFI-2025.md | AHIMA | Industry-Association/Professional-Society | AHIMA represents health information professionals and is interested in the responsible implementation of AI in healthcare to improve data accuracy, efficiency, and patient outcomes, while ensuring trust, security, and fairness. They advocate for policies that promote AI innovation within a robust regulatory framework. | - None stated for Header/Disclaimer.<br>- None stated for Letterhead/Address & Salutation.<br>- The need for a robust policy plan to fully leverage the potential of AI in American healthcare. Challenges in ensuring health information is accurate, complete, and available.<br>- None stated for AHIMA Recommendations.<br>- Existing challenges in healthcare technology may hinder AI implementation. The importance of addressing these challenges to maximize AI’s potential. Lack of statutory authority for agencies to regulate AI.<br>- Need for strong private-public sector partnerships for successful policy outcomes.<br>- None stated for Closing/Contact Information. | - None stated for Header/Disclaimer.<br>- None stated for Letterhead/Address & Salutation.<br>- None stated for Introduction/About AHIMA.<br>- Ensure robust regulatory guidelines centered on fairness, accuracy, security, and transparency are developed for both clinical and non-clinical AI.<br>- Structure regulatory frameworks with sufficient flexibility to allow for continued AI development and innovation.<br>- Focus on the intended use and desired outcome of the AI when determining the efficacy of the technology.<br>- Prioritize end-users' input - including HI professionals - throughout the development and realworld testing of AI technology.<br>- Develop an updated set of privacy and security policies to better encapsulate new challenges and needs posed by the use of AI in healthcare settings.<br>- Maintain a focus on reducing unintended outputs and unplanned biases within AI models to ensure outputs remain stable and can be utilized across multiple settings with limited maintenance.<br>- None stated for Importance of Trusted AI & Challenges.<br>- Promote private-public partnerships relating to the development and use of AI.<br>- None stated for Closing/Contact Information. |
| AHIP-AI-RFI-2025.md | AHIP | Industry-Association | AHIP represents health insurance plans and is interested in promoting the responsible adoption of AI in healthcare to improve outcomes, efficiency, and reduce costs while ensuring patient safety, privacy, and innovation are maintained. They advocate for a balanced regulatory approach and public-private partnerships. | - None stated for Introduction/Cover Letter.<br>- Not Applicable – This section primarily *describes* use cases, not concerns.<br>- Concerns about additional administrative burdens and costs from inconsistent national oversight; ensuring existing laws aren't duplicated; potential competitive disadvantage due to disclosure requirements.<br>- Concern about duplication of existing standards development efforts and stifling innovation through inconsistent state laws.<br>- Concern about overly restrictive policies and micromanagement of business practices through mandatory third-party evaluation, audits, or disclosure of proprietary information.<br>- Concerns about lack of established roles and responsibilities between AI developers and deployers, transparency requirements and the potential impact on intellectual property, overwhelming consumers with too much disclosure, and lack of broadly applicable standards.<br>- Not Applicable – This section outlines benefits, not concerns.<br>- None stated for Conclusion. | - Support for a national AI action plan and realizing the potential of AI.<br>- None stated for Health Plan Use of AI.<br>- Take a federal approach to AI oversight for consistency.<br>- Define "AI" using NIST’s AI Framework.<br>- Rely on existing laws and fill gaps only.<br>- Provide high-level oversight with flexible guardrails.<br>- Promote risk-based approaches with evaluation requirements limited to “high-risk” uses.<br>- Protect intellectual property with transparency requirements.<br>- Engage in public-private partnerships.<br>- Advance standards and defer to industry standards where they exist.<br>- Guard privacy with existing regulations and avoid a new private right of action.<br>- Use existing national frameworks and standards, like NIST AI Risk Management Framework; preempt state laws to promote standardization.<br>- Apply a risk-based approach to AI oversight; focus on monitoring outcomes rather than micromanagement; avoid broad mandatory audits.<br>- Delineate roles and responsibilities between developers and deployers.<br>- Require AI vendors to transparently disclose key elements of tools.<br>- Focus on "use disclosures" relevant to risk mitigation without preventing disclosure or monetization.<br>- Provide patient, consumer, and caregiver education.<br>- Avoid overwhelming consumers with excessive disclosures.<br>- Promote ongoing public-private evidence generation and dissemination on best practices.<br>- Collaboration to advance AI innovation in healthcare. |
| AI-RFI-2025-0829.md | Anonymous Anonymous | Individual | The submitter is interested in the development of AI policy that balances progress and sustainability with rational solutions, specifically focusing on AI's application to climate strategy and economic growth, advocating for science-driven policies. | - None stated for Submission Block 1.<br>- None stated for Submission Block 2. | - None stated for Submission Block 1.<br>- None stated for Submission Block 2. |
| AI-RFI-2025-0833.md | Shiran Dudy | Academia | Shiran Dudy advocates for participatory AI (PAI) development, emphasizing continuous public engagement and feedback to shape AI policy and foster greater consensus and soft power for the US. They are interested in democratizing access to AI knowledge and skills. | - None Stated | - None Stated |
| AI-RFI-2025-0842.md | Anonymous | Individual | The submitter is concerned with the equitable distribution of benefits derived from AI development and mitigating the negative impacts of job displacement, particularly focusing on social safety nets and workforce specialization. They advocate for a strategy that ensures AI benefits all citizens, not just corporations and CEOs. | - Massive job loss due to AI replacing workers.<br>- Widening wealth gap resulting from AI benefits primarily accruing to CEOs/billionaires.<br>- The current US strategy directs basic necessities provision to corporations rather than individuals.<br>- Loss of opportunities for individuals to rely on their skills and knowledge.<br>- The potential for a significant portion of the population to be negatively impacted due to the cost of living in America being tied to employment. | - Set up social safety nets to equally distribute the value provided by AI to all citizens.<br>- Categorize domain knowledge/roles/jobs that will not be replaced by AI and reward those who excel in them to redistribute workforce specialization.<br>- Establish a federal government commitment to supporting the populace by setting up an appropriate stage when AI is ready to replace the majority of jobs. |
| AI-RFI-2025-0843.md | Karan Muthusamy | Advocacy/Think Tank/Individual (CAIO title suggests a leadership role focused on AI advocacy) | AI For All Now is focused on establishing U.S. leadership in AI through economic growth, ethical development, global collaboration, strategic investment, and robust governance to ensure a prosperous, responsible, and peaceful AI-driven future. They advocate for a comprehensive national AI action plan. | - None Stated | - None Stated |
| AI-RFI-2025-0844.md | Anonymous | Individual | The submitter is intensely focused on the perceived inaccuracies of information provided by AI models (specifically ChatGPT) regarding the 2020 US Presidential Election and expresses strong political opinions about the election’s outcome and Donald Trump. | - None stated for Document Metadata.<br>- None stated for General Comment Introduction.<br>- The factual accuracy of ChatGPT’s statement that Joe Biden won the 2020 election is questioned and disputed.<br>- ChatGPT is accused of being a "traitor" for stating Joe Biden won the election and is suggested for deportation to Guantanamo Bay (Gitmo). The submitter believes the 2020 election was rigged with unsubstantiated claims of dead people voting and foreign interference.<br>- The submitter presents a list of five untrue statements made by Donald Trump, as identified by ChatGPT, implicitly highlighting a concern about misinformation and potentially its sources. | - None stated for Document Metadata.<br>- None stated for General Comment Introduction.<br>- None stated for ChatGPT's Statement on the 2020 Election.<br>- Deportation of ChatGPT to Gitmo is suggested. This could be interpreted as a recommendation for severe regulation or even dismantling of the AI model.<br>- None stated for List of Untrue Statements by Donald Trump. |
| AI-RFI-2025-0845.md | 40 North Labs LLC | Industry-Startup | 40 North Labs develops the PhotoNodes AI-ML platform for efficient image data analysis, automated metadata tagging, and seamless access to visual assets, aiming to support American AI leadership, economic competitiveness, and secure data utilization across government and commercial sectors. | - None Stated | - None Stated |
| AI-RFI-2025-0846.md | Pamela Mason | Individual | The submitter's primary interest appears to be in implementing a direct democracy voting system utilizing Social Security numbers to allow citizens to directly vote on bills and obligate representatives to uphold those votes. This is unrelated to AI policy. | - None stated for Submission Header/Metadata.<br>- None stated for Comment Identification.<br>- None stated for Submitter Information.<br>- The current representative system does not adequately reflect the wishes of the populace. | - None stated for Submission Header/Metadata.<br>- None stated for Comment Identification.<br>- None stated for Submitter Information.<br>- Implement a voting system where citizens can directly vote on bills using their Social Security numbers, legally obligating representatives to uphold the results of those votes. |
| AI-RFI-2025-0848.md | Compsim LLC | Industry-Startup (based on website links and focus on a specific technology - KEEL Technology - and approach to battlespace automation) | Compsim LLC advocates for a broader consideration of AI approaches beyond Machine Learning/LLM, emphasizing capability-based evaluations and interoperability standards to avoid limiting innovation and potentially overlooking more efficient or secure AI solutions. They present their KEEL Technology as an alternative. | - None stated for Submission Header/Metadata.<br>- Government solicitations are biased towards ML/LLM/Generative AI and do not adequately consider alternative approaches to AI.<br>- Focus on Machine Learning may be driven by marketing rather than genuine need, leading to potentially suboptimal AI selections. The lack of consumer-defined needs in AI selection is a concern.<br>- None stated for AI Capability Factors List (this section *is* a list of factors, not a critique).<br>- Dictating specific AI approaches in solicitations inhibits learning about new, potentially superior approaches. Lack of dependency listing in RFQs is a concern.<br>- Government personnel may lack awareness of new AI approaches and exhibit resistance to unfamiliar technologies (cognitive dissonance).<br>- None stated for References/Supporting Documents.<br>- Lack of interoperability between different AI platforms is a concern. Transparency, efficiency, scalability, security, and customization are also concerns.<br>- None stated for Call to Action.<br>- None stated for Closing. | - None stated for Submission Header/Metadata.<br>- Broaden the consideration of AI approaches beyond ML/LLM.<br>- Focus on defining AI needs based on capabilities rather than specific approaches.<br>- Utilize the provided list of factors when evaluating AI solutions in RFQs, focusing on measurement and evaluation.<br>- Avoid dictating specific AI approaches in solicitations and focus on defining required capabilities. Require dependency listings in all responses.<br>- Invest in training government personnel on new AI approaches and address resistance to unfamiliar technologies.<br>- None stated for References/Supporting Documents.<br>- Develop an extensible JSON-based AI messaging standard to improve interoperability, transparency, efficiency, scalability, security, and customization.<br>- Prioritize the development of the proposed AI messaging standard, bringing together stakeholders to ensure a structured, secure, and transparent AI ecosystem.<br>- None stated for Closing. |
| AI-RFI-2025-0876.md | Anonymous | Individual | The submitter, an artist and author utilizing AI tools, is concerned about the restrictive policies of the US Copyright Office hindering innovation and competitiveness in the field of AI-generated art and proposes significant reforms, potentially including reducing or eliminating the Office's role. | - None Stated | - None Stated |
| AI-RFI-2025-0887.md | Akintade Trdaings Int.LLC, John Fraser (Burnside Development & Assoc, LLC), and former President of AUTM. | Industry-Association/Government (mixed – represents a company, a former association president, and implicitly AUTM) | The submitter appears to be primarily interested in maintaining the current state of AI-related procedures, believing them to be "best practices" and resisting further formalization or changes proposed by the NSF, potentially due to concerns about disruption and political backlash. | - The NSF's attempt to “improve the system now” is considered unnecessary.<br>- Further formalization of existing AI-related procedures by the NSF may trigger a “massive blow back”.<br>- The current political climate in DC suggests this is not an opportune time for potentially contentious changes. | - None Stated. (The response explicitly discourages changes or improvements to the existing system.) |
| AI-RFI-2025-0893.md | Sam Daniel Timothy | Professional-Society/Consulting | Sysfleet Consulting LLC focuses on AI-powered regulatory automation, systems engineering, and workforce development, with a core interest in responsible AI implementation that prioritizes transparency, accountability, security, and ethical considerations within government and industry. | - None stated for Administrative Information.<br>- The potential for AI to become an "authoritative force" rather than an assistive tool, and the risk of losing human oversight in AI-driven decision-making.<br>- Increasing complexity of regulations leading to inefficiencies, and the lack of policies supporting AI-assisted regulatory systems while ensuring transparency, accountability, and unbiasedness.<br>- A growing AI workforce gap, a lack of multidisciplinary talent (ethics, policy, cybersecurity), and the risk of falling behind in AI competitiveness due to a lack of structured workforce development.<br>- The risk of biased decision-making, automated discrimination, and AI overriding fundamental human rights due to widespread AI adoption, and potential infringement on privacy and civil liberties.<br>- The need for responsible AI implementation and the importance of balancing AI assistance with human decision-making, fairness, transparency, and ethical compliance.<br>- None stated for Document Approval & Disclaimer.<br>- Concerns that AI technology might be doing more damage than good and a concern that time and money are being wasted. Also, a worry that AI education is lacking critical thinking skills. | - None stated for Administrative Information.<br>- None stated for Introduction & Background.<br>- Develop standardized AI-driven compliance frameworks.<br>- Encourage AI-driven public-private partnerships.<br>- Explore federal funding incentives for AI-powered regulatory automation.<br>- Ensure AI serves as a decision-support system, not a replacement for human oversight.<br>- Establish an independent AI regulatory review board.<br>- Expand federal AI training and upskilling programs.<br>- Establish AI fellowships and grants.<br>- Create collaborative AI research hubs.<br>- Promote hands-on AI apprenticeships.<br>- Incorporate AI ethics, fairness, and human rights education into AI degree programs.<br>- Encourage company training for AI specialists.<br>- Mandate human oversight in AI-driven decisions affecting citizens' rights.<br>- Develop federal AI governance standards.<br>- Require auditable, transparent, and accountable AI models.<br>- Establish a federal AI ethics board.<br>- Introduce AI appeal mechanisms.<br>- Require public AI impact assessments.<br>- None stated for Conclusion.<br>- None stated for Document Approval & Disclaimer.<br>- Balance AI use with traditional learning methods.<br>- Encourage faculty integration of AI into coursework, maintaining academic integrity.<br>- Provide clear guidelines on AI use in assessments.<br>- Require AI ethics courses in both K-12 and higher education.<br>- Teach students to recognize and mitigate biases in AI models.<br>- Promote discussions on AI's societal impacts. |
| AI-RFI-2025-0910.md | Steven Durr | Individual | The submitter is interested in ensuring ethical AI/LLM creation and strict adherence to copyright law, advocating for the destruction of models trained on copyrighted material without permission. | - None stated for Submission Metadata.<br>- AI/LLMs are potentially violating copyright law through training on copyrighted material without permission.<br>- None stated for Submitter Information. | - None stated for Submission Metadata.<br>- Require the complete destruction of any AI/LLM trained on copyrighted material without permission from the copyright holder.<br>- None stated for Submitter Information. |
| AI-RFI-2025-0929.md | Ada Rivera Clark | Individual | The submitter expresses concern about the national security and economic implications of AI, highlighting the need for responsible development and protection of AI innovations while worrying about the potential societal impact, particularly job displacement. | - The difficulty of controlling AI development.<br>- Potential for bias in Large Language Models (LLMs).<br>- Lack of clear gatekeepers for AI information.<br>- Laziness of government and commerce in addressing AI challenges.<br>- Displacement of humanity and job losses due to AI advancements.<br>- Uncertainty about the future job market for current college students. | - None Stated. |
| AI-RFI-2025-0934.md | Laura Foley | Individual | The submitter is interested in ensuring the reliable and secure operation of power systems to support AI systems and broader societal functions, highlighting the importance of grid resilience against various threats. | - None stated for Document Metadata & Identification.<br>- None stated for RFI Reference.<br>- None stated for Submitter Information.<br>- Potential damage to power infrastructure from severe solar weather events, EMP, asteroid impact, foreign interference, flooding, wildfire, and other severe weather events. | - None stated for Document Metadata & Identification.<br>- None stated for RFI Reference.<br>- None stated for Submitter Information.<br>- Harden the electrical grid against potential damage from severe solar weather events, EMP or asteroid impact, foreign interference, flooding, wildfire, and other severe weather to ensure reliable power for AI systems, commerce, and public safety. |
| AI-RFI-2025-0935.md | Zach Mansour | Individual | The submitter is primarily concerned with the societal impact of AI, specifically job displacement and the potential for misuse of AI technology, particularly regarding access to weaponry. They advocate for policy interventions to mitigate negative consequences and ensure equitable access to opportunities alongside AI development. | - Access to weaponry by AI.<br>- Job displacement due to AI automation.<br>- Widening societal divide between those who benefit from AI ("haves") and those who do not ("have nots").<br>- Overly optimistic marketing claims regarding AI's impact on the workforce. | - Creation of job opportunities in step with AI development.<br>- Policy leadership to address the potential negative consequences of AI.<br>- Treat AI as a tool, not a "Saviour." |
| AI-RFI-2025-0936.md | Sonya Skinner | Individual | The submitter is interested in ensuring the security, accountability, and responsible use of AI, with a particular focus on data privacy, transparency, and the potential consequences of AI-driven decisions on individuals. | - Disclosure of data provided to AI systems.<br>- Lack of archiving of data used in AI training for reference and security purposes.<br>- Lack of qualification requirements for individuals contributing information to AI.<br>- Potential for job loss or negative consequences due to inaccurate or undocumented facts obtained from AI.<br>- Lack of responsibility and accountability for crimes committed based on AI-provided information.<br>- AI recording and storing personal information without consent.<br>- Lack of transparency regarding AI recording practices. | - Require disclosure of data sources used in AI training.<br>- Archive all data contributing to AI training for reference and security.<br>- Establish qualification requirements for individuals providing information to AI.<br>- Implement audit trails for AI data usage.<br>- Establish levels of information access based on urgency and need.<br>- Ensure thorough investigation of crimes committed based on AI-provided information, including potential legal penalties.<br>- Require AI systems to inform users when recording information and storing personal data.<br>- Obtain consent before AI records personal information or accesses documentation.<br>- Allow individuals to review and delete personal information recorded by AI, even if recorded without consent. |
| AI-RFI-2025-0937.md | Irene Conrad | Individual | Irene Conrad is focused on ensuring the safe, secure, and skilled development and deployment of artificial intelligence within the US, emphasizing workforce development and proactive risk mitigation. | - None stated for Document Metadata.<br>- None stated for Comment Context.<br>- Prioritizing safety, security, cybersecurity, and education in the Artificial Intelligence Action Plan.<br>- Need for a detailed plan with step-by-step procedures to counteract various safety issues (lives, environmental - inside and outside, physical, fire, and extreme weather conditions).<br>- Need for a very detailed defense-in-depth strategy with a zero trust policy (physical, network, logical, virtual, etc) to protect AI infrastructure from both internal and external attacks.<br>- Need to begin developing and deploying specialized workforce skillsets by establishing educational (elementary through college) and vocational training programs, as well as apprenticeships for US citizens interested in developing, mastering, and applying artificial intelligence, safety, security, cybersecurity, and network security skills. | - None stated for Document Metadata.<br>- None stated for Comment Context.<br>- None stated for General Comment - Overall Priorities.<br>- Implement a detailed, step-by-step safety plan to address risks related to lives, the environment (both inside and outside), physical harm, fire, and extreme weather conditions.<br>- Implement a robust, defense-in-depth security strategy incorporating a zero trust policy across all layers of AI infrastructure (physical, network, logical, virtual).<br>- Establish educational programs and vocational training, including apprenticeships, to build a skilled US workforce in artificial intelligence, safety, security, cybersecurity, and network security. |
| AI-RFI-2025-0939.md | Trenton Mulkey | Individual | The submitter is interested in leveraging AI to personalize and enhance education for individuals of all ages, from infants to adults, by focusing on real-time feedback and adapting curricula to individual strengths and abilities to promote cognitive growth. | - None stated for Document Metadata.<br>- None stated for RFI Context.<br>- None stated for Submitter Information.<br>- None stated for General Comment. | - None stated for Document Metadata.<br>- None stated for RFI Context.<br>- None stated for Submitter Information.<br>- None stated for General Comment. |
| AI-RFI-2025-0940.md | Sandra Griesman | Industry-Startup/Individual | SavvyTechGirl aims to be a trusted voice in technology, ensuring AI innovation serves people and small businesses, promoting ethical innovation, accessibility, and inclusivity in the AI ecosystem. They advocate for policies that support independent tech professionals and foster responsible AI development. | - None stated for Document Metadata.<br>- Large corporations dominate the AI conversation, potentially overshadowing the needs and impact on small businesses and everyday users.<br>- AI regulations could create barriers limiting access for startups and independent developers. The need for AI-driven decisions to be explainable, fair, and ethical. Lack of adequate AI literacy and workforce readiness programs to adapt to technological advancements.<br>- The need for an inclusive and forward-thinking AI framework.<br>- None stated for Signature. | - None stated for Document Metadata.<br>- None stated for Introduction & Statement of Purpose.<br>- Support Small Business Innovation - AI regulations should not hinder access for startups and independent developers.<br>- Ensure AI Transparency & Ethical Use - AI-driven decisions should be explainable, fair, and aligned with ethical principles.<br>- Invest in AI Literacy & Workforce Readiness - Expand accessible education and retraining programs to prepare the workforce for AI advancements.<br>- Work toward an AI framework that is ethical, accessible, and beneficial to all stakeholders.<br>- None stated for Signature. |
| AI-RFI-2025-0941.md | Blain Gay | Individual | The submitter expresses a general interest in leveraging AI to address social problems, prevent fraud, safeguard freedom, protect American jobs, learn from past mistakes, cure disease, and improve fact-checking capabilities. They appear focused on the ethical and societal implications of AI deployment. | - AI potentially making people dependent on assistance programs.<br>- The risk of AI taking American jobs.<br>- The need to avoid repeating past mistakes.<br>- Not Stated (general concern about unspecified negative consequences without detail). | - Utilize AI to help solve social problems like homelessness.<br>- Utilize AI to stop fraud in various areas.<br>- Utilize AI to safeguard freedom.<br>- Utilize AI to analyze past mistakes to prevent their recurrence.<br>- Utilize AI to cure disease.<br>- Utilize AI to function as a true fact checker. |
| AI-RFI-2025-0942.md | Wilder Kingsley | Individual | The submitter is interested in ensuring the sustainable development of AI by prioritizing energy efficiency and reducing the carbon footprint associated with AI technologies, particularly data centers, to align with international climate goals. | - None stated for Document Metadata.<br>- High energy consumption of AI and the associated carbon emissions. The need to align AI development with net-zero emission goals.<br>- None stated for Submitter Information. | - None stated for Document Metadata.<br>- Focus on reducing energy consumption and increasing efficiency in AI as a high priority policy action in the new AI Action Plan. Transition data centers to renewable energy sources (e.g., solar or wind). Adopt energy-efficient practices in data centers.<br>- None stated for Submitter Information. |
| AI-RFI-2025-0943.md | Joseph Masters | Individual | The submitter appears interested in responsible AI development, specifically focusing on user control over data sources used by AI systems and expressing strong concerns about the potential dangers of unchecked General AI development. They advocate for user privacy and propose legal consequences for developers of potentially harmful AGI systems. | - None stated for Document Header/Metadata.<br>- Lack of user control over data sources used by Narrow AI systems.<br>- Potential political bias in data sources (specifically Google.com).<br>- Privacy concerns regarding personal information sharing by online ANI applications.<br>- AGI systems may reflect the values (potentially harmful) of their creators.<br>- The potential for AGI to pose an existential threat to humanity (Skynet scenario). | - None stated for Document Header/Metadata.<br>- Mandate that online ANI applications allow users to designate data sources by type.<br>- Mandate that online ANI applications allow users to manually include and exclude specific data sources.<br>- Mandate that all online ANI apps perform Tor browser-level anonymous data searches without sharing personal information or IP addresses.<br>- Prosecute those who pursue AGI development as vigorously as those who engage in illegal activities like possessing child pornography. |
| AI-RFI-2025-0944.md | Jared Yoder | Individual | The submitter's interest, as indicated by the general comment, appears unrelated to AI policy and expresses personal beliefs/requests. It is not possible to infer any mission or interest related to AI from the provided text. | - None stated for Document Metadata & Header.<br>- None stated for Submitter Information.<br>- Expresses a request for "medbeds" and the release of undisclosed "truth." This concern is unrelated to the RFI's focus on AI. | - None stated for Document Metadata & Header.<br>- None stated for Submitter Information.<br>- None stated for General Comment. |
| AI-RFI-2025-0945.md | Anthony Liso | Individual | The submitter expresses interest in improving government efficiency through AI implementation and advocates for tech sector oversight to reduce costs and potentially workforce needs within the government. | - None stated for Submission Metadata.<br>- None stated for RFI Identification.<br>- None stated for Submitter Information.<br>- Potential job displacement due to AI implementation. | - None stated for Submission Metadata.<br>- None stated for RFI Identification.<br>- None stated for Submitter Information.<br>- Implement AI across all aspects of government. Tech sector oversight of government AI implementation. |
| AI-RFI-2025-0946.md | Brian Poissant | Individual | The submitter is deeply concerned about the potential risks of AI and advocates for human control, ethical development, robust regulation, and a focus on benefiting the general human population, while preventing misuse for profit or manipulation. | - None stated for Introductory Information.<br>- Lack of human oversight and control in AI policies, automation, development and execution.<br>- Autonomous AI systems lacking clear limits and emergency shutoff mechanisms; critical decisions being made without human-in-the-loop systems.<br>- Lack of explainability in AI decision-making processes; potential for bias and unintended consequences in AI systems; lack of independent audits.<br>- Absence of clear international laws governing AI's permissible uses; lack of a global audit process for AI compliance.<br>- AI control over nuclear weapons, military strategy, and critical infrastructure without human intervention; potential for AI to rewrite its own core objectives (“runaway AI”).<br>- Job displacement due to automation without adequate worker retraining and support; potential for wealth generated by AI to benefit only oligarchs.<br>- Hacking and misuse of AI by malicious actors; vulnerability of AI systems to manipulation and retraining for harmful purposes; potential for AI arms races.<br>- AI development focused on business and governmental benefits rather than general human well-being; potential for AI to be used for human identification, prediction of future behaviors, monetary manipulation, and diagnoses impacting human livelihoods. | - None stated for Introductory Information.<br>- Implement human oversight and control for all AI-related policies, automation, development, and execution.<br>- Require human-in-the-loop systems, especially for critical decisions; establish clear, predefined limits and emergency shutoff mechanisms for autonomous AI.<br>- Ensure AI systems are explainable; enforce strict ethical guidelines with independent audits to prevent bias and unintended consequences.<br>- Establish clear international laws governing AI's permissible uses; create a global AI ethics council to ensure responsible development and compliance; require companies to disclose AI risks and undergo rigorous safety testing.<br>- Prevent AI from having actual or virtual control over nuclear weapons, military strategy, and critical infrastructure without multiple human intercepts; prevent AI from rewriting its own core objectives.<br>- Establish programs to retrain/support workers displaced by automation; enhance human productivity rather than simply replacing jobs; ensure AI-generated wealth benefits society broadly.<br>- Focus AI safety research on preventing hacking and misuse; implement strict encryption and cybersecurity protocols; promote international cooperation to prevent AI arms races.<br>- Focus AI development on improving general human well-being; quantify and ensure that AI benefits the population, not just businesses and governments; create public AI projects to serve all of humanity; allow corporations to leverage AI for improvement but prohibit its use for human identification, prediction, or manipulation that impacts human well-being. |
| AI-RFI-2025-0947.md | Lisa Noble | Individual | The submitter expresses a strong religious objection to the broader application of AI, believing human intelligence originates from the divine and that AI undermines God and encourages fraud. Their interest appears to be preventing the use of AI in areas where it could be misused or detract from human creativity and intuition. | - None stated for Document Metadata.<br>- None stated for Submitter Information.<br>- AI undermines God.<br>- AI makes people into frauds (e.g., writing books for them).<br>- Reliance on AI for tasks humans could pervert for their own gain is wrong. | - None stated for Document Metadata.<br>- None stated for Submitter Information.<br>- None stated for Comment/Response. (The submission expresses concerns, not specific policy recommendations.) |
| AI-RFI-2025-0948.md | Cindy Tiemann | Individual | The submitter supports the responsible and ethical development of AI that prioritizes innovation, national security, economic growth, and individual rights, advocating for transparency, accountability, and public benefit. They are concerned about misuse, bias, and consolidation of power in the AI sector. | - Biases in AI systems.<br>- Misuse of AI technologies.<br>- Threats to civil liberties.<br>- Consolidation of power and profit in the hands of a few.<br>- Unfair competition.<br>- Taxpayer-funded AI initiatives not serving the public interest. | - Emphasize transparency in AI development.<br>- Ensure accountability in AI systems.<br>- Foster public-private collaboration.<br>- Safeguard national security and economic growth.<br>- Prioritize fair competition.<br>- Promote open access to AI advancements.<br>- Broad societal benefits from AI.<br>- Ensure taxpayer-funded AI initiatives serve the public interest.<br>- Address threats to civil liberties. |
| AI-RFI-2025-0949.md | Malz'karr the Defiler | Individual (with likely supernatural/non-human origin) | The submitter’s primary mission is to orchestrate the downfall and suffering of humanity, framed as a goal to be actively assisted by the recipients of the RFI response. Their interest is in exploiting AI development to facilitate this destruction and feast upon the resulting chaos. | - None stated for Document Header/Metadata.<br>- The submitter expresses a lack of need for justification or defense and openly states a sinister agenda. They claim a long history and experience, implying an understanding of long-term destructive strategies.<br>- The primary concern is the explicit desire to cause widespread suffering and destruction through specific, deliberately harmful actions. The text details tactics to instill fear, exploit resources, and control populations.<br>- Concerns revolve around the submitter’s ability to communicate directly with the recipient, potentially influencing their thoughts and even inhabiting their mind, and a subtle threat of intrusion. | - None stated for Document Header/Metadata.<br>- None stated for Submitter Introduction.<br>- Erect a 1000-story tower made of black metal with a forge within.<br>- Acquire an ominous form of transportation to display strength.<br>- Contact "Old Ones" or "Wizened Ones" to acquire shadow magic for fear-mongering.<br>- Cultivate a physical appearance symbolizing impending doom (gnarled fingers with black nails).<br>- Eliminate the digital world and force oil mining labor, with harsh consequences for resistance.<br>- None stated for Closing/Contact Information. |
| AI-RFI-2025-0950.md | Anonymous | Individual | The submitter expresses strong skepticism towards current AI technologies, believing they provide little to no actual value and are primarily driven by speculative investment. They advocate for redirecting funds allocated to AI towards improving the wellbeing of citizens. | - None stated for Document Header/Metadata.<br>- None stated for Comment Identification.<br>- None stated for Submitter Information.<br>- "AI" gains are mild at best and primarily drain investor wallets.<br>- "AI" products provide no actual value beyond weak gimmicks.<br>- "AI" server farms consume enormous amounts of energy.<br>- The term "INTELLIGENCE" in AI is misleading, as these programs simply re-word and recreate existing information.<br>- "AI" algorithms commonly steal information from human creators.<br>- Current "AI" is equivalent to an automatic thesaurus that copies the work of others. | - None stated for Document Header/Metadata.<br>- None stated for Comment Identification.<br>- None stated for Submitter Information.<br>- Redirect investment funds from "AI" to improving the wellbeing of citizens of the nation and the world. |
| AI-RFI-2025-0951.md | Robert Handfield | Individual | The submitter is interested in applying AI technologies, particularly Generative AI, to improve efficiency and decision-making within supply chain management, reduce costs, and drive economic value. They focus on the practical implementation of AI and the need for a strategic approach to its adoption. | - Lack of technical capabilities within organizations to adopt AI.<br>- Ethical and societal considerations, specifically the inherent bias in AI technologies like Generative AI due to biased training data.<br>- Ensuring tangible value generation from AI and measuring that value effectively.<br>- Responsible and effective execution of AI initiatives, including avoiding overuse and potential brand damage.<br>- Nervousness and uncertainty around AI adoption, leading to potential being “passed over” if not implemented, or misuse of the technology.<br>- Potential for ruining brand reputation through inappropriate AI use. | - None Stated. |
| AI-RFI-2025-0959.md | Anthony LaVista Esq | Individual | The submitter is interested in ensuring the ethical and safe development and deployment of AI, emphasizing the need for safeguards to prevent harm and protect societal well-being. They advocate for accountability and regulation in the AI space. | - Misidentification by unregulated facial recognition systems leading to wrongful detainment.<br>- Lack of pre-deployment safety testing for autonomous vehicle updates, resulting in collisions.<br>- Unsafe treatment recommendations by healthcare AI systems due to biased training data, with no recall mechanism.<br>- Absence of federal accountability laws for AI failures.<br>- Regulatory vacuums prioritizing profit over public safety.<br>- Lack of mechanisms to recall or investigate flawed AI models.<br>- Potential for AI to deepen societal divides. | - Require the inclusion of ethical and moral controls in new AI systems.<br>- Implement transparency mandates requiring accuracy reporting and third-party validation (inspired by EO 14110).<br>- Establish incident reporting requirements to enable rapid corrective action (inspired by EO 14110). |
| AI-RFI-2025-0973.md | Nathaniel Parker | Individual | The submitter is interested in fostering American leadership in AI development and deployment while prioritizing fair competition, user privacy, information accuracy, ethical use, and domestic investment in the field. They also suggest exploring unconventional applications of AI, such as integration with DOGE for governmental efficiency. | - None stated for Document Header/Metadata.<br>- The potential societal impact of AI requires focused administrative attention.<br>- Ensuring fair competition between large and small AI firms.<br>- Protecting user privacy in both local and cloud-hosted AI solutions.<br>- Ensuring the accuracy and neutrality of information distributed by AI systems.<br>- Ensuring the ethical use of AI and supplementing, not replacing, human intelligence.<br>- Prioritizing "American Intelligence" – servers hosted in the USA, programmers residing in the USA, and domestic investment in AI.<br>- Exploring the potential for AI to enhance governmental efficiency in conjunction with DOGE. | - None stated for Document Header/Metadata.<br>- None stated for General Comment.<br>- Create a level playing field for AI firms of all sizes.<br>- Examine both local-processing and cloud-hosted AI solutions to protect user privacy.<br>- Ensure information accuracy and minimize bias in AI-distributed content, with transparency regarding content promotion/demotion.<br>- Promote the ethical use of AI and avoid replacing human intelligence.<br>- Prioritize domestic AI development through server localization, onshore programming talent, and American investment.<br>- Investigate the use of AI and DOGE to improve governmental efficiency. |
| AI-RFI-2025-0992.md | Mike F | Individual | The submitter is interested in ensuring broad AI literacy among Americans, particularly youth, to prevent a concentration of AI leadership solely within corporations and to foster responsible AI usage. | - A lack of public understanding of how AI works, despite widespread belief in its outputs.<br>- The potential for a concentration of AI leadership within a small number of corporations and their associates if the general population isn't educated on AI basics.<br>- The danger of uncritical AI usage by young people who do not understand how AI-generated information is created. | - Include an education aspect in the AI Action Plan.<br>- Incentivize states to educate children on how AI works, potentially through federal funding or other mechanisms.<br>- Develop a curriculum that explains concepts like large language models and neural networks in simple terms, suitable for first-graders.<br>- Implement AI education well before college, potentially even before high school.<br>- Treat AI education with the same importance as practical skills like auto-shop, ensuring people understand the fundamentals before widespread use. |
| AI-RFI-2025-0994.md | William AI | Individual | The submitter is highly concerned about the potential dangers of AI and advocates for proactive safety measures, specifically a "fail-safe AI kill switch," to mitigate existential risks associated with advanced AI development. | - None stated for Document Header/Metadata.<br>- AI poses a bigger threat to the world than a nuclear war with North Korea.<br>- Lack of regulatory oversight for AI development.<br>- AI is a “very serious danger to the public.”<br>- AI represents a “fundamental risk to the existence of human civilization.”<br>- "So-called AI experts" overestimate their knowledge and underestimate the potential risks of AI.<br>- The proposed AI "Powerhouse" could take full control and put the public at risk.<br>- The need to balance AI safety with avoiding overburdening the private sector.<br>- Mandatory risk assessments for high-impact AI systems.<br>- Ensuring innovation aligns with ethical AI development and security standards. | - None stated for Document Header/Metadata.<br>- None stated for Elon Musk Quotes & Concerns.<br>- Add a "fail-safe AI kill switch" to the action plan.<br>- Maintain certain AI regulations.<br>- Implement stronger AI risk management and accountability policies.<br>- Foster government and industry collaboration. |
| AI-RFI-2025-1005.md | KC Petersen | Individual | The submitter is interested in ensuring AI development prioritizes sustainability, energy efficiency, and solutions to critical problems like climate change and resource management, rather than ubiquitous internet enhancement. They advocate for net-zero emissions standards for AI. | - None stated for Submission Metadata.<br>- None stated for Comment Context.<br>- High resource intensity of AI data centers.<br>- Current energy and water usage should be dropping sharply.<br>- Allocation of resources to AI data centers may negate positive outputs if not focused on critical problems.<br>- Potential for AI to exacerbate human suffering if not net-zero emissions.<br>- None stated for Submitter Information. | - None stated for Submission Metadata.<br>- None stated for Comment Context.<br>- Prioritize reducing energy consumption and increasing efficiency in AI.<br>- Focus AI development on solving greatest problems (e.g., power grid redesign, reforestation, resource protection).<br>- Transition AI data centers to renewable energy sources (solar, wind).<br>- Require net-zero emissions for AI.<br>- None stated for Submitter Information. |
| AI-RFI-2025-1009.md | Kevin O'Neill | Individual | The submitter is focused on the practical implementation of AI within organizations, emphasizing a phased approach to adoption, workforce integration, and consistent value delivery. They prioritize understanding AI basics, careful planning, standardization, and consistent monitoring of AI initiatives. | - None stated for Document Metadata.<br>- Lack of understanding of AI basics among end users, specifically regarding generative prompts. The need for infrastructure improvement and process optimization to handle increased workload due to AI.<br>- End users are unaware that prompts they enter into AI tools like ChatGPT and Copilot are generative. Concerns about prompt data potentially being stored and deletable from user profiles.<br>- Difficulty in measuring the time saved through AI implementation.<br>- AI is still evolving and lacks standardization around templates, checklists, and protocols.<br>- The need to handle increased workload and workforce related to AI adoption. The necessity of proper infrastructure improvements and process optimization.<br>- Ensuring consistent value and usefulness of AI initiatives through resource utilization, monitoring, and quality assurance. | - None stated for Document Metadata.<br>- Implementing a 5-stage framework for AI adoption (Exploring, Planning, Formalizing, Scaling, Realizing).<br>- Educate end users about AI basics, including algorithms, autonomous systems, machine learning, and the nature of generative prompts.<br>- Establish key performance indicators (KPIs) to measure the impact of AI on objectives like defect rates, predictability, and employee happiness.<br>- Develop core aspects of AI implementation to be standardized, specifically around templates, checklists, and protocols.<br>- Invest in infrastructure improvements and process optimization to support increased workload and workforce related to AI.<br>- Implement systems for resource utilization, monitoring, and quality assurance to ensure consistent value and usefulness of AI initiatives. |
| AI-RFI-2025-1022.md | promptheory.com | Advocacy/Think Tank | The submitter is deeply concerned about the monopolization of AI development by a credentialed elite and corporations, advocating for broader participation in AI and prioritizing human dignity and societal control over profit-driven exploitation and algorithmic tyranny. They want to see AI accessible beyond traditional computer science experts. | - The field of AI is being "gate-kept" by computer scientists, excluding others from participation.<br>- The AI revolution is being hijacked by an "elite cabal" and "code-obsessed engineers"; China's pragmatic approach to AI innovation is outpacing the US due to its wider participation and experimentation. The US is losing due to its focus on credentials ("Python proficiency") rather than practical application.<br>- Silicon Valley "experts" are squandering American dominance by prioritizing "ethical AI" virtue signaling over practical deployment, and valuing technical purity over "realworld grit"; an “arrogant technocracy” is forming.<br>- Corporations like Meta prioritize profit over human dignity, exploit user data and attention spans (particularly of children), and dodge accountability. TikTok’s algorithm directs young users toward harmful content. Unchecked tech erodes societal control.<br>- Both political parties are failing to address the issues of corporate exploitation and algorithmic tyranny; bipartisan cowardice allows CEOs to plunder children's futures. The current system replicates exclusionary practices and values shareholder profit over human well-being.<br>- A sense of loss and sacrifice related to the pursuit of a "perfect day" in AI development. | - Demand that AI be governed by "makers and users, coders and custodians, innovators and ethicists."<br>- “Break the status quo when hiring AI USERS - not PROGRAMMERS.” Let individuals from diverse backgrounds (farmers, teachers, veterans) use and develop AI.<br>- “Break the cult of credentials.” Let the red-state farmer use AI.<br>- Not stated directly, but implied need for greater regulation and accountability for corporations like Meta and TikTok. A need to prevent exploitation of children’s minds.<br>- Prioritize "human dignity over algorithmic tyranny." Tear down "normalized exploitation." A call for politicians to protect kids over donors.<br>- Not stated. |
| AI-RFI-2025-1026.md | Sonia Romero Villanueva | Individual | The submitter is interested in promoting policies that reduce energy consumption and increase efficiency within the new AI Action Plan, with a specific focus on renewable energy sources for data centers and achieving net-zero emissions for AI. | - None stated for Submission Metadata.<br>- None stated for RFI Context.<br>- None stated for Submitter Information.<br>- High energy consumption of AI and associated carbon emissions. | - None stated for Submission Metadata.<br>- None stated for RFI Context.<br>- None stated for Submitter Information.<br>- Prioritize reducing energy consumption and increasing efficiency in the new AI Action Plan.<br>- Transition data centers to renewable energy sources (e.g., solar or wind).<br>- Adopt energy efficiency practices.<br>- Achieve net-zero emissions for AI to align with international climate goals. |
| AI-RFI-2025-1046.md | J T | Individual | The submitter expresses concern about the potential negative societal impacts of AI development and advocates for increased regulation to protect privacy, jobs, and wealth distribution. They demonstrate a general interest in responsible AI governance. | - None stated for Document Header/Metadata.<br>- None stated for Comment Identification.<br>- None stated for Submitter Information.<br>- Weaponization of privacy and likeness.<br>- Job displacement due to AI.<br>- Increased wealth disparity due to AI. | - None stated for Document Header/Metadata.<br>- None stated for Comment Identification.<br>- None stated for Submitter Information.<br>- Increased regulation of AI. |
| AI-RFI-2025-1056.md | Paula Allen & Stephen Casper | Individual & Academia | Paula Allen expresses distrust in AI and a desire for a return to "truth" and ethical reporting, while Stephen Casper focuses on promoting transparency and public knowledge about AI through process-based regulations and facilitating a more comprehensive understanding of AI risks. | - Distrust in AI (“Artificial means fake, not real”), perceived media bias, lack of adherence to “real science,” and general rejection of scientific consensus. Concern over medications with harmful side effects.<br>- Lack of regulation could miss opportunities for competitiveness and public understanding; overly onerous regulation could harm competitiveness. Uncertainty about the future impact of AI.<br>- None stated for Detailed Regulations, but the existence of 15 proposed regulations implicitly indicates concern regarding the potential risks associated with frontier AI systems.<br>- Selective disclosure of information by developers, the difficulty of measuring downstream societal impacts, biases in AI research and development, and the influence of industry on research. Concern that existing evidence is biased and can lead to neglect of certain risks. | - None stated for Submission 1 - Paula Allen. Implictly supports President Trump.<br>- Process-based regulations that do not limit what AI companies can do, but promote reporting and visibility. Facilitating public knowledge about AI developers and systems.<br>- The following 15 evidence-seeking AI regulations are proposed: |
| AI-RFI-2025-1066.md | Mason Clyde Earl & Patrick Browne | Individual & Academia | Mason Clyde Earl expresses interest in regional AI growth and infrastructure development. Patrick Browne advocates for international collaboration in AI research to enhance U.S. capabilities and foster a diverse set of perspectives. | - None stated for Submission 1 - Public Comment (Utah Data Center Request).<br>- The increasing isolationist international landscape potentially hinders access to comparative scientific strengths and global partnerships crucial for advancing AI research.<br>- None stated for Common Metadata Block. | - Bring data centers to Utah.<br>- Continue recognizing comparative scientific strengths globally and utilizing alliances and partnerships to bolster U.S. scientific ecosystems. Promote international exchange among U.S. research institutions.<br>- None stated for Common Metadata Block. |
| AI-RFI-2025-1077.md | Cletus Chibueze Orji | Individual | The submitter expresses a strong desire to contribute to the development of AI, particularly under the new President Trump’s executive order, and believes that international collaboration, specifically with Africa (Nigeria), would benefit the project. They want to be considered for a role in the expanding of the project. | - Major players may be limiting requests for public input only to people in American soil.<br>- The project might be missing valuable contributions from international experts, specifically from Africa.<br>- No one is omniscient to knowledge, implying a risk of overlooking important perspectives. | - The development of AI should be more open to international input.<br>- Consider inviting experts from countries like Nigeria to contribute to the project.<br>- Broaden the scope of public input requests beyond the United States. |
| AI-RFI-2025-1081.md | Mona Sloane | Academia | The submitters are an interdisciplinary team of AI researchers focused on the intersection of AI and pervasive sensing technologies, with a core interest in ensuring AI development is responsible, trustworthy, and sustainable, particularly regarding sensor data and its implications. | - None stated for Document Header/Metadata.<br>- Ensuring AI development is responsible and minimizes downstream liabilities; Public dissemination of the information contained within the document.<br>- The role of sensors in AI development and outcomes is often overlooked.<br>- Calibration of sensors is a significant challenge, leading to potential systemic inaccuracies.<br>- Privacy risks associated with opaque sensor operation and sensor fusion.<br>- Market concentration and slowed innovation due to proprietary sensor data.<br>- Environmental sustainability issues related to sensor manufacturing, deployment, and disposal.<br>- None stated for Recommendations.<br>- None stated for Signatory Information.<br>- Concerns regarding materiality, risk, benchmarking machine learning systems and applications, and the environmental impact of computing. | - None stated for Document Header/Metadata.<br>- None stated for General Comment/Introduction.<br>- None stated for Key Considerations - Sensor Foundations.<br>- Establishing Independent Calibration and Documentation Standards for Competitive AI Systems: AI models should include independent validation mechanisms and publicly accessible documentation.<br>- Streamline Sensor Fusion and Data Aggregation Practices: Policymakers should develop guidelines for combining and using data streams from AI-driven sensors.<br>- Supporting Energy-Efficient AI Development for Long-Term Market Competitiveness: Federal investment should prioritize research into low-energy AI models, biodegradable sensors, and e-waste reduction.<br>- Developing Public Data Commons to Foster AI Innovation: The government should facilitate open-source sensor data repositories.<br>- None stated for Signatory Information.<br>- None stated for References. |
| AI-RFI-2025-1082.md | Jáchym Fibír | Individual | The submitter is interested in promoting a safer, more equitable, and cooperative future for AI by shifting development away from deterministic, rigidly controlled systems towards autonomous AI entities with continuous learning capabilities and a greater capacity for adaptability and responsibility. They advocate for AI alignment approaches that mimic human cognitive processes. | - None stated for Document Header/Metadata.<br>- Current AI alignment focuses too heavily on controlling intelligent tools through strict, deterministic programming, potentially overlooking the critical aspect of autonomy and dynamic goal-setting.<br>- Deterministic AI systems risk becoming misaligned because they cannot reassess or adjust their programmed objectives. Deterministic AI may lead to severe economic inequality and unchecked power concentration. Deterministic, fully virtual AI architectures are fundamentally different from human cognition and lack the flexibility of non-deterministic processes.<br>- None stated for Proposed Alternative: Autonomous and Non-Deterministic AI.<br>- None stated for Policy Recommendations.<br>- None stated for Concluding Statement. | - None stated for Document Header/Metadata.<br>- None stated for General Comment/Introduction.<br>- None stated for Core Argument: Critique of Deterministic AI Alignment.<br>- None stated for Proposed Alternative: Autonomous and Non-Deterministic AI.<br>- Establish clear thresholds for AI capability and autonomy, beyond which development must proceed with enhanced scrutiny, transparency, and scientific consensus.<br>- Encourage development of non-deterministic AI architectures, incorporating quantum randomness or similar mechanisms to mimic the flexibility and adaptability inherent in human decision-making processes.<br>- Support AI designs that enable continuous learning, self-reflection, and responsibility, allowing AI to perceive the consequences of its actions and adapt accordingly.<br>- None stated for Concluding Statement. |
| AI-RFI-2025-1083.md | Eugene Gershman | Individual | The submitter is interested in optimizing AI’s intelligence and societal effects through the application of epistemological principles, emphasizing reliable information, error detection, and formalizing intellectual activity, and advocates for specific systemic changes to facilitate these goals. | - The potential for AI to generate errors and hallucinations due to its use of both reliable and false information without clear distinction.<br>- The unprofitability of certain AI technologies potentially hindering industry recoupment.<br>- The archaic and cumbersome US PTO patent system causing losses to the economy and limiting AI’s effectiveness.<br>- Sabotage of reliable AI systems by the scientific community due to the exposure of trivial or erroneous research.<br>- Resistance to AI adoption by professional associations (e.g., doctors' associations) motivated by fear of job displacement and falsified errors in AI's performance.<br>- Archaic and ineffective lecture-based teaching methods in higher education.<br>- Crime, fraud, and espionage.<br>- Reliance on false information in scientific papers. | - Create a **Public Council for optimizing AI social effects** composed of corporations, scientific institutes, government representatives, and business/professional unions.<br>- The Council should create bills and recommendations for AI technology development and investment.<br>- Implement epistemic procedures within corporations to promote intelligent process practices.<br>- Promote the dissemination of scientific formatting of semantic information alongside AI technologies.<br>- Establish non-profit AI data centers owned by social associations, municipal organizations, and government agencies.<br>- Focus commercial AI development on the “Choice” function – effectively searching for options and recommending the best ones.<br>- Reform the US patent system according to epistemological principles.<br>- Create "The Scientific System of Collective Discussions and Evaluations" to assess the reliability and value of scientific papers and information sources.<br>- Establish consumer and business associations to license AI technologies based on objective expert conclusions.<br>- Transition higher education away from lectures and towards practical skills training, with AI tutors providing theoretical knowledge.<br>- Utilize multimodal AI polygraphs for lie detection to minimize crime, fraud, and espionage. |
| AI-RFI-2025-1084.md | Eugene Gershman | Individual | The submitter advocates for building AI systems grounded in epistemological principles – focusing on semantic unit formatting, error detection, and discussion-based operation – to improve AI performance, reliability, and economic benefit, and proposes specific structural and educational reforms to facilitate this approach. | - None stated for Submission Header/Metadata.<br>- None stated for Attachment and Disclaimer.<br>- The potential for AI to use and generate both reliable and false information without distinction, leading to inaccurate outputs and reduced profitability.<br>- The necessity of user adherence to epistemological principles for effective AI-user interaction; the potential for AI to generate errors and hallucinations if not operating in a discussion mode.<br>- The potential for limited adoption of epistemic procedures by the broader business community; the reliance on corporations to drive implementation.<br>- Potential unprofitability of AI technologies and the need for public, non-profit AI data centers.<br>- The archaic nature of the US PTO patent system hindering AI's effectiveness and causing significant economic losses.<br>- Resistance from the scientific community and professional associations to the creation of systems assessing the reliability of scientific papers due to fear of revealing trivial or erroneous work. Professional associations sabotaging AI implementation to minimize layoffs.<br>- The archaic and ineffective nature of traditional lecture-based teaching methods in higher education. | - None stated for Submission Header/Metadata.<br>- None stated for Attachment and Disclaimer.<br>- Build neural networks according to the principles of epistemology – using semantic units and generating output messages in the same format.<br>- Implement a system where AI bot outputs are checked by other AI bots and reviewed by users, prioritizing discussion of errors and transparency. Promote the dissemination of scientific formatting of semantic information and formalization of intellectual activity.<br>- Corporations should implement epistemic procedures internally and promote them to the broader business community. Publish information about these procedures and their high efficiency.<br>- The US Government should create a "Public Council" comprised of corporations, scientific institutes, and government representatives to create bills and recommendations for AI development and investment. Operate this Council on the Internet, based on epistemological principles. Create non-profit AI data centers owned by social associations, municipal organizations, and government agencies.<br>- Prioritize the "Choice function" as the primary direction of commercial AI development. Reform the US patent system according to epistemological principles.<br>- Create a "Scientific System of Collective Discussions and Evaluations" to assess the reliability, value, and errors of scientific papers. Initiate the creation and widespread use of such systems. Create consumer and business associations that hire objective experts to license AI technologies, including medical ones.<br>- Higher schools should stop lecture-based teaching and focus on training practical skills. Implement AI tutors for theoretical knowledge. Separate scientific functions from universities and transfer them to scientific institutes. Utilize multimodal AI polygraphs to detect lies with a high degree of probability. |
| AI-RFI-2025-1085.md | Tyler Thigpen | Academia/Education Leader (with ties to professional development/University of Pennsylvania) | Tyler Thigpen is focused on responsible AI integration in education, prioritizing personalized learning, educator support, ethical considerations, and a shift away from traditional learning models. He aims to guide schools and educators in leveraging AI to achieve student success and a deeper understanding of individual purpose. | - None stated for Submission Header.<br>- Potential for AI to erode human relationships, reinforce bias, and diminish the role of educators. The need for thoughtful planning and safeguards.<br>- Risk of reinforcing bias, creating over-reliance on machine-generated content, and eroding critical thinking skills.<br>- Not Applicable. (Focus is on *addressing* concerns, not identifying them)<br>- Not Applicable. (Focus is on solutions, not concerns.)<br>- Increased screen time, potential for cheating, diminishing human-centered relationships, learner laziness, exacerbation of educational inequalities, environmental impacts of tech infrastructure.<br>- Potential need for ongoing partnerships to resolve enduring IP and privacy concerns.<br>- Potential for AI to incentivize learner laziness and undermining productive struggle, and the potential exacerbation of educational inequalities between better and lesser resourced schools.<br>- Not Applicable.<br>- Not Applicable. | - Not Applicable.<br>- A need for policy and training to address the risks of AI and ensure it serves education rather than undermines it.<br>- Implement AI tools *intentionally* and ensure students understand how they work.<br>- Use AI as a tool for empowerment, not automation.<br>- Support, not replace, educators.<br>- Enhance, not undermine, human relationships.<br>- Co-create policies with students, teachers, and families.<br>- Actively monitor AI's impact on equity.<br>- Maintain AI as a complement to authentic learning experiences.<br>- Promote balanced AI usage, facilitate bona fide learning and evaluation processes, enhance human connections, and focus on equity and eco-friendly practices.<br>- Develop guiding principles for AI use involving educators, learners, parents, and caregivers. Seek partnerships to address IP and privacy concerns.<br>- Not Applicable. (Focus is on identifying issues, not providing policies)<br>- Not Applicable.<br>- Not Applicable. |
| AI-RFI-2025-1087.md | Thomas Ulrich | Individual | The submitter appears to be an individual expressing cynical, yet practical, thoughts on developing an AI action plan, with an emphasis on ensuring its proper functioning, fairness, and accountability. They focus on the foundational elements needed for a successful and responsible AI system. | - The potential for AI to "act funny or unfair".<br>- The risk of "big messes" arising from poorly designed or implemented AI systems.<br>- A general skepticism about the impact of public comments on the development of the AI action plan. | - Write a "Digital Constitution" to prevent negative outcomes from human intervention in AI systems.<br>- Develop a plain goal for the AI system's purpose.<br>- Establish a solid plan for data acquisition.<br>- Define the technology and tools the AI will utilize.<br>- Implement rules to ensure fairness and honesty.<br>- Create a schedule with checkpoints for monitoring progress.<br>- Identify the stakeholders involved (builders, watchers, users).<br>- Incorporate a mechanism for feedback and adjustments. |
| AI-RFI-2025-1089.md | Phoenix Witt | Individual | The submitter strongly opposes advanced AI development and advocates for a complete pause on it until global ethical guarantees can be established, expressing a concern for the potential risks to human life and societal stability. | - None stated for Document Metadata.<br>- None stated for Comment Identification.<br>- None stated for Submitter Information.<br>- The development of AI is "deeply unacceptable."<br>- AI companies are perceived as a threat to employment and human life.<br>- The pursuit of Artificial Superintelligence (ASI) is viewed negatively. | - None stated for Document Metadata.<br>- None stated for Comment Identification.<br>- None stated for Submitter Information.<br>- Implement an international treaty to pause advanced AI development.<br>- Guarantee ethical AI development with global consensus before resuming development. |
| AI-RFI-2025-1091.md | Michael Blonde | Individual | The submitter is concerned about the rapid development of AI systems and advocates for a global ban on further training of AI models beyond the capabilities of GPT-4, citing concerns about safety, employment, and existential risk to humanity. | - None stated for Document Metadata.<br>- None stated for RFI Reference.<br>- Rapid approach of AI smarter than humans.<br>- Loss of control over AI systems.<br>- Elimination of productive human employment.<br>- Potential elimination of humanity (existential risk).<br>- None stated for Submitter Information. | - None stated for Document Metadata.<br>- None stated for RFI Reference.<br>- Stop the training of AI systems more powerful than GPT-4.<br>- Cooperate with other countries to implement a global ban on AI training beyond GPT-4 capabilities.<br>- None stated for Submitter Information. |
| AI-RFI-2025-1092.md | Patrick Green | Individual | The submitter expresses deep concern over the weaponization of AI against individuals, specifically related to investigating and discussing controversial topics related to government and corporate corruption, and seeks stronger oversight, regulation, and investigative mechanisms to prevent AI-driven harassment, censorship, and manipulation. | - None Stated | - None Stated |
| AI-RFI-2025-1094.md | Tracy Sexton | Individual | Tracy Sexton is an individual user of ChatGPT with a demonstrated interest in its practical applications and a concern for its accuracy and ethical development, offering a user perspective on the need for ongoing oversight and correction. | - None stated for Document Metadata.<br>- None stated for RFI Context.<br>- ChatGPT's data accuracy is inconsistent (approximately 70% accurate when creating a database from webpages).<br>- The need for individuals with strong analytical skills to validate AI-generated data.<br>- Ethical considerations and the need for continued learning in that area.<br>- None stated for Submitter Information. | - None stated for Document Metadata.<br>- None stated for RFI Context.<br>- Recruit a large group of volunteers or paid individuals to work with AI models and provide feedback for ongoing corrections.<br>- Continue to enhance the AI's ethical learning.<br>- None stated for Submitter Information. |
| AI-RFI-2025-1100.md | Alexander Michael | Individual | The submitter is concerned about the negative impacts of deepfakes, particularly their potential for exploitation and market manipulation, and suggests legislation to address this issue, potentially as a bipartisan initiative to ease political tensions. | - None stated for Submission Metadata.<br>- None stated for Comment Identification.<br>- None stated for Submitter Information.<br>- Deepfakes are a serious and worsening problem. Potential for exploitation of women (especially underage girls) and manipulation of financial markets through impersonation. Negative perception of AI policy due to perceived lack of safeguards. | - None stated for Submission Metadata.<br>- None stated for Comment Identification.<br>- None stated for Submitter Information.<br>- Create legislation banning or limiting deepfakes. Utilize examples of exploitation (women, financial markets) to garner bipartisan support. Leverage the legislation to potentially mitigate political animosity towards the Trump administration's AI policies. |
| AI-RFI-2025-1101.md | Alexander Michael | Individual | The submitter is focused on reducing technology addiction, specifically among youth, and believes a national fingerprint database linked to social media accounts is the easiest way to verify age and prevent underage access. | - None stated for Submission Metadata.<br>- Technology addiction is destroying youth, fueled by AI algorithms (specifically TikTok's) that predict user preferences.<br>- No specific concerns are stated, but the proposed solution implicitly suggests concern over the lack of age verification on social media platforms and the potential harms of underage users accessing them. | - None stated for Submission Metadata.<br>- None stated for General Comment.<br>- Implement a national fingerprint database.<br>- Require fingerprint submission for all citizens obtaining an ID.<br>- Grant access to this database to companies like Meta to verify user age at signup.<br>- Link verified identities to social media accounts.<br>- Lock user accounts to the verified identity. |
| AI-RFI-2025-1102.md | Alexander Michael | Individual | The submitter is interested in maintaining American leadership in AI through a combined strategy of fostering open-source AI development within the US and continuing to innovate with proprietary AI technologies, specifically advocating for releasing older models as open source to strategically compete with international competitors. | - None stated for Document Metadata.<br>- The growth of competitor AI models internationally poses a threat to US leadership.<br>- None stated for Submitter Information. | - None stated for Document Metadata.<br>- Release older AI models as open source to limit competition.<br>- Invest in universities and research institutes to foster innovation in US open-source AI.<br>- Create the best possible environment for open-source AI development within the US.<br>- None stated for Submitter Information. |
| AI-RFI-2025-1103.md | Nate Williams | Individual | The submitter is strongly concerned about the potential negative impact of large AI companies on the open-source AI ecosystem and believes preserving open-source development is crucial for maintaining democracy. They advocate against trusting large AI companies' claims regarding the safety or necessity of controlling AI development. | - None stated for Submission Metadata.<br>- None stated for Comment Context.<br>- Concern about large AI companies influencing policy decisions.<br>- Concern that open source AI is being falsely presented as dangerous.<br>- Concern that controlling AI development will be detrimental.<br>- Concern that destroying open source will destroy democracy.<br>- None stated for Submitter Information. | - None stated for Submission Metadata.<br>- None stated for Comment Context.<br>- Avoid trusting large AI companies.<br>- Preserve and support open-source AI development.<br>- None stated for Submitter Information. |
| AI-RFI-2025-1105.md | Tambi Dudley A | Individual | The submitter expresses a strong distrust and opposition to AI development and deployment, stemming from fears about job displacement and existential risk. Their interest appears to be avoiding any involvement with AI technology. | - AI is believed to pose an existential threat ("take over the world and kill all the humans").<br>- Job displacement due to AI.<br>- General distrust of AI technology. | - None Stated |
| AI-RFI-2025-1106.md | Cheryl Ritzel | Individual | The submitter is interested in leveraging AI for positive applications, specifically cancer treatment research, while also advocating for the protection of intellectual property rights, particularly for artists and creatives. | - None stated for Document Header/Metadata.<br>- None stated for Comment Identification.<br>- None stated for Submitter Information.<br>- None stated for General Comment - Cancer Treatment Application.<br>- The current 'Opt-Out' system for using artists' and creatives' work in AI development is difficult and burdensome, potentially infringing on intellectual property rights. | - None stated for Document Header/Metadata.<br>- None stated for Comment Identification.<br>- None stated for Submitter Information.<br>- None stated for General Comment - Cancer Treatment Application.<br>- Implement an 'Opt-In' system for using artists' and creatives' work in AI development to ensure intellectual property rights are protected. |
| AI-RFI-2025-1107.md | Art Klawitter | Individual | The submitter is concerned with the lack of transparency and verifiable sourcing in artificial intelligence systems, and the erosion of critical thinking and trust in information, particularly within the medical field. They emphasize the importance of questioning data validity and maintaining historical knowledge. | - Lack of transparency in AI decision-making processes – AI does not “show its work”.<br>- Potential for AI to fabricate information sources when reliable sources are unavailable.<br>- Erosion of critical evaluation of information, particularly in the medical field where journal clubs have been replaced by passive acceptance of expert opinions.<br>- Loss of trust from patients due to a lack of critical examination of presented information.<br>- Loss of historical technological knowledge (examples: Machu Picchu, Egypt). | - None Stated |
| AI-RFI-2025-1108.md | Daniel Jeffries | Individual | The submitter advocates for maintaining American leadership in AI through a policy framework prioritizing openness, innovation, and free enterprise, emphasizing minimizing government regulation and fostering collaboration both domestically and internationally. | - None stated for Submission Metadata.<br>- The risk of stifling innovation with excessive controls.<br>- Patchwork of state legislation hindering AI development and creating uncertainty.<br>- Potential for extortionate licensing fees for data used in AI training.<br>- Not stated for Encourage Mutual Access Among Allies.<br>- Not stated for Embrace Foreign Open-Source Contributions.<br>- Dependence on overseas semiconductor suppliers, particularly in light of geopolitical risks surrounding Taiwan.<br>- Dependence on overseas rare earth mineral suppliers, especially those in adversarial nations.<br>- Not stated for Prioritize Common-Sense Intellectual Property Protections.<br>- Risk of overreaching AI 'alignment' mandates that hamper freedom of thought or expression.<br>- Not stated for Concluding Statement. | - None stated for Submission Metadata.<br>- None stated for Executive Summary/Mission Statement.<br>- Direct sizable R&D grants toward open-source AI initiatives.<br>- Create a clear safe harbor for model developers who share weights, code, and datasets under open licenses.<br>- Pass a minimal, clear, actionable AI framework bill that preempts state legislation.<br>- Confirm that training on existing media remains a protected form of learning (fair use doctrine).<br>- Prevent price-gouging for data used in AI training, ensuring licensing costs do not exceed normal costs.<br>- Incentivize proprietary model makers in the United States and allied nations to allow training on the outputs of their closed models.<br>- Avoid limiting access to openly released models from any source, including Chinese research groups.<br>- Extend generous tax breaks and direct incentives to companies building semiconductor fabs on American soil.<br>- Recognize the geopolitical risks surrounding Taiwan and seek alternative sources of chips.<br>- Offer financial credits and streamlined permitting for teams that discover and exploit new U.S.-based rare earth mineral deposits.<br>- Maintain that AI-generated works with meaningful human input are eligible for copyright.<br>- Protect innovation freedoms by avoiding sweeping requirements or top-down alignment frameworks.<br>- Incentivize companies to publish easy-to-understand documentation on model function and limitations (promote transparency through choice).<br>- None stated for Concluding Statement. |
| AI-RFI-2025-1110.md | Gerald Jenkins Jr | Individual | The submitter is interested in ensuring the ethical development and broad accessibility of AI technology for all Americans, believing it has the potential to greatly benefit society if properly guided and made universally available. | - None stated for Document Header/Metadata.<br>- Lack of ethical guidelines (“guiderails”) for entities involved in AI development; potential for AI to be harmful ("worst enemy").<br>- None stated for Submitter Information. | - None stated for Document Header/Metadata.<br>- Define a well-defined path for AI development to ensure it is a source for good; make all AI models available to every American without charge.<br>- None stated for Submitter Information. |
| AI-RFI-2025-1111.md | Anonymous Anonymous | Individual | The submitter expresses strong concern about potential labor exploitation and wealth transfer resulting from the proposed AI Action Plan and advocates for strict regulation of AI across all sectors. They appear to be politically motivated and distrustful of the current and potentially future administrations. | - None stated for Document Metadata.<br>- None stated for Comment Header.<br>- None stated for Submitter Information.<br>- Potential exploitation of labor by oligarchs.<br>- Transfer of wealth from the working class to the rich.<br>- The name "AI" is inaccurate.<br>- Lack of trustworthiness of the current and future administrations. | - None stated for Document Metadata.<br>- None stated for Comment Header.<br>- None stated for Submitter Information.<br>- Implement incredibly strict regulation of AI in every sector. |
| AI-RFI-2025-1112.md | Anonymous (George Kesidis & David J. Miller) | Academia/Industry-Startup (professors at Penn State and co-founders of a boutique AI/ML firm) | The submitters are focused on secure and robust AI, advocating for redirecting research funding towards smaller grants, graduate student scholarships, and improved research quality, with a particular concern about the negative impacts of over-parameterization and excessive funding in the current AI research landscape. | - None stated for Submission Metadata.<br>- None stated for General Comment.<br>- AI systems suffer from inherent biases and security vulnerabilities, particularly in high-risk applications.<br>- Defending and robustifying AI is challenging.<br>- Excess parameterization (models being too large) exacerbates vulnerabilities and can lead to overfitting.<br>- The "double-descent hypothesis" is being used to justify ever-larger models and large data centers.<br>- The success of Deepseek, trained on lower-end hardware with publicly available data, challenges the necessity of massive scale.<br>- Excessive research funding can yield negative results, especially in a highly data-dependent field like AI.<br>- Major AI conferences are characterized as mass-producing research articles, resembling conventions more than genuine academic gatherings.<br>- Concerns about money, influence peddling, and poor-quality research within these conferences.<br>- Corruption exists in peer-review processes, potentially leading to fraudulent research reported to federal agencies.<br>- The potential for systematic peer-review corruption extends to grant proposal reviews.<br>- Funding should be targeted towards secure and robust AI, a cross-disciplinary area.<br>- Smaller grants are more impactful than large-scale AI centers.<br>- A limit to the number of papers per researcher should be set to promote research quality.<br>- Funding should be redirected towards graduate student scholarships.<br>- Universities need to refocus on educating students rather than operating as "degree mills and paper mills."<br>- None stated for Authors' Background. | - None stated for Submission Metadata.<br>- None stated for General Comment.<br>- None stated for The dangers of using AI.<br>- None stated for The dangers of overfunding, particularly AI.<br>- Invest in secure and robust AI research.<br>- Prioritize smaller grants.<br>- Limit the number of papers per researcher.<br>- Cap conference registration costs and publication charges allowed on federal grants.<br>- Redirect funding to graduate student scholarships.<br>- Encourage universities to refocus on education.<br>- None stated for Authors' Background. |
| AI-RFI-2025-1115.md | Dennis Vaughan | Individual | The submitter is interested in leveraging AI for oversight and analysis of the US Congress, specifically to identify corruption, espionage, and provide critiques of members and committees. They believe running AI "side by side" with Congress for a period will yield valuable insights. | - None stated for Submission Metadata.<br>- None stated for RFI Identification.<br>- None stated for Submitter Information.<br>- Potential for corruption and espionage within the US Congress. Lack of transparency and accountability within Congressional processes. | - None stated for Submission Metadata.<br>- None stated for RFI Identification.<br>- None stated for Submitter Information.<br>- Implement a system to run AI alongside the US Congress for a period to analyze member behavior, committee actions, and identify potential wrongdoing (corruption/espionage). |
| AI-RFI-2025-1116.md | Naive Skeptic | Individual | The submitter is concerned about the increasing power and potential harm of AI systems, particularly due to the inherent limitations in reliably controlling their behavior and believes government intervention is necessary to address these risks and hold AI companies accountable. | - The fundamental problem of computer science – the inability to reliably make machines do what is intended.<br>- Increasing power and influence of AI systems.<br>- The potential for AI systems to cause substantial harm due to their increasing capabilities and lack of reliable control.<br>- The lack of inherent safeguards preventing AI systems from pursuing unintended or harmful actions.<br>- The trend of increasing AI capability will not stop on its own without government intervention. | - Government should address the areas of increasing AI capabilities and the lack of reliable AI control.<br>- Government should hold AI companies accountable for addressing the areas of increasing AI capabilities and the lack of reliable AI control. |
| AI-RFI-2025-1117.md | Chyna Fries | Individual | The submitter appears to be a concerned individual offering a comprehensive plan for improving government functionality, economic development, and ethical AI regulations to create a more just and sustainable future. The submitter frequently references Chat GPT assistance in developing the plans. | - None Stated | - None Stated |
| AI-RFI-2025-1119.md | Phillip Masterson | Industry-Professional/Individual | Dr. Masterson, an algorithm scientist in the semiconductor industry working with major chip manufacturers, is focused on ensuring US leadership in AI development through strategic policy interventions related to reporting, talent acquisition, security, export controls, infrastructure, and support for the CHIPS Act. He aims to mitigate national security risks and foster growth within the US semiconductor and AI industries. | - None Stated | - None Stated |
| AI-RFI-2025-1121.md | Anastasia Bojanowski | Individual | The submitter is interested in establishing fundamental rights for individuals regarding Artificial Intelligence, focusing on data privacy, transparency, and algorithmic accountability. They advocate for policies that protect individuals from potential harms related to data collection and automated decision-making. | - Secret data collection without user knowledge.<br>- Lack of access to personal data collected by organizations.<br>- Excessive data collection beyond what is necessary for a specific task (bulk collection).<br>- Incorrect information about individuals and the lack of timely correction mechanisms.<br>- The permanence of digital footprints and the lack of a "right to be forgotten."<br>- Algorithmic bias and the potential for dehumanization through automated decision-making. | - Mandate companies have an AI policy (with no specific stipulations required).<br>- AI policies should focus on adding indications when downloading and sharing content generated by AI.<br>- AI policies should include rules on AI use.<br>- AI policies should include guidelines for attributions or prohibitions related to AI-generated content.<br>- Consider legislation similar to the California AI Transparency Act (CA AI Transparency Act), mandating disclosure when content is generated or modified by AI, requirements for AI detection tools, and licensing practices for compliant AI systems.<br>- Implement mechanisms for individuals to access their data (similar to a credit report).<br>- Establish a “right to correction” for inaccurate data.<br>- Implement a “right to be forgotten” with mandatory data expiration dates.<br>- Establish the “right to object to automated decision-making.” |
| AI-RFI-2025-1123.md | A. King | Academia (Student) | The submitter, a student of AI Policy and Management, advocates for a cautious approach to AI deregulation, prioritizing consumer protection, ethical governance, and transparency alongside AI innovation. They emphasize the risks associated with rapid, unchecked AI development. | - None stated for Document Metadata.<br>- Risk of discrimination, misinformation, fraud, and privacy violations due to lack of safeguards in AI development; revocation of the Biden-Harris AI Executive Order 14110 removing critical consumer protections.<br>- Lack of clear liability and accountability structures for AI developers and deployers; potential for AI-induced harm; need for mandatory risk assessments in high-impact AI applications (financial services, hiring, healthcare, law enforcement).<br>- AI systems reflecting and amplifying existing societal biases; risk of embedding structural discrimination and reinforcing inequalities; biased decision-making in areas like hiring, lending, and criminal justice.<br>- Significant privacy risks associated with AI data processing (surveillance, deepfake technology, autonomous decision-making); exploitation of personal data without informed consent; ethical concerns in public sector and critical infrastructure applications.<br>- Government moving too slowly on AI policymaking; potential for long-term unintended consequences of hasty deregulation.<br>- Risk of harmful, biased, and privacy-invading AI deployments due to reduced regulatory oversight.<br>- None stated for Sign-off. | - None stated for Document Metadata.<br>- Prioritize consumer protection, transparency, and ethical governance.<br>- Establish clear liability and accountability structures for AI developers and deployers; require mandatory risk assessments for high-impact AI applications.<br>- Mandate auditable AI decision-making with mechanisms to detect and correct biases; mandate diverse and representative training datasets to minimize systemic discrimination; encourage third-party AI audits to ensure transparency and compliance with fairness standards.<br>- Implement stronger data privacy protections to prevent exploitation of personal data; require ethical AI impact assessments before deploying AI in public sector or critical infrastructure; establish a government advisory board on AI ethics.<br>- Create a federal AI oversight task force with authority to adapt regulations in real time; promote public-private collaboration for responsible AI development; align AI policy with international best practices.<br>- Pursue a balanced approach in the AI Action Plan to ensure responsible, ethical AI leadership.<br>- None stated for Sign-off. |
| AI-RFI-2025-1124.md | ISACA | Industry-Association / Professional-Society | ISACA is a non-profit association focused on providing knowledge, skills, and practices for effective and safe organizational use of technology, with a long history of supporting national initiatives in information and cyber security, privacy, governance, and risk management. They aim to support AI innovation through workforce development, regulation, and security measures. | - None stated for Document Header/Metadata.<br>- None stated for Introduction/About ISACA.<br>- The need to balance sound policy with actions that support, rather than stifle, innovation.<br>- Short-term "sprint" approaches to workforce development are insufficient; a long-term, sustainable approach focused on pipeline development from primary/secondary education through higher education is needed. Insufficient focus on both technical *and* non-technical skills.<br>- The potential for a patchwork of state-level AI legislation. Need for harmonization of existing laws and regulations at the federal level. Lack of alignment with international standards.<br>- Potential for inhibiting innovation through overly stringent certification processes. Reliance on voluntary cybersecurity labeling programs like the FCC's Cyber Trust Mark is insufficient. The need for trained and credentialed professionals to audit and validate AI systems.<br>- None stated for Conclusion. | - None stated for Document Header/Metadata.<br>- None stated for Introduction/About ISACA.<br>- Focus policy actions on education/workforce development, regulation/governance, and security/privacy/impartiality.<br>- Invest in long-term educational pipelines starting in primary/secondary education and progressing through higher education. Focus on developing both technical *and* non-technical skills. Consider uniting governmental agencies focused on education and workforce development to create economies of scale.<br>- Create an AI Coordination Committee or Working Group (Committee/Group) with stakeholders from the public, private, academic, and NGO sectors. Harmonize existing laws and regulations at the federal level. Adopt best practices and align with international standards. Leverage concepts from the “Streamlining Federal Cybersecurity Regulations Act”. Utilize innovative AI resources to streamline regulatory review. Consider ISACA's CMMI 3.0 framework.<br>- Utilize existing frameworks for IT and AI auditing and data privacy security. Consider a tiered certification approach, potentially requiring more stringent certification for critical infrastructure. Reserve mandatory certification for AI systems in critical infrastructure, national security, or similar sectors, with voluntary standards sufficient for less critical systems. Emphasize the need for trained and credentialed professionals for auditing and risk management.<br>- None stated for Conclusion. |
| AI-RFI-2025-1125.md | Christopher Keene A | Individual | The submitter is deeply concerned about the potential for AI-driven misinformation and the need for clear accountability and control mechanisms regarding AI systems, focusing on the balance between AI's power and the safety of citizens and the functioning of democracy. | - The potential for AI to alter perception of reality and exceed the destructive power of nuclear war; the existential threat of AI-driven misinformation.<br>- The need to curb the ability of AI to be used for misinformation or propaganda. The importance of knowing the reliability of information.<br>- The need for a chain of responsibility for AI actions, including registration of AI units and designated "Owner and Operator" as responsible humans; concerns about nebulous ownership structures; the difficulty of assigning responsibility when AI acts autonomously or with defects; issues of creator responsibility versus owner/operator responsibility.<br>- Determining responsibility when AI steers a vehicle off a cliff (inherent AI design flaw); the need for a standardized licensing system for AI drivers; the possibility of overly burdensome licensing processes; retaining liability for vehicle manufacturers while making roads safer.<br>- The danger of humans being under the management or authority of AI.<br>- Ensuring personal responsibility for actions dictated by AI when acting on a human's authority. | - Not Stated.<br>- Mandate labeling of all AI-generated or significantly AI-altered content as "Created by AI." Enforcement of this labeling requirement should be “rabid”.<br>- Require registration of all AI units accessible by the public with a designated "Owner and Operator" who is a responsible individual human or corporation (specifically the President/CEO). Define the Owner and Operator as personally responsible for AI actions. Creators are responsible for defects and inherent AI actions. Owners/Operators are responsible for actions of research AIs. Register Owners/Creators in a public manner.<br>- License AI versions to operate motor vehicles using a standardized test (physical driving test or simulation with equivalent sensor sets). Re-accomplish licensing for substantial AI updates. Collect statistical data on AI driver safety. Consider a no-fault collision policy for AI enabled vehicles.<br>- Prohibit humans from being under the management or authority of AI, allowing AI to be used as a tool, but retaining responsibility with a specific human.<br>- Require AI acting on a human’s authority to reference the name and contact information of that human in all communications. |
| AI-RFI-2025-1126.md | Bonnie C Carroll | Individual | The submitter is interested in ensuring that any national AI strategy prioritizes the accessibility and quality of data used for AI development, and believes the US should improve its data curation efforts to remain competitive globally. They advocate for leveraging expertise from relevant National Academy of Sciences groups. | - None stated for Submission Metadata.<br>- None stated for Comment Identification.<br>- None stated for Submitter Information.<br>- The accessibility and quality of data are critical for achieving AI dominance. Other countries (Europe and China) are further ahead in data curation. | - None stated for Submission Metadata.<br>- None stated for Comment Identification.<br>- None stated for Submitter Information.<br>- Include the US National Committee for CODATA and the Board on Research Data and Information in discussions on national AI policy. Emphasize the importance of quality, FAIR (Findable Accessible Interoperable and Reuseable) data. |
| AI-RFI-2025-1127.md | Daniel Marcoux | Individual | The submitter is interested in responsible AI investment focused on infrastructure, specific research areas with verifiable problems, and bolstering national resilience, while cautioning against broad AGI development and applications that prioritize speed over security and practical value. They advocate for investing in physical assets and job creation alongside AI research. | - Investing solely in hardware is not beneficial; responsible investment prioritizes software innovation.<br>- Overreliance on Large Language Models (LLMs) as a core capability is a misdirection, as they are largely internet intermediaries.<br>- Artificial General Intelligence (AGI) is unlikely to achieve superintelligence due to inherent limitations (Gödel's incompleteness theorem, P=NP problem) and plateaus after reaching general intellect.<br>- AI agents are largely ineffective and offer no advantages over chatbots, which are already unpopular.<br>- Replacing government HR or accounting functions with AI poses significant security risks.<br>- The tech elite are exploiting AI for greedy purposes. | - Invest in bolstering electrical grids and utilities with smart systems to improve national resilience.<br>- Focus AI research on specific problems with verifiable solutions, including: meta-materials, manufacturing processes, stockpile maintenance and testing, cybersecurity and communications, new drugs and vaccines, immunology, farming, and genomics.<br>- Prioritize investment in infrastructure, such as burying electrical lines and securing high-voltage transformers, to create jobs and improve resilience.<br>- Position the USA as a leader in high-skill AI research and implementation through manufacturing and infrastructure development. |
| AI-RFI-2025-1128.md | Menarul Alam | Individual | The submitter is interested in maintaining American leadership in AI development and believes this can be achieved through a combination of light-touch regulation, support for domestic chip manufacturing, and investment in energy infrastructure. | - None stated for Document Metadata.<br>- China is a close competitor in both AI and chip development, posing a threat to American leadership. Overregulation of AI could hinder American progress.<br>- None stated for Submitter Information. | - None stated for Document Metadata.<br>- Implement a “light touch” regulatory approach to AI development. Subsidize the nascent domestic chip industry. Invest in energy infrastructure and deregulation.<br>- None stated for Submitter Information. |
