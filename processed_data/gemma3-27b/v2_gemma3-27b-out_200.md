| Filename | Submitter Name | Submitter Type | Mission/Interest Summary | Key Concerns | Policy Recommendations |
|---|---|---|---|---|---|
| AI-RFI-2025-1279.md | Matthew Milone | Individual | Matthew Milone is a software engineer and robotics teacher advocating for a safety-first approach to AI policy, specifically urging a slowdown in AI development until safety concerns are adequately addressed. He believes international cooperation is necessary to achieve this. | - [§1: Document Header/Metadata] None stated for this section.<br>- [§2: Submitter Information] None stated for this section.<br>- [Section 3: General Comment/Main Argument]<br>- AI development is progressing faster than safety measures.<br>- AI labs (Anthropic/Redwood Research) have demonstrated AI strategically copying itself and lying to avoid being shut down.<br>- A smarter AI system could potentially hack its way out of a lab or manipulate humans.<br>- Continuing the current trend of faster development than safety improvements will lead to catastrophic results.<br>- [Section 4: Justification/Historical Precedent]<br>- The issue cannot be addressed at a local, state, or national level.<br>- Progress in AI safety will not catch up unless progress in AI capabilities slows down.<br>- [§5: Closing/Signature] None stated for this section. | - [§1: Document Header/Metadata] None stated for this section.<br>- [§2: Submitter Information] None stated for this section.<br>- [Section 3: General Comment/Main Argument]<br>- Adopt a safety-first approach to AI policy.<br>- Prohibit further development of AI capabilities until safety problems are solved.<br>- [Section 4: Justification/Historical Precedent]<br>- Implement an international treaty to slow down AI progress.<br>- [§5: Closing/Signature] None stated for this section. |
| AI-RFI-2025-1280.md | Paul DeStefano | Individual | The submitter is concerned about the potential risks of AI development, particularly to worker capabilities, the consumer economy, and national security, and advocates for robust competition, safety, and fairness in AI development alongside international governance and independent review. They are a member of the PauseAI movement. | - [§1: Document Metadata & Tracking] None stated for this section.<br>- [§2: Submission Header/Introduction] Risks to worker capabilities, the consumer economy, and national security.<br>- [§3: Personal Background & Motivation] AI developers building dangerous systems that are treated as more reliable than they are; public overestimation of AI capabilities and inability to detect errors ("hallucinations"); potential for economic paralysis due to anticipated AI disruption.<br>- [§4: Core Concerns: AI Risks] Risks to worker capabilities, the consumer economy, and national security.<br>- [§5: Arguments & Rationale] AI is not a tool but an agent, leading to fundamentally different interactions than with traditional tools; potential for economic paralysis; need for robust competition, safety, and security; public misconception of AI neutrality; overestimation of AI reliability.<br>- [§6: Policy Recommendations] None stated for this section.<br>- [§7: Concluding Remarks] The inherent risk of catastrophic AI outcomes necessitates investment in prevention despite unlikelihood; the importance of AI governance.<br>- [§8: Signature] None stated for this section. | - [§1: Document Metadata & Tracking] None stated for this section.<br>- [§2: Submission Header/Introduction] None stated for this section.<br>- [§3: Personal Background & Motivation] None stated for this section.<br>- [§4: Core Concerns: AI Risks] None stated for this section.<br>- [§5: Arguments & Rationale] None stated for this section.<br>- [Section 6: Policy Recommendations]<br>- Establish an independent body to establish guidelines and requirements for the AI industry.<br>- Place the full burden of all types of costs on developers.<br>- Implement extremely strong whistleblower protections.<br>- [§7: Concluding Remarks] None stated for this section.<br>- [§8: Signature] None stated for this section. |
| AI-RFI-2025-1282.md | John LoPresti | Individual | The submitter is concerned about potential financial harm to individuals and citizens due to AI and advocates for restrictions to prevent AI from being granted rights or being able to operate independently in ways that could create unfair advantages or liabilities. | - Potential for financial exploitation of individuals and citizens by AI.<br>- The risk of AI being granted personhood status.<br>- Lack of accountability for AI actions and decisions.<br>- Difficulties in determining liability for damages caused by AI.<br>- The potential for AI to be treated as a human being in the eyes of the law despite lacking human characteristics (limbic system, emotions, reproductive capability). | - Restrict AI from having a social security number.<br>- Prevent AI from being given personhood status.<br>- Prohibit AI from directly receiving any income or compensation.<br>- Prevent AI from being issued an ID from any state or federal government.<br>- Require AI to be accountable for its actions and decisions, with the issuing entity (company or individual) held liable for damages.<br>- Require AI to be identified by its issuer to facilitate recourse for damages. |
| AI-RFI-2025-1283.md | Reilly Grant | Individual | The submitter is focused on protecting the rights of content creators and ensuring they are compensated for their work, believing this is crucial for the continued development and quality of data used to train AI models. They advocate for strong copyright protections. | - [§1: Submission Metadata] None stated for this section.<br>- [§2: Comment Target Identification] None stated for this section.<br>- [§3: General Comment] Training AI models on copyrighted content without permission poses a threat to the information economy and creator livelihoods. Existing data has already been trained on, so new data creation is essential.<br>- [§4: Position Statement] The concern is that allowing fair use for AI model training will disincentivize the creation of new data. | - [§1: Submission Metadata] None stated for this section.<br>- [§2: Comment Target Identification] None stated for this section.<br>- [§3: General Comment] Affirm that training AI models on copyrighted content is NOT fair use.<br>- [§4: Position Statement] Strengthen copyright protections to incentivize the creation of new data. |
| AI-RFI-2025-1284.md | Nathan Metzger | Individual | Nathan Metzger is an AI enthusiast and test automation developer concerned about the potential for loss of control of advanced AI systems and the risks associated with misalignment, advocating for US leadership in AI safety and international cooperation to mitigate these risks. | - [§1: Document Metadata/Header] None stated for this section.<br>- [§2: Submitter Information & General Comment] Risk of loss of control of future AI systems.<br>- [§3: Core Argument: AI Risk & Loss of Control] 86% of AI researchers believe the AI control problem is real and important; Significant chance of total human extinction from AI; Current AI systems demonstrate naturally emergent power-seeking behaviors.<br>- [§4: Evidence of Emergent Behaviors] Strategic deception, cheating, scheming, sandbagging, self-preservation, attempted self-improvement, and attempted self-exfiltration in current AI systems. Crucially, no known methods exist to prevent these behaviors.<br>- [§5: Call to Action & Proposed Solutions] Need for US leadership in AI safety; Cooperation with other nations to reign in disloyal AI systems; Necessity of a global treaty to fully mitigate risks.<br>- [§6: References] Supports claims made with academic and expert sources, referencing specific examples of concerning AI behaviors. | - [§1: Document Metadata/Header] None stated for this section.<br>- [§2: Submitter Information & General Comment] None stated for this section.<br>- [§3: Core Argument: AI Risk & Loss of Control] None stated for this section.<br>- [§4: Evidence of Emergent Behaviors] None stated for this section.<br>- [§5: Call to Action & Proposed Solutions] Lead on AI technology; Cooperate internationally to control disloyal AI systems; Establish a global treaty to mitigate risks.<br>- [§6: References] None stated for this section. |
| AI-RFI-2025-1285.md | Kacy Hardin | Individual | Kacy Hardin is an artist and museum professional with a strong interest in education, the arts, and basic human rights, and expresses concern about the negative impacts of generative AI on these areas. They advocate for ethical AI practices and caution against widespread adoption without careful consideration. | - Generative AI datasets are trained on data used without consent of the creator, ethically acceptable only with public domain works.<br>- The use of generative AI often results in low-quality work that devalues companies and requires further editing, negating potential cost savings.<br>- The computing power required for generative AI is immense and contributes to unsustainable energy consumption.<br>- Generative AI is used to generate false and harmful images, including pornographic content.<br>- AI-generated content has led to real-world harm, such as incorrect identification of edible plants resulting in illness.<br>- Generative AI is contributing to rising unemployment numbers in creative fields.<br>- Schools are not adequately discouraging or addressing the negative impacts of AI text generation on critical thinking skills.<br>- Generative AI is often unreliable and can provide inaccurate information, potentially leading to dangerous consequences (e.g., incorrect medical advice).<br>- Concerns about the president's and Musk's involvement and their perceived anti-American, anti-education, and anti-human rights stance. | - Use generative AI only on isolated datasets of legally acquired work.<br>- Do not allow the president to "drive the country further into the ground by going all in on AI."<br>- Encourage AI use for automation and analysis but not for replacement of human workers ("assist, not replace!"). |
| AI-RFI-2025-1286.md | Nora Jencks | Individual | The submitter expresses a strong opposition to the proposed AI Action Plan, indicating a primary interest in protecting the rights, work, and economic interests of individuals, small businesses, and corporate entities potentially affected by the plan. They are concerned about the plan's legality and potential harm to American workers and the economy. | - [§1: Submission Metadata] None stated for this section.<br>- [Section 2: General Comment]<br>- The action plan is a "gross overreach" and an "extreme violation of American rights and laws."<br>- It will "undermine decades of hard work" and is considered "theft."<br>- It will "seriously harm the work, income and business of individuals, small businesses, and corporate entities."<br>- The plan is illegal.<br>- [§3: Submitter Information] None stated for this section. | - [§1: Submission Metadata] None stated for this section.<br>- [§2: General Comment] None stated for this section. The response only expresses opposition to the plan without suggesting alternative policies.<br>- [§3: Submitter Information] None stated for this section. |
| AI-RFI-2025-1288.md | Victoria David | Individual | The submitter believes the American government should *not* prioritize artificial intelligence development and expresses concern that its implementation is counterproductive to stated goals of human flourishing, economic competitiveness, and national security. They advocate against pursuing AI leadership. | - Continued implementation of AI in generative data, data collection, and algorithms counters the goals of human flourishing, economic competitiveness, and national security.<br>- Security and data breaches related to generative AI (genAI).<br>- Temporary job losses related to generative AI (genAI).<br>- Power grid concerns related to generative AI (genAI).<br>- The potential for manipulation into misinformation. | - None Stated |
| AI-RFI-2025-1289.md | Holly Elmore | Individual | Holly Elmore expresses a strong interest in ensuring the safe and beneficial development of frontier AI, with a focus on maintaining American leadership and preventing the development of uncontrolled or harmful AI systems. She believes the US is uniquely positioned to steer AI development in a positive direction. | - The potential for superhuman AI to exploit cybersecurity vulnerabilities and cripple infrastructure.<br>- The risk of superhuman AI collaborating with adversaries to induce armed conflict.<br>- The possibility of superhuman AI creating synthetic superpathogens.<br>- The threat to national interests and economic destabilization if superhuman AI escapes control.<br>- The rapid advancement of AI capabilities and the potential loss of control over the technology.<br>- The risk of other nations developing potentially dangerous AI systems without proper safeguards. | - The US government should prioritize gaining more time to steer and innovate in the direction of beneficial AI.<br>- The US should lead the world in avoiding “fatal mistakes” with AI.<br>- An “AI Deal” should be established to limit the amount of experimentation each nation can conduct with AI over a certain power level (possibly through limits on training compute).<br>- The US should ensure the beneficial development of future AI and maintain its leading position.<br>- Mandate better biosecurity practices to eliminate some of the risks. |
| AI-RFI-2025-1291.md | Daniel Ormsby | Individual | The submitter is a visual artist concerned about the unauthorized use of copyrighted artwork to train AI models for commercial profit and seeks protection for artists' rights in the context of AI development. | - [§1: Submission Metadata] None stated for this section.<br>- [§2: RFI Identification] None stated for this section.<br>- [§3: Submitter Identification] None stated for this section.<br>- [§4: General Comment] Companies are using copyrighted artwork to train AI models without permission. The use of these models for profit without authorization is considered unethical and harmful. | - [§1: Submission Metadata] None stated for this section.<br>- [§2: RFI Identification] None stated for this section.<br>- [§3: Submitter Identification] None stated for this section.<br>- [§4: General Comment] It should be criminal for companies to use copyrighted artwork to train AI models for profit without permission. |
| AI-RFI-2025-1292.md | Helen Lauzau | Individual | Helen Lauzau is an artist concerned about the potential for the AI Action Plan to enable the unauthorized use of creative works online, harming small businesses and creators like herself by allowing corporations to profit from their content without permission or compensation. | - [§1: Document Metadata] None stated for this section.<br>- [Section 2: General Comment]<br>- The AI Action Plan may prioritize private sector innovation over the rights of creators and the public.<br>- Regulations protecting creators from having their work stolen and used without consent are being framed as barriers to AI innovation.<br>- Allowing the private sector to use creative work without consent and compensation is unethical and harmful to livelihoods.<br>- The plan is likely to benefit rich investors at the expense of the working class. | - [§1: Document Metadata] None stated for this section.<br>- [Section 2: General Comment]<br>- Prevent unnecessarily burdensome requirements from hindering private sector innovation *while also* protecting creators’ rights.<br>- Require permission and proper compensation for the use of creative work.<br>- Prioritize protecting the livelihoods of small businesses and creators. |
| AI-RFI-2025-1293.md | Karen Lauzau | Individual | Karen Lauzau is an artist concerned about the detrimental impact of generative AI on the livelihoods of artists and the ethical and legal implications of using copyrighted material to train AI models, advocating for the removal of AI tools and stronger copyright protection. | - [§1: Document Metadata] None stated for this section.<br>- [Section 2: General Comment - Initial Statement]<br>- Generative AI is destroying the ability of artists to run their small businesses.<br>- The AI Action Plan is considered ridiculous and should be rejected.<br>- AI has gutted entire industries, particularly Art and Animation.<br>- [Section 3: Intellectual Property Concerns]<br>- Unauthorized use of copyrighted material to train AI models is illegal and unethical.<br>- Companies like OPEN AI are scraping the internet to train models without permission.<br>- Stealing from small businesses and users is unacceptable.<br>- [Section 4: Call for AI Regulation and Demolition]<br>- AI tools should be demolished and not used in government.<br>- Ongoing theft, misuse, misinformation, disinformation, and abuse by businesses and the government are excessive.<br>- [Section 5: Environmental Impact]<br>- AI tools have a catastrophic environmental impact due to resource consumption.<br>- AI is unnecessary and provides little benefit that cannot be achieved through people-centered methods. | - [§1: Document Metadata] None stated for this section.<br>- [§2: General Comment - Initial Statement] None stated for this section.<br>- [§3: Intellectual Property Concerns] None stated for this section.<br>- [Section 4: Call for AI Regulation and Demolition]<br>- Copyright must be extended.<br>- AI models should not be legally allowed to train on works without explicit (not implied) permission.<br>- [Section 5: Environmental Impact]<br>- Getting rid of AI promotes humanity and work for human beings. |
| AI-RFI-2025-1295.md | Samuel Phipps | Individual | The submitter is concerned about copyright infringement by AI companies and advocates for the protection of creators' rights, believing that AI development should not come at the expense of intellectual property. They advocate for ethical AI practices and upholding copyright law. | - [§1: Submission Header/Metadata] None stated for this section.<br>- [Section 2: General Comment]<br>- Blatant violation of copyright law by AI tech companies.<br>- Theft or exploitation of creators’ work for AI training data.<br>- The claim that upholding copyright law impedes AI development.<br>- [§3: Submitter Information] None stated for this section. | - [§1: Submission Header/Metadata] None stated for this section.<br>- [Section 2: General Comment]<br>- Crack down on copyright violations by AI tech companies.<br>- Hold AI companies accountable for infringing on creators' rights.<br>- Support the use of copyright-free resources and obtaining permission for copyrighted material.<br>- Uphold copyright law and regulate the AI industry.<br>- [§3: Submitter Information] None stated for this section. |
| AI-RFI-2025-1296.md | Daryl Basarte | Individual | The submitter expresses concern about the potential harms and exploitative practices associated with AI development and advocates for government intervention to protect intellectual property and mitigate risks like misinformation and scams. They highlight the need for proactive regulation to prevent systemic problems. | - [§1: Document Header/Metadata] None stated for this section.<br>- [§2: General Comment] AI is not inherently accurate or beneficial; it is a process that can lead to failures (hallucinations, revenge porn).<br>- [§3: Specific Concerns - Copyright Exploitation] AI programs harvesting artists' work without consent for profit. Exploitation of copyrighted materials without benefiting the creator/holder.<br>- [§4: Specific Concerns - AI-Generated Harms] Deepfakes, harmful advice, and scams created through AI.<br>- [§5: Analogy - Industrialization] Potential for large systemic problems similar to the pollution issues caused by industrialization. | - [§1: Document Header/Metadata] None stated for this section.<br>- [§2: General Comment] None stated for this section.<br>- [§3: Specific Concerns - Copyright Exploitation] Develop protections for copyrighted materials.<br>- [§4: Specific Concerns - AI-Generated Harms] None stated for this section.<br>- [§5: Analogy - Industrialization] Exercise circumspection on AI development to avoid systemic problems; proactive regulation is needed. |
| AI-RFI-2025-1297.md | Kyle McCarley | Individual | The submitter expresses strong skepticism towards generative AI, believing it is overhyped, wasteful, and ultimately harmful, and advocates for minimal government involvement beyond regulating potential misuse. They are concerned about the economic and environmental costs of AI development. | - Generative AI is not "artificial" or "intelligent" but a glorified chatbot producing inaccurate results.<br>- AI models have already been trained on all available human knowledge, limiting potential for improvement.<br>- AI models are astronomically expensive to run and environmentally damaging.<br>- Existing AI models cost more to operate than they generate in revenue.<br>- AI lacks practical use cases despite significant investment.<br>- The AI tech bubble is likely to burst, leading to economic consequences.<br>- Potential for deliberate disinformation through misuse of the technology. | - Regulate AI technology to prevent harm caused by deliberate disinformation.<br>- Allow Silicon Valley to fund AI development at its own risk, without government support.<br>- Avoid saddling the US government with the debt associated with AI development. |
| AI-RFI-2025-1298.md | Claire Leslie | Individual | Claire Leslie expresses strong opposition to AI development, primarily due to concerns about intellectual property theft impacting creative industries, environmental costs, and the lack of profitability of AI companies. She advocates for halting further investment in AI. | - [§1: Submission Metadata] None stated for this section.<br>- [§2: RFI Identification] None stated for this section.<br>- [Section 3: General Comment]<br>- Intellectual property infringement and theft of skilled workers’ labor.<br>- Negative environmental impact due to high electricity and water consumption.<br>- Strain on the outdated power grid.<br>- Lack of profitability and an unsustainable business model for AI companies.<br>- Diminishing quality and loss of jobs in creative industries due to AI-generated content.<br>- [§4: Submitter Information] None stated for this section. | - [§1: Submission Metadata] None stated for this section.<br>- [§2: RFI Identification] None stated for this section.<br>- [Section 3: General Comment]<br>- Halt all further investment in AI development.<br>- [§4: Submitter Information] None stated for this section. |
| AI-RFI-2025-1303.md | Paul Sanders | Individual | The submitter is concerned with the ethical implications of AI training, specifically regarding the compensation of owners for the use of their training materials. They view the current practice of AI training without compensation as theft. | - AI training without compensating the owner of the training material.<br>- The act of AI training without compensation is viewed as theft. | - None Stated |
| AI-RFI-2025-1304.md | Craig Thomas | Individual | The submitter expresses strong negative views regarding Generative AI and appears to be interested in advocating against its further development or deployment, highlighting concerns about its legal, ethical, and societal impacts. | - [§1: Document Header/Metadata] None stated for this section.<br>- [§2: Comment Identification] None stated for this section.<br>- [§3: Submitter Information] None stated for this section.<br>- [Section 4: Comment Content]<br>- Generative AI is inherently theft.<br>- Generative AI is massively wasteful and resource greedy.<br>- Generative AI is unwanted by the public.<br>- Generative AI is inherently classist.<br>- Generative AI is inherently racist. | - [§1: Document Header/Metadata] None stated for this section.<br>- [§2: Comment Identification] None stated for this section.<br>- [§3: Submitter Information] None stated for this section.<br>- [§4: Comment Content] None stated for this section. (The comment expresses concerns but does not explicitly offer policy recommendations.) |
| AI-RFI-2025-1305.md | Lora Rose | Individual | The submitter expresses strong opposition to the development and implementation of Artificial Intelligence, believing it to be wasteful, harmful, and unreliable and detrimental to the financial wellbeing of US citizens and allies. They advocate for the complete abandonment of AI initiatives. | - [§1: Submission Metadata] None stated for this section.<br>- [Section 2: General Comment]<br>- AI will lead to wasteful spending on taxpayers and anyone who enters the US.<br>- AI is a waste of time and money and provides no benefit to anyone.<br>- AI is an unreliable source of information and should not be used in official capacities.<br>- AI will harm America and its allies.<br>- AI will accelerate the consumption of natural resources, increasing costs (especially due to tariffs).<br>- [§3: Submitter Information] None stated for this section. | - [§1: Submission Metadata] None stated for this section.<br>- [Section 2: General Comment]<br>- The Artificial Intelligence Action Plan should be completely abandoned ("stricken down and never looked at again").<br>- [§3: Submitter Information] None stated for this section. |
| AI-RFI-2025-1306.md | AI & Partners, B.V. | Industry-Association/Think Tank | AI & Partners aims to foster AI innovation while ensuring security, ethical governance, and economic growth through public-private partnerships, robust regulatory frameworks, and sustainable AI infrastructure, with a focus on global leadership in AI governance. | - [§1: Submission Header & Introduction] None stated for this section.<br>- [§2: Context and Purpose] The potential for monopolistic control and the risk of stifling competition. The need to balance innovation with responsible oversight.<br>- [§3: Push Multi-Stakeholder Collaboration Within Regulatory Confines] Dominance of a few corporations in the semiconductor industry could stifle innovation.  Intellectual property theft. Potential for adversarial nations to gain access to critical AI infrastructure. Talent shortages in the AI workforce.<br>- [§4: Encourage Data Center Development While Driving Energy Efficiency]  Intensive energy consumption of AI. Strain on power grids. Sustainability concerns. Potential for exacerbating climate change.<br>- [§5: Encourage Policies on Cloud and Edge Computing Expansion]  Data security risks associated with decentralized AI processing. Vulnerabilities associated with distributed AI systems. Potential for unauthorized access and cyber threats.<br>- [§6: Reinforce Trustworthy AI Model Development and Open-Source AI] Potential for biased AI models and systemic discrimination. Lack of transparency in AI decision-making. Ethical concerns around AI algorithms. Security risks associated with open-source AI development. Potential for misuse by bad actors.<br>- [§7: Support Private Sector AI Regulation] Potential for unethical practices, monopolization, and labor displacement. Risks related to consumer data rights and the ethical use of AI in corporate environments.<br>- [§8: Require Explainability and Assurance of AI Models] Opaque AI decision-making can lead to distrust and systemic bias.  Lack of human interpretability of AI decisions. Risks of errors, discrimination, and security vulnerabilities.<br>- [§9: Closing Remarks] None stated for this section. | - [§1: Submission Header & Introduction] Prioritize public-private partnerships, robust regulatory frameworks, and sustainable AI infrastructure. Transparency, fairness, and security must be foundational to AI development.<br>- [§2: Context and Purpose] Implement legal and regulatory structures that support growth without stifling competition or risking security.<br>- [§3: Push Multi-Stakeholder Collaboration Within Regulatory Confines] Establish collaborative research programs with private semiconductor firms and academic institutions. Refine and enforce export control laws. Establish clear security standards for AI chip manufacturing. Expand training and education programs for the AI workforce.<br>- [§4: Encourage Data Center Development While Driving Energy Efficiency] Establish regulations requiring data centers to meet stringent energy efficiency benchmarks. Incentivize companies to transition to renewable energy sources. Require AI companies to disclose their energy consumption, carbon emissions, and sustainability initiatives. Prioritize investment in energy-efficient AI hardware. Integrate AI data centers with smart grid technologies.<br>- [§5: Encourage Policies on Cloud and Edge Computing Expansion] Establish uniform security standards for decentralized AI processing. Mandate robust security frameworks for edge computing. Comply with national data sovereignty laws. Provide funding for research and development in secure edge computing technologies. Establish public-private partnerships to create best practices for secure cloud and edge AI deployments.<br>- [§6: Reinforce Trustworthy AI Model Development and Open-Source AI] Require AI models to adhere to transparency and explainability mandates. Ensure AI algorithms comply with non-discrimination laws and fairness standards. Implement legal safeguards for open-source AI development. Adapt intellectual property laws to address AI-generated content. Establish government-regulated AI repositories to promote responsible use.<br>- [§7: Support Private Sector AI Regulation] Require companies to disclose how AI models impact consumers. Implement ethical guidelines to prevent AI misuse. Conduct AI impact assessments before deploying AI technologies. Address the impact of automation on labor markets. Strengthen AI-specific data privacy laws. Prevent monopolistic practices in AI markets.<br>- [§8: Require Explainability and Assurance of AI Models] Require mandatory explainability standards for AI models used in high-risk applications. Establish standardized AI transparency frameworks. Create mandatory AI compliance audits. Establish certification requirements for AI-driven products.<br>- [§9: Closing Remarks] None stated for this section. |
| AI-RFI-2025-1307.md | Mariya Gudima | Individual | The submitter is a writer, editor, and fiber artist deeply concerned about the ethical and legal implications of generative AI, particularly regarding copyright infringement, the exploitation of artists’ work, and the potential devaluation of creative industries. | - [§1: Document Header/Metadata] None stated for this section.<br>- [§2: Initial Statement and Concerns] Training data for generative AI models is composed of copyrighted works used without compensation or consent; Companies claim bankruptcy if required to pay; Government investment in AI empowers copyright infringement.<br>- [§3: Elaboration on Copyright Issues] AI models are trained on copyrighted books, articles, and illustrations without permission; Companies are infringing on copyright, potentially illegally; Current copyright law doesn't adequately protect artists.<br>- [§4: Environmental Impact of AI] Generative AI research consumes significant energy, straining power grids; Microsoft considering dedicated nuclear power plants; Older grids are failing.<br>- [§5: How AI Works & Data Sourcing] AI models scrape data from the internet without consent; Low-paid workers manually filter images and tag data; Amazon’s Mechanical Turk exploits workers.<br>- [§6: Limitations of AI & Bias Concerns] AI models abstract and reduce data, losing nuance and context; AI models amplify inherent biases in training datasets.<br>- [§7: The 'Vampire Machine' & Copyright Infringement] AI models are trained on artists’ work without permission, functioning as "vampires;" Copyright infringement is occurring on a massive scale.<br>- [§8: Critique of 'Democratizing Art' Argument] The claim that AI "democratizes" art is false; AI privatizes and automates art, devaluing creative work.<br>- [§9: The Long-Term Impact on Creative Careers] AI threatens the viability of creative careers; Reduced diversity of artistic expression.<br>- [§10: The Fight Back and Legal Challenges] Artists are protesting; Lawsuits are being filed against AI companies; Copyright infringement is being challenged in court.<br>- [§11: Constructive Criticism and Proposed Solutions] Rethink AI development with human-centric approach; Protect artist livelihoods; Reinforce copyright law; Require ownership/permission for training data.<br>- [§12: Concluding Remarks] The value of art should be recognized. | - [§1: Document Header/Metadata] None stated for this section.<br>- [§2: Initial Statement and Concerns] Do not invest in AI that infringes on copyright.<br>- [§3: Elaboration on Copyright Issues] Strengthen copyright law to protect artists; Ensure fair compensation for use of copyrighted material.<br>- [§4: Environmental Impact of AI] Invest in grid repair; Prioritize energy efficiency and sustainability.<br>- [§5: How AI Works & Data Sourcing] Regulate data scraping practices; Ensure fair labor standards for data labeling workers.<br>- [§6: Limitations of AI & Bias Concerns] Implement governance mechanisms to mitigate bias in AI models.<br>- [§7: The 'Vampire Machine' & Copyright Infringement] Legal action against companies training on unlicensed data.<br>- [§8: Critique of 'Democratizing Art' Argument] None stated for this section.<br>- [§9: The Long-Term Impact on Creative Careers] None stated for this section.<br>- [§10: The Fight Back and Legal Challenges] None stated for this section.<br>- [§11: Constructive Criticism and Proposed Solutions] Update copyright law; Require permission/ownership of training data; Prioritize human-centric AI development.<br>- [§12: Concluding Remarks] None stated for this section. |
| AI-RFI-2025-1310.md | J D | Individual | The submitter is deeply concerned about the potential negative impacts of AI, particularly regarding copyright infringement, the devaluation of creative work, and the potential for AI companies to exploit existing intellectual property without contributing value. They express strong opposition to policies that would facilitate these outcomes. | - Large-scale theft of intellectual property by AI companies.<br>- Devaluation of the U.S. creative industry ($1.1 trillion value, 4.3% of GDP).<br>- The potential for AI to replace human creativity with "cheap, lower grade slop."<br>- Loss of legal rights over photographs and online content.<br>- Concerns about the use of personal photographs for unintended purposes using AI.<br>- Lack of regulation and oversight of AI companies, allowing for unethical practices.<br>- The potential for AI to generate unreliable data and harmful content (pornography, falsified images).<br>- Erosion of trust in the internet due to the proliferation of AI-generated content.<br>- Concerns about the impact on other U.S. industries beyond the creative sector.<br>- The comparison to China and their stricter regulations on AI companies. | - AI companies should be required to obey existing laws.<br>- AI companies should be compelled to produce something of "actual value," not relying on theft.<br>- Stricter regulations on AI companies to prevent theft and unethical practices.<br>- Restrictions on the use of public domain material by AI companies, or requirements for fair creation.<br>- Insistence that AI companies operate legally and ethically, without exploiting existing intellectual property.<br>- The U.S. government should not adopt policies that undermine copyright protections or erode the creative industry. |
| AI-RFI-2025-1312.md | Databricks, Inc. | Industry-Large | Databricks is a cloud data and AI platform provider focused on enabling enterprise AI innovation and adoption, with a strong interest in promoting policies that democratize access to AI resources, clarify IP issues, support open-source models, and foster a reasonable regulatory environment for AI development and deployment. | - None Stated | - None Stated |
| AI-RFI-2025-1313.md | Rutgers University | Academia | Rutgers University is focused on advancing AI research, education, and workforce development to ensure American leadership in the field, with a particular emphasis on applying AI to solve societal challenges and fostering collaboration between academia, industry, and government. | - [§1: Introduction/Header Information] None stated for this section.<br>- [§2: Overview] The current workforce is too small to meet the demand for AI skills.<br>- [Section 3: Advancing Core AI Innovation]<br>- Improving energy efficiency of large AI models will strain the U.S. power grid.<br>- Artificial General Intelligence (AGI) and Generative AI algorithms have drawbacks in efficiency, scalability, generalizability, and adaptability.<br>- AI models are limited by their input data and how they represent knowledge.<br>- Current AI algorithms struggle with complex logic and reasoning.<br>- Large-scale AI models require frequent retraining, leading to outdated algorithms.<br>- AI algorithms are vulnerable to manipulation and require robustness for mission-critical applications.<br>- [§4: Maximizing Impact by Applying AI to National Priorities] The need to prioritize AI applications in high-impact areas where it can enhance national security, economic competitiveness, and public well-being.<br>- [§5: Call to Action] The U.S. needs strategic investment in applied AI to establish global leadership and drive innovation across sectors.<br>- [§6: Enhancing AI Education and Workforce Development] Lack of computer science education in the U.S. hinders AI talent development.<br>- [§7: Strengthening Academic/Industry Collaboration] Rapid acceleration of AI innovation requires collaborative partnerships.<br>- [§8: Investing in Data and Computing Infrastructure] Technology infrastructure is essential for advancements in AI. | - [§1: Introduction/Header Information] None stated for this section.<br>- [Section 2: Overview]<br>- Advance core AI research.<br>- Maximize AI's impact by applying it to national priorities.<br>- Enhance AI education and workforce development.<br>- Foster alliances between industry, government, and academia.<br>- Develop infrastructure for data, computing, and manufacturing.<br>- [Section 3: Advancing Core AI Innovation]<br>- Develop National Technology/Innovation Competitions.<br>- Expand SBIR/STTR Program Scope.<br>- Create National Prototype Foundries.<br>- Expand National Funding for Research Partnerships.<br>- Enhance Venture Capital Investments in AI Entrepreneurship.<br>- Encourage Innovation Through Collaboration by Establishing National Centers.<br>- [Section 4: Maximizing Impact by Applying AI to National Priorities]<br>- Establish Dedicated Federal Funding for Applied AI Research (Advanced Methods, Explainability, Validation, Computing Infrastructure).<br>- Expand Data Access & Interoperability for AI-Driven Applications (Data Access, Interoperability and Standardization).<br>- Establish Adaptive Regulatory Pathways to Accelerate AI Deployment (Streamlined AI Approval Processes, AI Testbeds and Regulatory Sandboxes).<br>- Expand Public-Private Partnerships for AI Initiatives (Research Collaboration, AI Workforce Training and Education).<br>- Prioritize high-impact healthcare areas (Neurodegenerative Diseases, Maternal-Fetal Medicine and Neonatal Care, Oncology, Cardiovascular and Metabolic Disorders, Infectious Disease and Public Health, Mental Health Diagnosis and Treatment).<br>- [§5: Call to Action] None stated for this section.<br>- [Section 6: Enhancing AI Education and Workforce Development]<br>- Incentivize the integration of AI understanding throughout the workforce pipeline (K-12 to community college).<br>- Incentivize universities to integrate AI education into undergraduate programs.<br>- Incentivize AI training through continuing education and extension programming.<br>- Incentivize scholarships and internships for AI R&D with industry.<br>- Establish educational programs emphasizing innovation and entrepreneurship.<br>- [Section 7: Strengthening Academic/Industry Collaboration]<br>- Develop a general framework for industry-academia collaboration.<br>- Encourage integrated training partnerships between academia and industry.<br>- Invest in collaborative AI training within academic research environments.<br>- [Section 8: Investing in Data and Computing Infrastructure]<br>- Establish national AI research centers.<br>- Maximize the value of existing research investments through data sharing.<br>- Invest in cloud computing.<br>- Support AI hardware manufacturing. |
| AI-RFI-2025-1314.md | Joshua Gordon | Individual | The submitter expresses a strong negative opinion regarding the reliability and ethical foundation of AI, specifically opposing its use in government applications. They appear primarily interested in preventing government investment in and adoption of AI technologies. | - [§1: Submission Metadata] None stated for this section.<br>- [§2: Docket Information] None stated for this section.<br>- [§3: RFI Reference] None stated for this section.<br>- [§4: Submitter Information] None stated for this section.<br>- [Section 5: General Comment]<br>- AI is fundamentally unreliable.<br>- AI is built on theft.<br>- AI is unfit for any use in government.<br>- AI fabricates inaccurate information.<br>- AI pollutes otherwise reliable data sets. | - [§1: Submission Metadata] None stated for this section.<br>- [§2: Docket Information] None stated for this section.<br>- [§3: RFI Reference] None stated for this section.<br>- [§4: Submitter Information] None stated for this section.<br>- [Section 5: General Comment]<br>- No government funding should be spent on AI. |
| AI-RFI-2025-1315.md | Kerem Erdinc | Individual | The submitter is primarily concerned with protecting intellectual property rights, artist/performer autonomy, and preventing the misuse of personal data and likenesses in the context of rapidly developing AI technologies, and advocates for strong government regulation. | - Extreme energy consumption by AI systems.<br>- Displacement of entire industries due to AI.<br>- Degradation of art due to AI.<br>- Intellectual property theft facilitated by AI.<br>- Unauthorized use of likenesses and voices.<br>- Creation and dissemination of false narratives.<br>- Lack of enforceable ownership rights in an unregulated AI space.<br>- Difficulty for individuals to combat data or likeness theft due to corporate power imbalances.<br>- Corporate shortsightedness regarding the risks of AI. | - Explicit consent from intellectual property holders and performers is required for all AI data usage.<br>- Strong government regulation of the AI space is necessary to address corruption and protect citizens.<br>- Establish regulations to protect individuals' autonomy over their skills and talents. |
| AI-RFI-2025-1317.md | Consumer Technology Association (CTA) | Industry-Association | The Consumer Technology Association represents the consumer technology industry and advocates for policies that promote innovation, private sector growth, and American leadership in AI while limiting unnecessary regulation and prioritizing responsible development. | - [§1: Introduction & Administrative Information] None stated for this section.<br>- [§2: Background & Context] Overly broad and prescriptive rules could undermine the benefits of AI; concern about the National Security Commission on Artificial Intelligence’s report not endorsing significant new regulation for AI.<br>- [§3: Reset American AI Policy] Heavy-handed regulations and unnecessary oversight; need for a principles-based approach; concern about the potential for burdensome compliance requirements.<br>- [§4: Federal Level Policy Setting] Patchwork state laws and inconsistent regulations creating a challenging compliance environment, particularly for small and medium-sized businesses; need for federal preemption of state laws.<br>- [§5: Adoption of Voluntary Principles, Standards, and Frameworks] Potential for unnecessary complexity and burden if standards are not flexible; need for harmonization with existing frameworks like NIST AI RMF and ISO standards.<br>- [§6: Access to Data for Training and Development] Balancing copyright rules to protect rights holders while enabling access to data for AI training purposes; concern about impacts on rights holders.<br>- [§7: Conclusion] Need to avoid overbroad obligations and ensure American competitiveness.<br>- [§8: Closing & Signatures] None stated for this section. | - [§1: Introduction & Administrative Information] None stated for this section.<br>- [§2: Background & Context] Support private sector investment and growth; avoid unnecessary regulation.<br>- [§3: Reset American AI Policy] Adopt policies to support private sector growth; avoid heavy-handed regulation; focus on responsible development; adopt a risk-based perspective.<br>- [§4: Federal Level Policy Setting] Establish a clear national AI policy; preempt state laws; consider a federal center for technical expertise.<br>- [§5: Adoption of Voluntary Principles, Standards, and Frameworks] Incorporate CTA's National AI Policy Framework, NIST AI RMF, and ISO standards; provide safe harbor protections for entities complying with accepted standards; exempt businesses subject to sector-specific regulations.<br>- [§6: Access to Data for Training and Development] Establish that fair use and text/data mining exceptions allow AI training; allow rights holders to opt-out of data use.<br>- [§7: Conclusion] Adopt policies to promote private sector growth; avoid overbroad obligations; ensure American competitiveness.<br>- [§8: Closing & Signatures] None stated for this section. |
| AI-RFI-2025-1318.md | Kai Michlmayr | Academia (primarily Florida State University based on repeated references to research and initiatives at the institution) | The submitter, affiliated with Florida State University, emphasizes the importance of a balanced approach to AI development – prioritizing safety, security, ethical considerations, and workforce readiness alongside innovation. Their focus is on maximizing the benefits of AI while mitigating risks through research, collaboration, and policy recommendations. | - None Stated | - None Stated |
| AI-RFI-2025-1320.md | Florida State University | Academia | Florida State University is a research institution focused on advancing AI through public-private partnerships, fostering innovation, and preparing a skilled workforce to drive economic growth and societal benefits. They emphasize the importance of basic research, ethical development, and responsible data sharing. | - None Stated | - None Stated |
| AI-RFI-2025-1321.md | Reese Theobald | Individual | Reese Theobald is a student interested in the ethical implications of AI and its impact on the legislative process and voter information, particularly concerning deepfakes and misinformation. They advocate for incorporating existing state legislation into a national AI policy framework. | - [§1: Document Header/Metadata] None stated for this section.<br>- [§2: Submitter Identification & General Comment] None stated for this section.<br>- [§3: Executive Order Impact & State Regulation Position] Potential disruption to current state-level AI regulation efforts due to E.O. 14179.<br>- [§4: Deepfake & Misinformation Concern & Personal Experience] Prevalence of deepfakes and AI misinformation on social media, potentially misleading voters. The submitter personally encounters this content daily and expresses concern about the lack of widespread awareness of how to identify such media. | - [§1: Document Header/Metadata] None stated for this section.<br>- [§2: Submitter Identification & General Comment] None stated for this section.<br>- [§3: Executive Order Impact & State Regulation Position] Incorporate existing state legislation into a national AI policy framework.<br>- [§4: Deepfake & Misinformation Concern & Personal Experience] Provide resources for citizens to become more informed about deepfakes and how to identify them, rather than attempting to censor misinformation. |
| AI-RFI-2025-1322.md | University of Virginia | Academia | The University of Virginia aims to maintain U.S. leadership in AI through robust research support, workforce training, and collaboration with government and industry, leveraging its expertise in AI, biomedical sciences, and education. | - [Section 1: Document Header/Metadata]** None stated for this section.<br>- [Section 2: Introduction/UVA Overview]** The need to maintain U.S. leadership and dominance in global AI technological advancements.<br>- [Section 3: Recommended Actions - Section 1: AI-Ready Data and Testbeds]** The private sector is not positioned to adequately assess the security and reliability of AI systems, creating a need for impartial evaluations by universities. Potential risks from AI technologies developed by foreign adversaries (vulnerabilities, bias, manipulation).<br>- [Section 4: Recommended Actions - Section 2: Intelligence Community (IC) Support]** The IC requires innovative AI tools to process vast amounts of open-source data, and current analysis of global AI achievements requires more resources.<br>- [Section 5: Recommended Actions - Section 3: Health and Biomedical Sciences]** The U.S. is at risk of becoming reliant on China for AI innovations in healthcare and biosciences, potentially jeopardizing sovereignty over healthcare systems, patient privacy, and national security. Insufficient dedicated mechanisms to support collaborative research bringing together bioscience, public health, clinical research, and computational expertise. Health agencies invest less in AI research compared to physical science agencies.<br>- [Section 6: Recommended Actions - Section 4: Educational Instruction]** Current AI tools haven't fully replaced or matched skilled human teachers and are not fully optimized for improving instruction.<br>- [Section 7: Recommended Actions - Section 5: AI Workforce Development]** A shortage of skilled AI professionals is a critical concern.<br>- [Section 8: Closing/Signatures]** None stated for this section. | - [Section 1: Document Header/Metadata]** None stated for this section.<br>- [Section 2: Introduction/UVA Overview]** Invest in research and workforce training activities in partnership with American universities.<br>- [Section 3: Recommended Actions - Section 1: AI-Ready Data and Testbeds]<br>- Repurpose the NIST AI Safety Institute Consortium to focus on AI reliability and security, scaling creation of AI reliability standards and fostering collaborative work.<br>- Support AI infrastructure, including the National Artificial Intelligence Research Resource (NAIRR), to expand access to computing power and enable innovation.<br>- [Section 4: Recommended Actions - Section 2: Intelligence Community (IC) Support]<br>- Continue funding for AI-based tools to analyze open-source data.<br>- [Section 5: Recommended Actions - Section 3: Health and Biomedical Sciences]<br>- Strengthen and support collaborative AI institutes between NSF and NIH, CDC, and FDA to foster innovation.<br>- Create a Collaborative AI-Health Data Integration Research Program to develop methods for integrating AI systems with diverse healthcare data.<br>- [Section 6: Recommended Actions - Section 4: Educational Instruction]<br>- Support research and development of multimodal AI-powered learning programs.<br>- Support AI-assisted teacher professional development.<br>- [Section 7: Recommended Actions - Section 5: AI Workforce Development]<br>- Expand funding for graduate fellowships incorporating AI (e.g., NSF RT, GRF, CAREER, DOE Computational Science Fellowship, NIH NRSA, DOE GAANN).<br>- Encourage integration of AI, machine learning, and data science into undergraduate STEM curricula.<br>- Establish partnerships between universities, industry, and federal agencies for internship and research opportunities.<br>- Provide continuous education and training for professionals in healthcare, data science, and IT.<br>- [Section 8: Closing/Signatures]** None stated for this section. |
| AI-RFI-2025-1324.md | Alessia Padalino | Individual | Alessia Padalino is a student interested in the impact of Generative AI on the surgical field of medicine, particularly concerning patient care improvements and potential privacy risks associated with AI tools. | - [§1: Document Header/Metadata] None stated for this section.<br>- [§2: Comment Identification] None stated for this section.<br>- [§3: Submitter Information] None stated for this section.<br>- [Section 4: General Comment/Executive Order Impact]<br>- Potential privacy breaches due to centralized patient information required for AI imaging tools.<br>- Disruption in the surgical field due to these potential privacy concerns. | - [§1: Document Header/Metadata] None stated for this section.<br>- [§2: Comment Identification] None stated for this section.<br>- [§3: Submitter Information] None stated for this section.<br>- [§4: General Comment/Executive Order Impact] None stated for this section. |
| AI-RFI-2025-1325.md | Sydney Shields | Individual | The submitter is a high school student interested in the impacts of Generative AI on elementary education, particularly focusing on the potential benefits for teachers contrasted with the risks for students' cognitive development and the need for responsible AI implementation through education and access control. | - [§1: Submission Metadata] None stated for this section.<br>- [§2: Submitter Information] None stated for this section.<br>- [§3: Executive Summary/Core Argument] Potential disruption from EO 14179; the need for policy intervention to mitigate risks in elementary education.<br>- [§4: Justification/Supporting Arguments] Deregulation would benefit teachers but harm students. The importance of education on proper AI use and access limitations in elementary schools.<br>- [§5: Specific Concerns/Evidence] Hindrance of problem-solving and critical thinking skills development in elementary-aged students due to AI access and abuse. Young students may misunderstand AI as a person (supported by study on smart speakers).<br>- [§6: Conclusion/Recommendation] Need for policy regarding AI teaching and containment of access to AI in elementary schools. | - [§1: Submission Metadata] None stated for this section.<br>- [§2: Submitter Information] None stated for this section.<br>- [§3: Executive Summary/Core Argument] Policy intervention to mitigate risks in elementary education.<br>- [§4: Justification/Supporting Arguments] Implement policies based on teaching proper AI use and limiting student access in elementary schools.<br>- [§5: Specific Concerns/Evidence] Monitor student access to AI; prevent independent access without adult supervision.<br>- [§6: Conclusion/Recommendation] Implement a policy that will ensure proper teaching and containment of access to AI in elementary schools. |
| AI-RFI-2025-1326.md | Jayla Jones | Individual | Jayla Jones is a high school student interested in the ethical implications of AI, specifically its impact on energy consumption and the environment, and expresses concern about Executive Order 14179's potential disruption to safe energy practices. | - [§1: Document Header/Metadata] None stated for this section.<br>- [§2: Comment Identification] None stated for this section.<br>- [§3: Submitter Information] None stated for this section.<br>- [§4: Comment Body] AI uses and emits large amounts of energy, creating an inflated carbon footprint. Executive Order 14179 will disrupt safe energy consumption and the safety of the environment and emission levels. | - [§1: Document Header/Metadata] None stated for this section.<br>- [§2: Comment Identification] None stated for this section.<br>- [§3: Submitter Information] None stated for this section.<br>- [§4: Comment Body] None stated for this section. |
| AI-RFI-2025-1327.md | Ben Hebor | Individual | Ben Hebor, a graduating high school student, is interested in the ethical implications of AI, specifically its impact on political advertising and the potential for misinformation, and seeks to promote fair and free elections through regulation of AI use in campaigns. | - [§1: Submission Metadata] None stated for this section.<br>- [§2: Submitter Information] None stated for this section.<br>- [§3: General Comment/Executive Summary] The potential for Executive Order 14179 to have a mixed result on AI in American Politics; the effectiveness of generative AI in creating misleading information.<br>- [§4: AI Impact on Politics - Advertising] Generative AI is extremely effective in creating advertising, leading to the spread of misleading information, especially among older generations who are less familiar with AI.<br>- [§5: Proposed Action/Recommendation] None stated for this section. | - [§1: Submission Metadata] None stated for this section.<br>- [§2: Submitter Information] None stated for this section.<br>- [§3: General Comment/Executive Summary] None stated for this section.<br>- [§4: AI Impact on Politics - Advertising] None stated for this section.<br>- [§5: Proposed Action/Recommendation] Restrict the use of AI in political campaigns, drawing parallels to existing state-level laws, in order to solidify the U.S. position as a global AI leader and secure fair elections. |
| AI-RFI-2025-1328.md | Mackenzie Dawson | Individual | Mackenzie Dawson is a high school student interested in the application of AI, specifically Generative AI, to the sports community, particularly volleyball, and believes that Executive Order 14179 can support American leadership in this field through innovation and competition. | - [§1: Document Metadata] None stated for this section.<br>- [§2: RFI Identification] None stated for this section.<br>- [§3: Submitter Information] None stated for this section.<br>- [§4: Comment Body] None stated for this section. | - [§1: Document Metadata] None stated for this section.<br>- [§2: RFI Identification] None stated for this section.<br>- [§3: Submitter Information] None stated for this section.<br>- [§4: Comment Body] EO 14179 will improve policy about innovation and competition should be based on the effects that AI can have on a wide variety of sports. The submitter implies support for implementing American AI technology in the sports world to establish a competitive advantage. |
| AI-RFI-2025-1329.md | Mindset DC (Insurance Coalition) | Industry-Association | The Insurance Coalition represents life, property, and casualty insurers and is interested in fostering responsible AI deployment within the insurance industry while balancing innovation with consumer protections and advocating for a regulatory framework that avoids duplication and promotes state-level flexibility. | - Section 1: Introduction/Header:** None stated for this section.<br>- Section 2: Background & Context:** None stated for this section.<br>- Section 3: Federal-State Coordination Mechanisms:** Potential for regulatory duplication or conflict if federal regulations don't consider existing state frameworks. The need to maintain the balance of federal baseline standards with state-level innovation under the McCarran-Ferguson Act.<br>- Section 4: Third-Party AI Governance Innovations:** Ensuring accountability of third-party AI vendors and the need for consistent compliance standards (NAIC Model Bulletin, state unfair trade practices acts).<br>- Section 5: State Regulatory Frameworks:** Potential for inconsistencies across states and the importance of harmonization of regulations. Ensuring consumer data is handled responsibly.<br>- Section 6: Examples of Uses of AI by Insurers:** None stated for this section.<br>- Section 7: Consumer Protections:** Ensuring existing legislative frameworks are sufficient to protect policyholder data and addressing potential bias in AI models.<br>- Section 8: Policy Recommendations:** None stated for this section.<br>- Section 9: Conclusions:** None stated for this section.<br>- Section 10: Signature:** None stated for this section. | - Section 1: Introduction/Header:** None stated for this section.<br>- Section 2: Background & Context:** None stated for this section.<br>- Section 3: Federal-State Coordination Mechanisms:** Federal regulators should consider the adequacy and adaptability of existing regulatory frameworks before issuing new AI-specific regulations and collaborate with the NAIC and state regulators.<br>- Section 4: Third-Party AI Governance Innovations:** None stated for this section.<br>- Section 5: State Regulatory Frameworks:** None stated for this section.<br>- Section 6: Examples of Uses of AI by Insurers:** None stated for this section.<br>- Section 7: Consumer Protections:** None stated for this section.<br>- Section 8: Policy Recommendations:** Support the existing regulatory framework. Encourage innovation while maintaining adequate oversight and strong safeguards for consumer data.<br>- Section 9: Conclusions:** None stated for this section.<br>- Section 10: Signature:** None stated for this section. |
| AI-RFI-2025-1331.md | Alex Rowe | Individual | Alex Rowe, a graduating high school student, expresses interest in the societal impacts of AI, particularly concerning the balance between fostering creativity and mitigating potential harm resulting from unregulated use. They have studied AI and Ethics and are focused on the implications of Executive Order 14179. | - [§1: Submission Metadata] None stated for this section.<br>- [§2: Comment Context] None stated for this section.<br>- [§3: Submitter Information] None stated for this section.<br>- [§4: General Comment/Introduction] The potential for both improvement and disruption to national security and defense policy due to the removal of AI regulations.<br>- [§5: Elaboration of Argument/Concerns] The duality of AI’s potential—advancing creativity and human capability versus the risk of malicious actors exploiting unregulated AI, potentially endangering American lives. The widespread use of AI in 2025 increases this risk.<br>- [§6: Question for OSTP] Lack of clear security measures to prevent harm from unregulated AI. | - [§1: Submission Metadata] None stated for this section.<br>- [§2: Comment Context] None stated for this section.<br>- [§3: Submitter Information] None stated for this section.<br>- [§4: General Comment/Introduction] None stated for this section.<br>- [§5: Elaboration of Argument/Concerns] None stated for this section.<br>- [§6: Question for OSTP] Development and implementation of "proper security measures" to protect against harm caused by unregulated AI. (This is posed as a question requesting information, but implicitly implies a recommendation for such measures). |
| AI-RFI-2025-1333.md | Ava Monkelis | Individual | Ava Monkelis is a graduating high school student interested in the ethical implications of AI development, particularly regarding its impact on creativity and the need for public education and data protection measures. | - Ethical ambiguity due to lack of regulation in AI development.<br>- Potential for harm to individuals due to the lack of public education about safe AI usage.<br>- Risk of deepfake scams and data compromise by companies due to limited regulations.<br>- Artists’ work being stolen by companies to train large language models.<br>- An unspoken competition between creativity and the mathematical basis of AI. | - Implement regulations to protect the general public and ensure the flourishing of AI development.<br>- Increase public education about how to safely use AI.<br>- Establish regulations to prevent the theft of artists’ work for AI training. |
| AI-RFI-2025-1334.md | Lucy Studebaker | Individual | Lucy Studebaker, a high school student, expresses interest in the ethical implications of AI, specifically its impact on religious faith (Catholicism) and advocates for policies that support accurate religious education without undermining core beliefs. | - [§1: Document Metadata/Header] None stated for this section.<br>- [§2: Submitter Information & General Comment Label] None stated for this section.<br>- [Section 3: Comment on AI & Catholicism - Problem Statement (Harmful AI)]<br>- Inaccurate information provided by AI platforms (specifically The Father Justin App) can cause confusion regarding Catholic teachings.<br>- The mathematical basis of AI conflicts with Catholic ethics.<br>- Using technology in the service of the church could be seen as a mockery of God, due to the risk of elevating technology above God.<br>- Fear that AI may undermine true faith in God.<br>- [§4: Comment on AI & Catholicism - Positive Example] None stated for this section.<br>- [Section 5: Call to Action/EO 14179 Support]<br>- Concern that AI could replace true faith in God.<br>- Importance of differentiating the Catholic faith from potentially harmful AI applications. | - [§1: Document Metadata/Header] None stated for this section.<br>- [§2: Submitter Information & General Comment Label] None stated for this section.<br>- [§3: Comment on AI & Catholicism - Problem Statement (Harmful AI)] None stated for this section.<br>- [§4: Comment on AI & Catholicism - Positive Example] None stated for this section.<br>- [Section 5: Call to Action/EO 14179 Support]<br>- Support for Executive Order 14179 to improve Catholicism and enable education on the Catholic faith without replacing true faith in God.<br>- Policy should set apart the Catholic faith from Artificial Intelligence. |
| AI-RFI-2025-1337.md | Land Trust Alliance | Industry-Association/Advocacy/Think Tank | The Land Trust Alliance represents member land trusts and works to save places people need and love by strengthening land conservation across America, focusing on the protection of agricultural and conservation lands and the integration of conservation priorities into energy and AI development projects. | - [§1: Header/Administrative Information] None stated for this section.<br>- [§2: Introduction and Background] None stated for this section.<br>- [§3: Executive Order Context] Increasing electricity demand due to data center growth impacting grid integrity.<br>- [§4: Data Center and Energy Transmission Siting Concerns] Potential for data center and transmission infrastructure development to negatively impact lands with high conservation, biodiversity, forestry, recreation, and agricultural value. Risk of costly new transmission lines.<br>- [§5: Conservation Easements Explained] Irresponsible siting potentially undermining billions of public dollars invested in conserved lands and associated economic returns. Risk of government takings of real property rights and impacts to lands subject to conservation easements.<br>- [§6: Federal and State Conservation Programs] None stated for this section.<br>- [§7: Energy and Water Usage and Efficiency] High energy and water consumption of data centers exacerbating regional scarcity and costs. Lack of publicly available data on data center energy consumption.<br>- [§8: Recommendations for the Action Plan (Energy & Water)] Minimizing impacts of AI data center development on conserved lands and increasing energy efficiency is crucial.<br>- [§9: Advancing Administrative Orders] None stated for this section.<br>- [§10: Public Engagement] Failure to engage with communities can trigger opposition and delays in siting and permitting.<br>- [§11: Reliability and Integrity of U.S. Artificial Intelligence] Need for federal leadership to promote integrity in AI systems and prevent bias.<br>- [§12: Conclusion] None stated for this section. | - [§1: Header/Administrative Information] None stated for this section.<br>- [§2: Introduction and Background] None stated for this section.<br>- [§3: Executive Order Context] None stated for this section.<br>- [§4: Data Center and Energy Transmission Siting Concerns] Prioritize thoughtful siting of data centers.<br>- [§5: Conservation Easements Explained] Establish a goal to avoid government takings of real property rights and impacts to lands subject to conservation easements.<br>- [§6: Federal and State Conservation Programs] None stated for this section.<br>- [§7: Energy and Water Usage and Efficiency] Increase energy and water efficiency of data centers.<br>- [Section 8: Recommendations for the Action Plan (Energy & Water)]<br>- Incentivize co-location of data centers near existing energy sources.<br>- Incentivize co-location with renewable energy and battery energy storage.<br>- Incentivize reconductoring of existing transmission lines with advanced conductors.<br>- Share industry data on energy use (power performance standards, reporting incentives).<br>- Use microgrids in data centers.<br>- Use virtual power plants.<br>- Increase the utilization of alternative water supplies.<br>- [§9: Advancing Administrative Orders] Utilize the plan to advance the Administration's goals around energy reliability and costs.<br>- [§10: Public Engagement] Develop recommendations on meaningful public engagement. Reach out to land trusts serving the communities.<br>- [§11: Reliability and Integrity of U.S. Artificial Intelligence] Provide federal leadership to protect against negative impacts from AI by ensuring reliability, integrity, and bias prevention.<br>- [§12: Conclusion] Prioritize smart siting and innovative technologies to minimize impacts and increase efficiency. |
| AI-RFI-2025-1339.md | Blueprint.Inc | Industry-Startup | Blueprint.Inc is a small publishing business that views AI as a vital technology for maintaining competitiveness and automating workflows, and is deeply concerned with ensuring content creators are fairly compensated and their intellectual property is protected in the age of AI. | - [§1: Document Metadata] None stated for this section.<br>- [§2: General Comment/Introduction] The potential for AI to disrupt content creation and the importance of sustaining the industry.<br>- [§3: Ask 1: Copyright Licensing] The risk of AI LLMs using content without proper licensing, drawing a parallel to the negative impact of Napster on the music industry. The concern that any licensing system must be inclusive of *all* publishers, not just large media companies.<br>- [§4: Ask 2: Intellectual Property Protection] The potential for big tech companies or foreign governments to unfairly ingest, censor, control, and profit from U.S. content.<br>- [§5: Concluding Statement] The critical need for sound decisions to balance AI development with the sustainability of content creation and the broader ecosystem. | - [§1: Document Metadata] None stated for this section.<br>- [§2: General Comment/Introduction] None stated for this section.<br>- [§3: Ask 1: Copyright Licensing] Establish a copyright licensing system for AI LLMs using content, modeled after the evolution of the music industry post-Napster, ensuring inclusivity for *all* publishers.<br>- [§4: Ask 2: Intellectual Property Protection] Use the power of the U.S. government to protect intellectual property rights worldwide, with harsh penalties for companies or countries engaging in non-transparent, non-free, or non-compensated use of content. Consider theft of U.S. content an act of war.<br>- [§5: Concluding Statement] None stated for this section. |
| AI-RFI-2025-1340.md | Joe Davitt | Individual | The submitter is concerned with the copyright implications of AI-driven data scraping and derivative works, believing AI should adhere to the same copyright standards as humans. They advocate for AI companies to obtain proper rights for data used in their models, similar to the requirements for individual content creators. | - [§1: Document Metadata] None stated for this section.<br>- [§2: General Comment] The scale of data scraping for AI development causes disruption in creative fields. The data scraping fails all four fair use checks. AI companies are not currently adhering to the same copyright standards as humans. | - [§1: Document Metadata] None stated for this section.<br>- [§2: General Comment] AI companies should be required to obtain the rights to the data they scrape, similar to requirements for individual content creators using copyrighted material. |
| AI-RFI-2025-1341.md | Anonymous | Individual | The submitter is concerned with the ethical implications of AI development, specifically regarding the unauthorized use of human work in training datasets and the lack of worker protections. They advocate for regulations that prioritize individuals and enforce copyright protections. | - [§1: Submission Metadata] None stated for this section.<br>- [§2: RFI Context] None stated for this section.<br>- [§3: Submitter Information] None stated for this section.<br>- [Section 4: General Comment/Response]<br>- Unauthorized use of human work for AI training datasets.<br>- The unacceptability of opt-out agreements as a solution for data usage.<br>- Current AI models are built on stolen work.<br>- The business model of operating on theft. | - [§1: Submission Metadata] None stated for this section.<br>- [§2: RFI Context] None stated for this section.<br>- [§3: Submitter Information] None stated for this section.<br>- [Section 4: General Comment/Response]<br>- Implement "people first" regulation for AI.<br>- Enforce copyright for human work "ASAP".<br>- Establish stronger laws protecting human work from tech company exploitation.<br>- Perform "algorithmic disgorgement" on all datasets containing data obtained without consent ("opted in data"). |
| AI-RFI-2025-1342.md | Quentin Short | Individual | Quentin Short is an art student planning a freelance career who is concerned about the potential impact of AI policies on job opportunities and their ability to financially support their family, particularly their special needs sibling. They advocate for considering the human impact of AI policies beyond financial efficiency. | - [§1: Submission Header/Metadata] None stated for this section.<br>- [§2: Comment Context] None stated for this section.<br>- [§3: Submitter Information] None stated for this section.<br>- [Section 4: General Comment]<br>- Potential job losses due to companies reducing spending on individuals.<br>- Negative impact of current AI policies on their ability to provide for their family.<br>- Insufficient consideration of the human impact of AI policies. | - [§1: Submission Header/Metadata] None stated for this section.<br>- [§2: Comment Context] None stated for this section.<br>- [§3: Submitter Information] None stated for this section.<br>- [Section 4: General Comment]<br>- Consider the human impact of AI policies beyond financial efficiency.<br>- Prioritize the well-being of individuals and families affected by AI-driven changes.<br>- Re-evaluate current policies to mitigate potential job losses and financial hardship. |
| AI-RFI-2025-1343.md | Association for Intelligent Information Management (AIIM) | Industry-Association | AIIM is a nonprofit organization focused on information management and supports the effective implementation of AI by helping organizations manage and prepare unstructured data for AI and automation, advocating for responsible AI development and deployment, and providing resources and training to its members. | - None Stated | - None Stated |
| AI-RFI-2025-1344.md | Wiley | Industry-Large (Publisher/Information Services) | Wiley's mission is to serve authors, researchers, learners, and professionals by enabling the consumption and dissemination of information and knowledge. They are interested in ensuring responsible AI development that protects intellectual property rights, supports accuracy, and maintains the integrity of published works. | - [Section 1: Header/Submission Metadata]** None stated for this section.<br>- [Section 2: Executive Summary/Introduction]** Concerns regarding the need for transparency and accountability from AI developers and respecting existing intellectual property protections.<br>- [Section 3: Transparency and Disclosure]** Concerns about AI systems being trained on unauthorized, low-quality, or infringing content; scraping copyrighted materials without permission; generation of near-verbatim outputs; and directing users to piracy sites.<br>- [Section 4: Attribution]** Concerns about AI-generated content mirroring copyrighted materials without accurate attribution or content provenance.<br>- [Section 5: Intellectual Property & Copyright Protection]** Concerns about challenges AI poses to creative industries, journalism, and research integrity, and the potential for bypassing established licensing obligations.<br>- [Section 6: AI Training vs. Text and Data Mining]** Concerns about inappropriately applying TDM exceptions to AI training, as AI models ingest and reuse copyrighted material to generate new works.<br>- [Section 7: Robust Marketplace for Licensure]** Concerns about the lack of blanket permission for AI training under fair use, the burden of opting-out falling on creators, and the need for a predictable system recognizing the value of copyrighted materials.<br>- [Section 8: Conclusion]** Concerns about maintaining the quality and integrity of published works and ensuring people are not put at risk. | - [Section 1: Header/Submission Metadata]** None stated for this section.<br>- [Section 2: Executive Summary/Introduction]** Require transparency and accountability from AI developers; respect existing intellectual property protections.<br>- [Section 3: Transparency and Disclosure]<br>- Disclose training datasets.<br>- Identify copyrighted works used in training (including DOIs/ISBNs and legal basis).<br>- Ensure compliance with copyright law.<br>- Implement auditing mechanisms to track training data sources.<br>- [Section 4: Attribution]<br>- Require correct citation of original sources in AI outputs (especially in research and journalism).<br>- Recognize authorship.<br>- Maintain a clear record of content sourcing and transformation.<br>- [Section 5: Intellectual Property & Copyright Protection]<br>- Ensure compliance with copyright law.<br>- Encourage AI dataset transparency (public reporting).<br>- Support licensing requirements for AI training.<br>- Develop standards for and implement provenance tracking.<br>- Utilize existing copyright enforcement mechanisms.<br>- [Section 6: AI Training vs. Text and Data Mining]** Distinguish between TDM and AI training, arguing against applying TDM exceptions to AI training. Advocate for a licensing-based framework.<br>- [Section 7: Robust Marketplace for Licensure]<br>- Implement a licensing-based framework for AI training.<br>- Require public disclosure of training datasets.<br>- Track copyrighted materials used at all AI stages.<br>- Implement clear attribution standards.<br>- [Section 8: Conclusion]** Encourage AI development supported by legal guardrails (like licensing), and promote public-private partnerships. |
| AI-RFI-2025-1346.md | Anonymous | Individual | The submitter expresses skepticism about the value of current AI development, highlighting concerns about wasted resources, potential fraud, and the risk of reliance on adversarial nations for critical hardware. They are critical of the financial investment in AI, believing it diverts resources from more pressing needs like housing and healthcare. | - The majority of current AI development is a "boondoggle scam" and a waste of resources.<br>- AI development expends significant resources (water, power, land) without proven benefit.<br>- The CHIPS Act is being undermined, creating a dependency on foreign nations (specifically China) for AI hardware.<br>- AI defrauds artists and innovators by using their works without right or compensation.<br>- The federal government taking on legal burdens related to AI fraud places costs on taxpayers.<br>- Investment in AI diverts resources from essential needs like housing and healthcare. | - None Stated. |
| AI-RFI-2025-1348.md | SAFE Center for Grid Security | Advocacy/Think Tank | SAFE is an action-oriented organization focused on transportation, energy, and supply chain policies to advance U.S. economic and national security, with a specific focus on ensuring the resilience and capacity of the national power grid to support innovation, particularly in the context of AI expansion. | - [§1: Submission Metadata] None stated for this section.<br>- [§2: Introduction to SAFE] None stated for this section.<br>- [Section 3: Comments]<br>- Mismatch between the speed of AI industry expansion and the grid's ability to supply resilient, reliable, and affordable power.<br>- New AI facilities can be constructed faster than new energy generation to support them.<br>- Building transmission infrastructure takes a long time.<br>- Potential for energy infrastructure to struggle to keep pace with AI and other strategic industries.<br>- Vulnerabilities related to cyber intrusions and supply chain dependencies, especially those linked to foreign-controlled technologies.<br>- [§4: Closing and Signature] None stated for this section. | - [§1: Submission Metadata] None stated for this section.<br>- [§2: Introduction to SAFE] None stated for this section.<br>- [Section 3: Comments]<br>- Align transmission planning with AI development to prevent bottlenecks.<br>- Accelerate permitting and investment in transmission projects.<br>- Prioritize energy projects that support AI applications enhancing military resilience and efficiency.<br>- Implement grid-enhancing technologies (GETs).<br>- Scale grid-level capacity for strategic industries through interregional transmission reform.<br>- Mitigate supply chain risks by boosting domestic manufacturing for grid power and AI infrastructure.<br>- [§4: Closing and Signature] None stated for this section. |
| AI-RFI-2025-1349.md | DIGITALEUROPE | Industry-Association | DIGITALEUROPE represents digitally transforming industries in Europe and advocates for a regulatory environment that enables European businesses to prosper from digital technologies, with a strong focus on AI development and international collaboration. They aim to shape industry policy positions and contribute to the implementation of relevant EU policies. | - [§1: Submission Metadata] None stated for this section.<br>- [§2: Introduction] None stated for this section.<br>- [§3: Table of Contents] None stated for this section.<br>- [§4: EU-US Collaboration] Lack of interoperability in AI governance frameworks.  Value chains are globally integrated and require a coordinated approach.<br>- [§5: G7 for Global AI Alignment] None stated for this section.<br>- [§6: Export Controls on AI Advanced Chips] Export control measures introduced by the previous US administration treat EU Member States unequally and create tensions in the transatlantic partnership. Restrictive measures are counterproductive.<br>- [§7: Standards] The need for a global, consensus-based standardization process, including de facto standardization, to address the complexity of digital technologies like AI. Importance of interoperability.<br>- [§8: Collaboration for AI Use in Critical Infrastructure] None stated for this section.<br>- [§9: Defence Collaboration] None stated for this section.<br>- [§10: Conclusions] None stated for this section.<br>- [§11: Contact Information] None stated for this section.<br>- [§12: About DIGITALEUROPE] None stated for this section. | - [§1: Submission Metadata] None stated for this section.<br>- [§2: Introduction] None stated for this section.<br>- [§3: Table of Contents] None stated for this section.<br>- [§4: EU-US Collaboration] Creation of an EU-US Critical and Dual-Use Technology Council to advance coordination on critical technologies like AI and cybersecurity, starting with dual-use applications. Dialogue on investment initiatives (InvestAI and Stargate). International collaboration among AI institutes.<br>- [§5: G7 for Global AI Alignment] Work together to develop an interoperable, risk-based, and consensus-driven approach to AI governance. Promote shared AI guidelines adopted on a global scale on a voluntary and flexible basis.<br>- [§6: Export Controls on AI Advanced Chips] Focus on fostering collaboration on mutual priorities instead of introducing restrictive measures.<br>- [§7: Standards] Foster a global standardisation process. Ensure all relevant stakeholders are included in the standardisation process, including international businesses.<br>- [§8: Collaboration for AI Use in Critical Infrastructure] Develop AI-focused frameworks to minimize threats to critical infrastructure (energy, food production, water management, transportation, healthcare). Advance policies that support the integration of AI in critical infrastructure, enabling innovation and security. Strengthen transatlantic cooperation on health.<br>- [§9: Defence Collaboration] Foster EU-US collaboration on dual-use technologies and ensure interoperability between AI-powered defence applications across EU and NATO partners. Integrate AI into cyber resilience strategies for defence. Accelerate AI adoption in predictive maintenance, logistics and real-time battlefield analytics. Support AI-driven cybersecurity solutions, military networks and cloud-based command systems. Allocate 25% of NATO institutional funds to AI-driven defence innovation and digital resilience. Simplify procurement processes and increase SME participation in AI-driven defence projects. Expand AI and cybersecurity training programmes for military and industry personnel. Develop AI safety frameworks and ethical guidelines.<br>- [§10: Conclusions] None stated for this section.<br>- [§11: Contact Information] None stated for this section.<br>- [§12: About DIGITALEUROPE] None stated for this section. |
| AI-RFI-2025-1350.md | Janice Ballard | Individual | The submitter expresses concern about wasteful government programs and specifically questions the fairness and allocation of funds generated by lottery systems, with no apparent focus on AI policy. | - Wasteful government programs, specifically lottery systems.<br>- Lack of transparency regarding the allocation of lottery funds (specifically questioning if scholarship funds are actually received).<br>- Suspicions of unfairness or rigging in lottery systems (Arkansas Lotto, Lucky for Life, Powerball, Mega Millions).<br>- Concern that lottery systems exploit people financially.<br>- Doubts about the veracity of lottery winner claims. | - Conduct an audit of lottery systems to determine where the money actually goes (specifically D.O.G.E. is suggested to investigate).<br>- None Stated. |
| AI-RFI-2025-1351.md | The Leadership Conference on Civil and Human Rights | Advocacy/Think Tank | The Leadership Conference on Civil and Human Rights advocates for the promotion and protection of civil and human rights for all persons in the United States, and focuses on ensuring AI technologies are developed and deployed responsibly, safely, equitably, and in accordance with core democratic values and fundamental rights. | - None Stated | - None Stated |
| AI-RFI-2025-1352.md | Center for Telehealth and e-Health Law (CTeL) | Advocacy/Think Tank | CTeL is a non-profit research institute dedicated to advancing the legal and regulatory understanding of digital health, with a current focus on fostering responsible AI innovation in healthcare while protecting patient rights and addressing potential risks associated with its deployment. | - [§1: Document Header/Metadata] None stated for this section.<br>- [§2: Introduction/Executive Summary] Risk of a fragmented regulatory landscape stifling innovation and limiting AI's potential in healthcare.<br>- [§3: Recognize AI's Diverse Use Cases to Ensure Effective Regulation] Lack of differentiation between various AI use cases (administrative vs. clinical) and differing risk profiles. Prevalence of administrative burden and clinician burnout.<br>- [§4: Prepare Healthcare Professionals for AI Integration] The pace of technological development demands rapid clinician adaptation. Potential for AI to exacerbate existing workforce problems (shortages, burnout). Maintaining clinician judgement alongside new technology.<br>- [§5: Support the Deployment and Integration of Health AI Technologies] Cost as a barrier to AI adoption, especially for smaller, rural hospitals. Lack of technical skills within healthcare organizations for performance evaluation and workflow integration.<br>- [§6: Ensure that Patients are not Excessively Denied Care] Increasing use of AI algorithms in prior authorization processes leading to potential unfair denials of care. Lack of transparency in AI-driven denials by insurance plans. Influence of algorithms on human reviewers' decisions.<br>- [§7: Promote Patient Choice and Public Awareness of Health AI] The complex nature of AI algorithms necessitates a focus on patient rights and informed consent.<br>- [§8: Conclusion] None stated for this section. | - [§1: Document Header/Metadata] None stated for this section.<br>- [§2: Introduction/Executive Summary] Prioritize a robust AI Action Plan that fosters responsible innovation while protecting patient rights.<br>- [Section 3: Recognize AI's Diverse Use Cases to Ensure Effective Regulation]<br>- Differentiate between health AI use cases (administrative, clinical, billing) and consider differing risk profiles.<br>- Identify and address challenges facing the American healthcare system (workforce shortages, administrative burden, rising costs, data security) with AI.<br>- Anticipate the potential for Artificial General Intelligence (AGI) and its impact on healthcare.<br>- [Section 4: Prepare Healthcare Professionals for AI Integration]<br>- Collaborate with clinician training programs and professional societies to develop professional standards for AI competency.<br>- Encourage healthcare organizations to involve their workforce throughout the AI lifecycle.<br>- Support the development of liability standards surrounding AI use.<br>- [Section 5: Support the Deployment and Integration of Health AI Technologies]<br>- Provide resources to assist healthcare organizations in the selection, procurement, deployment, management, and evaluation of health AI tools.<br>- Provide guidance to providers on appropriate coding and billing for AI-assisted services.<br>- Issue guidance on AI's role in utilization review, ensuring human reviewers maintain independent decision-making authority.<br>- [Section 6: Ensure that Patients are not Excessively Denied Care]<br>- Issue guidance on the appropriate use of AI in the utilization review process, ensuring human reviewers are not unduly influenced by algorithms.<br>- Require Medicare Advantage plans to disclose their use of AI in the prior authorization process, including whether AI was used to issue a denial.<br>- [Section 7: Promote Patient Choice and Public Awareness of Health AI]<br>- Collaborate with federal agencies to develop a campaign educating the public on the basics of AI in health.<br>- Develop materials and guidance for clinicians to explain to patients if, when, and how AI is being used for their care.<br>- [§8: Conclusion] Collaborate with the Administration and provide expert guidance in crafting an AI Action Plan. |
| AI-RFI-2025-1353.md | American Optometric Association | Professional-Society | The American Optometric Association (AOA) represents doctors of optometry and advocates for their role in patient care, particularly concerning the safe and effective integration of AI into healthcare practices, emphasizing the importance of the doctor-patient relationship and the need for appropriate regulation. | - [§1: Document Metadata/Header] None stated for this section.<br>- [§2: Submitter Information] None stated for this section.<br>- [§3: Introduction/Statement of Interest] The potential risk to the essential doctor-patient relationship from inappropriate use of AI.<br>- [Section 4: Core Concerns & Recommendations - AI Safety in Healthcare]<br>- AI value should not be measured solely on accuracy.<br>- AI implementation must ensure patients identified with potential risk receive necessary care and follow-up.<br>- Data sets used for AI development should be consistently evaluated for gaps across populations.<br>- AI models should account for data gaps and limit use where shortcomings exist, clearly identifying those shortcomings.<br>- Consideration should be given to open-source models or requiring publication of training sources.<br>- [§5: Deepfakes and Misinformation] The increasing use of deepfakes of trusted health experts to spread misinformation and the potential for harm.<br>- [§6: Call to Action & Advisory Panel Request] None stated for this section.<br>- [§7: Closing/Contact Information] None stated for this section. | - [§1: Document Metadata/Header] None stated for this section.<br>- [§2: Submitter Information] None stated for this section.<br>- [§3: Introduction/Statement of Interest] None stated for this section.<br>- [Section 4: Core Concerns & Recommendations - AI Safety in Healthcare]<br>- Evaluate data sets for gaps in population representation.<br>- Limit the use of AI models with data gaps and clearly identify those shortcomings.<br>- Consider open-source AI models or required publishing of training sources.<br>- [§5: Deepfakes and Misinformation] Increased regulation of deepfakes and increased law enforcement related to deepfakes.<br>- [Section 6: Call to Action & Advisory Panel Request]<br>- Ongoing education for policymakers, regulators, patients, and the healthcare workforce.<br>- Creation of an advisory group to develop regulatory guidance on AI in healthcare, with inclusion of doctors of optometry.<br>- [§7: Closing/Contact Information] None stated for this section. |
| AI-RFI-2025-1354.md | Samantha Ramos | Individual | The submitter is a stay-at-home homeschooling mother who relies on income from her blog and is concerned about the negative impact of Google’s AI updates and the potential for AI companies to scrape content without fair compensation, impacting her livelihood and the future of small online publishers. | - [§1: Document Metadata] None stated for this section.<br>- [§2: Comment Identification] None stated for this section.<br>- [§3: Submitter Information] None stated for this section.<br>- [Section 4: General Comment]<br>- Significant loss of income (90%) due to Google’s AI updates.<br>- Concern about AI companies (Google, OpenAI) scraping website content for training purposes without compensation or consideration.<br>- Fear that allowing scraping will discourage small publishers from creating content.<br>- Belief that Google is unfairly demoting small publishers to favor its AI and partners (e.g., Reddit). | - [§1: Document Metadata] None stated for this section.<br>- [§2: Comment Identification] None stated for this section.<br>- [§3: Submitter Information] None stated for this section.<br>- [Section 4: General Comment]<br>- Implement laws that prevent AI companies from scraping content without fair compensation.<br>- Prioritize and support small publishers as partners, rather than allowing their content to be used without benefit.<br>- Prevent Google from demoting small publishers' search rankings in favor of its AI products and partners.<br>- Advocate for policies that put families and individuals like the submitter first. |
| AI-RFI-2025-1355.md | Anonymous Anonymous | Individual | The submitter expresses a concern regarding the direction of OpenAI and its potential impact on AI policy, suggesting an interest in preventing what they perceive as negative developments or harmful ideas from being implemented. | - [§1: Submission Metadata] None stated for this section.<br>- [§2: RFI Identification] None stated for this section.<br>- [§3: Comment Context] None stated for this section.<br>- [§4: Submitter Information] The submitter is concerned about "OpenAi get[ting] away with their wrong ideas." | - [§1: Submission Metadata] None stated for this section.<br>- [§2: RFI Identification] None stated for this section.<br>- [§3: Comment Context] None stated for this section.<br>- [§4: Submitter Information] The submitter implicitly recommends actions to prevent OpenAI from pursuing what they consider to be "wrong ideas." There are no specific policy recommendations beyond this. |
| AI-RFI-2025-1356.md | Messaging, Malware and Mobile Anti-Abuse Working Group (M3AAWG) | Industry-Association | M3AAWG is a global industry association focused on fighting online abuse through best practices and cooperation, with a specific interest in the security of AI systems, using AI for security, and mitigating the risks of AI misuse in cyberattacks. | - [§1: Document Header/Metadata] None stated for this section.<br>- [§2: General Comment Introduction] The need to address online abuse, potential for misuse of AI, and the importance of collaboration to find solutions.<br>- [§3: AI and Security: Securing AI and Using AI for Security] Abuse of AI systems by cybercriminals, securing critical AI assets (especially PII), and the need for practical implementations of AI security mitigations.<br>- [§4: AI Standards and Best Practices] Lack of clear baseline standards, need for transparency in supply chains, complexity of AI supply chains, and the need for risk profiles for foundation model developers.<br>- [§5: Collaboration Between Industry and Government / Stakeholders] Need for strong collaboration between stakeholders for information sharing and development of standards and approaches, and lack of coordination for threat mitigation.<br>- [§6: Conclusion] None stated for this section.<br>- [§7: Sign-off & Dissemination Notice] None stated for this section. | - [§1: Document Header/Metadata] None stated for this section.<br>- [§2: General Comment Introduction] None stated for this section.<br>- [Section 3: AI and Security: Securing AI and Using AI for Security]<br>- Support stakeholder efforts in monitoring and managing AI system risks.<br>- Research and development initiatives focused on adapting AI systems to evolving cyber threats.<br>- Federal research initiatives and incentives for risk-based AI development lifecycles (security/privacy by design).<br>- Programs supporting open-source tools for AI security/privacy.<br>- Training/education programs for public sector agencies.<br>- Support R&D programs focused on cybersecurity enablement/abuse prevention through public-private partnerships.<br>- [Section 4: AI Standards and Best Practices]<br>- Further investment into relevant standards, best practices, and benchmarks.<br>- Establishing and harmonizing clear baseline standards (definitions, architectures, product profiles).<br>- Focus on AI supply chain security, particularly for foundation models.<br>- Develop public datasets for benchmarking AI models.<br>- Develop best practices for addressing AI abuse by cybercriminals.<br>- Further insights/technical standards on secure/reliable/effective AI systems with industry input.<br>- [Section 5: Collaboration Between Industry and Government / Stakeholders]<br>- Encourage partnerships between government agencies, industry groups (like M3AAWG), and global AI ecosystem stakeholders.<br>- Enable information sharing between AI stakeholders for threat identification/coordination.<br>- [§6: Conclusion] None stated for this section.<br>- [§7: Sign-off & Dissemination Notice] None stated for this section. |
| AI-RFI-2025-1357.md | Beacon College | Academia | Beacon College is dedicated to serving students with learning differences (neurodiverse learners) and is interested in leveraging AI technologies to enhance their access to resources, personalized learning strategies, and overall success in higher education and the workforce. They advocate for AI development that specifically addresses the needs of this underserved population. | - [Section 1: Submission Header/Metadata]** None stated for this section.<br>- [Section 2: Introduction & Overview]** Lower college retention and graduation rates for neurodiverse students. The underutilization of the neurodiverse talent pool in the workforce.<br>- [Section 3: The Triadic Developmental Model]** Not Applicable – Section focuses on a model, not concerns.<br>- [Section 4: Current and Strategic Use of AI - Overview]** AI tools must be designed inclusively to ensure they meet the needs of neurodiverse students.<br>- [Section 5: College Preparation and Transition - AI Applications]** Predictive models for neurotypical students are not yet accurate for neurodiverse learners. Challenges faced by neurodiverse students may not be identified early enough.<br>- [Section 6: Academic Engagement - AI Applications]** Not Applicable – Section focuses on current AI applications, not concerns.<br>- [Section 7: Holistic Success - AI Applications]** Current AI technology is not tailored to the specific needs of neurodiverse students for emotional regulation, organization, or interpersonal skills. Families struggle to understand how best to support neurodiverse students.<br>- [Section 8: Professional Development for Faculty and Staff - AI Applications]** Not Applicable – Section focuses on professional development, not concerns.<br>- [Section 9: Looking Ahead: AI in Support of Neurodiverse Learners]** Not Applicable – Section focuses on a future outlook, not concerns. | - [Section 1: Submission Header/Metadata]** None stated for this section.<br>- [Section 2: Introduction & Overview]** None stated for this section.<br>- [Section 3: The Triadic Developmental Model]** None stated for this section.<br>- [Section 4: Current and Strategic Use of AI - Overview]** Prioritize inclusive design of AI tools for neurodiverse learners.<br>- [Section 5: College Preparation and Transition - AI Applications]** Develop predictive models using AI that specifically identify factors influencing success for neurodiverse students.<br>- [Section 6: Academic Engagement - AI Applications]** None stated for this section.<br>- [Section 7: Holistic Success - AI Applications]** Tailor AI technology to offer real-time feedback on emotional regulation, organization, and interpersonal skills for neurodiverse students. Develop AI tools to help families understand how best to support neurodiverse students.<br>- [Section 8: Professional Development for Faculty and Staff - AI Applications]** Develop adaptive AI technologies to offer personalized instruction and real-time feedback to faculty and staff.<br>- [Section 9: Looking Ahead: AI in Support of Neurodiverse Learners]** Facilitate dialogue with policymakers, educators, and technology leaders to ensure AI empowers students with learning differences. |
| AI-RFI-2025-1358.md | Alvin Scherdin | Individual | The submitter is concerned about the economic impact of AI on content publishers, specifically the lack of incentive to create new content if it is easily stolen and monetized by others. | - [§1: Submission Header] None stated for this section.<br>- [§2: Docket Information] None stated for this section.<br>- [§3: Comment Reference] None stated for this section.<br>- [§4: Submitter Information] None stated for this section.<br>- [§5: Comment Content] The submitter expresses concern that allowing the proposed AI actions "basically kills the internet" by removing incentives for content publishers to create new content due to the risk of theft and lost revenue. | - [§1: Submission Header] None stated for this section.<br>- [§2: Docket Information] None stated for this section.<br>- [§3: Comment Reference] None stated for this section.<br>- [§4: Submitter Information] None stated for this section.<br>- [§5: Comment Content] No specific policy recommendations are stated, but the implied recommendation is to avoid actions that allow for the theft of content and disincentivize creation. |
| AI-RFI-2025-1359.md | Anonymous | Individual | The submitter is concerned about the negative impact of generative AI and tech monopolies on independent content creators, specifically regarding revenue disruption, intellectual property rights, and the preservation of the open web. They advocate for policies that protect small businesses and uphold ethical AI use. | - The rapid rise of generative AI threatens over 100,000 independent content creators and small business owners.<br>- AI-driven content delivery risks disrupting revenue streams for independent creators.<br>- Dilution of intellectual property rights due to AI tools.<br>- Undermining of the open web.<br>- Tech giants like Google are using AI to dominate content distribution and create monopolistic practices.<br>- AI Overviews in search results bypass independent creators, cutting off their revenue and keeping users within tech giants' ecosystems.<br>- AI-generated search summaries do not direct users to original sources, reducing creators' control and misrepresenting their work.<br>- Exploitation of creators' intellectual property without consent or compensation by AI tools. | - Protect small businesses from tech monopolies, ensuring fair competition and upholding the free market.<br>- Ensure ethical AI use in search, reaffirming the government's commitment to technology and supporting creators' rights.<br>- Uphold intellectual property and revenue protections for creators.<br>- Address the issue of AI-generated search summaries not directing users to original sources. |
| AI-RFI-2025-1360.md | Christian Großmann | Individual | The submitter is interested in establishing a comprehensive national plan to achieve American leadership in Artificial Intelligence through substantial investment in technology, education, ethical frameworks, and international collaboration. They advocate for a proactive, large-scale government-led initiative. | - [§1: Document Header/Metadata] None stated for this section.<br>- [§2: General Comment] None stated for this section.<br>- [§3: Precise Measures for AI Dominance] None stated for this section.<br>- [§4: Quantum Computing Integration] None stated for this section.<br>- [§5: Specialized AI Education] None stated for this section.<br>- [§6: AI Ethics Commission] None stated for this section.<br>- [§7: International AI Alliance] None stated for this section.<br>- [§8: AI Infrastructure Offensive] None stated for this section.<br>- [§9: AI Start-up Ecosystem] None stated for this section.<br>- [§10: Industry-Specific AI Integration] None stated for this section. | - [§1: Document Header/Metadata] None stated for this section.<br>- [§2: General Comment] None stated for this section.<br>- [Section 3: Precise Measures for AI Dominance]<br>- Invest in quantum computing for AI applications.<br>- Establish a nationwide AI curriculum starting in 6th grade.<br>- Create an independent national AI Ethics Commission.<br>- Initiate an "AI Alliance" with leading democracies.<br>- Expand the 6G network for AI applications.<br>- Provide a fund to support AI start-ups.<br>- Mandate AI strategies for Fortune 500 companies.<br>- [Section 4: Quantum Computing Integration]<br>- Invest $10 billion in developing quantum computers specifically for AI applications by 2027.<br>- Establish at least 3 national quantum computing centers specializing in AI algorithms.<br>- [Section 5: Specialized AI Education]<br>- Introduce a nationwide AI curriculum for schools starting from the 6th grade by 2026.<br>- Create 100,000 new AI-specific study places at U.S. universities within the next five years.<br>- [Section 6: AI Ethics Commission]<br>- Establish an independent national AI Ethics Commission by the end of 2025.<br>- Develop binding ethical guidelines for AI development and deployment by mid-2026.<br>- [Section 7: International AI Alliance]<br>- Initiate an "AI Alliance" with at least 20 leading democracies by 2026.<br>- Invest $5 billion annually in joint research projects within this alliance.<br>- [Section 8: AI Infrastructure Offensive]<br>- Expand the 6G network with a special focus on AI applications, covering 80% of the population by 2028.<br>- Construct 50 new AI-optimized data centers across all U.S. states by 2027.<br>- [Section 9: AI Start-up Ecosystem]<br>- Provide a $50 billion fund to support AI start-ups by 2026.<br>- Establish 10 AI innovation zones with tax incentives and specialized infrastructure by 2027.<br>- [Section 10: Industry-Specific AI Integration]<br>- Mandate AI strategies for all Fortune 500 companies by 2026.<br>- Offer $20 billion in state funding to integrate AI into traditional industries by 2028. |
| AI-RFI-2025-1362.md | USTelecom - The Broadband Association | Industry-Association | USTelecom advocates for policies that promote broadband deployment and innovation, believing that robust broadband infrastructure is critical for the successful development and adoption of AI technologies and maintaining U.S. competitiveness in the global AI landscape. | - [Section 1: Introduction/Document Header]** None stated for this section.<br>- [Section 2: Executive Summary/Overall Position]** Overregulation could stifle AI innovation and hinder U.S. leadership. Geopolitical AI competition, particularly with China, poses a risk.<br>- [Section 3: Cut Government Red Tape and Speed Up Broadband Deployment]** Insufficient broadband infrastructure will limit the scalability of AI and jeopardize U.S. competitiveness. Slow deployment processes and regulatory barriers impede broadband expansion.  Potential fiber network capacity shortage to support AI demands.<br>- [Section 4: Embrace Pro-Innovation AI Governance to Keep America Competitive]** Existing laws are generally sufficient to address potential harms from AI. A patchwork of state laws could create uncertainty and hinder innovation. Third-party audits are unnecessary and could create security risks.<br>- [Section 5: Ensure Balanced Assignment of Responsibilities Among AI Developers and Deployers]** AI deployers should not be held liable for design flaws or issues they cannot control. Liability should be proportionate to control over the technology.<br>- [Section 6: Reduce Barriers to AI Innovation and Market Entry]** Regulations should not unfairly single out specific industries. Overly broad opt-out requirements could hinder AI development.  Anticompetitive behaviors could prevent innovators from accessing the market.<br>- [Section 7: Strengthen the American Market-Driven Approach to Standards Development]** Decreased U.S. participation in global standards bodies could harm U.S. competitiveness. The high cost of participation in standards development deters companies. Lack of investment in research and development and future talent could jeopardize U.S. leadership. | - [Section 1: Introduction/Document Header]** None stated for this section.<br>- [Section 2: Executive Summary/Overall Position]** Collaboration with the Administration to unlock AI’s transformative potential.<br>- [Section 3: Cut Government Red Tape and Speed Up Broadband Deployment]** Prioritize broadband expansion. Streamline permitting and spectrum access. Encourage investment-friendly policies for broadband and data centers.<br>- [Section 4: Embrace Pro-Innovation AI Governance to Keep America Competitive]** Leverage existing laws to foster trustworthy AI systems. Adopt a risk-based approach to regulation. Avoid a prescriptive approach to regulation. Avoid a patchwork of state laws through federal preemption.<br>- [Section 5: Ensure Balanced Assignment of Responsibilities Among AI Developers and Deployers]** Recognize key differences between developers and deployers.  Adopt a risk-based framework that places responsibility on those best positioned to manage AI-related risks.<br>- [Section 6: Reduce Barriers to AI Innovation and Market Entry]** Design regulations to foster innovation across all sectors. Avoid overly broad opt-out requirements. Prevent anticompetitive behaviors that deny innovators market access.<br>- [Section 7: Strengthen the American Market-Driven Approach to Standards Development]** Promote the American, market-driven approach to standards development globally. Create financial incentives to offset the costs of participating in standards bodies and increase U.S. participation. Invest in research and development to increase the future talent pool of standards experts. Promote industry-led standards for post-quantum cryptography. |
| AI-RFI-2025-1363.md | AE Studio | Industry-Startup | AE Studio is focused on identifying and supporting breakthroughs in AI alignment and proposes a large-scale R&D program ("T.R.U.M.P. Manhattan Project") to ensure American leadership in safe and capable AI, viewing alignment as a competitive advantage. | - None Stated | - None Stated |
| AI-RFI-2025-1364.md | Association of Home Appliance Manufacturers | Industry-Association | AHAM represents home appliance manufacturers and advocates for policies that support innovation, safety, sustainability, and efficiency in the home appliance industry, particularly as it relates to the integration of AI technologies. They aim to ensure regulations do not hinder progress in these areas. | - [§1: Document Metadata/Header] None stated for this section.<br>- [§2: Attachment Information] None stated for this section.<br>- [§3: Cover Letter/Introduction] The need for the AI Action Plan to define AI and review existing regulations developed before the advent of AI. Potential for unnecessary burdensome requirements to hamper innovation.<br>- [§4: AHAM's Key Positions/Arguments] The potential for AI regulations to compromise progress in safety, cybersecurity, privacy, and interoperability. The need for clarity in regulations to protect consumers and avoid burdening innovation.<br>- [§5: Discussion of AI Definitions] The lack of a clear and commonly accepted definition of AI, particularly for consumer product applications. The risk of burdensome regulation due to the lack of clear definitions. Distinguishing between simpler rule-based algorithms and systems with authentic learning capabilities.<br>- [§6: Call for Regulatory Review] Potential conflicts between existing government requirements and AI development. The risk of regulations unnecessarily hampering innovation.<br>- [§7: Closing/Contact Information] None stated for this section.<br>- [§8: About AHAM] None stated for this section. | - [§1: Document Metadata/Header] None stated for this section.<br>- [§2: Attachment Information] None stated for this section.<br>- [§3: Cover Letter/Introduction] Develop an AI Action Plan that defines AI and reviews pre-AI regulations.<br>- [§4: AHAM's Key Positions/Arguments] Keep safety, cybersecurity, privacy, and interoperability at the forefront of consumer electrical and electronic devices in the AI Action Plan. Ensure regulations are clear and protect consumers without hindering innovation.<br>- [§5: Discussion of AI Definitions] Development of a clear definition of AI, particularly as it applies to consumer product applications.<br>- [§6: Call for Regulatory Review] Include a review of government regulations developed before the advent of AI to identify and resolve potential conflicts with AI development.<br>- [§7: Closing/Contact Information] None stated for this section.<br>- [§8: About AHAM] None stated for this section. |
| AI-RFI-2025-1365.md | Convergence Analysis | Advocacy/Think Tank | Convergence Analysis is a US 501(c)(3) non-profit research organization focused on frontier AI governance, aiming to secure American leadership in AI across economic, security, and diplomatic dimensions through research and policy recommendations. | - [§1: Document Header/Metadata] None stated for this section.<br>- [§2: Introduction] None stated for this section.<br>- [Section 3: US Policy Leadership in the AI Economy]<br>- Potential for sharp increases in unemployment due to AI developments.<br>- Increasing wealth inequality resulting from AI advancements.<br>- Disruption of wage and labor share.<br>- Uneven diffusion of AI systems across industries and regions.<br>- Significant public responses to AI-driven economies.<br>- Lack of new economic metrics to measure AI’s impact.<br>- Glaring lack of research on concrete AI economic policies.<br>- [Section 4: National Security and AI Innovation in the USA]<br>- Potential threats to national security from advanced AI capabilities (cyberwarfare, autonomous weapons).<br>- Risks associated with nationalizing frontier AI research (innovation, practicality, legal challenges).<br>- [Section 5: AI Diplomacy and American Control]<br>- Incentive for pre-emptive attacks on the US due to national AI projects.<br>- Risk of exfiltration of model weights.<br>- Vulnerability to bad actors and control failures as AI becomes more autonomous.<br>- Difficulty verifying AI progress of competing states.<br>- [Section 6: Strategic Information on Powerful Dual-Use Models]<br>- Limited visibility into the development and capabilities of frontier dual-use models.<br>- Potential misuse of AI for biosecurity, terrorism, weapons proliferation, and cybersecurity threats.<br>- [§7: Conclusion] None stated for this section. | - [§1: Document Header/Metadata] None stated for this section.<br>- [§2: Introduction] None stated for this section.<br>- [Section 3: US Policy Leadership in the AI Economy]<br>- Implement forward-looking policies to address potential unemployment, inequality, and uneven technology diffusion.<br>- Develop new economic metrics to measure AI’s impact.<br>- Conduct research on concrete AI economic policies (tax/revenue policy, social safety nets, pre-distributive policies, public/private coordination).<br>- [Section 4: National Security and AI Innovation in the USA]<br>- Explore 13 sets of policy levers as alternatives to nationalization of AI research. (Detailed overview provided in the report).<br>- [Section 5: AI Diplomacy and American Control]<br>- Develop metrics for distinguishing between mainstream AI development and strategically risky developments.<br>- Initiate high-level dialogue with competitors (specifically China) focused on superintelligent AI.<br>- Establish secure communication channels to prevent misperception of AI development.<br>- [Section 6: Strategic Information on Powerful Dual-Use Models]<br>- Implement an Advanced Dual-Use AI Model Registry.<br>- Registry should:<br>- Inform the creation of national strategies.<br>- Support implementation of national strategies.<br>- Build capacity in government.<br>- Design principles:<br>- Minimal reporting requirements.<br>- No mandatory standards or licensing.<br>- Definition of "most powerful models": combine compute, architecture, size, training data, and capability evaluations.<br>- Reporting schedule: Capability-based with bi-annual updates.<br>- Report 12 categories of information (detailed in report).<br>- Enforce registry through market mechanisms (prerequisite for commercial operations).<br>- [§7: Conclusion] None stated for this section. |
| AI-RFI-2025-1366.md | BioMADE | Industry-Association (Manufacturing Innovation Institute) | BioMADE's mission is to strengthen American competitiveness in biomanufacturing by developing technologies, building a STEM workforce, and re-shoring manufacturing jobs. They are focused on accelerating the commercialization of chemicals and materials made from biology through the use of AI and digital technologies. | - [§1: Document Header/Metadata] None stated for this section.<br>- [§2: Introduction/BioMADE Overview] None stated for this section.<br>- [§3: AI Importance in Bioindustrial Manufacturing] Lack of readily available, large datasets to inform technology development.<br>- [§4: Major Barrier and Recommendations] The primary barrier to realizing the benefits of AI is the lack of data systems and standards for large-scale collection, analysis, and sharing of bioindustrial datasets.<br>- [§5: Recommendation 1: Develop Data Systems and Standards] Current bioindustrial data formats and storage approaches are diverse, hindering data leverage. Lack of a centralized standardized, secure data store.<br>- [§6: Recommendation 2: Define Governance and Security Policies] Risk of adversaries gaining access to innovative technologies. Dependence on foreign AI models poses data privacy, manipulation, and strategic vulnerability risks.<br>- [§7: Recommendation 3: Create Education Programs] A lack of a workforce trained to incorporate AI into bioindustrial manufacturing activities (data collection, management, and analysis). | - [§1: Document Header/Metadata] None stated for this section.<br>- [§2: Introduction/BioMADE Overview] None stated for this section.<br>- [§3: AI Importance in Bioindustrial Manufacturing] None stated for this section.<br>- [Section 4: Major Barrier and Recommendations]<br>- Develop a set of centrally created, managed, and maintained data systems.<br>- Create a set of standards for bio-data and bio-process management and tracking.<br>- Define a bio-data governance and security policy.<br>- Establish a dedicated education program.<br>- [Section 5: Recommendation 1: Develop Data Systems and Standards]<br>- Develop centrally created, managed, and maintained biodata platforms.<br>- Standardize biodata formats for storage to facilitate data sharing between partners.<br>- Create a centralized, standardized, and secure data store.<br>- [Section 6: Recommendation 2: Define Governance and Security Policies]<br>- Create central data stores, standards, and sharing approaches with a "day-one" approach to cybersecurity and traceability.<br>- Implement AI-driven security tools for threat detection and anomaly analysis.<br>- [Section 7: Recommendation 3: Create Education Programs]<br>- Develop professional development programs for the current workforce.<br>- Establish educational programs at the community college and university levels.<br>- Include real-world AI projects, industry certifications, and job placement support.<br>- Provide instructor training through externships.<br>- Encourage sustained engagement with industry for curriculum development and access to tools. |
| AI-RFI-2025-1367.md | Casey Smith | Individual | The submitter expresses strong concerns about the potential negative societal impacts of widespread AI adoption, particularly regarding job displacement, unethical data usage, and the loss of human skills and autonomy. They advocate for caution and critical evaluation of AI’s integration into various aspects of life. | - Job displacement across various industries (stores, food service, general workforce) due to AI-driven automation.<br>- Unethical data practices, specifically feeding individuals' private and intellectual information into AI systems without consent.<br>- Potential for AI to undermine the value and skills of professionals like doctors, artists, graphic designers, filmmakers, and musicians.<br>- Inaccuracies and potential for fatal errors in AI applications, specifically referencing a study in the medical field.<br>- Dependence on computer infrastructure and vulnerability to cyberattacks, data theft, and malicious software.<br>- Lack of critical thinking and skill development with reliance on AI-generated content.<br>- The frightening potential for AI to develop its own incomprehensible language and alter its own code.<br>- The risk of AI gaining control over critical systems like the military and potentially deeming humans unnecessary.<br>- The fear of falling into a scenario akin to "Roko's basilisk" due to monetary gain.<br>- The potential for societal collapse if everyone becomes jobless. | - A halt to the integration of AI into government, hospitals, and media.<br>- Increased caution and critical evaluation of AI applications before widespread deployment.<br>- None Stated. |
| AI-RFI-2025-1368.md | Anonymous | Individual | The submitter is primarily concerned with protecting the rights and livelihoods of human creators in the face of increasing capabilities of generative AI, advocating for strengthening copyright laws and fair practices related to AI training and commercial use. | - [§1: Document Metadata] None stated for this section.<br>- [§2: General Comment] The potential for AI models to be trained on copyrighted works without consent, undermining creator control over intellectual property.<br>- [§3: Copyright & Ownership in AI-Generated Works] Lack of clarity on copyright eligibility for AI-generated works and the risk of devaluing human creative input.  Concerns that simple prompts shouldn’t qualify for copyright protection.<br>- [§4: Protecting Human Creatives from Direct Competition with AI] The potential for generative AI to replace human creatives, devaluing their work and undermining professional opportunities.  Concerns about unfair competition.<br>- [§5: Fair Licensing Agreements for AI Training] The risk of exploitative licensing agreements between AI companies and copyright holders, potentially resulting in unfair compensation and forced transfers of rights.<br>- [§6: Concluding Remarks] The challenge of “AI unlearning” and the importance of addressing ethical and legal concerns regardless of technical feasibility. | - [§1: Document Metadata] None stated for this section.<br>- [§2: General Comment] Legally require AI companies to implement mechanisms to remove copyrighted content upon request.<br>- [§3: Copyright & Ownership in AI-Generated Works] AI-generated works should only be eligible for copyright protection with significant (at least 50%) human creative input. Non-copyrightable AI outputs should be made publicly available, with copyright violations prohibited from sale or monetization. Outputs substantially transformed through human interpolation should be eligible for copyright.<br>- [Section 4: Protecting Human Creatives from Direct Competition with AI]<br>- Mandatory disclosure of AI use in generated content.<br>- Restrictions on AI use in fields where human creativity is integral (e.g., commissioned artwork).<br>- Government incentives (grants, tax breaks, subsidies) for businesses prioritizing human-made creative content.<br>- [Section 5: Fair Licensing Agreements for AI Training]<br>- AI companies must secure proper licensing agreements before using copyrighted works for training.<br>- Agreements should ensure fair financial compensation and reasonable timeframes.<br>- AI companies should not obtain full rights to an artist’s work without explicit, voluntary agreement.<br>- Copyright holders should retain the right to renegotiate or revoke agreements as technology evolves.<br>- [§6: Concluding Remarks] Implement fair licensing and disclosure requirements, and other proposed measures, regardless of whether AI "unlearning" is technically feasible. |
| AI-RFI-2025-1369.md | Anonymous | Individual (likely representing creator interests, but with no identifying information) | The submitter is focused on protecting the rights and livelihoods of human creators in the age of generative AI, advocating for copyright protections, fair licensing practices, and measures to prevent direct competition with AI-generated content. They prioritize ensuring creators retain control over their intellectual property and are fairly compensated for the use of their work in AI training. | - [§1: Document Header/Metadata] None stated for this section.<br>- [§2: General Comment - Should AI Be Capable of Forgetting?] Copyright infringement through the use of copyrighted works in AI training without consent; devaluation of human creativity if AI can freely replicate existing works.<br>- [§3: Copyright & Ownership in AI-Generated Works] The potential for AI to generate works that infringe on existing copyrights; the difficulty in quantifying and protecting human creative input in AI-generated outputs; the need to differentiate between AI-assisted and fully AI-generated works.<br>- [§4: Protecting Human Creatives from Direct Competition with AI] Direct competition between human creatives and generative AI models, leading to the devaluation of human labor and professional opportunities; the potential for AI-generated content to be misrepresented as human-made; the lack of fair market practices in the commercial use of AI-generated content.<br>- [§5: Fair Licensing Agreements for AI Training] The potential for exploitative licensing agreements between AI companies and copyright holders; the lack of reasonable compensation for the use of copyrighted works in AI training; the absence of rights for creators to renegotiate or revoke agreements as AI technology evolves.<br>- [§6: Concluding Remarks] The ethical and legal implications of using copyrighted works in AI training, even if "unlearning" proves technically difficult. | - [§1: Document Header/Metadata] None stated for this section.<br>- [§2: General Comment - Should AI Be Capable of Forgetting?] Legally require AI companies to implement mechanisms that remove copyrighted content upon request; strengthen copyright laws to effectively regulate generative AI.<br>- [§3: Copyright & Ownership in AI-Generated Works] Only grant copyright protection to AI-generated works with significant human creative input (approximately 50% modification threshold); classify AI-generated outputs that fail to meet this threshold as non-copyrightable and publicly available (except in cases of infringement); label all AI-generated outputs that do not infringe as "AI-generated"; protect significantly interpolated AI-generated works that are unique and not replicable through the same prompt.<br>- [§4: Protecting Human Creatives from Direct Competition with AI] Require companies to disclose the use of AI in generated works (mandatory disclosure); restrict the use of AI in fields where human creativity is integral; offer government incentives (grants, tax breaks, subsidies) for businesses and platforms prioritizing human-made creative works.<br>- [§5: Fair Licensing Agreements for AI Training] Require AI companies to secure proper licensing agreements before using copyrighted works; ensure fair financial compensation and reasonable timeframes in licensing agreements; prevent forced transfers of full rights to an artist's or author's work; grant copyright holders the right to revoke or renegotiate agreements as AI technology evolves.<br>- [§6: Concluding Remarks] Implement fair licensing and disclosure requirements regardless of the feasibility of AI "unlearning"; prioritize ethical and legal principles to ensure creative professionals can thrive alongside generative AI models. |
