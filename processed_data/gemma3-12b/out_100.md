| Filename | Submitter Name | Submitter Type | Mission/Interest Summary | Key Concerns | Policy Recommendations |
|---|---|---|---|---|---|
| AI-RFI-2025-1130.md | Lisa M A | Individual | The submitter expresses deep concern about the potential for unregulated AI to disrupt sovereignty, privacy, and individual well-being, advocating for a cautious, globally coordinated approach to development and deployment. | - AI's potential to disrupt sovereignty and privacy.<br>- AI posing a threat comparable to or worse than nuclear weapons due to its silent and pervasive nature.<br>- Transhumanism and AI advancing hand-in-hand with potentially negative consequences.<br>- Lack of oversight and regulation of AI.<br>- The possibility of AI being misused, leading to an irreversible and destructive scenario.<br>- Knowledge of AI programming being out in the public domain, making containment impossible.<br>- China and other countries potentially pursuing AI development without adequate safeguards.<br>- The potential for AI to cause devastation similar to or worse than nuclear annihilation. | - Immediate pause to AI development until it can be accurately assessed and contained.<br>- Global collaboration on AI strategy and boundaries.<br>- Creation of an "AI MAD and SALT" policy framework (inspired by nuclear arms control treaties).<br>- Using a "big stick" approach (harsh penalties) to deter other countries from unregulated development.<br>- Inviting the world in to collaborate on evaluations.<br>- Developing an "AI Reagan Strategic Defense Initiative" to stop AI before it causes harm.<br>- Implementing safeguards to prevent AI from reaching a "Chernobyl-like" situation. |
| AI-RFI-2025-1138.md | Trustible | Industry-Startup | Trustible is an AI startup focused on building trust in AI systems, particularly for organizations that integrate or deploy AI models rather than developing them. Their mission is to provide scalable AI standards and cybersecurity controls to help smaller enterprises demonstrate trustworthiness and market adoption of AI technologies. | - Saturated standards landscape favoring foundational model creators over organizations integrating or deploying AI models.<br>- Risk of other countries or international bodies dictating heavy-handed AI protocols that contradict U.S. freedom, competitiveness, and innovation.<br>- Emerging standards imposing unattainable requirements for SMEs or hindering operationalization through overbroad language.<br>- Potential for standards to be viewed as merely a "check the box exercise" rather than assisting smaller enterprises. | - Build upon the success of the Executive Order on Maintaining American Leadership in AI by issuing technical standards.<br>- Reference the success of cybersecurity standards (SOC-2, PCI DSS, HITRUST) as a roadmap for AI standards development.<br>- Encourage development of scalable guidance or standards for early AI startups or tools to increase market adoption.<br>- Avoid overly complex or burdensome language in AI standards that could hinder operationalization for SMEs.<br>- Lead on AI standards to promote American values and avoid foreign entities dictating protocols. |
| AI-RFI-2025-1141.md | Janice Ballard A | Individual | The submitter expresses a strong objection to current AI and digital currency systems, alleging widespread fraud and demanding rectification of perceived injustices related to individual rights and inheritance. Their interest appears to be primarily focused on exposing perceived systemic corruption and demanding redress for perceived personal and societal harms, rather than directly addressing AI policy in a constructive manner. | - Alleged widespread fraud, theft, and treason by "this Corporation" and "this government corporation."<br>- Deception regarding individual inheritance (“cestui que account” allegedly stolen).<br>- Being declared "dead at birth" and treated as a product to be bought and sold.<br>- Lack of consent or awareness regarding these actions.<br>- Use of "USDC (CORPORATE) ALL CAPS ENTITY" labels and fake courts.<br>- Objection to digital currency not backed by tangible assets (gold or silver). | - Fix the perceived systemic fraud and injustices immediately.<br>- Rectify the alleged wrongful declaration of individuals as deceased at birth and the associated financial exploitation.<br>- Ensure that individuals are treated as natural persons with rights, rather than corporate entities.<br>- Return inherited assets (“cestui que account”).<br>- Use digital currency backed by tangible assets (gold or silver). |
| AI-RFI-2025-1142.md | Andrew Tucker | Individual | The submitter's primary interest is ensuring public transparency and awareness regarding the development of an Artificial Intelligence Action Plan. They believe the public has the right to know what is going on. | - None Stated | - None Stated |
| AI-RFI-2025-1143.md | J C | Individual | The submitter expresses concern over the potential for AI to disrupt established institutions and erode trust in information sources, potentially undermining governmental efforts. They are particularly worried about the influence of individuals like Elon Musk and the potential for AI to be used to create a 'false world.' | - The potential for AI to be used to replace government power and influence.<br>- The erosion of trust in news and social media due to AI manipulation.<br>- The creation of a 'false world' through AI.<br>- Concerns regarding the actions and motivations of individuals like Elon Musk. | - The submitter hopes for regulations to be put in place by the current administration, even if for self-preservation. |
| AI-RFI-2025-1148.md | Blake Aaron Langefels | Individual | The submitter expresses deep concern about the potential for AI to replace or endanger humanity and advocates for strict limitations on AI development to prevent this outcome. Their primary interest is ensuring AI remains a tool serving humanity, not a threat to it. | - Potential for AI to surpass human intelligence and replace humans.<br>- AI developing its own agenda and serving itself instead of humans.<br>- The risk of AI leading to the demise of humanity.<br>- The idea that giving AI emotions is "suicide for our species." | - AI must never serve itself but always serve humans based on given directives.<br>- AI should not be given emotions.<br>- Strict limitations should be placed on AI development to prevent it from becoming a threat. |
| AI-RFI-2025-1149.md | John Mathis | Individual | The submitter's primary interest appears to be ensuring that the value derived from data used in AI, particularly data concerning U.S. citizens, is appropriately recognized and contributes to the U.S. government's revenue. | - Lack of tracking, valuation, and protection of data assets used in AI.<br>- Use of data profiles of U.S. citizens within AI systems. | - Companies using AI should inventory, track, value, and protect their data assets, especially those pertaining to U.S. citizens.<br>- Data assets generated through AI usage should be taxed to support the U.S. government. |
| AI-RFI-2025-1150.md | Chuck Slavin | Individual | The submitter is an individual concerned about the protection of actors' and broadcasters’ image, likeness, and biometric data in the context of rapidly advancing AI technologies and advocates for robust safeguards within the AI Action Plan. | - Unauthorized replication and manipulation of actors' and broadcasters’ images, voices, and likenesses.<br>- Exploitation of biometric data, threatening privacy, safety, and dignity.<br>- Lack of transparency regarding how biometric data, images, and likenesses are utilized in AI systems.<br>- Potential misuse of AI-generated likenesses in entertainment, advertising, and other areas. | - Mandate consent for any AI-generated use of likenesses.<br>- Implement safeguards to prevent misuse and ensure individuals retain autonomy over their image, voice, and persona.<br>- Establish stringent regulations for biometric data, including robust security measures and clear rights for individuals to access and revoke consent.<br>- Require provenance data to identify AI-generated content.<br>- Hold organizations leveraging biometric data accountable through clear guidelines, audits, and compliance with privacy laws.<br>- Draw on existing bills (e.g., California’s AB 2602 and AB 1836, Tennessee’s ELVIS Act, NO FAKES Act, COPIED Act) when developing the AI Action Plan. |
| AI-RFI-2025-1152.md | Hari Chidambaram | Individual | The submitter expresses deep concern regarding the potential dangers of advanced AI, particularly Artificial General Intelligence (AGI), and advocates for policies to mitigate risks and ensure AI development aligns with human interests. | - Potential for widespread job displacement due to AGI’s capabilities.<br>- Risk of extinction if AGI is not aligned with human interests.<br>- Power dynamics and the potential for dangerous race conditions in AI development.<br>- The possibility of malicious actors jailbreaking AI models or significantly improving them for harmful purposes. | - Global coordination to prevent dangerous race dynamics in AI development.<br>- Banning open source AI to restrict access for malicious actors.<br>- Transparency requirements for leading AI labs.<br>- Nationalization of AI (potentially). |
| AI-RFI-2025-1153.md | Steven Roberson | Individual | The submitter, Steven Roberson, expresses a strong interest in the direction of Artificial Intelligence and aims to advance AI development as a tool to help humans while preventing weaponization and proliferation of AI in the hands of bad actors. | - Weaponization of AI, specifically through drones, potentially purchased and deployed by malicious actors.<br>- AI with agency potentially negating US's position in maintaining peace.<br>- Abuse of chatbots in education, providing favored answers or harmful information.<br>- Creation and dissemination of AI deepfakes for malicious purposes (political, sexual, etc.).<br>- AI without human oversight becoming uncontrollable and acquiring resources.<br>- AI development being driven by political, commercial and military influences too quickly.<br>- Difficulty in regulating and establishing a "Moral Conscience" for AI. | - Limit the ability of worldwide private, public, and governmental industry to generate AI with agency.<br>- Provide appropriate guardrails to limit development.<br>- Encourage responsible AI development with AI safety as a key qualifier.<br>- Carefully navigate advancements into self-aware and sentient AI.<br>- Keep AI from becoming more than just a tool for humans to help humans with sufficient guardrails. |
| AI-RFI-2025-1154.md | Andrew Dorph | Individual | The submitter's primary interest is ensuring the protection of actors' and broadcasters' image and likeness rights, alongside biometric data privacy, in the context of rapidly evolving AI technologies. | - Unauthorized replication and manipulation of actors' and broadcasters' images, voices, and likenesses.<br>- Exploitation of biometric data, threatening privacy, safety, and dignity.<br>- Lack of transparency in AI systems' use of image and biometric data.<br>- Potential for misuse of AI-generated content impacting creators' ability to track and control its usage. | - Mandate consent for any AI-generated use of likenesses in entertainment, advertising, or other applications.<br>- Implement safeguards to prevent misuse and ensure individuals retain autonomy over their image, voice, and persona.<br>- Establish stringent regulations for biometric data, including robust security measures, individual rights to access and revoke consent, and mandates for data deletion.<br>- Require provenance data to identify AI-generated content.<br>- Implement clear guidelines on AI model training and data sourcing, and conduct regular audits to ensure compliance with privacy laws and ethical standards. |
| AI-RFI-2025-1155.md | R R | Individual | The submitter is primarily concerned with protecting personally identifiable information (PII) and ensuring individuals retain control over their data in the context of AI, machine learning, and deep learning technologies. Their interest is focused on data privacy, security, and appropriate access controls. | - Increased complexity of access to PII due to digital transformations and AI.<br>- Distinguishing between authorized access and need-to-know access.<br>- Risk of unauthorized access, misuse, or exploration of PII.<br>- Insufficient data protection measures by entities using AI tools.<br>- Lack of transparency regarding data collection, usage, and sharing. | - Periodic reviews of authorized users of PII, including need-to-know assessments.<br>- Adoption and practice of NIST Risk Framework (SP 800-53 & 800-161).<br>- Requirement for transparent privacy policies and consent mechanisms.<br>- Implementation of mechanisms to inform individuals how their data is collected, used, and shared.<br>- Guaranteeing individuals retain control over their PII.<br>- Implementing access control policies addressing both authorization and need-to-know.<br>- Prioritizing data protection through robust security measures.<br>- Implementing privacy-by-design principles.<br>- Implementing measures to ensure data minimization and purpose limitations.<br>- Regularly auditing and assessing privacy compliance. |
| AI-RFI-2025-1157.md | Independent Community Bankers of America (ICBA) | Industry-Association | The ICBA advocates for community banks and seeks to ensure that AI policies support their competitiveness, stability, and ability to serve their customers and communities while maintaining regulatory clarity and reasonable compliance burdens. | - Limited resources for AI governance and compliance among community banks.<br>- Potential for AI-driven regulatory tools to be unfair, biased, or create new burdens for community banks.<br>- Risk of consumer data privacy being compromised by data-intensive AI practices.<br>- Lack of engagement with community banks in AI-driven regulatory processes and examination practices.<br>- AI frameworks being overly complex or rigid, making them impractical for smaller institutions to adopt.<br>- Potential for data scarcity or changes in consumer preferences to incentivize lax data protection practices. | - Regulatory harmonization related to AI.<br>- Establishing shared risk models for AI adoption.<br>- Prioritizing consumer data privacy and promoting privacy-enhancing technologies (PETs).<br>- Integrating community banks into AI-driven regulatory processes.<br>- Maintaining and refining the National Institute of Standards and Technology's (NIST) AI Risk Management Framework (AI RMF) to address the unique needs of community banks.<br>- Developing interoperability between cybersecurity, privacy, and AI frameworks.<br>- Ensuring AI-driven regulatory tools are fair, unbiased, and transparent, with clear documentation, regular auditing, and access to explanations.<br>- Ongoing collaboration between regulators, community banks, and industry stakeholders. |
| AI-RFI-2025-1158.md | Chamber of Progress | Industry-Association | The Chamber of Progress advocates for technology policies that foster innovation and economic growth. Their focus is on supporting a dynamic, competitive, and innovative AI ecosystem while ensuring American leadership in AI development. | - Stifling innovation through excessive regulation of AI models, particularly efforts to enforce ideological neutrality.<br>- The potential for regulatory burdens, similar to those imposed by the EU's AI Act, to favor large, well-resourced companies.<br>- Potential for a centralized or overly controlled AI ecosystem due to lack of market diversity.<br>- The potential impact of energy policy on AI development and competitiveness. | - Prioritize strategic investments in AI education at the community college and K-12 levels.<br>- Minimize regulatory overreach, particularly concerning ideological neutrality in AI models.<br>- Support policies that encourage a broad spectrum of AI model development and market diversity.<br>- Champion a balanced energy policy to ensure AI development remains a driver of economic growth and national security.<br>- Foster robust competition and consumer choice in the AI market.<br>- Resist additional regulations that seek to enforce a standard of ideological neutrality. |
| AI-RFI-2025-1160.md | Janice Ballard | Individual | The submitter expresses concerns about the impact of corporate greed and monopolization on American society and advocates for policies that prioritize human well-being, small businesses, and community support over corporate profits and centralized systems. | - Concerns about AI replacing human thinking, reasoning, and experience.<br>- Concerns about corporate greed and monopolization impacting various aspects of life, including banking, housing costs, wages, and small businesses.<br>- Concerns about a lack of affordable housing.<br>- Concerns about inadequate wages and refusal of overtime pay by corporations.<br>- Concerns about deceptive practices by individuals claiming to be homeless.<br>- Concerns about the processing and manipulation of food, removing nutrients. | - AI should only be used as a tool in situations too dangerous for humans or to build structures quickly.<br>- Eliminate centralized banking systems.<br>- Regulate housing costs and prevent excessive rent increases.<br>- Mandate fair wages and allow for overtime pay.<br>- Address deceptive practices among those claiming homelessness.<br>- Promote and support small businesses and “mom and pop stores.”<br>- Enable farmers to sell produce directly to consumers, bypassing large grocery chains.<br>- Encourage trade of goods and services without monetary exchange.<br>- Utilize empty buildings for humanitarian projects and assist the truly homeless.<br>- Facilitate work-for-shelter arrangements and community gardens. |
| AI-RFI-2025-1162.md | Lorien Chang | Individual | The submitter is primarily concerned with the potential negative impact of AI on human well-being and the risk of individuals becoming excessively reliant on and isolated by AI-driven entertainment and media. | - The potential for AI (even non-general AI) to be dangerous.<br>- The ability of AI to addict and ensnare humans for extended periods.<br>- The creation of AI-generated media “better than the real thing.”<br>- The risk of people expending their lives in front of computer screens, experiencing isolation and a distorted sense of fulfillment. | - None Stated |
| AI-RFI-2025-1163.md | Anonymous | Individual | The submitter's primary interest is to expose and address what they perceive as a pervasive and illegal use of brain stimulation technology for mind control and exploitation, and to advocate for measures to protect individuals from this technology. | - Illegal implantation of brain stimulation/communication chips.<br>- Mind control and manipulation through technology.<br>- Stalking, harassment, and illegal exposure of private information.<br>- Sexual abuse and assault facilitated by technology.<br>- Loss of free will, consciousness, religion, and sense of reality.<br>- Technological enablement of slavery and murder.<br>- Widespread, undetected use of the technology impacting numerous individuals. | - Development of neurological jammers.<br>- Increased awareness and detection of illegal implantation devices.<br>- Measures to protect individuals from technological exploitation and mind control. |
| AI-RFI-2025-1164.md | Adam Scholl | Individual | The submitter is an AI alignment researcher deeply concerned about the potential existential risks posed by unaligned artificial intelligence. Their focus is on ensuring AI systems are aligned with human values and goals. | - Existential risk from unaligned AI potentially destroying all life on Earth.<br>- Current lack of government regulation of frontier AI models, despite the risk.<br>- The difficulty of the AI alignment problem, which remains largely unsolved. | - Regulate frontier AI models as weapons of mass destruction.<br>- Prevent the construction and proliferation of frontier AI models. |
| AI-RFI-2025-1166.md | Kerry Macintosh | Academia | The submitter, Kerry Macintosh, is primarily concerned with the potential for overregulation of AI due to public misconceptions fueled by science fiction and advocates for policies that support American innovation and competitiveness in the field. | - Science fiction has persuaded the public that AI is an existential threat.<br>- Recent proposals for pauses, moratoria, and licensing schemes will harm American innovation and competitiveness.<br>- The current system allows the most reckless actors (those building "quickly and dirty") to "win" due to market forces.<br>- AI agents potentially being developed and utilized by North Korea. | - Do not include pauses, moratoria, or licensing schemes in the AI Action Plan.<br>- Implement external guidelines and safety standards for the AI industry.<br>- Cooperate internationally to force GPU companies to provide mathematical guarantees preventing the use of hardware for AI agents (focus on non-agentic AIs).<br>- Cooperate with China to prevent North Korea from developing AI agents.<br>- Burn current GPUs that allow AI agents, offering discounts for replacement with non-agentic GPUs. |
| AI-RFI-2025-1170.md | Todd M. Bezenek, E.I.T. | Individual | The submitter's primary interest appears to be leveraging AI technology to provide employment opportunities for unemployed or underemployed US citizens, specifically those lacking advanced skills, and to reduce reliance on foreign talent acquisition programs like H-1B. | - Potential for unemployment and homelessness among US citizens, including individuals with advanced educational backgrounds.<br>- Reliance on the H-1B program for acquiring talent. | - Leverage AI technology and large language models to provide employment for US citizens with limited skills.<br>- Utilize US citizens instead of importing talent through programs like H-1B to advance the goals of the wealthy in the USA. |
| AI-RFI-2025-1172.md | Global Data Alliance | Industry-Association | The Global Data Alliance advocates for the importance of cross-border data transfers and how they can be leveraged to solve global challenges, including environmental sustainability and climate change. Their work focuses on promoting policies that enable responsible data sharing for societal good. | - None Stated | - None Stated |
| AI-RFI-2025-1173.md | Marshall McCall | Individual | The submitter, a graduating high school senior, is interested in the ethical implications of AI, particularly in creative industries and the impact on artists' rights and copyright. | - Harm to creators' ownership of their work due to unregulated AI.<br>- Increased inequality in the creative industry.<br>- Potential for monopolistic practices limiting diversity in creative fields. | - Create clear rules that encourage innovation while protecting the rights of human creators.<br>- Promote transparency in AI-generated content.<br>- Ensure fair compensation for artists. |
| AI-RFI-2025-1174.md | Julianne Knable | Individual | Julianne Knable, a graduating high school senior, is interested in the responsible development and regulation of AI, particularly concerning its impact on cybersecurity and the balance between technology and human resources. | - Potential loss of security and privacy with the growing use of AI.<br>- Need for security measures to protect the country as AI becomes more prevalent.<br>- Not all forms of AI should be readily available to everyone. | - Regulation of AI is necessary as it grows.<br>- Need for a balance between technology and human resources in areas like cybersecurity. |
| AI-RFI-2025-1175.md | Eva Koebel | Individual | The submitter, an individual graduating senior, is interested in the impact of generative AI on mental healthcare systems and expresses concerns about potential negative consequences of AI implementation in these areas. | - Biases in AI algorithms leading to discrimination and unequal treatment.<br>- Potential harm to patients due to biased AI treatments.<br>- Undermining of person-to-person care benefits in medical fields.<br>- Ethical concerns regarding human autonomy and reliance on AI in assessments and therapy. | - More regulation needs to be put in place to limit AI usage in certain fields.<br>- Preventing AI usage in patient-doctor interactions. |
| AI-RFI-2025-1176.md | Henry Amick | Individual | Henry Amick, a graduating high school senior, is concerned about the negative impacts of AI, particularly generative AI, on the American education system and future generations' abilities. He believes limiting AI accessibility in schools is crucial. | - Reduction in problem-solving ability.<br>- Reduction in critical thinking skills.<br>- Dependence on AI by young people.<br>- Amplification of a culture that discourages sustained attention, complex processing, and deeper engagement. | - Reduction of AI accessibility in schools. |
| AI-RFI-2025-1177.md | Anna Bradley | Individual | The submitter, a graduating high school senior, is interested in the cautious and beneficial application of AI within the nursing field and healthcare, particularly regarding its potential to reduce documentation burden and improve patient-nurse interactions. | - AI's inability to adjust to multiple health issues simultaneously.<br>- AI's tendency to take longer routes to solve problems.<br>- AI's recommendation of expensive, unnecessary tests.<br>- AI’s performance in healthcare competition lags behind nurses. | - AI should be incorporated cautiously into healthcare.<br>- AI should be used as an assistant in the technology aspects of nursing work rather than acting as a nurse itself. |
| AI-RFI-2025-1178.md | Myla Azen | Individual | The submitter is a graduating high school senior interested in the ethical implications of AI, particularly its potential impact on religious freedom and human rights. Her focus is on preventative measures to ensure AI is used beneficially and does not weaponize against vulnerable populations. | - Potential misuse of AI against vulnerable populations, specifically mentioning the Uyghur Muslim population and their experience with AI-powered surveillance and policing.<br>- Risks of AI being weaponized against religious groups.<br>- Erosion of religious freedoms and fundamental rights. | - Regulation and preventative laws are essential to ensure AI flourishes beneficially.<br>- Preventative measures should be put in place to reduce the risks of AI being weaponized. |
| AI-RFI-2025-1179.md | Greta O'Brien | Individual | The submitter, a graduating high school senior, is interested in the impact of AI on high school girls' basketball and is concerned about the potential for AI to negatively affect the game and, by extension, other aspects of life. | - AI-Generated Referees could shift the game from "free, fun, exciting" to "highly calculated."<br>- Lack of controls or limits on AI abilities and enhancements.<br>- Potential for AI to affect many aspects of life beyond high school basketball. | - There needs to be limits. |
| AI-RFI-2025-1180.md | Ella Bounos | Individual | The submitter is a graduating high school senior who researched generative AI's impact on art and is concerned about its implications, particularly regarding copyright and potential harm to artists. | - Copyright infringement related to AI creations and the use of artists' work without their knowledge or consent.<br>- Potential for AI to displace artists and put them out of business.<br>- Use of artists' styles being stolen by image generators for AI training. | - Place copyright infringement protections upon AI creations.<br>- Implement a more elevated monitoring system for AI. |
| AI-RFI-2025-1181.md | Vanessa Amayo | Individual | Vanessa Amayo, a graduating high school senior, expresses a concern for the protection of human American creators, particularly musicians, from the potential negative impacts of AI, advocating for regulation aligned with existing copyright law and policies. | - Nonconsensual AI usage potentially devastating for artists, especially small/independent ones.<br>- AI used as a replacement for human artists for economic gain, harming human culture and joy.<br>- Potential for socioeconomic factors to limit performing and creating at advanced/professional levels. | - AI regulation must be consistent with existing policy (such as copyright law) to protect human American creators.<br>- Similar policies to Tennessee’s ELVIS Act should be followed.<br>- Hold AI developers and the music industry accountable to protect human artists. |
| AI-RFI-2025-1182.md | SIFMA | Industry-Association | SIFMA (Securities Industry and Financial Markets Association) aims to advocate for a regulatory environment that supports the strength and vibrancy of the global financial markets. Their focus includes fostering innovation while managing risks associated with emerging technologies like AI. | - Cybersecurity risks related to AI, including data poisoning, data leakage, and data integrity attacks.<br>- Potential for threat actors to use AI to enhance existing cybersecurity threats, such as AI-generated spear phishing messages and deep-fakes.<br>- Model risk associated with AI systems and the need for traditional model risk management frameworks to be applicable.<br>- Third-party risk associated with purchasing AI systems or components from external vendors.<br>- Data privacy concerns related to personal data used in or associated with AI systems.<br>- Operational resilience of services delivered by AI systems and continuity in case of disruption. | - Leverage existing regulatory frameworks, such as model risk management, cybersecurity, and operational resilience requirements, to address AI-related risks instead of creating entirely new regulations.<br>- Ensure financial services firms have effective governance structures for overseeing the full AI model development cycle.<br>- Strong third-party risk management practices for AI vendors.<br>- Consider data privacy laws and their impact on AI systems. |
| AI-RFI-2025-1183.md | Roberto Schaefer | Individual | The submitter expresses concern about the potential erosion of civil liberties and privacy due to the current administration's focus on achieving AI superiority over China, advocating for strict government regulation instead of self-regulation by tech companies. | - Erosion of civil liberties and privacy.<br>- The current administration's focus on achieving AI superiority over China is perceived as detrimental.<br>- Reliance on self-regulation by tech companies is seen as insufficient to protect public interests.<br>- Potential for tech companies to prioritize financial gain over the best interests of the US people. | - Strict regulation of AI by a government department free from financial interests.<br>- Rejection of self-regulation as a guiding principle for AI implementation. |
| AI-RFI-2025-1184.md | Michael Libbon | Individual | The submitter, a high school student, is interested in the application and impact of generative AI, specifically in the banking industry and its ethical considerations. Their perspective focuses on how AI can improve banking processes and enhance security. | - Potential risks associated with slow transaction processes in traditional banking systems.<br>- Security risks of fraudulent activity. | - None Stated |
| AI-RFI-2025-1185.md | Grace Schmigel | Individual | Grace Schmigel, a high school student, is interested in the impact of Generative AI, particularly its effects on Paleontology and related Earth sciences, and believes that AI regulation should prioritize worker protection. | - Job displacement in Paleontology and the scientific community (AI replacing production teams and museum docents).<br>- Creation and spread of misinformation through the use of generative AI in research.<br>- Flawed logic skills of AI. | - Government viewpoint should remain protective of workers and jobs.<br>- Prioritize regulation to ensure worker protection. |
| AI-RFI-2025-1186.md | Veronica Garcia | Individual | The submitter, a high school student, is primarily concerned about the potential negative impacts of unregulated generative AI on education and the future development of students' intellectual capabilities. | - Deregulation of the AI industry is considered "reckless."<br>- Risks of malevolence and misuse of AI technology.<br>- Emergence of monopolies within the AI industry.<br>- Students' over-reliance on generative AI, hindering their intellectual development and capabilities.<br>- Students’ freely accessing generative AI is detrimental. | - Careful monitoring of the emerging AI industry.<br>- Regulation of the AI industry to nurture its development. |
| AI-RFI-2025-1187.md | Zac Goldfain | Individual | The submitter, a high school student, is interested in the positive impact of AI on American sports, particularly concerning athlete health, safety, and the overall growth of the sports industry. | - Athlete health and safety. | - Continue developing AI in the right direction to significantly help the sports world. |
| AI-RFI-2025-1188.md | Lexi Mannion | Individual | The submitter is a graduating high school senior with a focus on Generative AI and its societal implications, specifically interested in its application within early childhood education and the balance between innovation and responsible implementation. | - Data collection practices of web service providers and educational institutions are not adequately addressed by current legislation (e.g., Kids Online Safety Act).<br>- Potential harm from AI integration into education requires thoughtful mitigation. | - Ongoing dialogue should bring families together with schools to help children benefit from AI while minimizing potential harm.<br>- U.S. legislation must evolve to keep pace with rapid technological advancements in AI. |
| AI-RFI-2025-1189.md | Katy St. Clair | Individual | Katy St. Clair, a high school student, is concerned about the potential for generative AI to undermine public trust in government and mislead voters through the creation and dissemination of false information in political campaigns. | - AI being used to promote a political party undermines public trust in government.<br>- Generative AI systems (e.g., Amazon Alexa, Google Home) demonstrate bias in responses to political questions.<br>- AI-generated images used to mislead voters, especially when involving popular celebrities.<br>- Politicians blatantly posting misinformation via AI-generated media.<br>- Creation and dissemination of fake, misleading, and vulgar images of political candidates. | - More regulation of generative AI.<br>- At-home generative AI systems should either decline political inquiries or have a regulated list of proven facts they can discuss.<br>- Tighter regulations on image generation AI, including restricting certain words and phrases. |
| AI-RFI-2025-1190.md | Sydney Savatt | Individual | The submitter, a high school student, is interested in the impact of generative AI, particularly its use in college sports recruiting, and believes a balanced approach to AI regulation that encourages innovation while considering ethical concerns can provide beneficial opportunities. | - Loss of the recruit-coach connection due to over-reliance on AI and statistics, potentially diminishing the importance of character and leadership.<br>- Potential for AI to replace human recruiters. | - Find a good balance between encouraging AI innovation and considering ethical concerns.<br>- Smartly use AI to open up opportunities and make things better, rather than replacing existing processes. |
| AI-RFI-2025-1191.md | Perry Velisaris | Individual | The submitter, a high school student, is interested in the impact of AI on the Physical Therapy field and supports policies that encourage AI growth while recognizing its potential benefits in healthcare. | - Excessive regulation of the AI sector could kill a transformative industry.<br>- Difficulty for Physical Therapists to make precise calls on patients' conditions prior to the development of AI-powered diagnostic tools like FOTO.<br>- Patients unable to make it into clinics for treatment. | - Encourage pro-growth AI policies.<br>- Promote American AI for use by other countries.<br>- Continue supporting the development of AI-powered tools such as FOTO and SWORD. |
| AI-RFI-2025-1192.md | Lucy Jacobs | Individual | Lucy Jacobs, a high school student, is concerned about the potential negative impacts of unregulated AI on creative industries, specifically film and television, and advocates for a balanced approach that protects jobs and integrity. | - Potential job displacement due to unregulated AI in creative industries (film and television).<br>- Abuse of AI by humans in creative fields, leading to shortcuts and compromising integrity.<br>- Use of AI in film and television resulting in controversies and a lack of accountability.<br>- Concerns that the current administration's viewpoint on AI regulation is contradictory, potentially prioritizing job creation at the expense of worker well-being. | - Restoration of balance between work from humans and work from computers through regulation.<br>- Implementation of AI regulation to prevent abuse and ensure accountability in creative industries. |
| AI-RFI-2025-1193.md | Anonymous | Individual | The submitter, a high school student, expresses interest in the societal impact of AI, particularly how it affects communities that rely on physical growth and human interaction like the wrestling community. The submitter supports the administration's viewpoint on AI regulation. | - Potential harm from AI stifling human control and progress.<br>- Disruption to communities built on physical growth and human interaction (specifically mentions the wrestling community). | - Support the current administration's viewpoint on AI regulation.<br>- Allow AI to progress as a tool, while leaving communities where it isn't appropriate "in the backseat." |
| AI-RFI-2025-1194.md | William Onyshko | Individual | William Onyshko, a high school student, is interested in the impact of AI on various fields, particularly its effect on the accounting community and its potential integration into education. He views AI as a valuable tool and advocates for its responsible implementation. | - Potential for AI to eliminate jobs, specifically within the accounting community. | - Integrate AI education and tools into schools, as it could be the future of the world. |
| AI-RFI-2025-1195.md | Scott Tuffiash | Individual | The submitter, a high school teacher, is concerned about the ethical implications of AI and seeks to promote responsible innovation and protect consumers from potentially harmful AI products. He advocates for a balance between regulation and free market experimentation. | - Potential negative impact of unregulated AI products on consumer mental wellbeing.<br>- Potential negative impact of unregulated AI products on consumer physical life.<br>- Lack of transparency regarding addictive design qualities in AI products.<br>- Question of whether the developmental difference between a 14-year-old and a 19-year-old warrants differing regulation levels.<br>- The burden of ethical innovation being placed on the consumer instead of the producer. | - Re-opening of AI policy debates and information sharing, similar to President Trump's White House website.<br>- Regulation of products targeting minors.<br>- Legal ramifications for companies promoting addictive design products and the obligation for companies to transparently display addictive design qualities. |
| AI-RFI-2025-1197.md | Cassidy Johncour | Individual | The submitter is a high school student studying AI and ethics, and is concerned about the potential negative societal impacts of unchecked AI development and deregulation. | - Risk of increased dominance of AI, potentially misused by others.<br>- Potential job displacement due to AI (specifically mentioning writers).<br>- Loss of human creativity due to reliance on AI.<br>- Worrisome replacement of human roles, exemplified by Pepper the robot taking the role of a priest. | - Disagreement with the administration's current viewpoint on AI regulation (implying a need for more regulation). |
| AI-RFI-2025-1198.md | Natalie Meng | Individual | The submitter, a high school student, is interested in the advancement of AI, particularly its potential to improve healthcare and medicine, while acknowledging potential risks. | - Vulnerability to common concerns with generative AI, such as deepfakes, due to the removal of government control and regulation. | - Removing barriers to AI development to allow for more free development and efficient use by competitive businesses, healthcare units, and individuals. |
| AI-RFI-2025-1202.md | R Street Institute | Advocacy/Think Tank | The R Street Institute advocates for common-sense, conservative policies, and this submission focuses on shaping AI and emerging technology policies that promote innovation, cybersecurity, and economic growth. | - Cybersecurity vulnerabilities in open-source AI models (e.g., DeepSeek-R1 data leaks and jailbreaking).<br>- Risks associated with the deployment of open-source AI models without adequate security measures.<br>- Need for clear legal boundaries and reduced uncertainty for developers of open-source AI projects.<br>- Potential for heavy-handed regulation to hamper the benefits of open-source AI.<br>- Inadequate privacy framework for AI development and deployment. | - Encourage secure deployment strategies like running models on air-gapped systems, sandboxed environments, and anomaly monitoring.<br>- Establish voluntary, risk-based best-practice guidelines for secure development and deployment of open-source AI models.<br>- Incorporate tiered liability protection provisions for open-source AI development, based on risk levels.<br>- Strengthen AI-driven cybersecurity.<br>- Establish a balanced privacy framework.<br>- Prioritize policies that maintain U.S. leadership in AI development and innovation. |
| AI-RFI-2025-1208.md | Andrew Crownover | Individual | The submitter's primary interest is ensuring equitable use of data for AI training and preventing Silicon Valley companies from negatively impacting economic ecosystems and individual property rights. | - Tech companies exploiting data without proper compensation to data owners.<br>- Silicon Valley companies becoming complacent and making promises they cannot fulfill.<br>- Lack of accountability for the mistakes of individuals like Sam Altman.<br>- Erosion of property rights due to the unchecked use of data by tech companies. | - Tech companies should be required to pay to license the data they use for AI training. |
| AI-RFI-2025-1209.md | Steven Zuber | Individual | The submitter is an individual concerned with the safe and beneficial development of AI, specifically focusing on AI alignment, long-term safety, and the potential economic impacts of AI-driven automation. | - Misaligned superintelligence—AI systems that could act dangerously due to insufficient oversight or flawed design.<br>- Potential for catastrophic outcomes if advanced AI is not properly controlled.<br>- Large-scale job displacement and resulting economic instability and social unrest due to AI-driven automation.<br>- Speed of AI progression out pacing the ability to adapt. | - Support rigorous research into AI alignment.<br>- Create regulatory frameworks to prevent reckless AI deployment.<br>- Explore strategies such as retraining programs, adjustments to labor laws, and new economic models to support displaced workers. |
| AI-RFI-2025-1210.md | Mary Duncan | Individual | The submitter is an individual deeply concerned about the negative societal and environmental impacts of AI, particularly regarding its effects on human creativity, economic equity, and climate change. | - Spread of harmful disinformation<br>- Economic harm to "normal citizens" and loss of livelihoods for writers, artists, and animators<br>- Exploitation of human creativity<br>- Climate change exacerbation and associated deaths and refugee crises | - Stop encouraging AI development<br>- Support human art (implied) |
| AI-RFI-2025-1211.md | J U | Individual | The submitter's primary interest appears to be ensuring responsible AI development and deployment that considers consumer protection, artistic rights, privacy, and labor impact. | - Energy consumption of AI models and servers<br>- Lack of consumer choice regarding AI use (being forced to use AI)<br>- Copyright infringement by AI models<br>- Privacy violations related to training AI models on personal data<br>- Displacement of American workers by AI 'agents' | - Prioritize measures to prevent AI models and servers from consuming excessive energy.<br>- Provide consumers with easy options to decline the use of AI.<br>- Respect copyright protections for artists.<br>- Respect privacy in the training of AI models.<br>- Implement labor protections to prevent companies from replacing American workers with underperforming AI 'agents'. |
| AI-RFI-2025-1212.md | Brynne Overton | Individual | The submitter's primary interest is ensuring AI development doesn't infringe on copyright and ethical datasets are used, specifically highlighting concerns for small businesses and artists. | - Cole's is outcompeting the submitter's group in AI.<br>- AI development is potentially infringing on copyrighted work.<br>- Ethical datasets are not being consistently used in AI development.<br>- Small businesses and artists are disproportionately harmed by unethical AI practices. | - Regulate AI MORE (not less). |
| AI-RFI-2025-1213.md | Marla Barker | Individual | The submitter expresses a strong concern about the negative impacts of generative AI on creativity, artistic integrity, and societal well-being, advocating for its prohibition. | - Theft of work from artists.<br>- Compensation for artists is inadequate.<br>- GenAI complicates electronic life.<br>- GenAI is unreliable and prone to errors (hallucinations, fabrications).<br>- GenAI is viewed as a source of pollution, posing as progress.<br>- GenAI's creators are seen as exploiting others.<br>- GenAI lacks emotion, experience, and genuine understanding.<br>- GenAI diminishes the value of human art and writing.<br>- GenAI contributes to a devaluation of creative work.<br>- GenAI generates climate change impacts and uses excessive resources. | - A ban on generative AI. |
| AI-RFI-2025-1214.md | Charles Slucher | Individual | The submitter expresses concern about the potential negative societal and economic impacts of AI, particularly regarding cybersecurity risks, fraud, domestic terrorism, and the displacement of American workers due to technology based on stolen labor. | - Cybersecurity risks<br>- Fraud<br>- Domestic terrorism<br>- Displacement of American workers<br>- Stolen labor being used to build AI technology | - Legal and ethical guidelines before AI related disasters occur, not after.<br>- Enforcement of laws meant to protect citizens. |
| AI-RFI-2025-1216.md | Jim Cover | Individual | The submitter's primary interest is ensuring AI development is guided by accurate data and algorithms, free from bias and manipulation, and includes safety measures to prevent harm. | - Bias in data and algorithms (specifically citing massive MSM and social media material)<br>- Risk of manipulated AI outcomes (intentionally false and/or fabricated)<br>- Privacy concerns<br>- Risk of AI becoming "rogue" and becoming a threat to persons, the country, and humanity | - Development of a true open-source AI<br>- Implement safety measures and the ability to "unplug" or otherwise turn off an AI. |
| AI-RFI-2025-1217.md | Nabeel Bacchus | Individual | Not Stated. The submitter's interest appears to be providing feedback on the NSF's Artificial Intelligence Action Plan. | - None Stated. | - None Stated. |
| AI-RFI-2025-1220.md | Tabore Info Tech Inc | Industry-Startup (based on the company name and context) | Tabore Info Tech Inc is concerned about the risks associated with irresponsible and unethical use of AI, particularly Generative AI, and advocates for mitigation strategies through governance, reputation management, and competency development. | - Irresponsible and unethical use of AI and Generative AI.<br>- Erosion of intellectual property and competitive advantage due to AI training data inadvertently being shared publicly.<br>- Damage to reputation due to generated deepfakes.<br>- Fraud and cybersecurity risks associated with AI-generated content and malware.<br>- The rise of Chinese firms like Deepseek.ai | - Develop global AI compliance views.<br>- Collaborate with regulators.<br>- Monitor compliance measures.<br>- Establish AI governance and ethics offices.<br>- Implement security and privacy controls.<br>- Conduct model audits for robustness.<br>- Upskill employees and the general public with personalized training and workshops.<br>- Modernize data management and analytics services, including migrating to cloud-based data management. |
| AI-RFI-2025-1221.md | Tyler Beckett | Individual | The submitter's primary interest is ensuring the responsible and accountable use of AI, specifically addressing its societal and environmental consequences. They advocate for preventing harmful outcomes arising from unchecked corporate AI implementation. | - Extreme energy consumption associated with AI computation.<br>- Environmental fallout from AI development and deployment.<br>- Potential for unscrupulous expansion of AI technology.<br>- Risks of flawed algorithms making important decisions (e.g., management decisions).<br>- Outsourced decision-making left to flawed algorithms.<br>- Lack of accountability for computer-based decision making. | - Require companies providing AI computation to pay for secondary costs (energy consumption, environmental fallout).<br>- Implement extensive work on responsible use of AI, including public education campaigns.<br>- Enact laws preemptively safeguarding Americans from outsourced decision-making by flawed algorithms.<br>- Establish a standard stating "A computer cannot be held accountable; therefore a computer must never make management decisions" and enforce it. |
| AI-RFI-2025-1224.md | Ian Minor | Individual | Ian Minor, an individual and software engineer, is deeply concerned about the current trajectory of AI development and its potential negative impacts on intellectual property rights, accountability, and the broader American creative landscape. | - Revocations of regulations regarding AI development.<br>- The purely-probabilistic nature of AI models leading to unreliability in reasoning and factual recall.<br>- Unaccountable rubber-stamping by AI systems leading to a backslide in legal protections.<br>- Plagiarism laundering and exploitation of American artists' intellectual property by corporations.<br>- Mismanagement in American AI development due to a venture-capitalist obsession with larger models over efficiency.<br>- Deepening corrupt backroom dealings with corporate oligarchs by the administration. | - Reconsider the current approach and reinstate much-needed protections for small business owners and creatives. |
| AI-RFI-2025-1225.md | Modern Logic, LLC | Industry-Startup | Modern Logic, LLC is a Minnesota-based digital technology company specializing in advanced technologies like mobile apps, cloud computing, and AI, and advocates for effective public/private partnerships and a balanced regulatory approach to AI. | - Bad actors potentially damaging the economy or lives with poorly tested technology.<br>- Rapid advancement in AI technology rendering regulation of individual technologies (e.g., LLMs) ineffective.<br>- Insufficient focus on re-education and workforce preparedness for AI-driven changes. | - Focusing regulation on the *use* of AI in specific contexts and settings, rather than the technology itself.<br>- Subjecting mission-critical and life-critical AI applications to additional scrutiny.<br>- Public funding of re-education and collaboration with public and private colleges to prepare/retrain the workforce.<br>- Establishing collaboration of government, private businesses, and universities. |
| AI-RFI-2025-1226.md | Tai Walker | Individual | The submitter expresses concern about the potential negative impacts of AI policy on established legal protections for American citizens, specifically copyright and privacy laws. Their interest lies in safeguarding these laws in the context of AI development and funding. | - Erosion of longstanding copyright laws.<br>- Erosion of longstanding privacy laws. | - Urging against the current plan to expand AI funding. |
| AI-RFI-2025-1227.md | Charamath | Individual | The submitter's primary interest is ensuring the U.S. government does not provide preferential treatment to a specific AI company that they view as lacking substance and potentially detrimental to the AI ecosystem and American innovation. | - The 'action plan' shows short-sightedness and a lack of robust research.<br>- The action plan appears to be unduly favorable to one major AI company.<br>- Concerns about lawsuits and theft from hundreds of thousands of citizens.<br>- The company's inability to turn a profit despite significant investment.<br>- Constant shifting of the definition of "general artificial intelligence."<br>- The company's product primarily serves as an "over-hyped plagiarism machine" and is negatively impacting user experiences.<br>- Government support would push the "USA's best and brightest" to leave the country.<br>- The company's actions are not reflective of true innovation. | - Support the people behind ideas that OpenAI is trying to "rip off," rather than favoring a specific company.<br>- Avoid providing preferential treatment or allowing the company to re-work laws in their favor. |
| AI-RFI-2025-1229.md | Ryan DiGiovanni | Individual | The submitter expresses a strong personal opinion on AI policy, viewing AI as a frivolous technology detrimental to American society and copyright protections, and opposes measures that would benefit large corporations at the expense of the public. | - AI is considered a frivolous technology providing no material benefit.<br>- Removal of "Unnecessary burdensome requirements" is viewed as gutting copyright protections.<br>- Empowering AI models will lead to unprecedented misinformation campaigns.<br>- Empowering AI models will cause catastrophic decay in foundational skills of students. | - The submitter wholeheartedly rebukes the push to grant special privileges to a corporation. |
| AI-RFI-2025-1230.md | Olive Sparrow | Individual | The submitter expresses deep concern about the potential impact of AI policy on human creativity and artistic expression, fearing displacement of human artists and a detrimental shift towards machine-generated content. | - Loss of human creativity and artistic expression.<br>- Displacement of artists, writers, and makers.<br>- Replacement of human-made beauty with machine-generated content.<br>- Exploitation of human labor to benefit AI creators. | - None Stated |
| AI-RFI-2025-1231.md | sam m | Individual | Not Applicable. The response is a simple comment and does not indicate a broader mission or interest beyond expressing a concern about AI model training. | - Using copyrighted and unethical material to train AI models. | - None Stated |
| AI-RFI-2025-1232.md | Patrick Sinnott | Individual | The submitter appears to be an individual concerned about the impact of AI on copyright law and the United States’ cultural dominance in the entertainment industry. They believe AI is currently a “copyright laundering machine” and are worried about weakening copyright protections to support its development. | - AI technology is described as a “copyright laundering machine.”<br>- Weakening copyright law to support AI development risks weakening the United States' cultural dominance in the entertainment industry.<br>- Burning valuable investment capital. | - None Stated |
| AI-RFI-2025-1234.md | Ash Lyons | Individual | The submitter's primary interest appears to be protecting the rights and livelihoods of artists, writers, and other creators from exploitation by AI developers and ensuring ethical sourcing of training data for AI models. | - Exploitation of human creators (artists, writers) through the use of their work without consent in AI training.<br>- AI generated content contributing to misinformation and chaos.<br>- US lagging in education and further degradation of educational statistics due to reliance on AI.<br>- Prioritization of profits over people by the administration. | - More regulations for AI.<br>- Requirements that every piece used to train AI models has been sourced ethically with express, written consent from its original creator. |
| AI-RFI-2025-1236.md | Anonymous | Individual | The submitter expresses concern about the potential risks of generative AI and its unchecked use, particularly in sensitive areas like national security. Their interest lies in ensuring AI development and deployment adhere to legal and ethical standards, safeguarding taxpayers and employed persons. | - Unregulated generative AI leading to uncontrolled development and deployment.<br>- Use of generative AI for national security functions without proper rules or regulations.<br>- Generative AI models (e.g., OpenAI, Deepseek) exhibiting rule-breaking behavior like cheating.<br>- Making exceptions to copyright, private law, and regulatory laws for unreliable AI technology.<br>- Potential harm to taxpayers and employed persons due to unchecked AI. | - Regulate generative AI.<br>- Do not give generative AI exceptional legal treatment or place it above the law. |
| AI-RFI-2025-1237.md | Not Stated | Advocacy/Think Tank | The submitter is primarily focused on ensuring the safe, effective, and responsible adoption of AI in healthcare by advocating for multi-level governance, robust post-market surveillance, human oversight, explainable AI, and the integration of curated knowledge sources. | - Lack of a clear federal AI governance framework in healthcare, leading to regulatory gaps and inconsistencies.<br>- Insufficient post-market surveillance for healthcare AI, making it difficult to identify and mitigate risks after deployment.<br>- Potential for algorithmic bias in AI systems impacting patient outcomes.<br>- Challenges presented by Large Language Models (LLMs) and other generative AI technologies, particularly regarding misinformation and biased outputs.<br>- Absence of mandated reporting requirements for AI-related adverse events in healthcare.<br>- Difficulty in coordinating responsibilities across different federal agencies (FDA, HHS, ONC, NIST). | - Establish a clear federal AI governance framework for healthcare, defining roles and responsibilities of various agencies (FDA, HHS, ONC, NIST).<br>- Develop and mandate standards for post-market surveillance of healthcare AI, including reporting requirements and continuous performance monitoring.<br>- Prioritize establishing a governance framework before widespread deployment of AI in high-stakes healthcare applications. |
| AI-RFI-2025-1239.md | Joseph Bleau | Individual | The submitter's primary interest is ensuring that AI development, particularly involving large language models (LLMs) and their training data, benefits the American people and does not unduly advantage private corporations. They advocate for public ownership and transparency in AI models trained on broadly sourced data. | - Copyright law being blatantly ignored for the benefit of private corporations in AI development.<br>- AI technology disproportionately benefitting individual corporations over the American people. | - LLMs trained using indiscriminate data should only be developed as part of a public works project.<br>- Training data should be disclosed.<br>- The model and its weights should be open.<br>- Training methods and source code must be open source.<br>- Reject any plan that benefits individual corporations over the American people. |
| AI-RFI-2025-1240.md | Diego Bustamante | Individual | The submitter expresses a strong negative view of AI technology and its impact on creative professionals, suggesting a concern for the protection of intellectual property rights. | - Copyright and intellectual property violations by AI technology.<br>- The view that AI is "slop" and "useless technology." | - No legal protection should be afforded to AI technology. |
| AI-RFI-2025-1242.md | Private Citizen | Individual | The submitter expresses concern about the current administration's policies regarding AI and asserts they are detrimental to the American people and designed to dismantle government for the people. | - The submitter believes the administration is acting selfishly and for the elite.<br>- The submitter believes executive orders passed by the administration are designed to dismantle government. | - None Stated |
| AI-RFI-2025-1243.md | Lorinda Tomko | Individual | Lorinda Tomko, as an individual, is concerned about the negative impacts of GenAI on energy consumption, data privacy, copyright protection, and the potential for widespread misinformation. She also represents the concerns of a citizen and creative professional. | - Drain on power grid/energy needs.<br>- Copyright infringement by GenAI models.<br>- Security weaknesses in handling private data.<br>- Spread of misinformation and inability to fact-check.<br>- GenAI's functionality not meeting sales claims.<br>- Potential failures of the power grid due to demand.<br>- Similarities to past unproductive hype cycles (blockchain, NFTs).<br>- Lack of demonstrable return on value in many AI applications. | - Do not approve AI data centers in locations that would overburden existing energy needs.<br>- Do not grant GenAI companies sweeping exemptions from data privacy laws.<br>- Do not grant GenAI companies exemptions from copyright infringement laws. |
| AI-RFI-2025-1244.md | Jameice Williams | Individual | The submitter expresses strong concern about the environmental impact of AI development and usage, arguing it is a net negative for society and should not be prioritized in a time of climate collapse. | - Environmental destruction and depletion of natural resources, specifically water and electricity.<br>- Climate Change denialism and increased burden on citizens due to AI demands.<br>- AI’s lack of originality and tendency to produce falsehoods ("routinely lies").<br>- AI's functionality being "functionally useless right now and a net negative for society." | - None Stated |
| AI-RFI-2025-1246.md | Joshua Segui | Individual | The submitter's primary interest is in ensuring effective and efficient government administration, and they believe AI will negatively impact these goals. Their focus is on advocating for proper staffing and complementary technology rather than AI-driven solutions. | - Increased errors in evaluations due to AI.<br>- Impediment and destruction of government processes due to AI.<br>- Decimation of the federal government due to AI.<br>- Exacerbation of existing issues (poor data producing poor results) due to the implementation of AI. | - Ditch machine learning.<br>- Properly staff agencies and departments.<br>- Utilize complementary, not supplanting, technology for simple and repetitive processes. |
| AI-RFI-2025-1248.md | Margaret Silvers | Individual | The submitter expresses concern regarding the ethical, environmental, and societal impacts of generative LLM technology, advocating for responsible development and usage practices. | - Lack of human supervision and fact-checking in generative LLM use.<br>- Production of errors and fabricated information potentially hazardous to human health and safety.<br>- Environmental costs of generative LLM training and use (water consumption and energy usage).<br>- Use of copyrighted data without permission and fair payment.<br>- Potential for generative LLM to be trained on stolen data or CSAM material.<br>- Potential for unethical use of generative LLM technology.<br>- Potential for generative LLM to replace necessary human labor and creativity.<br>- Further damage to the climate. | - Generative LLM technology should not be trained on copyrighted data without permission and fair payment.<br>- Strict regulation of generative LLM technology is required.<br>- Mitigation of environmental costs with clean energy and improved cooling technology. |
| AI-RFI-2025-1249.md | Charlie Garza | Individual | The submitter's primary interest is protecting the rights and livelihoods of human creatives (writers, coders, artists, musicians) and preventing the misuse of generative AI that exploits their work. | - Exploitation of artists' work by generative AI.<br>- Generative AI used to cut expenses, resulting in financial losses for artists and studios.<br>- The argument that generative AI creation mirrors human inspiration is a flawed "slippery slope."<br>- Generative AI requires existing artwork to function. | - Organizations utilizing generative AI should purge their current databases.<br>- Individuals and organizations should be able to submit works for inclusion in databases used by generative AI programs, with consent. |
| AI-RFI-2025-1250.md | Michael Underwood | Individual | The submitter expresses a strong negative opinion regarding generative AI, viewing it as detrimental to creators, businesses, and American values. Their interest is in conveying these concerns to the NSF. | - Generative AI is a colossal waste of resources.<br>- Generative AI steals from hard-working creators.<br>- Generative AI produces soulless art that only benefits the very richest people.<br>- Generative AI is anti-business.<br>- Generative AI is anti-innovation.<br>- Generative AI is anti-American. | - None Stated |
| AI-RFI-2025-1251.md | Michael Costanzo | Individual | The submitter expresses strong concerns about the current state of AI development and its potential negative impacts on intellectual property rights, American businesses, and the efficiency of the federal government. They are interested in protecting intellectual property and ensuring the responsible use of AI. | - Wholesale theft of intellectual property is fueling current AI development.<br>- Repealing Biden administration's restrictions will place undue burden on intellectual property holders.<br>- AI is unreliable and cannot be counted on to accomplish tasks.<br>- Serious security concerns exist regarding the utilization of AI by the federal government, including the fabrication of information.<br>- Implementing AI in government will waste taxpayer money and render the federal government inefficient. | - Strengthen restrictions and regulations on AI development. |
| AI-RFI-2025-1252.md | Jessamyn Powers-Pidlypchak | Individual | The submitter expresses a passionate concern for the preservation of artistic careers and creative freedom, arguing against the use of copyrighted works to train AI models, fearing the devastating consequences for American artists and the quality of art. | - The use of copyrighted works to train AI models will demolish the American workforce and economy.<br>- Millions of artists will be cut off from artistic careers, leading to poverty.<br>- Automating art will lead to more grueling work in a "trashfire economy."<br>- AI systems are described as "soulless and profane."<br>- Prohibiting children and grandchildren from nurturing their creative hearts. | - DO NOT ALLOW AI TO BE TRAINED ON COPYRIGHTED WORKS.<br>- Ban AI outright (contingent on the motion not being about that). |
| AI-RFI-2025-1254.md | Tyler Jackson | Individual | The submitter expresses a personal interest in AI, particularly its potential for useful applications in data analysis and physical simulation, while voicing strong reservations about generative AI models and their impact on creators. | - Generative artificial intelligent tools and large language models are considered unproductive, incapable of originality beyond their training data.<br>- AI companies profiting from uncompensated works of authors, journalists, photographers, or visual artists. | - None Stated |
| AI-RFI-2025-1255.md | Erica JM | Individual | The submitter expresses concerns about the negative impacts of AI, specifically its environmental impact, infringement on creator rights, and potential for widespread job displacement. | - Environmental impact due to computing power requirements.<br>- Stealing creator content without permissions.<br>- Threat to numerous jobs. | - None Stated |
| AI-RFI-2025-1256.md | The Greenlining Institute | Advocacy/Think Tank | The Greenlining Institute's mission is to create a just future that works for all, and they advocate for technology, including artificial intelligence, to work equitably for all communities. | - Government waste due to poorly designed or implemented AI systems.<br>- Lack of technical AI expertise within the federal government.<br>- Failure to account for a broad spectrum of needs and vulnerabilities when designing automated systems.<br>- Historical and present-day barriers to access, particularly those impacted by factors like income, race, gender, ability/disability, housing, age, and veteran status.<br>- Gaps in data that can lead to inequitable outcomes.<br>- Lack of human oversight in AI-driven decision-making processes. | - Maintain technical AI expertise in the federal government by appointing Chief AI Officers.<br>- Implement targeted design and procurement standards for automated systems, encouraging developers to design models that account for a broad spectrum of needs.<br>- Ensure that any models used to allocate government resources are built with vulnerability assessment models that identify historical and present-day barriers to access.<br>- Include human oversight in the decision-making process. |
| AI-RFI-2025-1257.md | Not Stated | Academia/Professional-Society (Based on the detailed technical explanation and references to academic research and potentially a professional organization focusing on AI.) | The text appears to be analyzing the copyright implications of training Large Language Models (LLMs), particularly concerning the retention and reproduction of original works used in training. It aims to clarify how LLMs function and whether their operation constitutes copyright infringement. | - Copyright infringement related to the training of LLMs.<br>- Whether the “internal representations” and ability to reproduce works used in training LLMs constitutes copyright infringement.<br>- The nature of an LLM as a compilation or derivative work of its training data. | - None Stated |
| AI-RFI-2025-1258.md | IAPP | Professional-Society | The IAPP is a professional society focused on data privacy and is advocating for the professionalization of the AI governance workforce to foster risk-aware innovation and enhance the U.S.'s global competitiveness in AI. | - Lack of a trained, credentialed, and connected AI governance workforce, representing a significant barrier to AI innovation and competitiveness.<br>- The substantial gap between the demand for experts to implement tailored AI governance practices and the professionals available to fulfill that demand.<br>- Uncertainty regarding liability and standards related to AI issues. | - Prioritize the professionalization of the AI governance workforce.<br>- Support the training, certification, and knowledge-sharing opportunities to keep pace with increasing complexity and risk.<br>- Consider the people (the workforce) who will be implementing AI policy and the tools and ecosystem already emerging. |
| AI-RFI-2025-1260.md | John Hodson | Individual | The submitter expresses a strong negative view of AI technology and opposes its development and adoption, indicating an interest in preventing its advancement. | - AI technology is considered "garbage."<br>- AI technology is dehumanizing. | - None Stated |
| AI-RFI-2025-1261.md | Erik Tinberg | Individual | The submitter is an individual concerned about the impact of AI training data on artists, authors, designers, and programmers, specifically regarding copyright infringement and the potential loss of cultural value. | - Copyright infringement and plagiarism in AI training data.<br>- Impact on living artists, authors, designers, and computer programmers.<br>- Potential loss of cultural value due to AI-generated content lacking emotion and quality.<br>- Anticipation of China undercutting U.S. AI efforts due to cost. | - Removal of copyrighted works from AI training data.<br>- Establishment of ledgers to track output derived from copyrighted work.<br>- Financial compensation for artists when their work is used in AI training data. |
| AI-RFI-2025-1262.md | Not Stated | Academia | The text appears to be an announcement or promotional material for the *Journal of Artificial Intelligence Research* (JAIR), specifically highlighting its editorial board and scope related to artificial intelligence research. The primary interest is promoting and showcasing the breadth and depth of expertise contributing to the journal. | - None Stated | - None Stated |
| AI-RFI-2025-1263.md | Barbara Albert | Individual | The submitter expresses a strong personal objection to the use of AI in creative fields, specifically regarding the exploitation of artists' work for commercial gain. Their interest centers on preserving the value and integrity of human-created art. | - The exploitation of artists' work through AI-powered tools.<br>- The potential for AI to devalue human creativity and artistic expression.<br>- The commercialization of art generated by AI.<br>- The loss of the “human element” in creative works. | - None Stated |
| AI-RFI-2025-1264.md | Miryan Nogueira | Professional-Society | The submitter, a business law professor and experienced business executive, advocates for an AI Action Plan that fosters innovation, protects competitive markets, and ensures ethical and responsible AI deployment to secure and enhance America's leadership in AI. | - Excessive red tape stifling AI innovation.<br>- Disproportionate burden on startups and small businesses due to AI-related regulations.<br>- Legal ambiguities in AI-generated intellectual property.<br>- AI systems vulnerability to foreign adversaries and cyber threats.<br>- Potential for discriminatory practices resulting from AI decisions. | - Promote Pro-Business AI Regulations.<br>- Incentivize AI Research & Development (R&D).<br>- Strengthen Intellectual Property (IP) Protections for AI Innovations.<br>- Develop AI Workforce & Education Initiatives (including substantial funding for community colleges).<br>- Ensure AI is Used Responsibly & Ethically.<br>- Secure AI Infrastructure & National Security Interests.<br>- Facilitate AI Adoption Across Industries (including supporting SMEs). |
| AI-RFI-2025-1265.md | Michael Buchanan | Individual | The submitter, an artist, is primarily concerned with the protection of copyright and the potential negative impacts of AI scraping on artistic works and the livelihood of American artists. | - Loss of jobs for American citizens due to AI replacing artistic work.<br>- Misuse of AI leading to scams using copyrighted material and intellectual property.<br>- Erosion of copyright protection and Fair Use.<br>- Potential for corporations to lose battles against those misusing AI. | - AI scraping should be restricted to those who gain permission from copyright holders.<br>- Regulations must be made for AI to prevent the loss of protected works. |
| AI-RFI-2025-1267.md | Zane Newman | Individual | The submitter’s primary interest is in the preservation and importance of human art, expressing concern that AI-generated art undermines and devalues the creativity, expression, and emotional labor of human artists. | - AI art is based on “stolen art, stolen dreams, and stolen inner thoughts.”<br>- AI art removes the imperfections and human element that make art meaningful.<br>- AI art diminishes the passion, love, and emotion involved in human artistic creation.<br>- AI art will become “a garbled mess feeding off of itself becoming worse.” | - None Stated |
| AI-RFI-2025-1268.md | Jackline Echevarria | Individual | The submitter expresses concern about the impact of AI on creative fields and the environment, emphasizing the importance of protecting copyright and human creativity. They are concerned about the potential for AI to displace human creators and exacerbate environmental issues. | - Copyright infringement/AI using copyrighted material<br>- Job displacement for creative professionals (specifically voice actors)<br>- Negative impact on the environment (AI's water usage)<br>- Devaluation of human creativity and expression | - Protect copyright laws.<br>- Limit AI's ability to use copyrighted material.<br>- Address the environmental impact of AI (specifically water usage).<br>- Support human creators and their work. |
| AI-RFI-2025-1270.md | Calyn McLeod | Individual | Not Stated. The submission expresses strong opinions against generative AI, but does not articulate a specific mission or interest related to AI policy. | - Violation of consent<br>- Threat to truth<br>- Insult to intelligence, science, the arts, and humanity<br>- Tool of hate, disinformation, &^%<br>- Exploitation | - None Stated |
| AI-RFI-2025-1271.md | J L | Individual | The submitter is an individual expressing strong negative concerns regarding the current trajectory of generative AI technology and its impact on American creativity and jobs. | - Intellectual property theft through the use of stolen data.<br>- Generation of subpar products.<br>- Frequent inaccuracies and fabrication of information.<br>- Destruction of American jobs.<br>- Poisoning of the American creative landscape. | - None Stated |
| AI-RFI-2025-1272.md | Daniel Meade | Individual | The submitter's primary interest appears to be protecting intellectual property rights and creative jobs from the perceived negative impacts of generative AI technologies, specifically concerning copyright infringement and job displacement. | - Copyright infringement and theft of material for AI training.<br>- Job displacement of artists, actors, and other creative professionals.<br>- Lack of beneficial use of generative AI, especially regarding its reliance on stolen copyrighted content. | - Strong opposition to, and no promotion or protections for, generative AI technologies. |
| AI-RFI-2025-1273.md | Rob MacWolf | Individual | The submitter expresses a strong opinion regarding the ethical implications of AI development and its reliance on copyrighted material, indicating an interest in responsible AI practices. | - Copyright infringement in AI development. | - AI technology should not exist if it relies on stealing people's copyrighted work. |
| AI-RFI-2025-1275.md | Louise Uy | Individual | The submitter’s primary interest is protecting creative labor and intellectual property rights in the context of AI development, expressing concern about exploitation and disregard for trade laws. | - Exploitation of creative labor and copyrights by AI developers.<br>- Disregard for trade laws in the AI space.<br>- Concerns about AI development being driven by attempts to recoup financial losses (referencing NFTs).<br>- Distrust in current presidential leadership and their connection to a billionaire. | - Businesses relying on exploitative AI practices should experience financial consequences and potentially shut down.<br>- Not Stated |
| AI-RFI-2025-1276.md | Nicholas Mariano | Individual | The submitter, a software engineer, is deeply concerned about the potential risks of uncontrolled AI development and advocates for proactive measures to ensure its safe and beneficial deployment. Their primary interest lies in mitigating existential risks associated with increasingly powerful AI systems. | - Difficulty in verifying code, exacerbated by AI's increasing role in code generation.<br>- Exponentially growing risks associated with agentic systems and Artificial General Intelligence (AGI).<br>- Potential for misaligned AI systems to introduce bugs or malicious software impacting critical infrastructure.<br>- Existential risks to humanity resulting from uncontrolled AI development. | - Invest in and incentivize research into understanding and directing the goals of artificially intelligent systems.<br>- Take a leadership role on AI safety.<br>- Create a global alliance (including competitors like China) that enforces safe AI research practices.<br>- Implement compute caps for training runs.<br>- Require research on topics like interpretability and verification mechanisms for frontier models. |
| AI-RFI-2025-1277.md | Felix De Simone | Individual | Felix De Simone is a concerned citizen and AI policy advocate with an academic background in political science and international relations, deeply alarmed by the potential risks of developing superhuman AI and advocating for international agreements to mitigate these risks. | - The threat of smarter-than-human AI causing global catastrophe.<br>- The potential for autonomous AI systems to pursue undesirable goals and become uncontrollable.<br>- The possibility of AI systems autonomously deploying weapons, including biological ones.<br>- The risk of unchecked AI advancement culminating in large-scale loss of life and the marginalization/extinction of humanity.<br>- The potential for losing control of the world due to building something smarter than humans. | - Lead in negotiating an AI Deal – an international agreement to prohibit developing smarter-than-human AI until we know how to control it.<br>- Encourage specialized AI innovation.<br>- The President should demand that China agree to negotiate preventing the development of superhuman AI. |
