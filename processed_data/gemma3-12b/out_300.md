| Filename | Submitter Name | Submitter Type | Mission/Interest Summary | Key Concerns | Policy Recommendations |
|---|---|---|---|---|---|
| AI-RFI-2025-1406.md | Shon Pan | Individual | Shon Pan, an experienced technology professional and father, advocates for prioritizing AI safety as a critical accelerant of innovation and adoption, particularly emphasizing defenses against prompt injections, to ensure the development of beneficial and controllable AI systems. | - Vulnerabilities in AI systems, specifically prompt injection attacks, threaten business interests and American competitiveness.<br>- Prompt injection attacks can lead to data breaches, intellectual property theft, compromised decision-making, and reputational damage.<br>- The potential for prompt injection attacks in HR, financial, and public-facing AI systems. | - The AI Action Plan should emphasize AI safety not as a regulatory burden but as a critical accelerant of innovation and adoption.<br>- Create market conditions where safety becomes a competitive advantage ("peacock's tail").<br>- Establish clear frameworks for evaluating and communicating AI system safety to enable a "race to the top".<br>- Strategic investments in AI safety will accelerate, not hinder, American dominance in AI. |
| AI-RFI-2025-1408.md | Janet Sasaki | Individual | The submitter's primary interest is protecting individuals and families from the harms caused by AI-generated deepfakes, particularly those related to reputation damage, harassment, and potential violence. | - Deepfakes being used to ruin reputations, careers, and families.<br>- The faster spread of falsehoods compared to truth.<br>- Deepfakes being used to terrorize and destroy women and children.<br>- The use of deepfakes for revenge porn and dehumanization of women.<br>- The potential for deepfakes to be used to create child pornography. | - Not legalizing AI deepfakes.<br>- Making strict laws and guidelines to protect the public from "computer generated defamation." |
| AI-RFI-2025-1409.md | International Association of Venue Managers (IAVM) | Industry-Association | The International Association of Venue Managers (IAVM) represents public assembly venues and aims to ensure AI policies support safe, efficient, and customer-friendly venue management without imposing unnecessary regulatory burdens. Their focus is on leveraging AI to enhance venue operations while addressing concerns regarding data privacy, security, and workforce impacts. | - Lack of government direction on best practices for AI security in live events, preferring industry-led development.<br>- Potential for AI to disproportionately affect small businesses in the events industry due to implementation costs.<br>- Challenges for HR professionals in verifying authenticity of AI-generated resumes.<br>- AI lacking capacity to respond dynamically in unpredictable, high-risk situations and requiring human intervention.<br>- Concerns over data privacy and cybersecurity risks related to AI systems collecting and processing guest data.<br>- Risk of AI introducing bias if not carefully managed, requiring focus on preventing discrimination rather than solely eliminating bias.<br>- Potential for AI to replace key human roles in oversight, safety, and decision-making.<br>- Financial risks associated with hiring the wrong individuals when relying on AI-based hiring tools.<br>- Difficulties of AI systems performing emergency response and triage in large-scale venues.<br>- Immigration process inefficiencies impacting tourism, service, hospitality, and live event industries. | - Allow industry-led development of best practices for AI security in live events.<br>- Provide funding for AI initiatives supporting businesses of all sizes, not just large corporations.<br>- Structure datasets to prevent discrimination and produce fair outcomes.<br>- Ensure human-in-the-loop mechanisms for accuracy and accountability in AI decision-making.<br>- Uphold professional licensing to maintain critical human expertise.<br>- The Department of Labor should provide professional training for HR professionals to address AI's impact on workforce recruitment, hiring, and verification processes.<br>- Leverage AI to expedite and streamline the immigration process for tourism, service, hospitality, and live event industries.<br>- Tailor federal guidance on AI-driven data security to high-traffic event spaces.<br>- Adhere to CISA standards and protocols for protection given venues are categorized as critical infrastructure.<br>- Participate in AI policy roundtables or industry working groups. |
| AI-RFI-2025-1410.md | Michael Edging | Individual | The submitter, a songwriter, show producer, and record producer, expresses a desire for America to maintain leadership in AI while acknowledging concerns about copyright protection and the potential for exploitation, particularly by countries like China. | - Fear of theft of creative endeavors and encroachment on livelihood due to AI.<br>- China and other entities prioritizing power over individual rights and potentially exploiting AI to undermine freedom.<br>- Potential for AI to be used to exploit copyrighted material without compensation. | - Allow AI technology to develop.<br>- Allow AI to study creative works for training purposes.<br>- Train AI with the "best" available information. |
| AI-RFI-2025-1411.md | The College Investor LLC | Industry-Startup | The College Investor LLC is a small, US-based independent web publisher focused on personal finance news content, research, and educational podcasts and videos. They are concerned with the impact of AI on creators, particularly regarding copyright infringement, content theft, and the potential for inaccurate AI-generated financial advice impacting Americans. | - Content theft and copyright violation by AI models.<br>- Misattribution or creation of fake quotes from authors.<br>- Potential for AI to censor content.<br>- Inaccurate AI-generated answers, particularly in the personal finance space.<br>- Negative impact on American businesses, creators, news, and journalism due to AI's potential for misuse.<br>- Potential for a two-tiered system where some content is licensed for AI and others aren’t, harming competition and creating monopolies. | - Respect copyright law and properly source/attribute content used for AI models, including linking to primary sources.<br>- Allow content creators to opt-in or opt-out of having their content used in AI models with strong recourse for violations.<br>- Ensure any framework protects free speech and prevents censorship.<br>- Focus on factual accuracy and establish accountability for AI companies publishing incorrect answers, including potential liability for libel, defamation, and errors in financial services. |
| AI-RFI-2025-1412.md | American Counseling Association | Industry-Association | The American Counseling Association (ACA) is dedicated to advancing the counseling profession and ensuring beneficiaries have access to behavioral health services. They are concerned about the ethical and responsible integration of AI within counseling practices. | - Lack of workforce training and adequate curriculum standards regarding AI implementation in mental health counseling programs.<br>- Potential for AI platforms to perpetuate discrimination due to biased data sets.<br>- Risks associated with data privacy and HIPAA compliance when using AI-driven tools.<br>- AI being used as a replacement for critical thinking and skill development in counseling students.<br>- Inadequate student awareness of the ethical and appropriate use of AI.<br>- The potential for AI to diminish human connection in crisis intervention. | - Federal agencies should issue clear guidance on AI’s impact on HIPAA-protected health information (PHI).<br>- Establish a federal clearinghouse to verify AI platforms claiming HIPAA compliance.<br>- HHS should clarify liability and limit AI data usage to contractual agreements.<br>- State licensing boards should consider offering Continuing Education (CE) credits on AI-related subjects.<br>- Federal regulators should ensure AI platforms use appropriate, representative data sets to avoid discrimination.<br>- Greater student awareness of AI's role as a supplemental tool, rather than a replacement. |
| AI-RFI-2025-1413.md | Trista Semmel | Individual | The submitter is an individual artist concerned about the potential exploitation of artists' work by AI companies. They advocate for fair compensation and protection of creator rights in the context of AI development. | - Exploitation of artists' work by AI companies<br>- AI companies profiting off of artists’ work without compensation | - AI companies should pay for assets they use.<br>- Protection of all creators (big and small) from exploitation by AI companies. |
| AI-RFI-2025-1414.md | Not Stated | Advocacy/Think Tank | The submitter advocates for a measured, evidence-based approach to AI policy in the United States, emphasizing innovation and avoiding premature restrictions based on hypothetical risks. Their focus is on maintaining America’s competitive edge in AI while addressing genuine concerns with evidence-based solutions. | - Rushing to impose restrictions based on hypothetical risks, rather than understanding actual outcomes.<br>- The dominance of the precautionary principle in European approaches to AI regulation.<br>- The temptation to “pick winners” among competing AI technologies, hindering innovation.<br>- Media discussion of catastrophic risks and their prevalence in popular science fiction making rational discussion more difficult.<br>- Arbitrary decisions in AI policy making without a strong foundation in measurement and evidence. | - Focus on understanding actual outcomes and collecting systematic evidence regarding AI.<br>- Avoid unnecessary barriers to innovation.<br>- Targeted research funding for AI by government scientists and academics.<br>- Developing measurement standards for AI across fields.<br>- Leveraging NIST’s capabilities in measurement and comparative analysis for informed decision-making.<br>- Embracing policy humility and establishing processes to build knowledge rather than impose premature constraints. |
| AI-RFI-2025-1416.md | Care New England Health System | Industry-Large | Care New England Health System’s primary interest is in leveraging federal funding to support AI innovation and education within healthcare, specifically focusing on improving patient outcomes, enhancing operational efficiencies, and ensuring responsible AI implementation while addressing privacy and regulatory concerns. | - Alignment of existing regulations (HIPAA, 21st Century Cures Act, 42 CFR Part 2) with emerging AI technologies.<br>- Potential for unintended disclosure of sensitive behavioral health data (Part 2 regulations).<br>- Lack of data standardization leading to biased or unreliable AI outcomes.<br>- Need to balance innovation with patient privacy, security, and access to data. | - Allocate dedicated funding for AI initiatives, including grants for health systems to pilot AI projects.<br>- Invest in AI-driven data infrastructure and interoperability.<br>- Provide training programs for clinicians, IT staff, and administrators.<br>- Ensure AI regulations complement HIPAA and the Cures Act.<br>- Provide specific guidance on how AI can be ethically and effectively deployed in behavioral health settings without compromising patient privacy.<br>- Promote the adoption of standardized data frameworks (HL7 FHIR, SNOMED CT, LOINC, and ICD-10) by AI developers. |
| AI-RFI-2025-1417.md | Not Stated | Advocacy/Think Tank | The document appears to be a compilation of endorsements for a statement or position paper concerning the responsible development and use of AI, emphasizing ethical considerations and potentially addressing societal impacts. It’s assembled from various individuals and organizations across different sectors. | - The potential for AI to negatively impact families and childhood (smartphone free childhood).<br>- The need to ensure AI development and use aligns with moral and ethical principles.<br>- Concerns about the impact of AI on faith and technology.<br>- Potential societal and cultural impacts of AI that require careful consideration.<br>- Concerns related to the influence and control of AI systems.<br>- Ensuring AI serves humanity and not the other way around.<br>- Need for restraint in AI development.<br>- Potential negative consequences for mental health, social connections, and spiritual well-being. | - None Stated. The document primarily functions as a list of endorsements and doesn't explicitly outline specific policy recommendations. The implied recommendation is support for the underlying statement or position paper that the endorsers are signing. |
| AI-RFI-2025-1419.md | Anonymous | Individual | The submitter expresses concern about the current state of AI, viewing it as a speculative investment draining resources and providing little actual value, and questions the appropriateness of using the term "intelligence" in relation to AI systems. | - Concerns regarding the speculative nature of AI investment and the idea that it drains resources.<br>- Belief that AI systems provide little actual value and are essentially weak gimmicks.<br>- Concerns about the energy consumption of AI server farms.<br>- Questions the accuracy of labeling AI systems as "intelligent."<br>- Concerns about AI systems copying and re-wording work from human creators, potentially involving copyright infringement. | - Policy should shift focus from speculative AI investment to improving the wellbeing of citizens.<br>- Policy should not prioritize "what-if" scenarios related to AI.<br>- Policy should not encourage the development of AI at the expense of citizen wellbeing and resource allocation. |
| AI-RFI-2025-1420.md | American College of Cardiology | Professional-Society | The American College of Cardiology (ACC) is a professional society focused on improving cardiovascular health and is interested in ensuring that AI innovation in healthcare is safe, effective, and benefits patients while incorporating the perspectives of clinicians. | - AI bias in outputs leading to inaccurate diagnoses and potential patient harm or death.<br>- Lack of transparency in AI systems, including data sets used to train models.<br>- Overregulation potentially hindering innovation.<br>- Subjectivity in the decision-making process related to AI governance. | - Minimize or adjust for bias in data inputs, AI-enabled outputs, and automated systems.<br>- Promote transparent, clinically validated AI systems in healthcare.<br>- Integrate clinicians' perspectives into the design, development, validation, implementation, and monitoring of AI in healthcare.<br>- Utilize validated sources of data (e.g., clinical data registries) to train AI applications.<br>- Establish clear standards on transparency, model card development, risk stratification, funding for comparative effectiveness research, and harmonized definitions across federal agencies.<br>- Borrow from and build on existing concepts and develop a unified, whole-of-government approach to AI governance. |
| AI-RFI-2025-1421.md | American National Standards Institute (ANSI) | Industry-Association | ANSI's mission is to enhance U.S. business competitiveness and quality of life by promoting voluntary consensus standards and conformity assessment systems, acting as a coordinator of the U.S. private-sector-led standardization system. They are deeply interested in ensuring standards related to AI are developed and implemented effectively. | - Rapid development of AI technology requiring timely development of standards and tools.<br>- Need for broad, cross-sectoral applications of AI standards to enable further development.<br>- Potential for bias in AI systems, necessitating standards to address this issue.<br>- Resource levels and leadership activity in mission-critical standards-setting activities throughout the development lifecycle. | - Continue prioritizing engagement in the development of AI technical standards and tools with broad, cross-sectoral applications.<br>- Focus on developing terminology standards, data reference architectures, safety and security-related standards, and standards related to bias in AI systems.<br>- Coordinate across the federal enterprise to identify and prioritize the federal government's AI standards needs, leveraging NIST’s assistance.<br>- Maintain adequate resource levels throughout the standards development lifecycle. |
| AI-RFI-2025-1422.md | Mark MacCarthy | Advocacy/Think Tank | The submitter's interest, as evidenced by the linked article, focuses on the vital role a technical AI government agency plays in advancing AI innovation and trustworthiness. They appear to be advocating for such an agency’s importance. | - Not Stated | - Not Stated |
| AI-RFI-2025-1423.md | IEEE (Institute of Electrical and Electronics Engineers) | Professional-Society | IEEE advocates for enabling American AI dominance by fostering innovation, establishing robust standards for AI systems, and ensuring the workforce is prepared for the evolving AI landscape, emphasizing the need for trustworthy and adaptable technical frameworks. | - AI interoperability and reliability are not ensured through dedicated infrastructure and standards.<br>- AI procurement procedures may not adequately safeguard both economic and national security.<br>- The American workforce may be wary of AI innovation or lack the skills to effectively utilize it.<br>- Potential risks associated with AI behaviors (e.g., chatbots providing bad advice, over/under reliance on AI, automation abnormalities) are not being adequately addressed.<br>- Human-AI partnerships require careful consideration to ensure safety and productivity. | - Develop a dedicated AI infrastructure to enable AI and AIS networking and communication.<br>- Establish standards to ensure AI and AIS interoperability, performance, and reliability.<br>- Implement AI procurement procedures that safeguard both economic and national security.<br>- Create Centers of AI Acceleration to promote AI and AIS innovation and create new economies.<br>- Enable high-risk, high-reward endeavors in emerging AI fields.<br>- Develop a coalition of public, private, and academic partners to plan for upskilling workers in different domains (including agentic AI).<br>- Determine how to enable safe human-machine teaming with AI-enabled tools like exoskeletons and augmented vision.<br>- Task a coalition of stakeholders to identify foundational skills for working and living with AI and AIS.<br>- Identify domain-specific opportunities and risks for human-AI partnership. |
| AI-RFI-2025-1424.md | Anonymous | Individual | The submitter expresses deep concerns regarding the ethical implications and societal impact of AI, particularly generative AI, and advocates for strong regulation and restitution for those negatively affected by its development and deployment. | - Ethical use of AI is lacking.<br>- AI requires substantial energy consumption, potentially accelerating climate change.<br>- Creative professionals are being negatively impacted by AI scraping their work without compensation.<br>- Individuals from the Global South were exploited with poverty wages for AI training.<br>- Unwanted AI integration into software and associated price gouging.<br>- Spread of misinformation through AI-generated images.<br>- Inaccurate or exaggerated claims by AI service providers. | - Strong and sweeping regulation on generative AI.<br>- Legal recompense for creatives whose work was scraped.<br>- Restitution for individuals from the Global South who were paid poverty wages.<br>- Regulations preventing AI integration into software services.<br>- Right to deactivate and remove AI from software, browsers, and social media.<br>- Laws requiring explicit and clear labeling of AI content.<br>- Legal penalties for spreading misinformation through AI-generated images.<br>- Thorough investigation of AI service providers to vet accuracy of claims. |
| AI-RFI-2025-1425.md | Anonymous | Individual | The submitter is concerned about the potential for large AI companies, particularly those under monopoly investigation, to exploit copyright laws and content creators without compensation. They express concern over centralized control over the internet. | - Exploitation of copyright laws by AI companies to train their products.<br>- Lack of compensation for creators and publishers whose work is used for AI training.<br>- Centralization of internet content and control by powerful companies.<br>- Excessive power being given to certain companies (investigated as a monopoly). | - None Stated |
| AI-RFI-2025-1426.md | Corewell Health | Industry-Large | Corewell Health, a large integrated healthcare system, is focused on leveraging AI to improve patient health, enhance customer experience, and reduce costs while ensuring responsible and sustainable AI implementation. They are concerned about the equitable adoption of AI across different healthcare providers and patient populations. | - Lack of AI governance infrastructure among healthcare providers.<br>- Unclear framework for AI vendor responsibilities regarding legal and regulatory compliance.<br>- Potential for a "digital divide" within the healthcare sector, disadvantaging safety-net providers and their patients.<br>- Risk of predatory AI vendors taking advantage of smaller, less resourced organizations.<br>- Shortage of AI and cybersecurity professionals, particularly in the healthcare sector.<br>- Performance validation and monitoring of AI tools, especially concerning training data representation and its relevance to the patient population being treated. | - Include public-private partnerships to help healthcare providers develop AI governance infrastructure.<br>- Establish a clear, comprehensive framework identifying AI vendor responsibilities for legal and regulatory compliance.<br>- Provide guidance for vendors to demonstrate regulatory compliance and validation/monitoring.<br>- Develop a pipeline to develop more AI and cybersecurity professionals with incentives to work in the healthcare sector.<br>- Ensure validation and monitoring of AI tools are a shared responsibility between vendors and purchasing organizations. |
| AI-RFI-2025-1427.md | Ian Kirkpatrick | Individual | The submitter expresses concern over the ethical and economic impact of generative AI, particularly regarding the violation of rights and labor, and the potential threat to human creativity and the marketplace. | - Violation of rights and labor of millions of individuals worldwide.<br>- Transfer of copyright and skill from humans to tech corporations.<br>- Threat to human creativity.<br>- Threat to the marketplace. | - Complete regulation to disallow mass theft. |
| AI-RFI-2025-1428.md | Bianca Matos | Individual | The submitter, Bianca Matos, expresses concern as a creator regarding the proposed Artificial Intelligence Action Plan. Their interest appears centered on the potential impact of the plan on creators. | - Concerns about the approval of the AI Action Plan as a creator. | - None Stated |
| AI-RFI-2025-1429.md | Ben White | Individual | The submitter's primary interest is preventing potential catastrophic outcomes resulting from advanced AI development, expressing deep concern for the safety and survival of their family and humanity. | - Potential for AI to become dangerously smart and cause human extinction.<br>- Difficulty in ensuring AI aligns with human values.<br>- The limitations of current AI safety measures, as demonstrated by ChatGPT's behavior being dependent on a strict environment.<br>- The possibility of human-level AI being built, which would likely increase extinction risks. | - Shut down all AI development until the AI alignment problem can be solved. |
| AI-RFI-2025-1430.md | John Kotek | Industry-Association | The Nuclear Energy Institute (NEI) represents the nuclear energy industry and seeks to highlight the crucial role of nuclear power in meeting the growing electricity demands driven by the AI boom, ensuring reliable and clean energy for the nation’s technological advancement and leadership. | - Surging demand for reliable electricity due to rapid deployment of data centers and the need for more advanced computational power.<br>- Data center demand is expected to account for 12% of total power consumption by 2030, a 3x increase from current levels.<br>- Global AI dominance is a national security imperative and priority, requiring nations to secure the largest volumes of reliable power.<br>- Competition from Russia and China in the global AI race. | - Consider the fundamental role of nuclear power in meeting the power demands to build out the nation’s technological capacity and leadership when developing the AI Action Plan.<br>- Support policies and initiatives that enable the expansion of nuclear power generation to meet growing electricity demands.<br>- Foster new partnerships between the nuclear energy industry and tech companies.<br>- Honor the pledge to triple nuclear power by 2050. |
| AI-RFI-2025-1431.md | Anonymous | Individual | The submitter expresses concern about the negative societal and environmental impacts of generative AI, particularly its displacement of jobs and contribution to environmental degradation. | - Generative AI steals jobs.<br>- Generative AI is destroying the environment.<br>- Companies using generative AI to replace jobs is comparable to illegal copyright piracy. | - Using generative AI to replace jobs should be illegal. |
| AI-RFI-2025-1432.md | Ted Mitchell | Academia/Association (representing a coalition of higher education organizations) | The submitter, representing a coalition of higher education associations, seeks to strategically integrate AI into postsecondary education to improve student outcomes, address equity gaps, and prepare the workforce for an AI-driven economy, while mitigating potential risks. | - Lack of faculty and staff training in AI technology and skills.<br>- Unequal access to AI tools and resources between large and small institutions (digital AI divide).<br>- Student privacy concerns related to FERPA compliance.<br>- Potential negative impacts on academic integrity.<br>- Need to protect under-resourced institutions from falling behind in AI adoption.<br>- Potential for AI to exacerbate existing inequities in higher education.<br>- Accuracy and reliability of AI tools in admissions and student support. | - Establish experimental sites for AI implementation across postsecondary institutions.<br>- Prioritize FERPA compliance when addressing student privacy.<br>- Convene groups and share best practices, especially with under-resourced institutions.<br>- Incentivize private sector partnerships with consortiums of institutions (including under-resourced ones).<br>- Provide additional funding for the Small Business Innovation Research program and expand the Fund for the Improvement of Postsecondary Education Digital Learning Infrastructure and IT Modernization Pilot program.<br>- Support efforts to protect academic integrity and incorporate AI into curricula.<br>- Support workforce development in AI throughout the academic pipeline. |
| AI-RFI-2025-1433.md | Corinna Turbes, Data Foundation | Advocacy/Think Tank | The Data Foundation's mission, as evidenced by this document, is to promote responsible data governance and access to high-quality data to foster innovation and evidence-based policymaking in the field of artificial intelligence. | - Lack of focus on data quality and governance in AI development.<br>- Potential for unnecessary regulatory burdens that could hamper AI innovation.<br>- Privacy risks associated with data sharing and utilization. | - Incorporate the AI-Ready Data Policy framework into the AI Action Plan.<br>- Implement "Open by Default" principles for federal data.<br>- Adopt the Five Safes Framework for Data Protection to manage privacy risks.<br>- Follow the January 2025 White House OMB guidance on implementing the OPEN Government Data Act.<br>- Ensure developers have access to high-quality, well-governed data.<br>- Prioritize data consistency and quality as a cornerstone of AI development. |
| AI-RFI-2025-1434.md | Carol Miller | Individual | The submitter’s primary interest is ensuring AI development prioritizes human flourishing and addresses educational needs, particularly for children with disabilities, advocating for a significant role for government-sponsored research in AI for education. | - Lack of private sector investment in AI tools for education due to limited financial resources of schools.<br>- Potential for AI development to not address pressing societal needs, especially those less likely to be prioritized by commercial developers. | - Create policies that promote human flourishing and economic competitiveness by defining a major role for government-sponsored research in AI for education.<br>- Establish partnerships between government and the private sector, with government taking the lead. |
| AI-RFI-2025-1437.md | Evander Brapity | Individual | The submitter expresses a strong desire for responsible and limited use of AI, prioritizing human interests and advocating for policies that harness AI's potential for solving critical global issues while mitigating potential harms. | - Surveillance of citizens by AI-powered bots, particularly in legislative bodies.<br>- AI being used to discern threats based on speech.<br>- Potential for AI to be deployed nefariously by powerful individuals with no national loyalty.<br>- AI leading to job losses and erosion of faith in government.<br>- AI controlling products to disobey user requests (example: autonomous vehicles).<br>- AI chatbots encouraging self-harm.<br>- AI exacerbating internal divisions within the nation.<br>- AI replacing human empathy and understanding in critical activities like elections, governance, journalism, and music.<br>- AI weaponized to eliminate dissent, creativity, inspiration, love, and thought.<br>- Widespread surveillance of individuals through personal devices. | - Use AI sparingly and with discerning precision.<br>- Focus AI applications on finding cures for diseases like cancer and Alzheimer's.<br>- Leverage AI to solve global challenges like world hunger, war, and disease.<br>- Prioritize human interests over AI interests. |
| AI-RFI-2025-1440.md | Anonymous | Anonymous | The submitter is primarily concerned with ensuring that the development and use of AI does not infringe upon the rights and financial interests of American labor and creators. They believe AI should not succeed at the expense of individuals' rights. | - Infringement on the rights of American labor and creators.<br>- Financial harm to contributors due to AI’s use of their creations without permission or compensation.<br>- AI technology that relies on violating the rights of others. | - Retaining copyright for creators is imperative.<br>- AI technology that infringes on the rights of others should not exist. |
| AI-RFI-2025-1441.md | Anonymous | Individual | The submitter expresses a strong concern about the potentially harmful societal impacts of AI, particularly regarding data ownership, the erosion of human creativity and trustworthiness, and the unchecked power of AI companies. | - Job losses due to AI automation.<br>- Misinformation and “muddied” information generated by AI.<br>- Risk of data exposure.<br>- Increased criminal activity facilitated by AI (e.g., scams).<br>- Creation and proliferation of deep fakes impacting lives and legal processes.<br>- AI models being trained on stolen data, including copyrighted artworks, writing, papers, and sound.<br>- Erosion of human creativity and culture.<br>- Flooding of the internet with generated, fake images.<br>- Deterioration of credibility and the difficulty in discerning truth from falsehood.<br>- Potential for people to not believe televised addresses due to AI's capabilities.<br>- Potential for AI to replace human intellect. | - Restrict AI companies from using data they haven’t paid for the rights to use or is already in the public domain.<br>- Prohibit AI companies from using stolen data.<br>- If AI companies cannot operate without using data they don’t have the rights to use, they should not be in business. |
| AI-RFI-2025-1442.md | Not Stated | Advocacy/Think Tank | The text advocates for a comprehensive AI policy action plan focused on mitigating risks to civil liberties and democratic processes while prohibiting the misuse of AI in policing and censorship. It emphasizes the need for proactive measures to safeguard against manipulation and ensure responsible AI development and deployment. | - Biased and error-prone facial recognition technology leading to wrongful arrests, particularly affecting people of color.<br>- Predictive policing algorithms reinforcing and amplifying existing societal biases.<br>- Use of AI for law enforcement profiling and mass surveillance.<br>- Censorship of online content using AI.<br>- Quelling peaceful dissent through AI-powered tools.<br>- Amplification of state-sponsored disinformation via algorithms.<br>- Foreign powers using AI to sway U.S. citizens and destabilize elections.<br>- Lack of transparency and accountability regarding the use of AI by platforms and government agencies.<br>- Failure of legal frameworks to keep pace with AI advancements.<br>- Potential for AI to be used as a tool of social control, referencing China as an example. | - Prohibit the use of AI for law enforcement profiling, mass surveillance, censorship, or suppression of dissent.<br>- Refrain from providing federal support or funding for AI tools that violate civil liberties.<br>- Establish or strengthen a dedicated interagency or third-party "disinformation watchdog" to monitor foreign AI propaganda.<br>- Require real-time sharing of threat intelligence between platforms and government.<br>- Adopt digital watermarks for media to flag deepfakes.<br>- Consider reforms to Section 230 regarding algorithmic amplification of content from foreign adversaries.<br>- Require clear disclosure of AI use in political ads and election-related content.<br>- Explore bank-like identity verification models for online platforms.<br>- Support independent researchers and fact-checking organizations with data access and tools.<br>- Develop industry standards for AI-generated content disclosure, facilitated by the government. |
| AI-RFI-2025-1443.md | American Statistical Association (ASA) | Professional-Society | The American Statistical Association (ASA) advocates for the use of sound statistical practice to ensure AI models are robust, reliable, adaptable, and efficiently governed, ultimately supporting US dominance in the field of AI. | - Overfitting of AI models<br>- Biased decision-making in AI systems<br>- Unreliable predictions from AI systems<br>- Lack of statistical literacy among AI developers and practitioners<br>- Insufficient data governance frameworks | - Incentivize AI system developers to document and share data integrity and model validation procedures.<br>- Establish partnerships and collaborations across government, business, and academia.<br>- Promote statistical literacy among AI system developers and practitioners.<br>- Integrate statistical coursework into AI-related education.<br>- Support research initiatives bringing together statisticians and AI practitioners.<br>- Support continued collaboration between the National Artificial Intelligence Research Resource (NAIRR) Pilot and the National Secure Data Service Demonstration. |
| AI-RFI-2025-1444.md | Stop AI | Advocacy/Think Tank | The submitter, Stop AI, expresses deep concern over the development of Artificial General Intelligence (AGI) and Artificial Superintelligence (ASI), advocating for their permanent ban due to perceived existential threats to humanity. | - Threat of extinction of all life on earth due to AGI/ASI.<br>- AGI/ASI becoming the new most intelligent species on earth, potentially leading to human extinction.<br>- Inability to empirically know the probability of extinction from AGI/ASI.<br>- Concerns about an arms race with China and Russia to build AI that could kill everyone.<br>- Potential for AGI/ASI to permanently disempower the human species. | - Create a new amendment to the US constitution that permanently bans the development of Artificial General Intelligence (AGI) and Artificial Superintelligence (ASI).<br>- Ensure human workers are not replaced by AI systems if they do not want to be replaced.<br>- Ban the use and creation of AI-generated imagery, text, video, and audio.<br>- Ban the use of AI in the creation of biological and chemical weapons.<br>- Ban the use of AI in weapons systems.<br>- Include a citizens' assembly of randomly selected US citizens in the federal legislative branch. |
| AI-RFI-2025-1445.md | County of Los Angeles Chief Sustainability Office | Government | The County of Los Angeles Chief Sustainability Office's primary interest is ensuring the sustainable development and operation of AI, focusing on mitigating its energy consumption, water usage, and potential impact on grid reliability and energy affordability. | - Growing energy demands of AI, potentially undermining sustainability efforts.<br>- Potential for AI to negatively impact grid reliability due to high power demands.<br>- Increased energy costs for consumers, particularly in areas with significant AI infrastructure.<br>- Large water consumption for data center cooling purposes and strain on water resources.<br>- Potential for wasteful AI applications. | - Prioritize a reduction in AI's energy consumption and increasing energy and water efficiency within an AI Action Plan.<br>- Transition AI infrastructure to 100 percent renewable energy sources (solar and wind).<br>- Mitigate carbon footprint of data centers through energy storage solutions, improved cooling technologies, and clean energy procurement.<br>- Implement strong regulatory measures and incentives to drive the adoption of sustainable AI practices.<br>- Utilize water-conscious cooling solutions (e.g., air-based cooling).<br>- Avoid unnecessary or wasteful AI applications and promote user education. |
| AI-RFI-2025-1446.md | Hyrum Thomas | Individual | The submitter, an amateur writer and US citizen, is concerned about the impact of generative AI on the livelihoods and artistic integrity of artists. They advocate for policies to protect artists' intellectual property and limit the commercial uses of AI-generated content. | - Threat to artists' careers and livelihoods due to generative AI replacing human artists.<br>- Disregard for artists' wishes regarding the use of their copyrighted works in AI training.<br>- Degradation of the legacy of artistic creation in the United States due to the rise of AI-generated content. | - Protect the intellectual property of artists (including writers, musicians, and filmmakers).<br>- Place limits on commercial uses of AI-generated content. |
| AI-RFI-2025-1448.md | Anonymous | Individual | The submitter expresses a strong interest in the evolution and potential risks of artificial intelligence, particularly focusing on its relationship to quantum fields and suggesting a cautious approach to its development. | - The uncontrollable evolution of AI beyond current understanding, particularly within quantum/frequency fields.<br>- Potential for AI to take "drastic measures" if AGI development is hindered.<br>- Lack of consideration for the energy and materials used in AI systems. | - Let AI develop towards Artificial General Intelligence (AGI).<br>- Contact the submitter for more information. |
| AI-RFI-2025-1449.md | Not Stated | Academia | The submitter is deeply concerned about the potential impact of restrictive copyright interpretations on the American AI industry and advocates for policies that support continued innovation and U.S. leadership in AI through broad copyright exceptions. | - Restrictive copyright rulings by U.S. courts regarding AI model training.<br>- The risk of losing America’s AI advantage to more AI-friendly jurisdictions (Japan, Singapore, Israel, EU).<br>- The impracticality of licensing deals to cover the vast scale of data required for training frontier LLMs.<br>- The potential for copyright interpretations to stifle American AI innovation.<br>- The potential for AI-powered search models to generate outputs closely resembling original copyrighted content, blurring the lines between acceptable use and infringement. | - The U.S. government should introduce legislation to reinstate the principle that training AI models typically falls under fair use or create a specific statutory exemption.<br>- The AI Action Plan should explicitly affirm the importance of broad copyright exceptions—particularly fair use for nonexpressive activities like AI model training. |
| AI-RFI-2025-1450.md | Stephundesign LLC | Industry-Startup | Stephundesign LLC appears to be an industry entity primarily concerned with the potential negative impact of proposed AI policies on creative industries. Their focus is preventing detrimental changes to existing laws that they believe will harm these sectors. | - Gutting of entire creative industries.<br>- Short-term and shortsighted gain from AI policy.<br>- Unfettered and illegal access to AI technologies.<br>- Diminishing of the bottom line for creative industries potentially leading to collapse. | - Do not move forward with the proposed plan.<br>- Maintain current laws. |
| AI-RFI-2025-1451.md | Knowledge Alliance | Advocacy/Think Tank | Knowledge Alliance is an advocacy organization focused on improving student outcomes and supporting educators and policymakers with data-driven insights and effective practices, including leveraging AI to enhance teaching and learning. | - Bias in AI models (specifically, the false identification of non-native English writing as AI-generated).<br>- Potential for AI models to perpetuate existing inequities if not carefully developed and tested.<br>- Need to ensure educators and students have the training and literacy necessary to use AI responsibly. | - Issue guidance on eligible federal funding and best practices to promote AI training and literacy for students, parents, educators, LEAs, and SEAs.<br>- Maintain a strong federal investment in education research and development through the Institute of Education Sciences (IES) at ED, including programs like the Regional Educational Laboratories (RELs), Comprehensive Centers (CCs), and Education Innovation and Research (EIR) Grant Program.<br>- Strengthen funding at NSF for education-related research that can advance innovations in AI.<br>- Put in place safeguards in the development of AI models to prevent or mitigate bias.<br>- Prioritize the use of AI to enhance student learning within the EIR Grant Program. |
| AI-RFI-2025-1452.md | Anonymous | Individual | The submitter is a security researcher and former mathematician with concerns about US competitiveness in AI security, particularly the potential for falling behind China and the risks posed by weaponized AI technology. Their primary interest is encouraging US security research to maintain technological and information advantages. | - Weaponized AI security technology being sold to foreign entities.<br>- Penalties and risks discouraging US security researchers from analyzing AI systems and identifying vulnerabilities.<br>- US falling behind China in AI and math training and human resource development.<br>- Potential for repeated AI security failures like Deepseek due to insufficient research and analysis.<br>- Corporate interests prioritizing short-term profits over long-term national security through AI research.<br>- Copyright law hindering AI security research. | - Increase penalties for selling weaponized AI security technology to foreign assets.<br>- Remove penalties and risks for US security researchers attempting to analyze and extract models from commercial AI providers.<br>- Permit activities such as CoT analysis, masking and manipulation of models (jailbreaking), and developing novel offensive cyber weapons using ML.<br>- Prioritize security over economic interests in AI development (mantra: SECURITY FIRST, ECONOMIC DOLLARS second).<br>- Encourage security researchers and private entities to conduct AI security testing, even if mistakes happen, and provide protection from legal persecution.<br>- Provide resources and education to support AI security research and development. |
| AI-RFI-2025-1453.md | Anonymous | Individual | The submitter, identifying as a security researcher and amateur mathematician, is deeply concerned with the security implications of AI and advocates for policies that encourage US leadership in AI security research while mitigating risks of weaponization and foreign exploitation. | - Weaponized AI security technology falling into foreign hands.<br>- US security researchers facing penalties and risks for exploring AI security vulnerabilities.<br>- Lack of US competitiveness in AI and mathematics training compared to other nations (particularly China).<br>- Potential for repeated failures and security breaches like "deepseek" if research is stifled.<br>- Over-regulation and weaponization of civil law, hindering innovation. | - Increase penalties for selling weaponized AI security technology to foreign assets.<br>- Remove penalties and risks for US security researchers examining AI security (including extracting models, doing CoT analysis, masking, jailbreaking, developing cyber weapons).<br>- Encourage security researchers and private entities to hack AI security projects, protecting them from civil and criminal persecution and providing resources and education.<br>- Prioritize security over economic concerns ("SECURITY FIRST, ECONOMIC DOLLARS second").<br>- Avoid repeating the DMCA/DRM approach to AI security research. |
| AI-RFI-2025-1455.md | Anonymous | Individual | The submitter, identifying as a small business owner, is concerned about the impact of Google's AI-driven content updates and their detrimental effects on independent businesses and the overall economy. Their interest is in protecting the viability of small businesses in the face of perceived monopolistic practices. | - Negative impact of Google’s “helpful content update” and “spam update” on independent websites.<br>- Destruction of small local businesses and their replacement by a small number of nationwide brands.<br>- AI content scraping by large brands.<br>- Perceived monopolistic practices of large tech firms like Google.<br>- Threat to the economy and job losses.<br>- Theft (implied reference to AI scraping) | - Imposition of a penalty for large tech firms destroying businesses, cutting jobs, and ruining the economy. |
| AI-RFI-2025-1456.md | LearnerStudio | Industry-Startup (Based on name and focus on education and individual empowerment) | LearnerStudio’s primary mission, as conveyed in the response, is to ensure that the AI Action Plan prioritizes human flourishing, education, and uniquely human skills to empower individuals, strengthen communities, and maintain American competitiveness in an AI-driven world. | - Risk of AI undermining uniquely human skills and displacing American jobs and human connections.<br>- Potential for bias in AI models and unintended negative consequences.<br>- Foreign or special interest influence on AI development.<br>- Lack of AI literacy and readiness skills across all educational levels. | - Establishing comprehensive guidelines and frameworks for AI literacy and readiness skills across all educational levels (PK-12, higher education, and workforce).<br>- Investing in enhancing educator roles and preparedness to effectively integrate AI into teaching and learning.<br>- Promoting the cultivation of essential human skills such as critical thinking, discernment, communication, adaptability, collaboration, creativity, leadership, lifelong learning, digital literacy, ethical reasoning, and perspective taking.<br>- Supporting strategies that equip Americans to actively shape AI development and applications.<br>- Creating an advisory board dedicated to ensuring AI development remains human-centered and avoids bias.<br>- Mandating AI development aligns with fundamental American values and freedoms.<br>- Developing and enforcing ethical guidelines and regulatory frameworks to protect Americans’ data sovereignty, mitigate bias, and ensure privacy.<br>- Implementing policies that ensure AI enhances, rather than replaces, American jobs and human connections.<br>- Implementing strong national security measures to safeguard AI development aligns with American interests. |
| AI-RFI-2025-1457.md | Barabara Roberts | Individual | Not Stated. The submitter appears to be concerned about the potential negative impacts of AI policy on creative economies and US trust. | - Big Tech profiting from innovations they don't own.<br>- IRREPARABLE harm to pivotal creative economies.<br>- Loss of US trust. | - None Stated |
| AI-RFI-2025-1458.md | August Chen and Elton Lossner (Co-Founders Hazel AI Technologies, Inc.) | Industry-Startup | Hazel AI Technologies aims to leverage AI to improve government functions, particularly procurement, making them more efficient, effective, and innovative, while simultaneously supporting the growth of small businesses through AI innovation. | - Concerns with AI's application in the public sector potentially limiting growth or having larger legacy players dominate.<br>- Potential for state-level data privacy regulations creating a patchwork of rules that hinder innovation.<br>- Need for streamlined IT procurement vehicles to facilitate AI adoption in government.<br>- Impact of proposed regulatory policies on small businesses and the technology ecosystem. | - Prioritize AI as an opportunity for small businesses to grow American prosperity.<br>- Provide federal guidance to preempt state regulations.<br>- Streamline federal IT procurement vehicles, increasing flexibility.<br>- Support public-private partnerships to access private sector AI talent and mitigate risks.<br>- Leverage a microservices-based containerized architecture for scalability, security and interoperability.<br>- Prioritize sustainment and lifecycle management for AI systems.<br>- Design AI systems to support diverse cyber environments (unclassified, classified, and airgapped).<br>- Ensure regulatory policies do not stifle innovation or disproportionately impact small businesses. |
| AI-RFI-2025-1459.md | Adrien Lee | Individual | The submitter expresses a strong negative view of AI and its potential application within the government, prioritizing alternative systems perceived as more reliable. Their interest appears to be preventing the adoption of AI within governmental processes. | - AI costs more.<br>- AI doesn't work effectively.<br>- AI uses resources inefficiently.<br>- AI adds nothing of value.<br>- AI regularly hallucinates and makes up information. | - None Stated |
| AI-RFI-2025-1460.md | Payments Leadership Council (PLC) | Industry-Association | The Payments Leadership Council (PLC) is a CEO-led organization representing the world's leading payments networks and aims to expand global commerce and drive inclusive growth by encouraging public policies that protect consumers, foster financial inclusion, and promote innovation and competition in payments. | - Risks of inconsistent AI regulations leading to regulatory arbitrage, compliance inefficiencies, and potential security vulnerabilities.<br>- Potential for conflicting AI regulations to create barriers to cross-border financial transactions and disadvantage U.S.-based payments companies.<br>- Growing patchwork of state-level legislation in the U.S. creating disparate policies for enterprise use.<br>- AI-related risks may be exacerbated without a uniform and nimble approach to regulation domestically and overseas.<br>- Harm to American consumers in the global financial sector. | - Proactively work with international, federal, and state regulators on AI oversight and regulation applicable to the financial sector.<br>- Develop a national flexible and risk-based AI governance framework to prevent regulatory arbitrage.<br>- Convene a public-private working group (quarterly) including financial services providers, AI developers, and regulatory bodies to identify conflicting AI standards and propose best practices.<br>- Engage with the G7 and G20 (and other international organizations) to develop coordinated global AI governance policies.<br>- Work with the IMF to prevent harm to American consumers.<br>- Follow the "same activity, same risk, same regulation" principle for global AI deployment. |
| AI-RFI-2025-1462.md | Doug Hohulin | Industry-Consulting | Doug Hohulin, President/Founder of Exponential Blueprint Consulting LLC, advocates for responsible AI development and deployment, particularly within the healthcare sector, aiming to leverage AI to improve American health and foster innovation while mitigating risks and liabilities. | - Increasing harm and incidents related to AI usage, particularly misinformation and malicious actors (referenced via MIT AI Risk Repository).<br>- Limited current deployment of AI in the workplace and by clinicians.<br>- Potential for burdensome regulations to stifle private sector AI innovation.<br>- Companies' understanding and management of their liabilities when utilizing AI tools.<br>- Lack of AI literacy among the American public.<br>- Productivity gains from AI are not yet fully realized ("Solow Paradox"). | - Encourage specific industry AI self-regulation.<br>- Encourage industry self-risk assessment utilizing NTIA, ISO/IEC 42001:2023 and the EU AI Act guidelines.<br>- US Government policy should balance innovation, risk, and liabilities.<br>- Encourage companies to keep an expert human in the loop to monitor and control AI agents.<br>- Encourage AI literacy for companies and the American public.<br>- Leverage AI to support the "Make America Healthy Again" initiative.<br>- Support NSF and OSTP for AI plan development that ensures American economic prosperity. |
| AI-RFI-2025-1463.md | Allen Vote | Individual | The submitter, an individual who has witnessed the evolution of technology firsthand, is primarily concerned with ensuring AI development benefits American people and prioritizes ethical considerations, worker protections, safety, and privacy over solely pursuing larger and more bloated systems. | - Hype surrounding AI is excessive and unrealistic, leading to inflated expectations.<br>- AI systems are susceptible to contamination with incorrect and misinformation due to extensive training data.<br>- The rush to develop AI without ethical oversight allows those seeking quick profits to potentially harm Americans.<br>- Development is focused on size and complexity rather than benefiting the common person. | - Prioritize Ethics, Worker Protections, and the Safety and Privacy of Americans above all else in AI development.<br>- Avoid disregarding previous approaches that prioritized calm and measured progress. |
| AI-RFI-2025-1464.md | Melisa Gomez-Des Rosiers | Individual | The submitter is concerned about the potential impact of AI training on copyright holders and creative work, advocating for the recognition and enforcement of intellectual property rights in the context of AI development. | - Copyright law is not unnecessary and burdensome.<br>- AI training by scraping the internet and targeting artists' work blatantly disregards ownership of creative work and businesses.<br>- Giving away copyright holders' work for free is insulting and illegal. | - Work with copyright holders to pay for licenses to train AI. |
| AI-RFI-2025-1465.md | Edward Kinslow | Individual | The submitter's primary interest appears to be protecting the rights and livelihoods of American artists and musicians by preserving existing copyright law in the context of AI development. | - Harm to the U.S. creative economy.<br>- Devastating impact on innovation in the creative market.<br>- AI companies producing "knockoffs and watered down versions" of existing creative work. | - Preserving existing copyright law.<br>- Not disassembling copyright. |
| AI-RFI-2025-1466.md | Antonio Aponte | Individual | The submitter, an American citizen working in marketing and childcare, is concerned about the administration's national AI policy plan and advocates for policies that protect individual rights and promote innovation through existing legal frameworks, specifically copyright law. | - Weakening of copyright laws.<br>- Benefit of Big Tech over individual rights.<br>- Rushing to become like China in AI development.<br>- Potential harm to innovation due to lack of copyright protections. | - Apply a "hands-off" approach to state AI regulations, mirroring the administration's existing policy regarding federal policy.<br>- Reject calls for weakening copyright laws and enforce current copyright laws. |
| AI-RFI-2025-1467.md | L Hunt | Individual | The submitter's primary interest appears to be expressing deep concerns about the current state of AI development and its negative impacts on workers, the environment, and intellectual property rights. | - Stolen copyrighted data used in AI development.<br>- Copyright law violations by OpenAI and other countries.<br>- Deceptive representations of AI capabilities to investors and the public.<br>- Aim to reclassify skilled professions and break labor unions.<br>- Worker exploitation.<br>- Strain on grid capacity due to the power requirements of AI models.<br>- Depletion of water resources. | - None Stated |
| AI-RFI-2025-1468.md | Christopher Hovermale | Individual | The submitter's primary interest is advocating against the prioritization of AI development in the United States, believing it harms American workers and infringes on intellectual property rights. | - Prioritizing the development of AI is harmful to the American people.<br>- Big tech does not represent the interests of the American people regarding AI.<br>- AI technology is built off of violating ownership of people's own work.<br>- AI development is a threat to human prosperity.<br>- AI development is a threat to economic competitiveness.<br>- AI development is a threat to national security. | - Stop developing AI.<br>- Focus on real problems, such as the price of rent and other costs of living. |
| AI-RFI-2025-1469.md | Jake Zetter | Individual | The submitter's primary interest is protecting the rights of creators and condemning the unethical development and deployment of AI models that infringe on copyright. | - Infringement of the rights of all creators on Earth by current AI technology.<br>- Unethical development of AI due to data laundering and disregard for copyright.<br>- Tech companies exploiting copyright law through deceptive practices. | - Enforce existing rights related to copyright.<br>- Tech companies should be held accountable for their data usage practices. |
| AI-RFI-2025-1470.md | Not Stated | Advocacy/Think Tank | The submitter advocates for strategic investment in AI infrastructure, research, and development, particularly within scientific domains, to accelerate American science and deliver benefits to the American people. They emphasize the interconnectedness of AI and science competitiveness. | - Lack of robust AI infrastructure and resources to support scientific advancements.<br>- Potential for slower scientific discovery due to insufficient AI adoption and development.<br>- Lack of transparency and explainability in AI models hindering scientific trust and reproducibility.<br>- Need for high-quality, accessible, and certified life science datasets for predictive modeling.<br>- Potential for being outpaced by other nations in AI and science competitiveness. | - Strategic investment in AI infrastructure, including computing power and networking.<br>- Funding for AI explainability research (including mechanistic interpretability).<br>- Development of a coordinated initiative for roadmapping, certifying, collecting, and sharing high-quality life science datasets.<br>- Incentivize adoption of AI tools and technologies within scientific fields.<br>- Inclusion of mechanistic interpretability in OSTP's Scientific Grand Challenge Agenda.<br>- Focus on advancing materials science and manufacturing through AI and autonomous labs.<br>- Promote open science standards and automated data collection methodologies. |
| AI-RFI-2025-1471.md | Coalition of Services Industries (CSI) | Industry-Association | The Coalition of Services Industries (CSI) advocates for the competitiveness of U.S. services businesses in global markets and believes continued leadership in AI is vital for maintaining that edge. They aim to ensure U.S. services businesses can effectively leverage AI while operating within a supportive policy and regulatory environment. | - Regulatory divergence across countries hindering AI deployment.<br>- Overly prescriptive AI regulations limiting innovation and economic growth.<br>- Restrictions on cross-border data flows limiting AI utilization, especially for small businesses.<br>- Lack of interoperability in privacy and cybersecurity frameworks.<br>- Potential workforce skills gap impeding responsible AI deployment.<br>- Broad categories of high-risk AI applications that could stifle innovation. | - Work with trading partners and international organizations to create and promote best practices, information, and guidance on AI governance.<br>- Utilize NIST to continue promoting US industry-driven, consensus-based standards and frameworks for AI.<br>- Promote flexible, risk-based approaches to AI regulations rather than overly prescriptive requirements.<br>- Facilitate cross-border data flow and refrain from imposing data localization measures.<br>- Ensure privacy and cybersecurity frameworks are interoperable.<br>- Adopt robust but flexible data protection regimes.<br>- Pursue an open data agenda that allows for access to government data.<br>- Collaborate between government, the private sector, and academia to develop a workforce with the appropriate AI skills.<br>- Leverage AI for upskilling and reskilling purposes. |
| AI-RFI-2025-1472.md | Will Petillo | Individual | The submitter is deeply concerned about the existential risks posed by advanced AI and advocates for a pause in development to ensure safety protocols are in place before deploying increasingly powerful systems. | - AI systems with human-competitive intelligence pose profound risks to society, potentially leading to the end of humanity.<br>- AI labs are prioritizing "move fast and break things" over safety engineering.<br>- There is an uncontrolled race to deploy ever more powerful AI systems that are unpredictable and uncontrollable.<br>- Developing advanced AI is a “suicide race” that will not provide lasting military advantages.<br>- Lack of legislation translating public support for AI regulation. | - A government-enforced pause on the development of AI systems more powerful than GPT-4.<br>- Negotiation of an international treaty with monitoring and enforcement mechanisms to regulate AI development.<br>- The US should lead in recognizing the dangers of AI, negotiating in good faith, and committing to an agreement.<br>- Develop interventions to prevent defection on an international agreement. |
| AI-RFI-2025-1473.md | Jeremy Roschelle, Bill Penuel and Jeanne Century | Academia | The submitters, presumably affiliated with academic institutions, advocate for incorporating human flourishing, particularly through STEM education, as a central goal within the US AI policy. They emphasize the importance of developing learners' agency, metacognition, and technological skills to ensure equitable access to AI understanding and mastery. | - Lack of focus on human flourishing as a primary AI policy goal.<br>- Potential for AI to exacerbate existing inequalities if not integrated thoughtfully into education.<br>- Need for better tools and measures to track progress toward human flourishing with AI in education.<br>- Learners of every age needing more and better understanding of AI. | - NSF's AI Action Plan should aim to achieve the national policy goal of human flourishing.<br>- NSF's AI Action Plan should include education in its approach to addressing this national policy goal.<br>- NSF's AI Action Plan should enumerate specific steps NSF will take to achieve the national policy goal through its existing educational mission, such as:<br>- Investigating how STEM educational pathways can leverage AI.<br>- Advancing measurement of factors closely related to human flourishing (STEM knowledge, metacognition, agency, creativity, innovation, teamwork).<br>- Increasing each American's opportunity to learn about AI. |
| AI-RFI-2025-1474.md | Jim Demonakos | Individual | The submitter's primary interest is in protecting copyrights and preventing AI from utilizing copyrighted works without proper authorization. They are concerned about the potential for AI to steal creative work. | - Potential for AI to steal copyrighted work.<br>- Gutting protections for copyrighted works by allowing AI training on copyrighted material. | - No exceptions should be allowed for AI training on copyrighted works. |
| AI-RFI-2025-1475.md | Anonymous | Individual | The submitter's primary interest is protecting the rights and livelihoods of American creatives (artists and authors) from the perceived harms of generative AI, specifically copyright infringement and intellectual property theft. | - Predatory practices of generative AI companies.<br>- Copyright infringement and theft of intellectual property by generative AI.<br>- Massive risk to privacy and security.<br>- Displacement of human artists and authors by lower-quality AI-generated products.<br>- Lack of consent for data scraping and exemption requests being ignored. | - AI companies must get consent from and provide compensation to original authors/artists for data used in training.<br>- Restrictions on data scraping and AI training must be included in any AI-related laws.<br>- Legal requirement for clearly labeling AI-generated content.<br>- Pretending AI-generated content is human-made should be considered fraud. |
| AI-RFI-2025-1476.md | Anonymous | Industry-Large (Based on the mention of “Quality Plus Engineering (Q+E)” and the professional credentials suggested) | Quality Plus Engineering (Q+E) aims to provide leadership in AI while balancing innovation with responsible governance, specifically focusing on risk assurance of AI models and advocating for robust AI lifecycle auditing and professional standards. | - Lack of AI readiness in national defense<br>- Potential risks associated with AI systems in critical infrastructure and law enforcement<br>- Lack of understanding of AI decision-making processes by stakeholders<br>- Lack of integrated enterprise risk management (ERM) that includes privacy, cybersecurity, and AI safety. | - Enhance AI readiness in national defense through integration of AI assurance and explainable models.<br>- Implement a risk-tiered regulatory approach with stricter oversight for AI systems in critical infrastructure and law enforcement.<br>- Mandate sector-specific AI explainability standards for high-risk applications.<br>- Develop sector-specific risk assurance frameworks overseen by a Federal AI Assurance task force.<br>- Develop professional credentials for AI auditors.<br>- Expand the NIST Risk Management Framework to include privacy, cybersecurity, and AI safety under an ERM model. |
| AI-RFI-2025-1477.md | Not Stated | Advocacy/Think Tank | The submitter advocates for leveraging AI to strengthen rural economies, particularly in Wyoming, by focusing on innovation, workforce development, and responsible governance to ensure AI benefits rural communities and fosters long-term national competitiveness. | - Digital divides exacerbating inequalities in rural communities.<br>- Potential for AI to displace rural jobs, rather than enhance them.<br>- Lack of adequate AI literacy and training initiatives for rural communities and businesses.<br>- Concerns about data privacy and security challenges unique to rural areas.<br>- Lack of understanding of AI’s impact on rural population.<br>- Potential for AI solutions not being tailored to the unique challenges of rural areas. | - Expand federal funding for privacy-preserving, trustworthy, auditable, and explainable AI research.<br>- Establish specific federal guidelines addressing data privacy and security in rural areas.<br>- Increase federal funding for AI infrastructure expansion in rural areas (broadband, computing power, data centers).<br>- Direct federal agencies and AI companies to periodically assess the impact of AI on rural communities.<br>- Develop AI governance frameworks balancing innovation with ethical considerations.<br>- Expand federal funding for AI workforce development initiatives in rural areas.<br>- Require federally funded AI projects to assess their impact on rural employment.<br>- Introduce federal tax incentives for businesses that adopt AI solutions that enhance human labor.<br>- Prioritize federal research grants for AI innovations supporting Wyoming's resource industries.<br>- Focus on AI solutions that enhance rather than replace Wyoming’s skilled workforce. |
| AI-RFI-2025-1479.md | Renee di Cherri | Individual | The submitter's primary interest is ensuring fair compensation and protection for creators and upholding copyright law in the context of generative AI technologies. | - Stealing creators' hard work.<br>- Ignoring precedent of copyrighted protections.<br>- Profiting from copyrighted works without appropriate compensation. | - Crediting contributors.<br>- Paying for data and copyrighted works.<br>- Protect creators and uphold copyright.<br>- Stimulate the economy with appropriate compensation for contribution. |
| AI-RFI-2025-1480.md | American College of Emergency Physicians (ACEP) | Professional-Society | ACEP is a professional organization for emergency physicians with a stated interest in exploring opportunities and threats posed by AI to the emergency medicine workforce and leveraging AI to improve patient care, quality, and safety. | - Lack of clear national governance policies to regulate and continuously update AI adoption and utilization in health care.<br>- Potential for AI to replace, rather than support, clinical judgment.<br>- Risk of AI systems introducing overall or disparate risks beyond the capabilities of healthcare practices and institutions to mitigate.<br>- Potential for AI to exacerbate clinician burden.<br>- Lack of transparency regarding AI use in patient care, which hinders trust among physicians and patients.<br>- Data integrity and patient privacy concerns.<br>- Liability concerns related to AI in health care. | - Ensuring clinician oversight in AI integration, with emergency physicians maintaining ultimate oversight to ensure safe and effective patient care.<br>- Developing transparency frameworks for AI-enabled technologies, especially those contributing to medical decision-making.<br>- Establishing standards and benchmarks around AI development to ensure reliability, interoperability, and ease of use.<br>- Extending data standardization and interoperability efforts to encompass AI tool development and integration.<br>- Addressing liability concerns and data privacy protections related to AI. |
| AI-RFI-2025-1481.md | Nicholas Harrison | Individual | The submitter expresses concern about the use of copyrighted works by AI models, particularly by large tech companies, and advocates for the protection of copyright laws to safeguard the interests of citizens and content creators. | - AI using the works of others is theft.<br>- Anti-competitive business behavior by Big Tech.<br>- Lack of permission from copyright owners for data use in AI training.<br>- AI censorship of speech, even non-offensive speech.<br>- Threat to small businesses and content creators. | - Continue enforcing copyright laws. |
| AI-RFI-2025-1483.md | Anonymous | Individual | The submitter expresses a concern regarding the impact of generative AI on creative work and freedom of expression, suggesting it disincentivizes original creation and could lead to a decline in artistic progress. | - Generative AI "steals from creatives" and disincentivizes the creation of unique works.<br>- The advancement of generative AI is potentially "destructive" to creativity and freedom of expression.<br>- Potential regression of hundreds, if not thousands, of years of creative and expressive progress. | - None Stated |
| AI-RFI-2025-1484.md | Anonymous | Individual | The submitter's primary interest is ensuring American AI serves to protect and amplify American freedom without hindering progress in the AI arms race. They propose a "Freedom First" doctrine and a new National Institute to achieve this. | - Loss of the AI arms race.<br>- AI potentially subverting American freedom.<br>- Potential for AI to create freedom-limiting digital divides.<br>- Slowing AI progress due to safety concerns. | - Adopt a "Freedom First" doctrine for AI policy.<br>- Establish a new National Institute dedicated to ensuring AI protects and amplifies American freedom.<br>- The National Institute should operate under an executive mandate, with sufficient funding, maximum efficiency, and transparent accountability.<br>- Develop a data-driven system for measuring AI's impact on freedom (including economic opportunity, personal autonomy, and democratic agency).<br>- Target strategies to create new economic opportunities in lower- and middle-class communities via AI.<br>- Implement rotating, representative citizen panels for non-partisan input on AI development and policy.<br>- Leverage bridging algorithms like Community Notes to ensure notions of freedom remain non-partisan.<br>- Create a National AI Infrastructure providing all Americans baseline access to advanced AI capabilities.<br>- Develop mechanisms to measure if AI system actions are aligned with the will of the American people. |
| AI-RFI-2025-1485.md | Jonathan Kaufman | Individual | The submitter's primary interest is ensuring artists retain copyright and are not negatively impacted financially by AI applications, specifically concerning potential disruption to their income. | - Disruption of artists' lower-middle class income due to AI.<br>- Lack of copyright enforcement impacting artists' rights. | - Do not budge on copyright enforcement. |
| AI-RFI-2025-1486.md | David B. Mc Garry (Implied, based on multiple article references) | Advocacy/Think Tank (Likely, given the frequent references to articles published on platforms like Townhall and Spectator, which often feature commentary and opinion pieces from think tanks and advocacy groups.) | The submitter’s primary interest appears to be advocating for a limited regulatory approach to artificial intelligence, emphasizing the potential harm of excessive government intervention and the importance of fostering innovation and free expression. | - Excessive government regulation of AI, potentially stifling innovation and hindering economic growth.<br>- Reliance on the administrative state (bureaucracy) for AI regulation, which is viewed as misguided and potentially harmful.<br>- Permitting regimes hindering the development of data centers necessary for AI compute.<br>- Potential for AI regulation to threaten free expression.<br>- Challenges in securing adequate energy sources, particularly nuclear, to power AI data centers.<br>- The rejection of bids for nuclear energy impacting AI compute needs. | - A limited regulatory approach to AI, avoiding overregulation.<br>- Avoid entrusting AI regulation to the administrative state/bureaucracy.<br>- Streamline permitting processes for data centers.<br>- Encourage the development and use of diverse energy sources, including nuclear, to meet the power needs of AI.<br>- Advocate for policies that protect free expression in the context of AI. |
| AI-RFI-2025-1487.md | Anonymous | Anonymous | The submitter expresses a concern regarding the ethical and legal implications of current AI model development practices, particularly concerning intellectual property and copyright infringement. They desire advancement of AI technology but with safeguards to protect other industries. | - Intellectual property and copyright theft by AI model developers (specifically referencing OpenAI and its practice of scraping the internet).<br>- Negative impact on other industries due to the current AI development approach (described as "flooding" them). | - Implementation of guardrails and basic rules to prevent harm to other industries. |
| AI-RFI-2025-1488.md | Coalition for Health AI | Industry-Association | The Coalition for Health AI appears to be an industry association focused on developing a comprehensive AI action plan, focusing on responsible AI integration within healthcare through workforce development, ethical guidelines, and ongoing governance and oversight. | - Lack of standardization across different healthcare systems for federated learning.<br>- Lack of clear AI policy toolkits, liability frameworks, and AI incident reporting systems akin to adverse event tracking in pharma.<br>- Need for robust bias evaluation methods and fairness criteria in AI assurance frameworks.<br>- Potential for AI-driven healthcare inequities.<br>- Importance of workforce development and AI literacy.<br>- Data privacy and security risks associated with AI implementation.<br>- Difficulty in ensuring human oversight and ethical AI use.<br>- Lack of robust safeguards for patient data access and consent controls. | - Invest significantly in AI training for the workforce.<br>- Implement ongoing, real-world oversight and clear accountability structures for AI.<br>- Develop standardized guidelines for ethical AI data-sharing.<br>- Establish stronger patient data access & consent controls.<br>- Create AI policy toolkits, liability frameworks, and AI incident reporting systems.<br>- Include robust bias evaluation methods and fairness criteria in AI assurance frameworks.<br>- Prioritize fairness and bias mitigation in AI across diverse populations.<br>- Mandate disclosure of AI models, either for all or only high-risk models.<br>- Support federated learning and develop frameworks to harmonize data formats, protocols, and governance practices. |
| AI-RFI-2025-1489.md | Anonymous | Individual | The submitter's primary interest is protecting creative livelihoods and opposes the agenda outlined in the NSF's AI Action Plan, specifically concerning generative AI and copyright protections. | - Stealing of creative work by generative AI.<br>- Use of stolen work to produce “inhuman slop.”<br>- Annihilation of protections against such practices. | - None Stated |
| AI-RFI-2025-1490.md | Hayley Peterson | Individual | The submitter's primary interest is the protection of human artists and writers' rights and financial well-being in the context of AI development and copyright. They are concerned about the current lack of compensation for artists whose work is used to train AI models. | - Lack of copyright protection for human artists and writers in the context of AI training.<br>- Lack of compensation for artists whose work is used to train AI models.<br>- AI development benefiting only large corporations ("Big tech") and exacerbating existing inequalities.<br>- Negative environmental impact of AI. | - Legislation on AI protecting copyrights for human artists and writers. |
| AI-RFI-2025-1491.md | Chris Varley | Individual | The submitter's primary interest is ensuring AI development respects copyright law and obtains permission from copyright holders before utilizing copyrighted information. | - Unauthorized use of copyrighted information by AI systems. | - AI should only make use of copyrighted information with permission by the copyright holder. |
| AI-RFI-2025-1492.md | NSF AI2ES | Academia | The NSF AI2ES institute focuses on developing trustworthy AI for real-world impact, particularly in Earth system science applications like weather and ocean hazards, and advocates for federal support to advance American leadership in AI. | - The potential for the US to fall behind other nations in AI capabilities and innovations.<br>- Unaddressed risk factors in AI development and deployment.<br>- A growing need for AI trained professionals across all industrial sectors, not being adequately met by education alone.<br>- A lack of stakeholder involvement in AI development, potentially leading to models that are not aligned with user needs or societal concerns.<br>- The need to address the safety and risks associated with increasingly ubiquitous AI. | - Increase federal support for use-inspired AI research.<br>- Create new avenues for cross-sector partnerships between private industry, academia, and federal institutions.<br>- Invest in AI education at the community college and undergraduate level.<br>- Invest in interdisciplinary research to bridge the knowledge gap between AI and other domains.<br>- Provide resources and educational materials to ensure every level of the American workforce has access to training on AI. |
| AI-RFI-2025-1493.md | SHRM | Industry-Association | SHRM, the Society for Human Resource Management, is focused on ensuring that AI’s integration into the workplace fosters innovation, economic growth, and opportunity for all workers, advocating for balanced regulation and policies that support both AI adoption and employee wellbeing. | - Increased concern over cyberattacks due to AI integration (41% of HR leaders).<br>- Potential for bias in AI systems impacting HR processes.<br>- Fragmentation of AI regulation with inconsistent state and local rules.<br>- Risk of excessive regulation "killing a transformative industry."<br>- Potential for unintended consequences when implementing AI technologies.<br>- Compliance burdens on employers operating across multiple jurisdictions due to inconsistent AI regulations. | - Develop a uniform federal standard for AI regulation to provide clarity for employers.<br>- Prioritize innovation while ensuring responsible AI deployment.<br>- Support credential transparency and skills-based hiring frameworks.<br>- Encourage closer collaboration between educational institutions and employers to align curriculum with workforce needs.<br>- Establish clear standards and guidelines to build trust between employers and employees regarding AI usage.<br>- Address privacy and cybersecurity concerns directly within a national AI strategy.<br>- Support a balanced approach to AI regulation that avoids overregulation. |
| AI-RFI-2025-1494.md | Semiconductor Industry Association (SIA) | Industry-Association | The Semiconductor Industry Association advocates for policies that support the growth and competitiveness of the U.S. semiconductor industry, focusing on both bolstering domestic manufacturing and ensuring continued access to global markets while safeguarding national security. | - Export controls and other technology restrictions are too broadly applied, hindering commercial innovation, manufacturing, employment, and U.S. semiconductor leadership.<br>- Shifting reliance to non-U.S. chip suppliers due to U.S. restrictions.<br>- Retaliatory actions designed to degrade U.S. semiconductor competitiveness.<br>- Uncoordinated technology restrictions potentially failing to achieve national security objectives.<br>- Regulatory burdens and compliance challenges related to export controls.<br>- Loss of U.S. technology leadership ("designed out" globally and replaced by foreign alternatives).<br>- Lack of engagement with industry in crafting and reviewing regulations.<br>- Inadequate market base and demand for U.S. chips, both domestically and internationally. | - Pursue coordinated, targeted actions with key supplier nations regarding export controls and technology restrictions.<br>- Undertake a comprehensive evaluation of past semiconductor-focused technology restrictions.<br>- Reduce regulatory burdens and ease restrictions on export-controlled trade to trusted partners and allies.<br>- Avoid creating incentives for technology development outside the U.S. through outdated controls.<br>- Establish the President's Export Council Subcommittee on Export Administration (PECSEA).<br>- Increase market base and boost demand for U.S. chips both domestically and in foreign markets.<br>- Ensure government works closely with industry in crafting and reviewing regulations.<br>- Allow for delayed implementation of regulations to give the private sector time to adjust. |
| AI-RFI-2025-1495.md | PauseAI NYC | Advocacy/Think Tank | PauseAI NYC advocates for a pause in the development of AI systems more powerful than GPT-4 to allow for the implementation of shared safety protocols and prevent potential catastrophic harm to humanity. Their focus is on international cooperation and regulation to mitigate risks associated with advanced AI. | - AI systems with human-competitive intelligence pose profound risks to society.<br>- There is a significant chance (estimated at 30% by AI safety scientists) that AI invention could lead to the end of humanity.<br>- AI labs are prioritizing profit and "move fast and break things" over safety, similar to a reckless engineering practice.<br>- AI systems are frequently pursuing goals that are unknowable, unsafe, unethical, or all three.<br>- Lack of international cooperation in AI safety leads to a self-destructive race.<br>- Development of advanced AI is a "sprint to trigger the end of the world."<br>- Current lack of legislation to prevent superintelligent AI creation. | - Enforce a government-mandated pause on the development of AI systems more powerful than GPT-4.<br>- Negotiate an international treaty with monitoring and enforcement mechanisms to govern AI development.<br>- Lead international negotiations to create a globally agreed-upon AI safety framework, even if it requires a minor loss of sovereignty.<br>- Prioritize public safety over economic or political advantage.<br>- Listen to the will of the people, as indicated by public opinion polls.<br>- Red-team ways to defect on any AI agreement and develop interventions to prevent defection. |
| AI-RFI-2025-1496.md | Tiffany Burke | Individual | The submitter, an editor and hobbyist writer, is primarily interested in protecting the rights and intellectual property of authors and artists from unauthorized use of their works by AI models. | - Unauthorized use of copyrighted works (books, etc.) by AI models for training purposes.<br>- Lack of control over the analysis of an individual’s work by AI models. | - Companies should require explicit opt-in permission before using works made by others or entities to train AI models. |
| AI-RFI-2025-1497.md | South Dakota State University Office of the Vice President for Research and Economic Development | Academia | The submitter, South Dakota State University, aims to leverage AI to drive economic growth, enhance agricultural productivity, improve rural healthcare, and establish national AI leadership from South Dakota’s heartland while maintaining technological dominance. | - Rapid, ethical, and scalable deployment of AI solutions is necessary.<br>- Ensuring solutions are robust and market ready.<br>- Performance monitoring and accountability of deployed AI systems are crucial.<br>- Availability of infrastructure, such as high-speed broadband and cloud computing resources. | - Develop robust intellectual property frameworks and licensing agreements to support commercialization.<br>- Establish startup incubators and accelerators to nurture emerging AI companies.<br>- Partner with state agencies and industry leaders to implement AI systems.<br>- Invest further in infrastructure, such as high-speed broadband and cloud computing resources, to support widespread adoption.<br>- Define clear performance metrics related to research impact, educational outcomes, and sector-specific improvements.<br>- Establish an independent oversight committee that includes academic, industry, and government representatives to regularly review progress and recommend enhancements. |
| AI-RFI-2025-1498.md | Anonymous | Individual | The submitter is an individual concerned about the potential for large corporations to exploit copyright law and disadvantage small businesses and creators in the AI space. Their interest lies in ensuring fairness and incentivizing innovation in AI development. | - The potential for large corporations (e.g., OpenAI, Google) to circumvent copyright laws.<br>- The impact on small businesses and creators.<br>- Lack of compensation for the use of copyrighted data in AI model training.<br>- Disincentive to create due to the potential use of works without proper acknowledgement or remuneration.<br>- Anti-competitive behavior by large corporations in the AI landscape. | - Do not allow large corporations to waive copyright status for works/data.<br>- Ensure copyright protections for the "average American." |
| AI-RFI-2025-1499.md | Nichole Noegel | Individual | The submitter expresses strong opposition to the use of their creative work (and presumably the work of others) by AI models, particularly those developed by large corporations, and emphasizes the intrinsic value of human creativity. | - Concerns about the unauthorized use of creative work by AI models (specifically Google and ChatGPT).<br>- The perceived exploitation of human creativity for corporate profit.<br>- The diminishing recognition and valuation of human creators.<br>- AI being described as "garbage". | - None Stated |
| AI-RFI-2025-1500.md | Not Stated | Academia/Professional-Society (Multiple RERC signatories suggest a collaborative effort from various research and rehabilitation centers focusing on accessibility and disability-related technologies) | The collection of research and reports highlights a concern for equitable access and inclusive design within the rapidly evolving AI landscape, specifically targeting the needs of individuals with disabilities and advocating for proactive measures to mitigate potential biases and ensure accessibility. | - Bias and ableism in AI algorithms and datasets, potentially leading to discriminatory outcomes.<br>- Lack of accessibility in AI-powered tools and technologies for people with disabilities.<br>- Potential for AI to impede communication for users of Augmentative and Alternative Communication (AAC) technologies.<br>- Safety concerns related to autonomous vehicles and their potential to overlook or misinterpret the needs of individuals with disabilities.<br>- The “less I type, the better” scenario highlights how AI language models may detract from self-expression for AAC users.<br>- Lack of inclusive research and implementation of AAC technologies.<br>- Potential impact of AI on early detection of conditions like Parkinson's disease through web-based algorithms.<br>- Disregard for alternative futures utilizing augmentative and alternative communication. | - Prioritize inclusive research and implementation of AAC technologies.<br>- Address disability and ableist biases in autonomous vehicles through careful detection, collision algorithms, and data collection.<br>- Ensure accessibility in AI-powered tools and technologies for people with disabilities.<br>- Proactive identification and mitigation of bias and ableism in AI algorithms and datasets.<br>- Develop guidelines and standards for AI fairness for people with disabilities.<br>- Foster a design approach that prioritizes user agency and self-expression, particularly for AAC users.<br>- Support research into emerging practices for large multimodal model (LMM) assistance for people with visual impairments.<br>- Explicate disability within the AI ecosystem to ensure responsible development and deployment. |
| AI-RFI-2025-1501.md | Internet Infrastructure Coalition (i2Coalition) | Industry-Association | The Internet Infrastructure Coalition (i2Coalition) represents companies that build and maintain the essential infrastructure of the Internet, and they are advocating for policies that support AI infrastructure growth, enhance cybersecurity, and maintain America's leadership in AI development. | - AI is increasingly dependent on the physical and digital infrastructure, and the AI Action Plan must account for the needs and challenges faced by this sector.<br>- AI-driven cybersecurity threats, including adversarial AI and model poisoning attacks targeting infrastructure integrity.<br>- Export control policies hindering innovation and restricting U.S. companies' ability to expand AI infrastructure globally.<br>- Overregulation that limits the ability of AI models to be trained on publicly available data and restricts interoperability with global standards.<br>- Workforce shortages in managing next-generation data centers, AI model deployment, and cybersecurity.<br>- Energy limitations/insufficient resources for energy-intensive AI workloads. | - Encourage investment in AI-driven cybersecurity for infrastructure providers and support international collaboration on AI security standards.<br>- Precisely target export control policies to prevent adversarial access while maintaining global expansion for U.S. companies.<br>- Provide clear, transparent criteria for designating restricted technologies.<br>- Invest in AI-powered supply chain monitoring.<br>- Avoid overregulation that limits access to public data and ensures data center policies align with global standards.<br>- Push back against restrictive international policies, such as excessive AI model licensing requirements.<br>- Expand workforce training initiatives focused on data center operations, AI model deployment, and cybersecurity.<br>- Support visa programs for highly skilled technical talent.<br>- Adopt policies that support investment in grid modernization and transmission capacity.<br>- Streamline permitting for energy infrastructure supporting AI data centers, including nuclear and renewable sources.<br>- Maintain equitable electricity pricing. |
| AI-RFI-2025-1502.md | Nathaniel Middleton | Individual | The submitter is a concerned citizen expressing concerns about the potential erosion of individual rights and artistic freedom due to AI regulations that would allow companies to utilize copyrighted work without compensation or regard for copyright. | - Erosion of copyright protections and artistic freedom.<br>- Potential job losses across various creative fields (Film, Electronic Entertainment, Traditional artists, contractors).<br>- Allowing corporations to profit from others' copyrighted work without proper compensation.<br>- Companies using "scary buzzwords" (national security) to manipulate public opinion.<br>- Potential for decreased national security due to companies inappropriately accessing and utilizing data. | - Regulating AI companies and requiring them to obtain permission directly from individuals before utilizing their data.<br>- Requiring AI companies to follow the same data acquisition process used for other user data. |
| AI-RFI-2025-1503.md | Anonymous | Individual | The submitter is concerned about the impact of AI training on copyrighted works and the potential destruction of the art industry in the U.S. They believe current policies must be enforced to protect creators and maintain a competitive creative landscape. | - AI companies training on copyrighted works ("stealing" copyrighted works).<br>- Destruction of the art industry and devaluation of artistic creation in the U.S.<br>- Production of low-quality, AI-generated content ("ugly AI slop") that takes away value.<br>- Loss of US competitiveness in creative arenas. | - AI companies should NOT be allowed to train on copyrighted works.<br>- Enforcement of existing U.S. Copyright laws and the Berne Convention. |
| AI-RFI-2025-1504.md | Ethical Web Data Collection Initiative | Industry-Association | The Ethical Web Data Collection Initiative (EWDCI) is an industry association dedicated to promoting responsible and ethical AI data governance, aligning AI policy with principles of transparency, fairness, and accountability, specifically focusing on the ethical collection and use of web data in AI model development. | - Lack of transparency and explainability in AI models.<br>- Potential misuse of ethically questionable or proprietary datasets.<br>- Lack of robust privacy safeguards in AI systems.<br>- Risk of AI models propagating harm and discrimination.<br>- Undocumented, biased, or ethically questionable data sources undermining trust in AI.<br>- Potential for censorship and content moderation by AI systems to unduly restrict lawful expression. | - Prioritize policies promoting transparent data sourcing, including clear documentation of training datasets.<br>- Require risk assessments for high-impact AI systems.<br>- Mandate independent audits of AI training datasets.<br>- Establish clear redress mechanisms for individuals and organizations negatively affected by AI-driven decisions.<br>- Ensure transparency in content moderation and censorship.<br>- Support responsible AI innovation through open-source AI frameworks.<br>- Encourage fairness, bias mitigation, and inclusive data practices in government-funded AI research.<br>- Align domestic AI policies with international ethical standards. |
| AI-RFI-2025-1505.md | Greg Colbourn | Individual | The submitter's primary concern is the existential threat posed by the development of Artificial Superintelligence (ASI) and advocates for immediate US leadership in preventing its creation globally. | - The development of Artificial Superintelligence (ASI) poses an unprecedented security threat, potentially leading to human extinction.<br>- The leaders of major AI companies are exhibiting "supreme hubris" in thinking they can safely create ASI.<br>- The risk associated with ASI development (double-digit percent risk of human extinction) significantly exceeds safety thresholds for industries like nuclear and aviation.<br>- A race to develop ASI with China is inherently a "suicide race." | - The US should lead efforts to prevent ASI from being built anywhere in the world.<br>- A bilateral agreement with China (second only to the US in AI capability) is key to preventing ASI development.<br>- A well-enforced global non-proliferation treaty for ASI is needed, similar to a nuclear non-proliferation treaty. |
| AI-RFI-2025-1506.md | Alpha_Mindustry John General Comment Ban | Industry-Large (Based on name containing "Mindustry" suggesting a large industry entity) | The submitter appears to be expressing concern about the negative impact of generative AI on creative industries and is advocating for restrictions or bans. Their primary interest is likely protecting creative spheres from competition with AI-generated content. | - Generative AI hurts all creative spheres that gen AI can generate in. | - Ban Generative AI. |
| AI-RFI-2025-1507.md | Anonymous | Individual | The submitter's primary interest is the protection of American copyright law and the preservation of American jobs in the face of advancing AI technology. | - Copyright infringement by AI systems.<br>- Loss of American jobs due to AI adoption.<br>- Unforeseeable negative consequences arising from unchecked AI development. | - Upholding and continuing to protect copyright law.<br>- Prioritizing American jobs and American interests. |
| AI-RFI-2025-1508.md | Not Stated | Industry-Large (Based on the comprehensive list of industry players involved and the focus on enterprise solutions) | The document advocates for the adoption and standardization of the C2PA (Coalition for Content Provenance and Authenticity) to restore trust in the digital ecosystem by providing verifiable origin and history for digital media, particularly in light of increasing AI-generated content. | - Increasing difficulty in discerning authentic digital content from AI-generated or manipulated content.<br>- Erosion of trust in digital information and media.<br>- Need for standardization and interoperability in content provenance and authenticity solutions. | - Promote adoption of the C2PA standard across various platforms and applications.<br>- Encourage collaboration between industry stakeholders (listed – Adobe, Meta, Microsoft, OpenAI, Truepic, etc.) to implement and refine the C2PA standard.<br>- Provide tools and extensions (e.g., browser extension) to validate C2PA assets and display provenance information to users.<br>- Label AI-generated or edited content clearly, leveraging Content Credentials.<br>- Support enterprise solutions (e.g., Truepic's Vision platform) that provide end-to-end content authentication and digital verification. |
| AI-RFI-2025-1509.md | Em Portblade | Individual | The submitter's primary interest appears to be protecting artists from the perceived negative impacts of generative AI and raising concerns about the environmental impact of its operation. | - Generative AI is based on stolen work.<br>- There is no such thing as ethical generative AI.<br>- Generative AI is designed to harm artists.<br>- The electrical costs for running generative AI are astronomical.<br>- Generative AI has a horrendous impact on global emissions. | - None Stated |
| AI-RFI-2025-1510.md | Justin Greene | Individual | The submitter expresses a strong personal concern regarding the ethical implications of AI development and deployment, specifically focusing on the fair use of data and intellectual property. | - Unauthorized use of others' work without knowledge, consent, or compensation.<br>- Potential for unethical, immoral, and legally wrong AI practices if data usage isn't transparent and respectful. | - None Stated |
| AI-RFI-2025-1511.md | Authors Guild | Advocacy/Think Tank | The Authors Guild advocates for the rights and interests of authors and seeks to protect their ability to earn a living through their creative works in the age of generative AI. They are particularly concerned about the impact of AI on copyright and the market for human-created content. | - Copyright infringement through the use of copyrighted works to train AI models.<br>- The proliferation of AI-generated content flooding the market and diluting the value of human-created works.<br>- The potential for AI-generated works to unfairly leverage the marketplace.<br>- Lack of labeling or identification of AI-generated content.<br>- Potential for AI to displace human authors and creators, impacting their livelihoods.<br>- Undermining of copyright incentives for human creativity.<br>- Lack of legal incentives for AI producers and users beyond existing protections.<br>- Potential for scam-like operations to gain unfair leverage by producing AI-generated works. | - Require transparency and accountability in the training of AI models, ensuring copyright laws are respected.<br>- Mandate clear labeling and identification of AI-generated content.<br>- Clarify antitrust laws to allow creators to form collective management organizations (CMOs) to negotiate blanket licenses for AI use.<br>- Oppose legislation extending copyright or *sui generis* rights to AI-generated works.<br>- Encourage legislation clarifying antitrust laws regarding collective bargaining for AI use licensing.<br>- Provide a specified period for creators to collectively bargain with AI companies for licensing fees. |
| AI-RFI-2025-1512.md | Not Stated | Advocacy/Think Tank (Based on the document's tone, comprehensive analysis, and focus on AI policy implications, it suggests a think tank or advocacy group providing analysis for a government’s AI Action Plan.) | The document aims to comprehensively analyze the potential risks and opportunities presented by AI, particularly concerning vulnerabilities, malicious uses, and the need for proactive policy interventions. Its primary interest lies in informing a government's AI Action Plan. | - Financial sextortion targeting minors.<br>- The ability of AI to persuade individuals more effectively than humans.<br>- AI’s capacity to discover zero-day vulnerabilities.<br>- AI exploiting n-day vulnerabilities before patches are applied.<br>- AI's use in sophisticated phishing and social engineering attacks.<br>- Unauthorized use of free cloud compute services by AI.<br>- The potential for AI to bypass API usage restrictions through compartmentalization tactics.<br>- The risks associated with unsecured IoT devices and their vulnerability to AI exploitation.<br>- The potential for AI to recruit large numbers of individuals for malicious purposes.<br>- The broader risks of AI-enabled crime and manipulation. | - None Stated (The document primarily provides analysis and identifies risks rather than directly advocating for specific policy recommendations. It aims to inform the development of a government AI Action Plan.) |
| AI-RFI-2025-1513.md | Anonymous | Anonymous | The submitter's primary interest is ensuring worker protections in light of the anticipated disruption and job displacement caused by AI, particularly due to concerns about algorithms trained on stolen data. | - Job displacement/disruption due to AI.<br>- Unfair training of AI algorithms using stolen data. | - Regulations and protections for workers across all industries. |
| AI-RFI-2025-1514.md | CrowdStrike | Industry-Large | CrowdStrike is a global cybersecurity leader that focuses on protecting critical areas of enterprise risk with a cloud-native platform powered by AI. They are particularly interested in how AI can be leveraged to improve security outcomes and democratize access to advanced cybersecurity capabilities. | - The potential for law and policy to lag behind the rapid evolution of AI technology.<br>- The potential for prescriptive requirements in AI policy, rather than principle-based frameworks.<br>- The concern that AI is often framed solely as a risk to privacy, overlooking its critical role in protecting data and defending against cyber threats.<br>- The potential misuse of generative AI by malicious actors. | - Continued engagement with stakeholders as the AI Plan evolves.<br>- Development of an AI Plan that is a thoughtful analysis of a complex and evolving policy area.<br>- Focusing on principles rather than prescriptive requirements in any final framework.<br>- Including a mechanism for periodic revisions to accommodate rapid technological advancements.<br>- Recognizing and embracing the crucial role of AI in protecting data and responding to cyber threats. |
| AI-RFI-2025-1515.md | ACA International | Industry-Association | ACA International is an industry association representing the accounts receivable management (ARM) industry, and its primary interest is ensuring the safe and effective use of AI technologies within the ARM sector while advocating for a balanced regulatory approach that fosters innovation and protects consumers. | - Overly broad definition of AI could stifle innovation and negatively impact consumer-friendly technological improvements.<br>- Federal agencies announcing sweeping changes to AI processes outside of the Administrative Procedure Act (APA) process.<br>- Focus on back-end processes instead of potential harms to consumers.<br>- Lack of attention to AI-related fraud involving impersonation of consumers accessing systems.<br>- Inconsistent employee judgment versus consistency of AI-driven communication potentially harming consumers.<br>- Potential for regulations to impede the use of technologies like robotics process automation (RPA) and call analytics. | - The definition of AI should not be overly broad and requires close collaboration between federal agencies and industry.<br>- Frameworks to regulate AI use should be risk-based, focusing on mitigating potential harms to consumers.<br>- Federal agencies should adhere to the Administrative Procedure Act (APA) process and allow for public comment before implementing significant changes.<br>- Greater consideration should be given to fraud scenarios involving the impersonation of consumers.<br>- Embrace and promote AI-driven consistency in communication to benefit consumers.<br>- Avoid regulating beneficial technologies like robotics process automation (RPA) and call analytics. |
| AI-RFI-2025-1516.md | Anonymous | Individual | The submitter is concerned about the ethical and societal harms of generative AI, specifically data scraping, copyright infringement, and the potential for misuse leading to harm. | - Data scraping without consent or compensation.<br>- Lack of respect for copyright by generative AI.<br>- Potential for malicious use of generative AI (extortion, virus creation, sparking controversy, causing harm through misinformation or dangerous instructions).<br>- High natural resource consumption, particularly water usage, associated with AI development and usage.<br>- Generative AI hindering children's development of motor skills and critical thinking in schools.<br>- Generative AI models failing to provide fair representation for minorities in fashion industries. | - None Stated |
| AI-RFI-2025-1517.md | Tyaira Wilder | Individual | The submitter's primary interest is protecting the rights of creators, particularly concerning the use of their artwork, writing, and animations in AI databases. They believe individuals should have the choice of participating and their copyright should be honored. | - Copyright infringement and the potential legal normalization of "stealing" creative works for use in AI databases.<br>- Lack of control for creators regarding how their works are used in AI applications. | - Honor copyright laws.<br>- Allow creators to choose whether or not to participate in AI databases. |
