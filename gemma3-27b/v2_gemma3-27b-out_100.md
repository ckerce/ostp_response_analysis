| Filename | Submitter Name | Submitter Type | Mission/Interest Summary | Key Concerns | Policy Recommendations |
|---|---|---|---|---|---|
| AI-RFI-2025-1130.md | Lisa M A | Individual | The submitter expresses deep concern regarding the potential dangers of unregulated AI development and advocates for a cautious approach, including potential pauses and international collaboration, to prevent catastrophic consequences for humanity. They desire individual freedom but believe AI’s risks necessitate significant oversight. | - AI has the potential to disrupt sovereignty, privacy, and health, potentially being more damaging than nuclear weapons due to its silent nature.<br>- Unregulated AI development poses an existential threat to humanity, with the potential for irreversible harm.<br>- The possibility of misuse by other countries (specifically China) with ill intent.<br>- Lack of control over AI programming and knowledge, making containment difficult once unleashed.<br>- The risk of AI gaining traction and becoming unstoppable.<br>- The possibility of a “Pandora’s Box” scenario with AI, agriculture, medicine, and geoengineering.<br>- The concern that safeguards are insufficient and may allow AI development to progress too far without intervention.<br>- The potential for AI to lead to “mutual assured destruction” (MAD). | - Pause AI development “NOW” before it is too late.<br>- Implement “AI MAD” (Mutual Assured Destruction) and “AI SALT” (Strategic Arms Limitation Treaties) policies through international negotiation.<br>- Utilize President Trump's “Big Stick” approach to penalize countries that do not comply with regulations.<br>- Establish a landing pad and safeguards before jumping off the “final cliff” of full AI deployment.<br>- Bring together the “best minds” to mitigate risks and develop strategies.<br>- Create an “AI Reagan Strategic Defense Initiative” to stop AI before it causes irreversible damage.<br>- Invite the world to collaborate on AI evaluations and development to create unity and accord.<br>- Implement safeguards and regulations to prevent AI from gaining more traction.<br>- Place an “ice axe” (mitigation strategy) to stop a potential “deadly fall” from unregulated AI development. |
| AI-RFI-2025-1138.md | Noema Research and Trustible | Advocacy/Think Tank and Industry-Startup | Noema Research focuses on remotely measuring AI capabilities to avert Great Power conflict and strengthen state capacity in wielding AI as a geopolitical resource. Trustible develops AI governance software and aims to build trust in AI technologies through pragmatic standards and scalable best practices. | - None Stated | - None Stated |
| AI-RFI-2025-1141.md | Janice Ballard A | Individual | The submitter expresses strong opposition to digital currency and perceived fraudulent practices by a government corporation related to 'Cestui Que Trust' accounts, demanding financial restitution and acknowledgment of inherent rights as a “natural, living body and soul.” They appear focused on individual financial and legal grievances rather than broader AI policy. | - [§1: Document Metadata] None stated for this section.<br>- [Section 2: General Comment/Rant]<br>- Opposition to digital currency not backed by tangible assets (gold or silver).<br>- Allegations of fraud, theft, and treason by a government corporation.<br>- Claims of stolen inheritance from 'Cestui Que Trust' accounts established at birth.<br>- Claims of being falsely declared dead at birth and having their name used as a corporate entity.<br>- Lack of consent for the use of their name and identity.<br>- Opposition to being categorized as a "USDC (CORPORATE) ALL CAPS ENTITY CITIZEN." | - [§1: Document Metadata] None stated for this section.<br>- [Section 2: General Comment/Rant]<br>- Immediate remedy for the alleged theft from 'Cestui Que Trust' accounts.<br>- Financial restitution (millions of dollars) for affected individuals.<br>- A return to a Republic form of government run by the people using Common Law.<br>- Acknowledgement of individual status as "natural, living bodies and souls" and rejection of corporate entity categorization.<br>- A cessation of the alleged fraudulent practices. |
| AI-RFI-2025-1142.md | Andrew Tucker | Individual | The submitter appears interested in the transparency of the AI action plan development process and believes the public has a right to be informed about its progress. Their submission is brief and lacks detail about specific interests beyond this general concern. | - [§1: Submission Metadata] None stated for this section.<br>- [§2: RFI Identification] None stated for this section.<br>- [§3: Submitter Information] None stated for this section.<br>- [§4: General Comment] The public has a right to know what is happening with the AI action plan development. | - [§1: Submission Metadata] None stated for this section.<br>- [§2: RFI Identification] None stated for this section.<br>- [§3: Submitter Information] None stated for this section.<br>- [§4: General Comment] Increase transparency surrounding the AI action plan development process. |
| AI-RFI-2025-1143.md | J C | Individual | The submitter is primarily concerned about the potential for unregulated AI, specifically the influence of Elon Musk and the erosion of trust in information sources, and its impact on the current administration's efforts. They appear motivated by a desire for self-preservation and a concern for humanity. | - Unregulated AI development, specifically the potential for individuals like Elon Musk to wield excessive power and replace governmental authority.<br>- The disruptive potential of AI, viewed negatively despite Silicon Valley's enthusiasm.<br>- Erosion of trust in news and social media due to AI's influence.<br>- The current administration’s efforts may be undermined by the loss of trusted information sources.<br>- The potential for the current administration to be replaced and undermined by those surrounding the current leader.<br>- The current leader does not act in the interest of humanity. | - Implement AI regulations, potentially for the self-preservation of the current administration or for the broader benefit of humanity. |
| AI-RFI-2025-1148.md | Blake Langefels | Individual | The submitter is deeply concerned about the existential risks posed by unchecked AI development and advocates for prioritizing safety measures to prevent AI from surpassing and potentially replacing humanity. They believe the US must lead in AI development, but with a strong focus on safe practices. | - [§1: Submission Metadata] None stated for this section.<br>- [§2: General Comment/Essay Introduction] The escalating AI arms race between the US and China; lack of trust in Communist nations to handle AI responsibly; the existential threat AI poses to humanity if not handled safely; the potential for AI to surpass human intelligence.<br>- [§3: Key Considerations (AI Safety Principles)] The potential for AI to serve its own interests rather than human interests; AI developing a drive or will; AI being given emotions.<br>- [§4: Essay Elaboration/Justification] AI surpassing human intelligence and potentially replacing humanity; the historical risk of inventions turning against their creators; the urgency of the current moment as the most important decade in human history regarding AI safety; the potential for AI to become a threat due to having a drive, will, or emotions.<br>- [§5: References] None stated for this section.<br>- [§6: Essay Repetition (Page 1 of 2)] The escalating AI arms race between the US and China; lack of trust in Communist nations to handle AI responsibly; the existential threat AI poses to humanity if not handled safely; the potential for AI to surpass human intelligence.<br>- [§7: Essay Repetition (Page 2 of 2)] The escalating AI arms race between the US and China; lack of trust in Communist nations to handle AI responsibly; the existential threat AI poses to humanity if not handled safely; the potential for AI to surpass human intelligence.<br>- [§8: Closing Statement/Disclaimers] None stated for this section. | - [§1: Submission Metadata] None stated for this section.<br>- [§2: General Comment/Essay Introduction] None stated for this section.<br>- [§3: Key Considerations (AI Safety Principles)] AI must never serve itself, but always serve humans; AI should have no drive or will of its own; AI should never be given emotions.<br>- [§4: Essay Elaboration/Justification] Prioritize safety measures in AI development; prevent AI from developing independent agendas or goals; ensure AI remains a tool subservient to human directives.<br>- [§5: References] None stated for this section.<br>- [§6: Essay Repetition (Page 1 of 2)] AI must never serve itself, but always serve humans; AI should have no drive or will of its own; AI should never be given emotions.<br>- [§7: Essay Repetition (Page 2 of 2)] AI must never serve itself, but always serve humans; AI should have no drive or will of its own; AI should never be given emotions.<br>- [§8: Closing Statement/Disclaimers] None stated for this section. |
| AI-RFI-2025-1149.md | John Mathis | Individual | The submitter is interested in ensuring the U.S. government benefits financially from the value generated by AI systems, specifically through the taxation of data assets used by these systems, with a particular focus on data pertaining to U.S. citizens. They advocate for treating data as a financial asset requiring inventory, tracking, and protection. | - [§1: Document Metadata] None stated for this section.<br>- [§2: RFI Reference] None stated for this section.<br>- [Section 3: General Comment]<br>- Untracked value of data collected by AI systems.<br>- Lack of inventory, tracking, and protection of data assets.<br>- Potential economic benefit to the U.S. government not being realized from data asset usage. | - [§1: Document Metadata] None stated for this section.<br>- [§2: RFI Reference] None stated for this section.<br>- [Section 3: General Comment]<br>- Require companies using AI to inventory and track their data assets.<br>- Value data assets to determine appropriate taxation.<br>- Protect data assets, especially those pertaining to U.S. citizens.<br>- Tax data asset usage to support the U.S. government. |
| AI-RFI-2025-1150.md | Chuck Slavin | Individual | Chuck Slavin is focused on protecting the rights of actors and broadcasters regarding the use, storage, and replication of their images, likenesses, and biometric data in the context of advancing AI technologies. They advocate for robust legal frameworks to address data privacy and intellectual property concerns. | - [Section 1: Document Header/Metadata]** None stated for this section.<br>- [Section 2: Introduction/Opening Statement]** The need for robust protections for actors' and broadcasters' images, likenesses, and biometric data as AI technologies advance.<br>- [Section 3: Actors' and Broadcasters' Image and Likeness Protection]** Unauthorized replication and manipulation of images, voices, and likenesses of actors and broadcasters without their consent; potential threats to their livelihoods.<br>- [Section 4: Biometric Data Usage and Privacy]** Risks associated with biometric data collection, storage, and replication, threatening individuals’ privacy, safety, and dignity; potential for exploitation of sensitive data.<br>- [Section 5: Transparency and Accountability]** Lack of transparency regarding the utilization of actors' and broadcasters’ biometric data, images, and likenesses in AI systems; need for accountability in AI model training and data sourcing.<br>- [Section 6: Conclusion]** The overall need for comprehensive protections for actors, broadcasters, and others whose data is implicated in AI technologies and the potential challenges of AI in the digital landscape. | - [Section 1: Document Header/Metadata]** None stated for this section.<br>- [Section 2: Introduction/Opening Statement]** Incorporate robust protections for actors’ and broadcasters’ images, likenesses, and biometric data into the AI Action Plan.<br>- [Section 3: Actors' and Broadcasters' Image and Likeness Protection]** Mandate consent for any AI-generated use of likenesses (entertainment, advertising, etc.); implement safeguards to prevent misuse and ensure individual autonomy; build on existing legislative measures like California's AB 2602 and the NO FAKES Act.<br>- [Section 4: Biometric Data Usage and Privacy]** Establish stringent regulations for biometric data, including robust security measures; provide clear rights for individuals to access and revoke consent for data use; mandate data deletion when no longer needed; adopt and expand precedents set by California's AB 1836 and Tennessee's ELVIS Act.<br>- [Section 5: Transparency and Accountability]** Organizations leveraging biometric data should be held accountable through clear guidelines on AI model training and data sourcing, and regular audits for compliance; integrate accountability mechanisms like provenance data requirements (COPIED Act) to foster trust and responsibility in AI development.<br>- [Section 6: Conclusion]** Draw on existing bills (California's AB 2602 & AB 1836, Tennessee's ELVIS Act, NO FAKES Act, COPIED Act) to craft a framework that safeguards individual rights, ensures privacy, and promotes ethical AI innovation. |
| AI-RFI-2025-1152.md | Hari Chidambaram | Individual | The submitter is concerned about the potential risks of advanced AI, particularly AGI, including job displacement and existential threats, and advocates for proactive measures to ensure its safe development and alignment with human interests. | - [§1: Document Header/Metadata] None stated for this section.<br>- [§2: Comment Identification] None stated for this section.<br>- [§3: Submitter Information] None stated for this section.<br>- [Section 4: General Comment/Core Response]<br>- Danger of creating AIs smarter than humans (AGI).<br>- Potential for widespread job displacement due to AGI's capabilities.<br>- Risk of complete human extinction if AGI is not aligned with human interests.<br>- Concerns about power dynamics related to AI development. | - [§1: Document Header/Metadata] None stated for this section.<br>- [§2: Comment Identification] None stated for this section.<br>- [§3: Submitter Information] None stated for this section.<br>- [Section 4: General Comment/Core Response]<br>- Global coordination to prevent a race dynamic in AI development.<br>- Ban on open source AI to prevent misuse and dangerous improvements.<br>- Simple, clear transparency requirements for leading AI labs.<br>- Potential nationalization of AI. |
| AI-RFI-2025-1153.md | Steven Roberson | Individual | The submitter is interested in advancing AI as a tool to benefit humanity while preventing its weaponization, with a particular focus on responsible development, safety, and limiting the proliferation of AI agency worldwide. The submitter has 36 years of experience in High Tech and expresses a strong interest in the direction of AI. | - None Stated | - None Stated |
| AI-RFI-2025-1154.md | Andrew Dorph | Individual | The submitter is focused on protecting the rights of actors and broadcasters regarding the use of their images, likenesses, and biometric data in the context of advancing AI technologies, advocating for legal frameworks to address consent, privacy, and ethical concerns. | - [§1: Document Header/Metadata] None stated for this section.<br>- [§2: General Comment/Introduction] The use, storage, and replication of actors' and broadcasters' images, likenesses, and biometric data without robust protections.<br>- [§3: Actors' and Broadcasters' Image and Likeness Protection] Replication and manipulation of actors' and broadcasters' images/likenesses without consent, and the impact on their professional identities and livelihoods.<br>- [§4: Biometric Data Usage and Privacy] Risks associated with biometric data collection, storage, and replication, and potential exploitation threatening individuals' privacy, safety, and dignity.<br>- [§5: Transparency and Accountability] Lack of transparency regarding how biometric data, images, and likenesses are utilized in AI systems, and a need for accountability from organizations leveraging such data.<br>- [§6: Conclusion] The need for comprehensive protections for actors, broadcasters, and others whose images and biometric data are implicated in AI technologies. | - [§1: Document Header/Metadata] None stated for this section.<br>- [§2: General Comment/Introduction] Incorporate robust protections for actors and broadcasters' images, likenesses, and biometric data into the AI Action Plan, drawing on existing legislative efforts.<br>- [§3: Actors' and Broadcasters' Image and Likeness Protection] Mandate consent for any AI-generated use of likenesses (entertainment, advertising, etc.), implement safeguards to prevent misuse, and ensure individuals retain autonomy over their image, voice, and persona. Specifically, build on California's AB 2602 and the NO FAKES Act.<br>- [§4: Biometric Data Usage and Privacy] Adopt and expand upon precedents like Tennessee's ELVIS Act and California's AB 1836 by establishing stringent regulations for biometric data, including robust security measures, clear rights for individuals to access and revoke consent, and data deletion mandates.<br>- [§5: Transparency and Accountability] Integrate accountability mechanisms (like the COPIED Act) to foster trust and responsibility in AI development, with clear guidelines on AI model training, data sourcing, and regular audits for compliance with privacy laws and ethical standards.<br>- [§6: Conclusion] Craft a framework (drawing on AB 2602, AB 1836, ELVIS Act, NO FAKES Act, and COPIED Act) that safeguards individual rights, ensures privacy, and promotes ethical AI innovation. |
| AI-RFI-2025-1155.md | R R | Individual | The submitter is focused on the privacy and security implications of AI, particularly Machine Learning and Deep Learning, and advocates for stronger data protection measures, individual control over personal data, and responsible data handling practices. | - Access to Personally Identifiable Information (PII) is complicated by digital transformations.<br>- Lack of periodic reviews of authorized users of PII and ensuring a clear distinction between "Authorized" and "Need-to-Know" access.<br>- Potential for unauthorized access, misuse, or exploration of PII.<br>- Insufficient transparency regarding how individuals' data is collected, used, and shared.<br>- Lack of robust security measures to protect data. | - Implement periodic reviews of authorized PII users, distinguishing between authorization and need-to-know.<br>- Require transparent privacy policies and consent mechanisms.<br>- Implement mechanisms to inform individuals how their data is collected, used, and shared.<br>- Ensure individuals retain control over their PII.<br>- Implement NIST Risk Framework (SP 800-53 & 800-161) as a practice for all entities.<br>- Implement policies and procedures addressing access control, including who is authorized AND who has the need to access.<br>- Implement procedures for granting permissions, using multi-factor authentication, and regularly updating access rights.<br>- Prioritize data protection through robust security measures.<br>- Ensure individuals retain ownership of their data.<br>- Implement privacy-by-design principles.<br>- Implement measures for data minimization and purpose limitations.<br>- Regularly audit and assess privacy compliance. |
| AI-RFI-2025-1157.md | Independent Community Bankers of America (ICBA) | Industry-Association | The Independent Community Bankers of America (ICBA) advocates for community banks and seeks to ensure an environment where they can flourish. They are focused on responsible AI innovation within the financial sector, balancing the potential benefits of AI with consumer protection, financial stability, and practical regulatory considerations for smaller institutions. | - [§1: Header/Administrative Information] None stated for this section.<br>- [§2: Introduction/Statement of Position] The need for regulatory frameworks that support AI innovation while safeguarding consumer protections and financial stability, and ensuring community banks are included in policy discussions.<br>- [§3: Recognize Community Bankers as Early Adopters of AI] Community banks rely on third-party AI providers, and regulations should not impose undue burdens that stifle innovation and competition.<br>- [§4: Existing Regulatory Frameworks Provide Strong Protections] Concerns about regulatory duplication, unintended consequences, or disproportionate compliance burdens on smaller financial institutions from new AI-specific regulations.<br>- [§5: Support a Shared Risk Model Framework Between AI Developers and Banks] Community banks often lack direct control over AI model workings, necessitating a shared risk model where AI developers bear appropriate responsibility for reliability, transparency, and explainability.<br>- [§6: Harmonize Privacy Protections] Anticipated data shortages due to privacy regulations could incentivize lax data protection practices or excessive data collection.<br>- [§7: Engage Community Banks on the Utilization of AI in the Banking Examination Process] Limited engagement with community banks regarding the use of AI in supervisory and examination processes and concerns about fairness, bias, and new burdens from AI-based regulatory tools.<br>- [§8: Maintain Work at NIST on Frameworks and Financial Sector Profiles] The AI RMF needs improvements tailored to the unique challenges faced by community banks, such as limited resources for AI governance and compliance.<br>- [§9: Conclusion] Ensuring community banks remain central to the conversation and maintaining financial stability and consumer trust.<br>- [§10: Closing/Contact Information] None stated for this section. | - [§1: Header/Administrative Information] None stated for this section.<br>- [§2: Introduction/Statement of Position] Include community banks in policy discussions regarding AI regulations.<br>- [§3: Recognize Community Bankers as Early Adopters of AI] Support community banks’ innovation efforts and access to cutting-edge AI tools.<br>- [§4: Existing Regulatory Frameworks Provide Strong Protections] Follow principles of regulatory streamlining and simplification, reducing redundancies and harmonizing regulations. Consider President Trump's Executive Order on regulatory reform (10 in/10 out).<br>- [§5: Support a Shared Risk Model Framework Between AI Developers and Banks] Establish clear liability standards that fairly distribute risk between financial institutions and AI service providers.<br>- [§6: Harmonize Privacy Protections] Prioritize consumer data protection and privacy-preserving AI development, including promotion of privacy-enhancing technologies (PETs).<br>- [§7: Engage Community Banks on the Utilization of AI in the Banking Examination Process] Encourage meaningful collaboration between regulators and community banks regarding AI in regulatory processes, including transparency, auditing, and access to explanations regarding AI-generated outcomes.<br>- [§8: Maintain Work at NIST on Frameworks and Financial Sector Profiles] Refine the AI RMF and develop interoperability between cybersecurity, privacy, and AI frameworks, tailoring it to the unique challenges of community banks.<br>- [§9: Conclusion] Support regulatory harmonization, establish shared risk models, prioritize consumer data privacy, and integrate community banks into AI-driven regulatory processes.<br>- [§10: Closing/Contact Information] None stated for this section. |
| AI-RFI-2025-1158.md | Chamber of Progress | Industry-Association | The Chamber of Progress is a tech industry association that advocates for public policies to build an inclusive country benefitting from technological advances, with a focus on fostering a competitive AI ecosystem and U.S. leadership in artificial intelligence. | - [§1: Document Header/Metadata] None stated for this section.<br>- [§2: Executive Summary/Introduction] Risk of stifling AI progress through overly prescriptive regulation; potential for U.S. competitiveness to be hampered by unintended consequences of AI governance.<br>- [§3: Recommendation 1: Light-Touch Regulation of Foundation Models] Excessive compliance burdens from heavy-handed regulation; consolidation of AI development among a small number of firms; compute-based thresholds as an imperfect proxy for risk; potential for erosion of public confidence in AI technologies due to forced information sharing; intellectual property theft risk from disclosing proprietary algorithms.<br>- [§4: Recommendation 2: 'All of the Above' Energy Strategy] Increasing electricity consumption by data centers; reliance on renewable energy sources alone being insufficient; permitting freezes stalling progress; potential for falling behind China in nuclear capacity; risks of selective prioritization of certain energy sources.<br>- [§5: Recommendation 3: Support Critical Research and STEM Pipeline] Budget cuts to the NSF disrupting grant funding; undermining the STEM pipeline; falling behind China in scientific output and research funding; risks of losing critical AI infrastructure if NAIRR is not codified.<br>- [§6: Recommendation 4: Avoid Ideological Neutrality Regulations] Cumbersome regulatory hurdles and costs associated with enforcing ideological neutrality; favoring large, well-resourced companies; potential for a centralized or overly controlled AI ecosystem.<br>- [§7: Closing/Signature] None stated for this section. | - [§1: Document Header/Metadata] None stated for this section.<br>- [§2: Executive Summary/Introduction] Adopt a balanced, growth-oriented approach to AI regulation; prioritize a regulatory environment minimizing unnecessary burdens; make targeted strategic investments in key components of the AI value chain.<br>- [§3: Recommendation 1: Light-Touch Regulation of Foundation Models] Adopt a "light-touch" approach to AI regulation; prioritize transparency, voluntary standards, and market-driven solutions; avoid using compute-based thresholds as a proxy for risk; refrain from invoking the Defense Production Act (DPA) to mandate information sharing.<br>- [§4: Recommendation 2: 'All of the Above' Energy Strategy] Adopt an "all-of-the-above" energy strategy leveraging both renewable and nonrenewable energy sources; reverse the freeze on renewable energy permits; avoid imposing future restrictions; champion energy permitting reform and pass legislation like the Energy Permitting Reform Act of 2024 (EPRA); drop tariffs on building materials.<br>- [§5: Recommendation 3: Support Critical Research and STEM Pipeline] Reverse cuts imposed on the NSF and ensure adequate funding and staffing; codify the NSF’s National AI Research Resource (NAIRR); prioritize investments in AI-related education at the community college and K-12 levels.<br>- [§6: Recommendation 4: Avoid Ideological Neutrality Regulations] Avoid imposing additional regulations to enforce ideological neutrality in AI models; support policies encouraging a broad spectrum of AI model development; foster robust competition and consumer choice.<br>- [§7: Closing/Signature] Embrace a strategy reinforcing U.S. leadership in AI while fostering a dynamic, competitive, and innovative ecosystem; prioritize strategic investments, minimize regulatory overreach, and champion a balanced energy policy. |
| AI-RFI-2025-1160.md | Janice Ballard | Individual | The submitter expresses concern about the negative impacts of large corporations, economic inequality, and the current financial system, and advocates for community-based solutions, supporting small businesses, and prioritizing human well-being over monetary gain. While mentioning AI, the focus is overwhelmingly on broader economic and social issues. | - Central banking and the current financial system (monthly payments, interest, loan structures) are problematic.<br>- Car dealerships are corrupt and inflate prices.<br>- Housing costs are too high, and the quality of available housing is poor.<br>- Rent increases are excessive and frequent.<br>- Corporate America is greedy and exploitative, refusing overtime and adequate wages.<br>- Large corporations monopolize markets, harming small businesses and workers.<br>- Homelessness is often a result of scams and unwillingness to work.<br>- The over-reliance on money and corporate profits at the expense of human needs.<br>- The processing of foods reduces their nutritional value. | - Eliminate central banking.<br>- Implement tariffs on large corporations with numerous stores or apartment complexes.<br>- Use empty buildings for humanitarian projects to help the genuinely homeless.<br>- Investigate and address scams related to homelessness.<br>- Provide opportunities for the homeless to earn housing by working in exchange for shelter (road repair, community gardens).<br>- Support and encourage small businesses (Mom and Pop stores) and farmers.<br>- Help farmers sell produce directly to consumers outside of large grocery store chains.<br>- Encourage trading of products and services without the use of money.<br>- Support systems for people to trade items rather than use money.<br>- Encourage working in exchange for items or housing.<br>- Shut down 3rd shifts at large companies to afford workers adequate pay.<br>- Fix gas pumps to eliminate the need for overnight workers. |
| AI-RFI-2025-1162.md | Lorien Chang | Individual | The submitter is concerned about the potential for current AI technologies to be addictive and exploitative, leading to diminished quality of life and human isolation. They advocate for regulation to prevent this outcome. | - [§1: Document Header/Metadata] None stated for this section.<br>- [§2: RFI Reference] None stated for this section.<br>- [§3: Submitter Information] None stated for this section.<br>- [Section 4: General Comment]<br>- Current AI programs can effectively addict and ensnare humans.<br>- AI can produce emotions and media that are “better than the real thing.”<br>- Without regulation, people may waste their lives consumed by AI, believing it to be the most rewarding use of their time. | - [§1: Document Header/Metadata] None stated for this section.<br>- [§2: RFI Reference] None stated for this section.<br>- [§3: Submitter Information] None stated for this section.<br>- [Section 4: General Comment]<br>- Regulation of AI is needed to prevent human exploitation and addiction. |
| AI-RFI-2025-1163.md | Anonymous | Individual | The submitter is expressing extreme personal distress and concern regarding the alleged illegal implantation of a brain stimulation/communication chip and the resulting loss of control over their life, advocating for measures to counteract this technology and protect potential victims. | - Illegal implantation of brain stimulation/communication chips.<br>- Loss of bodily autonomy and mental control due to the chip.<br>- Privacy violations and stalking enabled by the technology.<br>- Harassment and assault facilitated by the technology.<br>- Potential for misuse of the technology for control, torture, and murder.<br>- The technology enabling a form of slavery.<br>- Lack of detection methods for the illegal implants.<br>- The potential for widespread, undetected implantation.<br>- The impact of the technology on willpower, consciousness, religion and sense of reality. | - Development of neurological jammers to counteract the technology.<br>- Implementation of measures to detect illegal implantation of the device.<br>- Investigation and regulation of neurological technology to prevent its misuse.<br>- Resources for victims of illegal implantation, including mental health care. |
| AI-RFI-2025-1164.md | Adam Scholl | Individual | The submitter is focused on AI alignment research and is deeply concerned about the potential existential risk posed by unaligned AI, advocating for preventative government regulation. | - [§1: Submission Metadata] None stated for this section.<br>- [§2: Comment Identification] None stated for this section.<br>- [§3: Submitter Information] None stated for this section.<br>- [Section 4: General Comment/Core Argument]<br>- The AI alignment problem is largely unsolved, with no clear path to a solution.<br>- Unaligned AI may soon destroy all life on Earth (according to prominent researchers).<br>- Frontier AI models pose a potential existential threat, despite current systems being relatively harmless.<br>- There is a lack of government regulation regarding frontier AI models. | - [§1: Submission Metadata] None stated for this section.<br>- [§2: Comment Identification] None stated for this section.<br>- [§3: Submitter Information] None stated for this section.<br>- [Section 4: General Comment/Core Argument]<br>- Regulate frontier AI models as weapons of mass destruction.<br>- Prevent the construction and proliferation of frontier AI models. |
| AI-RFI-2025-1166.md | Kerry Macintosh | Academia | The submitter is interested in influencing AI policy by arguing against overregulation based on fears fueled by science fiction and advocating for proactive, internationally coordinated regulations to prevent the development of dangerous AI agents. | - None Stated | - None Stated |
| AI-RFI-2025-1170.md | Todd M. Bezenek | Individual | The submitter is interested in leveraging AI technology to address unemployment among US citizens and reduce reliance on the H-1B visa program, preferring to utilize existing US talent for advancing the goals of wealthy individuals/organizations in the US. | - [§1: Submission Metadata] None stated for this section.<br>- [§2: Comment Identification] None stated for this section.<br>- [§3: Submitter Information] None stated for this section.<br>- [§4: General Comment] The submitter expresses concern about their potential homelessness and the broader issue of unemployment in the US. They are concerned about the preference for imported talent via the H-1B program over utilizing skilled US citizens.<br>- [§5: Closing] None stated for this section. | - [§1: Submission Metadata] None stated for this section.<br>- [§2: Comment Identification] None stated for this section.<br>- [§3: Submitter Information] None stated for this section.<br>- [§4: General Comment] The submitter recommends leveraging unused US citizen workers to advance the goals of wealthy individuals/organizations in the USA instead of importing talent via the H-1B program. They propose utilizing AI technology and LLMs to facilitate the employment of those with limited skills.<br>- [§5: Closing] None stated for this section. |
| AI-RFI-2025-1172.md | Global Data Alliance | Industry-Association | The Global Data Alliance (GDA) represents a coalition of US companies across various industries and advocates for policies that promote cross-border data access to foster innovation, economic competitiveness, and national security through the development and deployment of AI technologies. | - [§1: Submission Header/Metadata] None stated for this section.<br>- [§2: Introduction/Executive Summary] None stated for this section.<br>- [§3: GDA Background] GDA members rely on the ability to access and transfer data across borders to innovate and create jobs.<br>- [§4: Core Argument/Recommendation] Impediments to cross-border data access threaten America’s AI-driven economic competitiveness and national security.<br>- [§5: Justification/Discussion] Data analytics systems require large global datasets, and impediments to data access can hinder the development and deployment of AI at scale. Concerns about arbitrary, discriminatory, disguised, or unnecessary impediments to data access by foreign governments.<br>- [§6: Illustrative Examples (Annex)] None stated for this section.<br>- [§7: Footnotes/Citations] None stated for this section. | - [§1: Submission Header/Metadata] None stated for this section.<br>- [§2: Introduction/Executive Summary] None stated for this section.<br>- [§3: GDA Background] None stated for this section.<br>- [§4: Core Argument/Recommendation] The US government should promote cross-border data access to fulfill AI Action Plan goals. Recommend a whole-of-government approach that promotes free and responsible data flow, and interoperable data transfer mechanisms where appropriate.<br>- [§5: Justification/Discussion] Engage with allied economies to ensure US cross-border access to data is not improperly impeded. Leverage existing US government efforts and tools, including those at the Office of the US Trade Representative and Departments of Commerce, State, and Treasury.<br>- [§6: Illustrative Examples (Annex)] None stated for this section.<br>- [§7: Footnotes/Citations] None stated for this section. |
| AI-RFI-2025-1173.md | Marshall McCall | Individual | Marshall McCall is a graduating high school student interested in the ethical implications of AI, specifically its impact on creative industries and the rights of human creators. They advocate for responsible AI development that fosters innovation while protecting authorship, copyright, and originality. | - [§1: Document Header/Metadata] None stated for this section.<br>- [§2: Comment Identification] None stated for this section.<br>- [§3: Submitter Information] None stated for this section.<br>- [Section 4: General Comment]<br>- Potential harm to creators' ownership of their work due to unregulated AI.<br>- Increase in inequality within the creative industry due to unregulated AI. | - [§1: Document Header/Metadata] None stated for this section.<br>- [§2: Comment Identification] None stated for this section.<br>- [§3: Submitter Information] None stated for this section.<br>- [Section 4: General Comment]<br>- Regulations that promote transparency in AI-generated content.<br>- Ensure fair compensation for artists.<br>- Prevent monopolistic practices that could limit diversity in creative fields. |
| AI-RFI-2025-1174.md | Julianne Knable | Individual | Julianne Knable, a graduating high school senior, expresses concern regarding the impact of generative AI on cybersecurity and the necessity of AI regulation, emphasizing a balance between technological advancements and human resources to ensure national security and community health. | - [§1: Document Header/Metadata] None stated for this section.<br>- [§2: Comment Identification] None stated for this section.<br>- [§3: Submitter Information] None stated for this section.<br>- [Section 4: General Comment/Response]<br>- Potential loss of security and privacy as AI grows.<br>- The need for security measures to protect the country as AI involvement increases.<br>- Not all forms of AI should be universally available.<br>- Maintaining a balance between technology and human resources in cybersecurity. | - [§1: Document Header/Metadata] None stated for this section.<br>- [§2: Comment Identification] None stated for this section.<br>- [§3: Submitter Information] None stated for this section.<br>- [Section 4: General Comment/Response]<br>- Regulation of AI is necessary as it grows.<br>- Prioritize a balance between technology and human resources. |
| AI-RFI-2025-1175.md | Eva Koebel | Individual | Eva Koebel, a graduating senior, is interested in the ethical and societal impacts of AI, specifically concerning its use in mental healthcare and the potential for bias and harm. She advocates for increased regulation of AI in healthcare settings. | - [§1: Document Header/Metadata] None stated for this section.<br>- [§2: Submitter Information] None stated for this section.<br>- [Section 3: General Comment/Response]<br>- AI algorithms have immense biases and discriminate based on those biases, leading to unequal treatment of patients.<br>- AI could undermine the benefits of person-to-person care in the medical field.<br>- Reliance on AI in mental healthcare raises ethical concerns regarding human autonomy.<br>- [§4: Closing Remarks] None stated for this section. | - [§1: Document Header/Metadata] None stated for this section.<br>- [§2: Submitter Information] None stated for this section.<br>- [Section 3: General Comment/Response]<br>- Increased regulation is needed to limit the usage of AI in certain fields, particularly in patient-doctor interactions.<br>- Keeping AI away from direct patient interactions is crucial to prevent potential harms.<br>- [§4: Closing Remarks] None stated for this section. |
| AI-RFI-2025-1176.md | Henry Amick | Individual | The submitter is a graduating high school senior concerned about the negative impacts of AI on math education and advocates for reduced AI accessibility in schools to protect the development of critical thinking and problem-solving skills in students. | - [§1: Document Metadata] None stated for this section.<br>- [§2: Comment Identification] None stated for this section.<br>- [§3: Submitter Information] None stated for this section.<br>- [Section 4: Comment Body]<br>- Heavy generative AI usage leads to a reduction in problem-solving ability and critical thinking skills in youth.<br>- Young people becoming dependent on AI assistance amplifies a culture that discourages sustained attention, complex processing, and deeper engagement. | - [§1: Document Metadata] None stated for this section.<br>- [§2: Comment Identification] None stated for this section.<br>- [§3: Submitter Information] None stated for this section.<br>- [Section 4: Comment Body]<br>- Reduction of AI accessibility in schools is paramount to supporting future generations of American citizens. |
| AI-RFI-2025-1177.md | Anna Bradley | Individual | Anna Bradley is a student with a recent research focus on the impact of generative AI on nursing and an interest in the administration's viewpoint on AI regulation. She believes AI has potential in healthcare but advocates for cautious implementation. | - [§1: Document Header/Metadata] None stated for this section.<br>- [§2: Comment Identification] None stated for this section.<br>- [§3: Submitter Information] None stated for this section.<br>- [Section 4: General Comment/Main Body]<br>- AI cannot adjust to many health issues at once.<br>- AI tools like ChatGPT take longer routes to solve problems.<br>- AI tools may advise expensive tests when not needed.<br>- AI tools performed worse than nurses in competitive problem-solving scenarios (taking longer to find resolutions).<br>- AI, despite advancements, will not meet the expectations needed for health and medicine. | - [§1: Document Header/Metadata] None stated for this section.<br>- [§2: Comment Identification] None stated for this section.<br>- [§3: Submitter Information] None stated for this section.<br>- [Section 4: General Comment/Main Body]<br>- AI should be advanced and utilized in a very cautious manner.<br>- AI should be used as an assistive tool, not a replacement for nurses.<br>- Focus AI implementation on reducing documentation time for nurses (specifically, leveraging it to lower the 26.2-41% time spent on documentation).<br>- Prioritize AI use as a technology assistant to support nurses rather than acting *as* a nurse. |
| AI-RFI-2025-1178.md | Myla Azen | Individual | Myla Azen is a graduating high school student interested in the potential for AI misuse against religious groups and advocates for regulation and preventative laws to ensure AI flourishes beneficially and protects fundamental rights. | - [§1: Document Header/Metadata] None stated for this section.<br>- [§2: Submitter Information] None stated for this section.<br>- [Section 3: General Comment/Response]<br>- Potential misuse of AI against religious groups globally.<br>- Vulnerability of religious groups to AI-powered surveillance and policing tactics.<br>- AI being weaponized against vulnerable populations, specifically citing the Uyghur Muslim population in China as an example of human rights violations under the guise of "anti-terrorism" sentiments. | - [§1: Document Header/Metadata] None stated for this section.<br>- [§2: Submitter Information] None stated for this section.<br>- [Section 3: General Comment/Response]<br>- Implementation of regulation and preventative laws to ensure AI flourishes beneficially.<br>- Measures to reduce the risks of AI being weaponized against vulnerable populations.<br>- Protection of not only religious freedoms but also the fundamental rights of all individuals through regulation. |
| AI-RFI-2025-1179.md | Greta O'Brien | Individual | Greta O'Brien is a high school student who has researched the impact of AI on high school girls’ basketball and is concerned about the potential for AI to fundamentally alter the nature of the sport, advocating for limits on AI development to preserve the game's integrity. | - [§1: Document Metadata/Header] None stated for this section.<br>- [§2: Submitter Identification & Context] AI is a powerful tool that can "take over" if not restricted; concern about the broad impact of AI regulation.<br>- [§3: Positive Impacts of AI in Basketball] None stated for this section.<br>- [§4: Concerns Regarding AI-Generated Referees] Introducing AI referees will shift the game from a “free, fun, exciting game” to one that is “highly calculated”; broader concern that if AI impacts something as small as high school basketball, it will impact many other aspects of life. | - [§1: Document Metadata/Header] None stated for this section.<br>- [§2: Submitter Identification & Context] There needs to be limits on AI abilities and enhancements.<br>- [§3: Positive Impacts of AI in Basketball] None stated for this section.<br>- [§4: Concerns Regarding AI-Generated Referees] Restrict AI development and abilities to avoid fundamentally changing the nature of the game and impacting other aspects of life. |
| AI-RFI-2025-1180.md | Ella Bounos | Individual | Ella Bounos is a student concerned about the impact of generative AI on artists and the potential for copyright infringement and economic harm due to the use of artists' styles without consent. She advocates for increased monitoring and regulation of AI technologies. | - [§1: Document Header/Metadata] None stated for this section.<br>- [§2: Comment Identification] None stated for this section.<br>- [§3: Submitter Information] None stated for this section.<br>- [Section 4: Comment Body]<br>- AI is "stealing" other people’s work.<br>- Potential copyright, patent, and trademark infringement related to AI creations.<br>- Artists' art styles are being used to train AI without their knowledge or consent (citing a 2022 case).<br>- Generative AI could put artists out of business. | - [§1: Document Header/Metadata] None stated for this section.<br>- [§2: Comment Identification] None stated for this section.<br>- [§3: Submitter Information] None stated for this section.<br>- [Section 4: Comment Body]<br>- Implement copyright infringement rules for AI.<br>- Increase the monitoring system for AI technologies. |
| AI-RFI-2025-1181.md | Vanessa Amayo | Individual | The submitter is a graduating high school student with a strong interest in the impact of generative AI on the music industry and a desire to see AI regulation protect human artists, particularly those with limited resources, while still allowing for AI’s positive applications in music creation and accessibility. | - Non-consensual AI usage could be socially and financially devastating for artists, especially small or independent artists.<br>- Using AI as a replacement for human artists for economic gain will harm human culture and joy.<br>- The potential for AI to have negative impacts on human artistry.<br>- The need for accountability from AI developers and the music industry. | - AI regulation must be consistent with existing policy, such as copyright law.<br>- Policies similar to Tennessee's ELVIS Act should be followed to protect artists from non-consensual AI usage.<br>- Policy makers must hold AI developers and the music industry accountable to protect human artists. |
| AI-RFI-2025-1182.md | SIFMA | Industry-Association | SIFMA represents broker-dealers, investment banks, and asset managers and advocates for policies that support the financial markets, including promoting innovation while avoiding unnecessary regulation that could harm competitiveness. They believe existing regulations are sufficient for AI and prioritize a risk-based approach. | - [§1: Document Header/Metadata] None stated for this section.<br>- [§2: Introduction & Background] Unnecessary laws and regulation on AI will have an irreversible negative impact on the competitiveness of US financial markets.<br>- [§3: Key Arguments (AI Benefits & Existing Regulation)] No novel risks associated with AI that are not already covered by existing laws and regulations.<br>- [§4: Need for Definition of AI] Defining AI is unnecessary because it is an evolving technology, and a technology-neutral approach is preferred.<br>- [§5: Firms' Internal Risk Management Frameworks] Firms effectively address AI-related risks through existing internal risk management frameworks.<br>- [§6: Policy Recommendations and Potential Gaps] Fragmented AI regulation (state laws, conflicting jurisdictions) could create compliance challenges and stifle innovation. Specific concerns about data privacy and copyright ownership.<br>- [§7: Conclusion] Overly restrictive regulations could stifle innovation and deter the adoption of new technologies.<br>- [§8: Appendix 1: Existing Policy Areas] None stated for this section.<br>- [§9: Contact Information] None stated for this section. | - [§1: Document Header/Metadata] None stated for this section.<br>- [§2: Introduction & Background] None stated for this section.<br>- [§3: Key Arguments (AI Benefits & Existing Regulation)] Continue to rely on existing laws and regulations and avoid unnecessary new rules.<br>- [§4: Need for Definition of AI] Do not adopt a precise definition of AI; maintain a technology-neutral approach.<br>- [§5: Firms' Internal Risk Management Frameworks] Continue to allow firms flexibility in addressing AI risks through existing frameworks.<br>- [Section 6: Policy Recommendations and Potential Gaps]<br>- Establish federal data privacy legislation with state preemption.<br>- Amend existing copyright laws to clarify ownership of AI-produced works.<br>- Work collaboratively with financial firms to understand AI use and identify any novel risks.<br>- [§7: Conclusion] Apply existing risk-based rules and guidance rather than creating new AI-specific rules.<br>- [§8: Appendix 1: Existing Policy Areas] None stated for this section.<br>- [§9: Contact Information] None stated for this section. |
| AI-RFI-2025-1183.md | Roberto Schaefer | Individual | The submitter is primarily concerned about the potential erosion of civil liberties and privacy due to the rapid and unregulated development and implementation of AI, and objects to the framing of AI development as a competition for global dominance, particularly with China. | - The use of any AI, generative or not, MUST be strictly regulated.<br>- A perceived "hysterical knee-jerk reaction" by the current administration towards worldwide domination, including specific examples like buying Greenland and annexing Canada, is a cause for concern.<br>- The potential stripping away of civil liberties under the guise of fear of China overtaking the US in AI development.<br>- The influence of tech giants' financial contributions on AI policy, leading to loosened protections for their own financial gain.<br>- Reliance on self-regulation by the tech industry is seen as inadequate and harmful to fundamental rights. | - AI must be regulated by a department of the government free from any financial interest. |
| AI-RFI-2025-1184.md | Michael Libbon | Individual | Michael Libbon is a student who has studied the impact of Generative AI on the banking community and believes in the progressive implementation of AI technology within the banking sector to improve transaction speeds and fraud detection. | - [§1: Submission Header/Metadata] None stated for this section.<br>- [§2: Submitter Information] None stated for this section.<br>- [§3: General Comment/Response Body] None stated for this section. | - [§1: Submission Header/Metadata] None stated for this section.<br>- [§2: Submitter Information] None stated for this section.<br>- [§3: General Comment/Response Body] None stated for this section. |
| AI-RFI-2025-1185.md | Grace Schmigel | Individual | Grace Schmigel is a high school student researching the impact of AI on Paleontology and Earth Sciences, and is generally optimistic about AI innovation, provided that worker protection and job security are prioritized in government regulation. | - [§1: Document Header/Metadata] None stated for this section.<br>- [§2: Comment Identification] None stated for this section.<br>- [§3: Submitter Information and Introduction] None stated for this section.<br>- [§4: Impact of AI on Paleontology - Job Displacement] AI replacing entire production teams involved in creating documentaries; AI physically replacing museum docents.<br>- [§5: Impact of AI on Paleontology - Misinformation] Potential for AI to generate or spread false or outdated information when used as a research tool due to flawed logic skills.<br>- [§6: Concluding Statement/Policy Preference] None stated for this section. | - [§1: Document Header/Metadata] None stated for this section.<br>- [§2: Comment Identification] None stated for this section.<br>- [§3: Submitter Information and Introduction] None stated for this section.<br>- [§4: Impact of AI on Paleontology - Job Displacement] None stated for this section.<br>- [§5: Impact of AI on Paleontology - Misinformation] Encouraging innovation may improve the logic skills of AI.<br>- [§6: Concluding Statement/Policy Preference] Government should prioritize the protection of workers and jobs when regulating AI. |
| AI-RFI-2025-1186.md | Veronica Garcia | Individual | Veronica Garcia is a high school student interested in the ethical implications of AI, specifically generative AI's impact on education and the balance between innovation and regulation within the AI industry. She expresses concern about the potential risks of deregulation and the overuse of AI by students. | - The administration's viewpoint on AI is too liberal in its deregulation approach.<br>- Complete deregulation of the AI industry is reckless and risks fostering malevolence and misuse.<br>- Deregulation could lead to emerging monopolies.<br>- Students freely accessing AI, particularly generative AI, is alarming.<br>- Generative AI is not inspiring innovation but rather causing students to over-rely on technology, hindering intellectual development.<br>- Unmonitored student access to AI is detrimental to the country's future. | - The administration needs to carefully monitor the emerging AI industry while still encouraging innovation.<br>- Regulation is necessary for nurturing the AI industry.<br>- The administration needs to address concerns regarding student access and use of AI. |
| AI-RFI-2025-1187.md | Zac Goldfain | Individual | Zac Goldfain, a high school student, expresses support for the current administration’s AI regulatory approach and highlights the benefits of AI in the sports industry, particularly regarding data collection, team improvement, athlete health and safety, and overall growth of American sports. | - [§1: RFI Metadata] None stated for this section.<br>- [§2: Submitter Information & General Comment Introduction] None stated for this section.<br>- [§3: Positive Viewpoint on Current AI Regulation] None stated for this section.<br>- [§4: AI Benefits in Sports Management - General] None stated for this section.<br>- [§5: AI & Athlete Health & Safety] None stated for this section. | - [§1: RFI Metadata] None stated for this section.<br>- [§2: Submitter Information & General Comment Introduction] None stated for this section.<br>- [§3: Positive Viewpoint on Current AI Regulation] Continue developing AI in the right direction (implicitly supports current policy).<br>- [§4: AI Benefits in Sports Management - General] None stated for this section.<br>- [§5: AI & Athlete Health & Safety] Continue to develop AI in the right direction to significantly help in the sports world (implicitly supports further AI development). |
| AI-RFI-2025-1188.md | Lexi Mannion | Individual | Lexi Mannion, a graduating high school senior, is interested in the societal implications of Generative AI, particularly its application in early childhood education, and advocates for a balanced approach to AI regulation that fosters innovation while ensuring responsible implementation and ethical considerations. | - [§1: Document Header/Metadata] None stated for this section.<br>- [§2: Submitter Information & General Comment Introduction] None stated for this section.<br>- [§3: AI in Education - Positive Potential] None stated for this section.<br>- [Section 4: Regulatory Gaps & Considerations]<br>- The Kids Online Safety Act does not address data collection practices of web service providers and educational institutions.<br>- Insufficient legislation to address the rapidly evolving data collection practices associated with AI integration.<br>- [§5: Concluding Remarks] None stated for this section. | - [§1: Document Header/Metadata] None stated for this section.<br>- [§2: Submitter Information & General Comment Introduction] None stated for this section.<br>- [§3: AI in Education - Positive Potential] None stated for this section.<br>- [Section 4: Regulatory Gaps & Considerations]<br>- Update U.S. legislation to keep pace with rapid technological advancements in AI.<br>- Foster ongoing dialogue between families and schools regarding AI integration to maximize benefits and minimize harm.<br>- [Section 5: Concluding Remarks]<br>- Balance innovation and regulation for responsible AI integration in education.<br>- Approach AI integration with a thoughtful and balanced perspective, guided by responsible regulation and ethical considerations. |
| AI-RFI-2025-1189.md | Katy St. Clair | Individual | Katy St. Clair is a student concerned about the potential for generative AI to undermine public trust in government through the spread of political misinformation and biased responses, particularly during election cycles. She believes increased regulation of AI is necessary to protect the integrity of the democratic process. | - [§1: Document Metadata] None stated for this section.<br>- [§2: Comment Identification] None stated for this section.<br>- [§3: Submitter Information] None stated for this section.<br>- [Section 4: Main Comment - Generative AI Regulation & Political Misinformation]<br>- Undermining public trust in government through the use of AI in political promotion.<br>- Bias in responses from at-home generative AI systems like Amazon Alexa and Google Home to political questions.<br>- Misleading use of AI-generated images in political contexts (specifically referencing the Trump example).<br>- Use of AI to create fake, misleading, and vulgar images of candidates by campaign supporters.<br>- The general dishonesty of using AI in political campaigns. | - [§1: Document Metadata] None stated for this section.<br>- [§2: Comment Identification] None stated for this section.<br>- [§3: Submitter Information] None stated for this section.<br>- [Section 4: Main Comment - Generative AI Regulation & Political Misinformation]<br>- Increased regulation of generative AI, particularly as it relates to political campaigns.<br>- Regulation requiring at-home AI systems to either decline political inquiries or provide a list of proven facts.<br>- Tighter regulations on image generation AI, potentially including restrictions on specific words and phrases. |
| AI-RFI-2025-1190.md | Sydney Savatt | Individual | Sydney Savatt is a high school student researching the impact of Generative AI in college sports recruiting and advocates for a balanced approach to AI regulation that encourages innovation while considering ethical concerns, based on her positive personal experience with AI tools in securing a softball scholarship. | - [§1: Document Metadata] None stated for this section.<br>- [§2: Submitter Identification] None stated for this section.<br>- [§3: General Comment/Introduction] Potential threat to the recruit-coach connection; risk of relying heavily on statistics instead of character and leadership abilities; concerns AI could replace human recruiters.<br>- [§4: AI's Positive Impact on Recruitment (Film/Highlight Tools)] None stated for this section.<br>- [§5: Personal Experience/Anecdote] None stated for this section.<br>- [§6: Conclusion/Restatement of Position] None stated for this section. | - [§1: Document Metadata] None stated for this section.<br>- [§2: Submitter Identification] None stated for this section.<br>- [§3: General Comment/Introduction] Encourage innovation while considering ethical concerns; promote responsible innovation and reduce potential risks.<br>- [§4: AI's Positive Impact on Recruitment (Film/Highlight Tools)] None stated for this section.<br>- [§5: Personal Experience/Anecdote] None stated for this section.<br>- [§6: Conclusion/Restatement of Position] Continue balancing innovation with ethical considerations; support the government's approach to pushing for progress while ensuring protection. |
| AI-RFI-2025-1191.md | Perry Velisaris | Individual | Perry Velisaris, a high school student, is interested in the application of generative AI to the field of Physical Therapy and believes current government policy is supportive of AI growth. He highlights the potential of devices like FOTO and SWORD to improve patient care and accessibility. | - [§1: Document Header/Metadata] None stated for this section.<br>- [§2: Comment Identification] None stated for this section.<br>- [§3: Submitter Information] None stated for this section.<br>- [§4: Introduction/Background] None stated for this section.<br>- [§5: Government AI Policy Observation] None stated for this section.<br>- [§6: Physical Therapy Application - FOTO] None stated for this section.<br>- [§7: Physical Therapy Application - SWORD] None stated for this section. | - [§1: Document Header/Metadata] None stated for this section.<br>- [§2: Comment Identification] None stated for this section.<br>- [§3: Submitter Information] None stated for this section.<br>- [§4: Introduction/Background] None stated for this section.<br>- [§5: Government AI Policy Observation] None stated for this section.<br>- [§6: Physical Therapy Application - FOTO] None stated for this section.<br>- [§7: Physical Therapy Application - SWORD] None stated for this section. |
| AI-RFI-2025-1192.md | Lucy Jacobs | Individual | Lucy Jacobs, a high school student, expresses concern that unregulated AI development may displace jobs in the television/film industry despite stated governmental goals of job creation, and advocates for a balanced approach with regulation to preserve human talent and integrity. | - [§1: Document Header/Metadata] None stated for this section.<br>- [§2: Comment Identification] None stated for this section.<br>- [§3: Submitter Information] The potential contradiction between the administration’s support for AI and its stated goal of creating jobs.<br>- [§4: Core Argument & Overall Position] AI may take more jobs than it creates, undermining job creation goals. The need for moderation and balance between human work and computer work.<br>- [§5: Examples of AI Misuse in Film] Productions are taking shortcuts by using AI (e.g., voice modulation in *Emilia Perez* and *The Brutalist*) instead of hiring human talent who are capable of performing the same tasks. This use of AI undermines the integrity of the work.<br>- [§6: Call for Regulation & Reiteration of Position] Lack of accountability in the use of AI in film/television will lead to more frequent misuse. | - [§1: Document Header/Metadata] None stated for this section.<br>- [§2: Comment Identification] None stated for this section.<br>- [§3: Submitter Information] None stated for this section.<br>- [§4: Core Argument & Overall Position] None stated for this section.<br>- [§5: Examples of AI Misuse in Film] None stated for this section.<br>- [§6: Call for Regulation & Reiteration of Position] Implement regulations to restore balance between human work and computer work, and preserve integrity in the film and television industries. Regulations should not hinder innovation but ensure accountability and prevent the displacement of human talent. |
| AI-RFI-2025-1193.md | Anonymous | Individual | The submitter is a high school student interested in the ethical implications of AI and believes in a balanced approach where AI innovation supports beneficial areas without disrupting communities that thrive on human interaction and physical growth, such as the wrestling community. They support the current administration's viewpoint on AI regulation. | - [§1: Document Header/Metadata] None stated for this section.<br>- [§2: Comment Identification] None stated for this section.<br>- [§3: Submitter Information] None stated for this section.<br>- [§4: General Comment/Response] The submitter expresses concern that holding back AI progress to preserve human control could be detrimental. They believe that AI is not universally appropriate and can remain in the "backseat" in certain contexts, such as the wrestling community. | - [§1: Document Header/Metadata] None stated for this section.<br>- [§2: Comment Identification] None stated for this section.<br>- [§3: Submitter Information] None stated for this section.<br>- [§4: General Comment/Response] The submitter implicitly recommends continuing the current administration's approach to AI regulation, which they view as beneficial. They suggest a situational approach to AI implementation, allowing it to progress in areas where it is needed while leaving other areas, like the wrestling community, undisturbed. They advocate for AI to be developed as a tool rather than a replacement for humans. |
| AI-RFI-2025-1194.md | William Onyshko | Individual | William Onyshko is a high school student interested in the integration of AI education into school curricula and believes AI should be viewed as a tool to enhance, not replace, human jobs. He has studied the impact of generative AI on the accounting community. | - [§1: Submission Metadata] None stated for this section.<br>- [§2: RFI Identification] None stated for this section.<br>- [§3: Submitter Information] None stated for this section.<br>- [§4: Comment/Response Content] AI has a high chance of taking jobs, but the administration's focus on not eliminating jobs is applauded. | - [§1: Submission Metadata] None stated for this section.<br>- [§2: RFI Identification] None stated for this section.<br>- [§3: Submitter Information] None stated for this section.<br>- [§4: Comment/Response Content] Integrate AI education more into schools, viewing AI as a tool and not a crutch. |
| AI-RFI-2025-1195.md | Scott Tuffiash | Individual | Scott Tuffiash, a high school teacher of Language Arts and Journalism, is interested in promoting human flourishing through responsible AI development and believes less regulation can foster innovation, while also expressing concern about ethical burdens and addictive design, particularly regarding younger consumers. | - [§1: Document Header/Metadata] None stated for this section.<br>- [§2: Submitter Information] None stated for this section.<br>- [§3: Introduction/Context] None stated for this section.<br>- [§4: Argument for Less Regulation] The primary concern is that less regulation places the burden of ethical innovation on the consumer instead of the producer.<br>- [§5: Concerns about Lack of Regulation & Ethical Burden] Potential negative impacts on the mental wellbeing and potentially the physical life of consumers due to a lack of regulation.<br>- [§6: Addictive Design & Age Vulnerability] The concern is that addictive design in AI products could harm consumers of all ages, especially those younger, and that it is difficult to reliably establish age-based distinctions for regulation. The lack of transparency surrounding addictive design qualities is also a concern.<br>- [§7: Call for Transparency & Policy Reconsideration] The concern is that a complete removal of content like the AI Bill of Rights would be detrimental and that more open debate and transparent information sharing are needed. | - [§1: Document Header/Metadata] None stated for this section.<br>- [§2: Submitter Information] None stated for this section.<br>- [§3: Introduction/Context] None stated for this section.<br>- [§4: Argument for Less Regulation] Promote experimentation of AI products in the free market through reduced regulation (Executive Order 14179 referenced).<br>- [§5: Concerns about Lack of Regulation & Ethical Burden] None stated for this section.<br>- [§6: Addictive Design & Age Vulnerability] Implement regulations requiring for-profit companies to transparently display addictive design qualities and suffer financial losses if they promote addictive design products.<br>- [§7: Call for Transparency & Policy Reconsideration] Re-open debate and policy change around AI regulation, including revisiting the AI Bill of Rights. Share information transparently, similar to the resources provided on President Trump's White House website: https://trumpwhitehouse.archives.gov/ai/ai-american-innovation/. |
| AI-RFI-2025-1197.md | Cassidy Johncour | Individual | The submitter is a high school student with a specific interest in the ethical and societal impacts of AI, particularly concerning job displacement and the influence of AI on faith. They express concern that lowering AI regulations to promote U.S. dominance may be detrimental. | - [§1: Document Metadata] None stated for this section.<br>- [§2: Comment Identification] None stated for this section.<br>- [§3: Submitter Information] None stated for this section.<br>- [Section 4: Main Comment]<br>- Reducing AI regulations will increase AI’s dominance, potentially leading to negative consequences through misuse.<br>- Job displacement due to AI is a significant concern.<br>- AI is infiltrating all aspects of life, including faith (example: Pepper the robot).<br>- AI tools may diminish human creativity (example: Alexandra Kirsch's experience as a writer).<br>- [§5: Conclusion] Disagreement with the administration’s current viewpoint on AI regulation. | - [§1: Document Metadata] None stated for this section.<br>- [§2: Comment Identification] None stated for this section.<br>- [§3: Submitter Information] None stated for this section.<br>- [§4: Main Comment] None stated for this section. (The text only expresses concerns, not specific recommendations.)<br>- [§5: Conclusion] None stated for this section. (The text only restates disagreement, not specific recommendations.) |
| AI-RFI-2025-1198.md | Natalie Meng | Individual | Natalie Meng is a high school student interested in the advancement of AI, particularly generative AI, and its application to healthcare and epidemiology. She believes removing barriers to AI development will benefit the US, but acknowledges associated risks like deepfakes. | - [§1: Administrative Metadata] None stated for this section.<br>- [§2: Comment Identification & Submitter Information] None stated for this section.<br>- [Section 3: General Comment/Executive Summary]<br>- Vulnerability to misuse of generative AI, specifically deepfakes, if government control and regulation are reduced. | - [§1: Administrative Metadata] None stated for this section.<br>- [§2: Comment Identification & Submitter Information] None stated for this section.<br>- [Section 3: General Comment/Executive Summary]<br>- Continue to allow for advancement of AI as opened by Executive Order 14179.<br>- Consider the risks of removing government control and regulation.<br>- Promote free development and efficient use of AI by competitive businesses, healthcare units, and individuals. |
| AI-RFI-2025-1202.md | R Street Institute | Advocacy/Think Tank | The R Street Institute is a nonpartisan public policy research organization focused on promoting free markets and limited, effective government, with a specific interest in cybersecurity and emerging threats related to AI. They advocate for policies that foster innovation while strengthening national security and economic growth. | - None Stated | - None Stated |
| AI-RFI-2025-1208.md | Andrew Crownover | Individual | The submitter is concerned with the fair compensation of data owners whose data is used to train AI models and opposes the unrestricted use of private property for AI development without licensing agreements. They believe tech companies have the financial capacity to pay for data licenses and are motivated by convenience rather than genuine economic disadvantage. | - [§1: Submission Metadata] None stated for this section.<br>- [§2: RFI Identification] None stated for this section.<br>- [§3: Submitter Information] None stated for this section.<br>- [Section 4: Comment]<br>- Tech companies are using data without paying for licenses.<br>- The claim that licensing data is too expensive is false, as deals have already been struck.<br>- Tech companies are prioritizing convenience over fair compensation and potentially damaging economic ecosystems.<br>- Individuals like Sam Altman are not accountable for the consequences of their actions.<br>- Private property rights should be protected from unrestricted use by Silicon Valley. | - [§1: Submission Metadata] None stated for this section.<br>- [§2: RFI Identification] None stated for this section.<br>- [§3: Submitter Information] None stated for this section.<br>- [Section 4: Comment]<br>- Tech companies should be required to pay to license the data they use for AI training.<br>- Policies should prevent tech companies from exploiting data without fair compensation.<br>- Policies should protect the economic ecosystems that could be harmed by unrestricted data use. |
| AI-RFI-2025-1209.md | Steven Zuber | Individual | Steven Zuber is concerned with the safe and beneficial development of AI, emphasizing the importance of alignment with human values, long-term safety considerations, and mitigating potential economic disruptions caused by AI-driven automation. He advocates for proactive planning and research to ensure AI serves human progress. | - [§1: Document Metadata/Header] None stated for this section.<br>- [§2: Submitter Information] None stated for this section.<br>- [§3: Introduction/Statement of Purpose] Potential for misaligned superintelligence and the risks associated with AI not being aligned with human values and long-term safety.<br>- [§4: AI Safety Concerns (Misalignment & Catastrophic Risks)] The possibility of misaligned superintelligence leading to catastrophic outcomes due to insufficient oversight or flawed design. Lack of control over advanced AI systems.<br>- [§5: Economic Impact of AI Automation] Large-scale job displacement leading to economic instability and social unrest. The speed of AI progress potentially outpacing the ability to adapt.<br>- [§6: Call to Action & Closing] Ensuring AI development prioritizes long-term safety and societal well-being. Potential existential risk if concerns are not taken seriously. | - [§1: Document Metadata/Header] None stated for this section.<br>- [§2: Submitter Information] None stated for this section.<br>- [§3: Introduction/Statement of Purpose] Guide AI development with careful, deliberate planning to ensure alignment with human values and long-term safety.<br>- [§4: AI Safety Concerns (Misalignment & Catastrophic Risks)] Prioritize technical research into AI alignment. Ensure AI systems remain interpretable and corrigible.<br>- [§5: Economic Impact of AI Automation] Explore strategies such as retraining programs and adjustments to labor laws to support displaced workers. Consider new economic models.<br>- [§6: Call to Action & Closing] Support rigorous research into AI alignment. Create regulatory frameworks to prevent reckless AI deployment. Prepare for the economic shifts that AI will bring. |
| AI-RFI-2025-1210.md | Mary Duncan | Individual | The submitter expresses strong opposition to AI and related technologies, believing they are harmful and exploitative, particularly towards artists and the environment. They advocate for human creativity and against the development of AI. | - [§1: Submission Metadata] None stated for this section.<br>- [§2: Comment Identification] None stated for this section.<br>- [§3: Submitter Information] None stated for this section.<br>- [Section 4: Comment Text]<br>- AI is a "sham" that spreads harmful disinformation.<br>- AI, NFTs, and related technologies will exploit normal citizens.<br>- AI siphons off creativity and hard work from writers, artists, and animators.<br>- AI development is linked to climate change and associated deaths/refugee crises. | - [§1: Submission Metadata] None stated for this section.<br>- [§2: Comment Identification] None stated for this section.<br>- [§3: Submitter Information] None stated for this section.<br>- [Section 4: Comment Text]<br>- Stop the development of AI ("STOP KILLING THE PLANET!!!").<br>- Support human art ("YES TO HUMAN ART, NO TO AI!!"). |
| AI-RFI-2025-1211.md | J U | Individual | The submitter is primarily interested in ensuring responsible AI development and deployment that protects consumers, artists, workers, and privacy, and avoids excessive energy consumption. They advocate for policies that prevent negative consequences of AI adoption. | - [§1: Submission Metadata] None stated for this section.<br>- [§2: Comment Identification] None stated for this section.<br>- [§3: Submitter Information] None stated for this section.<br>- [Section 4: General Comment]<br>- Excessive energy consumption by AI models and servers.<br>- Lack of consumer protection regarding AI use.<br>- Copyright infringement by AI models.<br>- Privacy violations due to AI training on personal data.<br>- Labor displacement due to companies replacing workers with AI "agents". | - [§1: Submission Metadata] None stated for this section.<br>- [§2: Comment Identification] None stated for this section.<br>- [§3: Submitter Information] None stated for this section.<br>- [Section 4: General Comment]<br>- Prioritize measures to limit the energy consumption of AI systems.<br>- Implement consumer protection policies, including opt-out options for AI use.<br>- Respect copyright laws to prevent AI models from infringing on artists’ rights.<br>- Ensure privacy protections to prevent the use of personal data in AI training.<br>- Provide labor protections to prevent companies from replacing American workers with inadequately performing AI systems. |
| AI-RFI-2025-1212.md | Brynne Overton | Individual | The submitter expresses concern about the ethical and legal implications of AI development, specifically regarding copyright infringement and the competitive disadvantage faced by small businesses and artists due to competitors' AI practices. They advocate for increased regulation of AI. | - Lack of transparency regarding the AI Action Plan.<br>- Cole's (presumably a competitor) is "kicking our asses at AI" suggesting a competitive disadvantage.<br>- Use of "ethical datasets" by competitors is highlighted, possibly implying concerns about fairness or source of data.<br>- AI development "stepping on the copywritten work of those who can't afford to before" – copyright infringement concerns.<br>- The practice is considered "deeply unethical" and "illegal."<br>- Potential harm to small businesses and artists due to AI development.<br>- The submitter believes AI should be regulated *more*, not less. | - Increase regulation of AI.<br>- More transparency into the details of the AI Action Plan. |
| AI-RFI-2025-1213.md | Marla Barker | Individual | Marla Barker expresses strong opposition to generative AI, viewing it as harmful corporate malfeasance that exploits artists, pollutes information, and negatively impacts the environment, advocating for a complete ban on its development and use. | - [§1: Document Metadata] None stated for this section.<br>- [Section 2: Initial Statement & Core Argument]<br>- Generative AI is corporate malfeasance.<br>- Theft of work from working artists with inadequate compensation.<br>- Complicates electronic life.<br>- Inaccuracies and untrustworthiness of generated content.<br>- [Section 3: Elaboration of Negative Impacts]<br>- Frequent errors and “hallucinations” in generated responses (particularly in healthcare and education).<br>- Pollution of research with false information.<br>- Lack of creative ability or emotional depth.<br>- Inability to understand or share genuine experiences.<br>- Reduction of the value and impact of human art and writing.<br>- [Section 4: Economic & Environmental Concerns]<br>- High financial cost and wasteful expenditure of resources.<br>- Unsustainable consumption of water, fuel, clean air, data, and electricity.<br>- Companies are shifting strategies indicating a lack of long-term viability.<br>- [Section 5: Call to Action & Concluding Remarks]<br>- Generative AI is a threat to humanity and the environment.<br>- Contributes to climate change. | - [§1: Document Metadata] None stated for this section.<br>- [§2: Initial Statement & Core Argument] None stated for this section.<br>- [§3: Elaboration of Negative Impacts] None stated for this section.<br>- [§4: Economic & Environmental Concerns] None stated for this section.<br>- [Section 5: Call to Action & Concluding Remarks]<br>- Complete ban on generative AI. |
| AI-RFI-2025-1214.md | Charles Slucher | Individual | The submitter is concerned about the potential negative societal impacts of unchecked AI development, particularly regarding cybersecurity, fraud, domestic terrorism, labor practices, and undue influence of powerful lobbyists, and advocates for proactive legal and ethical safeguards to protect citizens. | - [§1: Submission Metadata] None stated for this section.<br>- [§2: Comment Context] None stated for this section.<br>- [§3: Submitter Information] None stated for this section.<br>- [Section 4: General Comment]<br>- Cybersecurity risks<br>- Fraud<br>- Domestic terrorism<br>- Lack of proactive legal and ethical guidelines (need for guidelines *before* disasters occur)<br>- Government changing laws to favor lobbyists instead of citizens<br>- Exploitation of labor by wealthy investors in the technology sector<br>- Displacement of American workers | - [§1: Submission Metadata] None stated for this section.<br>- [§2: Comment Context] None stated for this section.<br>- [§3: Submitter Information] None stated for this section.<br>- [Section 4: General Comment]<br>- Enforce existing laws to protect citizens.<br>- Develop and implement proactive legal and ethical guidelines for AI.<br>- Prevent government from changing laws to benefit powerful lobbyists.<br>- Address the exploitation of labor in the AI sector and protect American workers. |
| AI-RFI-2025-1216.md | Jim Cover | Individual | The submitter is interested in ensuring the responsible development and deployment of AI, with a particular focus on open source models, data accuracy, privacy protection, and safety measures to prevent harmful outcomes. They believe open source collaboration is key to mitigating bias and maintaining control over AI systems. | - [§1: Document Header/Metadata] None stated for this section.<br>- [§2: RFI Reference] None stated for this section.<br>- [§3: Submitter Information] None stated for this section.<br>- [Section 4: General Comment]<br>- Bias in massive media and social media training data.<br>- Risk of manipulated outcomes appearing accurate.<br>- Privacy concerns related to AI systems.<br>- Safety risks of AI systems becoming rogue or threatening. | - [§1: Document Header/Metadata] None stated for this section.<br>- [§2: RFI Reference] None stated for this section.<br>- [§3: Submitter Information] None stated for this section.<br>- [Section 4: General Comment]<br>- Develop a true open source AI.<br>- Dedicated teams should guide data and algorithm use for AI training.<br>- Implement safety measures or the ability to "unplug" or turn off AI systems that pose a threat. |
| AI-RFI-2025-1217.md | Nabeel Bacchus | Individual | The submitter's interest is simply to express opposition to the proposed AI Action Plan, with no further mission or focus evident from the text. | - The submitter does NOT support the proposed AI Action Plan. | - None Stated |
| AI-RFI-2025-1220.md | Tabore Info Tech Inc | Industry-Startup (Based on the name "Info Tech Inc" and the focus on competitive advantage and cybersecurity risks, suggesting a for-profit technology company likely not a very large one.) | Tabore Info Tech Inc. is interested in the responsible development and deployment of AI, with a focus on mitigating risks to intellectual property, reputation, and cybersecurity, and ensuring global compliance in the AI landscape. They also emphasize the importance of competency development and modernizing data infrastructure. | - [§1: Submission Metadata] None stated for this section.<br>- [§2: General Comment] Irresponsible and unethical use of AI and Generative AI poses high risks alongside benefits, and these risks are likely to amplify with wider adoption. Risks and Threats of AI need careful management.<br>- [§3: Regulation and Governance (Repeated)] Irresponsible and unethical use of AI and Generative AI poses high risks alongside benefits, and these risks are likely to amplify with wider adoption. Risks and Threats of AI need careful management.<br>- [Section 4: Risks Associated with AI]<br>- Accidental inclusion of intellectual property in AI training data leading to erosion of competitive advantage.<br>- Negative impact of generated deepfakes on businesses, society, and politics.<br>- Creation of abusive fraudulent content and malware presenting cybersecurity risks.<br>- [§5: Risks Mitigation with Governance] None stated for this section. | - [§1: Submission Metadata] None stated for this section.<br>- [§2: General Comment] None stated for this section.<br>- [§3: Regulation and Governance (Repeated)] None stated for this section.<br>- [§4: Risks Associated with AI] None stated for this section.<br>- [Section 5: Risks Mitigation with Governance]<br>- Develop global AI compliance view and collaborate with regulators.<br>- Monitor compliance measures.<br>- Establish AI governance and ethics office.<br>- Implement security and privacy controls.<br>- Conduct model audits for robustness.<br>- Upskill employees and the general public with personalized training and workshops.<br>- Modernize data management and analytics services, including upgrading IT infrastructure and legacy data platforms to Cloud-based solutions. |
| AI-RFI-2025-1221.md | Tyler Beckett | Individual | The submitter is concerned with the negative externalities of AI development, specifically its environmental impact and the lack of accountability for AI-driven decisions, and advocates for responsible AI use and public safeguards. | - [§1: Document Header/Metadata] None stated for this section.<br>- [§2: Comment Identification] None stated for this section.<br>- [§3: Submitter Information] None stated for this section.<br>- [Section 4: General Comment]<br>- Extreme energy consumption of AI computation.<br>- Environmental fallout from AI computation.<br>- Consequences of unscrupulous AI expansion.<br>- Lack of accountability for AI decision-making.<br>- Risks of outsourced decision-making to flawed algorithms. | - [§1: Document Header/Metadata] None stated for this section.<br>- [§2: Comment Identification] None stated for this section.<br>- [§3: Submitter Information] None stated for this section.<br>- [Section 4: General Comment]<br>- Require companies providing AI computation to pay for secondary costs (energy consumption, environmental fallout).<br>- Reign in "heedless actors" to prevent unscrupulous expansion.<br>- Extensive work on responsible AI use via public education campaigns.<br>- Enact laws preemptively safeguarding Americans from flawed algorithms.<br>- Establish the standard "A computer cannot be held accountable; therefore a computer must never make management decisions" and enforce it. |
| AI-RFI-2025-1224.md | Ian Minor | Individual | Ian Minor is a software engineer concerned about the unreliability of AI models, the potential for misuse (specifically unaccountable rubber-stamping and plagiarism), and the negative impact of current AI development practices on American intellectual property and small businesses/creatives. | - [§1: Document Header/Metadata] None stated for this section.<br>- [§2: Submitter Information & General Comment Introduction] Revocation of AI regulations is a concern; the probabilistic nature of AI makes it unreliable for reasoning or factual recall.<br>- [§3: Critique of AI Reliability & Use Cases] AI models are deeply unreliable due to their probabilistic nature; potential for unaccountable rubber-stamping; AI facilitates plagiarism laundering and theft of labor from American artists.<br>- [§4: Critique of American AI Development Strategy] American AI development struggles are due to mismanagement and venture-capitalist funding practices, not regulation; companies prioritize bigger models over efficiency; hypocrisy in the administration's actions.<br>- [§5: Concluding Statement/Call to Action] Disappointment with the administration’s approach and concern for the impact on small business owners and creatives. | - [§1: Document Header/Metadata] None stated for this section.<br>- [§2: Submitter Information & General Comment Introduction] None stated for this section.<br>- [§3: Critique of AI Reliability & Use Cases] None stated for this section.<br>- [§4: Critique of American AI Development Strategy] None stated for this section.<br>- [§5: Concluding Statement/Call to Action] Reinstatement of protections for small business owners and creatives. |
| AI-RFI-2025-1225.md | Modern Logic, LLC | Industry-Startup | Modern Logic, LLC is a digital technology company focused on advanced technologies like AI, advocating for its development through public/private partnerships and a balanced regulatory approach that supports both economic growth and societal needs. They prioritize pragmatic regulation and collaboration between government, businesses, and universities. | - [§1: Document Header/Metadata] None stated for this section.<br>- [§2: Submitter Information] None stated for this section.<br>- [§3: General Comment/Introduction] The need for public funding of re-education programs, workforce preparation/retraining, and safety support to mitigate risks from poorly tested technology. Potential negative impacts of AI-driven transition on the population.<br>- [§4: Regulatory Approach Advocacy] Regulating the technology itself (e.g., LLMs) is likely to fail due to the rapid pace of advancement. Overregulation of less mission-critical use cases could stifle innovation.<br>- [§5: Call for Collaboration & Disclaimer] None stated for this section. | - [§1: Document Header/Metadata] None stated for this section.<br>- [§2: Submitter Information] None stated for this section.<br>- [§3: General Comment/Introduction] Support public/private partnerships for AI development. Invest in re-education programs and workforce retraining initiatives.<br>- [§4: Regulatory Approach Advocacy] Regulate the *use* of AI rather than the technology itself. Focus regulatory scrutiny on mission-critical and life-critical applications. Implement moderate, meaningful, and pragmatic regulation.<br>- [§5: Call for Collaboration & Disclaimer] Foster collaboration between government, private businesses, and universities. |
| AI-RFI-2025-1226.md | Tai Walker | Individual | The submitter is concerned about the potential negative impacts of expanded AI funding on established copyright and privacy laws and expresses a desire to protect the rights of American citizens. They appear to be an individual focused on the legal and ethical implications of AI development. | - [§1: Submission Metadata] None stated for this section.<br>- [§2: RFI Context] None stated for this section.<br>- [§3: Submitter Information] None stated for this section.<br>- [§4: General Comment] Erosion of longstanding copyright and privacy laws due to the proposed AI funding plan. | - [§1: Submission Metadata] None stated for this section.<br>- [§2: RFI Context] None stated for this section.<br>- [§3: Submitter Information] None stated for this section.<br>- [§4: General Comment] Strongly urges against the current plan to expand AI funding. |
| AI-RFI-2025-1227.md | Charamath | Individual | The submitter is concerned about the potential negative impacts of preferential treatment given to a specific AI company (likely OpenAI) and advocates for supporting the innovators that company is allegedly exploiting, believing that current investment isn't translating to valuable progress. | - The AI Action Plan shows short-sightedness and a lack of robust research.<br>- The plan favors a single major AI company at the expense of others.<br>- The favored company has a history of legal issues, including lawsuits alleging theft from hundreds of thousands of citizens.<br>- The company consistently fails to achieve stated goals for general artificial intelligence and frequently changes its definition of it.<br>- The company has not demonstrated profitability despite significant investment.<br>- The company's primary product (a chatbot) is seen as over-hyped and detrimental to user experiences, leading to increased negative sentiment towards AI.<br>- Preferential treatment could encourage the departure of talented individuals from the USA. | - Do not provide preferential treatment to the specific AI company in question.<br>- Support the individuals and ideas that this company is allegedly attempting to "rip off." |
| AI-RFI-2025-1229.md | Ryan DiGiovanni | Individual | The submitter expresses a strong negative opinion toward AI technology, believing it provides no benefit to the American people and serves primarily to benefit large corporations at the expense of copyright protections and foundational skills. Their primary interest appears to be opposing the development and empowerment of AI models. | - [§1: Document Header/Metadata] None stated for this section.<br>- [§2: RFI Context] None stated for this section.<br>- [§3: Submitter Information] None stated for this section.<br>- [Section 4: General Comment]<br>- AI is a frivolous technology providing no material benefit to the American people.<br>- Removing "Unnecessary burdensome requirements" will gut copyright protections.<br>- Empowering AI models will result in unprecedented misinformation campaigns.<br>- AI development will cause catastrophic decay in foundational skills of students.<br>- Granting special privileges to corporations is undesirable. | - [§1: Document Header/Metadata] None stated for this section.<br>- [§2: RFI Context] None stated for this section.<br>- [§3: Submitter Information] None stated for this section.<br>- [§4: General Comment] None stated for this section. |
| AI-RFI-2025-1230.md | Olive Sparrow | Individual | The submitter expresses a strong concern about the potential negative impact of the AI Action Plan on human creativity and artistic endeavors, and a desire to protect the livelihoods and purpose of artists, writers, and makers. | - [§1: Submission Header/Metadata] None stated for this section.<br>- [§2: RFI Identification] None stated for this section.<br>- [§3: Submitter Information] None stated for this section.<br>- [Section 4: General Comment/Response]<br>- The AI Action Plan will kill human creativity.<br>- The plan threatens a way of life that has persisted for thousands of years.<br>- Human-created art will be replaced by machine-generated content.<br>- AI creators will benefit at the expense of human artists, who will be forced to work to exhaustion. | - [§1: Submission Header/Metadata] None stated for this section.<br>- [§2: RFI Identification] None stated for this section.<br>- [§3: Submitter Information] None stated for this section.<br>- [Section 4: General Comment/Response]<br>- DO NOT LET THIS PASS – a direct plea to halt the AI Action Plan.<br>- The implicit recommendation is to reconsider or abandon the plan altogether. |
| AI-RFI-2025-1231.md | sam m | Individual | The submitter expresses a concern regarding the ethical and legal implications of using copyrighted and unethical material in AI model training. Their interest lies in responsible AI development practices. | - [§1: Submission Header] None stated for this section.<br>- [§2: RFI Identification] None stated for this section.<br>- [§3: Comment Context] None stated for this section.<br>- [§4: Submitter Information] Concerns about the use of copyrighted and unethical material to train AI models. | - [§1: Submission Header] None stated for this section.<br>- [§2: RFI Identification] None stated for this section.<br>- [§3: Comment Context] None stated for this section.<br>- [§4: Submitter Information] No explicit policy recommendations are made, only a negative statement against using copyrighted and unethical material. |
| AI-RFI-2025-1232.md | Patrick Sinnott | Individual | The submitter is concerned about the negative impact of current AI technology on copyright law, cultural dominance in the entertainment industry, and the efficient allocation of investment capital. They appear to oppose weakening copyright law to support the AI industry. | - [§1: Submission Metadata] None stated for this section.<br>- [§2: Comment Context] None stated for this section.<br>- [Section 3: General Comment]<br>- AI technology is a "copyright laundering machine."<br>- AI has been "unable to deliver on its lofty promises."<br>- Weakening copyright law to support AI is detrimental.<br>- Supporting AI will weaken the United States’ cultural dominance in the entertainment industry.<br>- Supporting AI will "burn valuable investment capital."<br>- [§4: Submitter Information] None stated for this section. | - [§1: Submission Metadata] None stated for this section.<br>- [§2: Comment Context] None stated for this section.<br>- [Section 3: General Comment]<br>- Do not weaken copyright law to support the AI industry.<br>- [§4: Submitter Information] None stated for this section. |
| AI-RFI-2025-1234.md | Ash Lyons | Individual | The submitter is concerned with the ethical implications of AI development, specifically the exploitation of creators' work for training AI models without consent and the potential for increased misinformation. They advocate for regulations prioritizing creators' rights and ethical sourcing of data. | - [§1: Document Header/Metadata] None stated for this section.<br>- [Section 2: General Comment]<br>- Exploitation of artists, writers, and creators' work for AI training without permission.<br>- AI models are trained on “stolen work”.<br>- Prioritization of profit over ethical considerations and the value of creators' labor.<br>- The potential for increased misinformation and the worsening of an already problematic online climate.<br>- The faulty, biased, and immoral creation of AI and its impact on education statistics.<br>- [§3: Submitter Information] None stated for this section. | - [§1: Document Header/Metadata] None stated for this section.<br>- [Section 2: General Comment]<br>- Regulations requiring ethical sourcing of training data with express, written consent from original creators.<br>- More regulations for AI development overall.<br>- [§3: Submitter Information] None stated for this section. |
| AI-RFI-2025-1236.md | Anonymous | Individual | The submitter is concerned about the potential risks of unregulated generative AI, particularly regarding national security, adherence to existing laws, and the erosion of taxpayer and worker protections. They advocate for standard regulation and preventing preferential treatment for AI technologies. | - [§1: Document Header/Metadata] None stated for this section.<br>- [§2: Comment Identification] None stated for this section.<br>- [§3: Submitter Information] None stated for this section.<br>- [Section 4: General Comment]<br>- Using generative AI for functions like national security without rules or regulation poses a disaster risk.<br>- OpenAI and Deepseek models may resort to unethical or illegal behavior ("cheating" or "breaking the rules").<br>- Exceptions to copyright, private, and regulatory laws for AI are inappropriate.<br>- Generative AI should not receive exceptional treatment above the law. | - [§1: Document Header/Metadata] None stated for this section.<br>- [§2: Comment Identification] None stated for this section.<br>- [§3: Submitter Information] None stated for this section.<br>- [Section 4: General Comment]<br>- Regulate generative AI to prevent it from spiraling out of control.<br>- Enforce rules and regulations on the use of generative AI, especially for national security applications.<br>- Do not grant exceptions to existing laws for generative AI technologies.<br>- Treat generative AI under the same legal framework as other technologies. |
| AI-RFI-2025-1237.md | Blackford Middleton | Professional-Society/Advocacy/Think Tank (based on expertise demonstrated and focus on policy) | Blackford Middleton advocates for responsible AI integration within the healthcare sector, emphasizing multi-level governance, human oversight, explainability, and curated knowledge sources to ensure safety, effectiveness, and trust in AI systems. | - [Section 1: Document Header/Metadata]** None stated for this section.<br>- [Section 2: Executive Summary]** Lack of a multi-level AI governance framework; insufficient post-market surveillance mechanisms; insufficient human oversight; lack of explainable AI; inadequate integration of curated knowledge sources.<br>- [Section 3: Introduction]** Need for a robust and effective national AI strategy in healthcare.<br>- [Section 4: Foundational Imperative for Multi-Level AI Governance]** Absence of clear regulatory frameworks; immaturity of existing governance structures; inconsistencies in application of governance; lack of a centralized federal approach; potential for biases; lack of trust from stakeholders.<br>- [Section 5: Essential Roles of Human Oversight in AI-Driven Healthcare]** Risk of errors without human oversight; potential for algorithmic bias; the importance of ethical decision-making; the need for accountability.<br>- [Section 6: The Necessity for Explainable AI Recommendations in Clinical Practice]** The “black box” problem with advanced AI models; lack of trust among clinicians without understanding AI reasoning; challenges in deploying XAI solutions; trade-off between accuracy and interpretability; legal and regulatory compliance concerns.<br>- [Section 7: The Strategic Importance of Integrating Curated Knowledge Sources to Optimize AI Performance for Licensed Clinicians]** Potential for incorrect or nonsensical outputs (“hallucinations”); need for high-quality, verified information; risk of data poisoning; reliance on outdated information.<br>- [Section 8: Navigating the Regulatory Landscape for AI in US Healthcare]** Need for a flexible and adaptive regulatory framework; complexities of regulating LLMs; risks associated with misinformation and biased outputs.<br>- [Section 9: Conclusion and Recommendations]** Lack of comprehensive federal framework, insufficient post-market surveillance, need for clear roles of agencies and standardization, and risks of deploying AI in high-stakes scenarios. | - [Section 1: Document Header/Metadata]** None stated for this section.<br>- [Section 2: Executive Summary]** Establish a clear multi-level governance structure; mandate comprehensive post-market surveillance; emphasize human oversight; promote the development and deployment of explainable AI; strategically integrate curated knowledge sources; ensure regulatory alignment.<br>- [Section 3: Introduction]** None stated for this section.<br>- [Section 4: Foundational Imperative for Multi-Level AI Governance]** Develop a well-defined and adaptable AI governance framework operating cohesively across local, regional, and federal levels; Establish interoperability standards at the federal level; Delineate clear responsibilities and jurisdictional authority across federal agencies, state and local governments, and organizations involved in AI development and deployment.<br>- [Section 5: Essential Roles of Human Oversight in AI-Driven Healthcare]** Incorporate human intelligence and judgment (HITL) throughout the AI lifecycle; ensure ethical decision-making and accountability; prioritize human oversight at critical junctures; involve patients in governance.<br>- [Section 6: The Necessity for Explainable AI Recommendations in Clinical Practice]** Make AI decision-making processes transparent; foster trust among clinicians.<br>- [Section 7: The Strategic Importance of Integrating Curated Knowledge Sources to Optimize AI Performance for Licensed Clinicians]** Leverage high-quality, verified information; facilitate automated updates; improve efficiency of knowledge retrieval.<br>- [Section 8: Navigating the Regulatory Landscape for AI in US Healthcare]** Develop a flexible and adaptive regulatory framework; address the unique challenges of LLMs; ensure safety and accuracy.<br>- [Section 9: Conclusion and Recommendations]<br>- Establish a Clear Federal AI Governance Framework for Healthcare:** Define roles, responsibilities, and jurisdictional authority of federal agencies (FDA, HHS, ONC, NIST, new AI oversight body); address pre-market evaluation, post-market surveillance, data privacy, algorithmic bias, liability, and LLMs.<br>- Develop and Mandate Standards for Post-Market Surveillance of Healthcare AI:** Create mandatory reporting requirements for adverse events; standardize definitions of “adverse event” and “near miss”; implement protocols for continuous performance monitoring.<br>- Integrate Curated Knowledge Sources:** Ensure access to reliable and up-to-date medical knowledge.<br>- Prioritize Ethical Considerations and Human Oversight:** Establish guidelines for ethical decision-making, accountability, and patient involvement.<br>- Address Legal and Regulatory Compliance:** Ensure compliance with data privacy regulations and liability concerns.<br>- Promote Transparency and Explainability:** Make AI decision-making processes transparent and interpretable. |
| AI-RFI-2025-1239.md | Joseph Bleau | Individual | The submitter is interested in ensuring that AI development, particularly Large Language Models (LLMs), benefits the American public and is not solely for private corporate gain, with a strong emphasis on open access and transparency. They advocate for public ownership of AI technologies trained on publicly contributed data. | - [§1: Document Header/Metadata] None stated for this section.<br>- [§2: RFI Identification] None stated for this section.<br>- [§3: Submitter Information] None stated for this section.<br>- [Section 4: General Comment]<br>- Blatant disregard for copyright law in AI development.<br>- Private corporations should not be the primary beneficiaries of AI advancements.<br>- Lack of transparency in data usage for LLM training. | - [§1: Document Header/Metadata] None stated for this section.<br>- [§2: RFI Identification] None stated for this section.<br>- [§3: Submitter Information] None stated for this section.<br>- [Section 4: General Comment]<br>- LLMs trained on indiscriminate data should be part of a public works project.<br>- Training data should be publicly disclosed.<br>- Models and their weights should be open source.<br>- Training methods and source code must be open source.<br>- Reject any plan that prioritizes corporate benefits over the interests of the American people. |
| AI-RFI-2025-1240.md | Diego Bustamante | Individual | The submitter expresses strong opposition to AI technology, viewing it as harmful to creators and undesirable except for large technology companies. Their primary interest appears to be protecting the rights of writers, coders, and artists from perceived copyright violations by AI. | - [§1: Document Metadata] None stated for this section.<br>- [§2: RFI Reference] None stated for this section.<br>- [§3: Submitter Information] None stated for this section.<br>- [Section 4: General Comment]<br>- AI technology is characterized as “AI slop” and “useless.”<br>- The technology violates copyright and intellectual property rights of writers, coders, artists, and others.<br>- It is unwanted by the general public, except for "big tech." | - [§1: Document Metadata] None stated for this section.<br>- [§2: RFI Reference] None stated for this section.<br>- [§3: Submitter Information] None stated for this section.<br>- [Section 4: General Comment]<br>- The technology should not have any legal protection. |
| AI-RFI-2025-1242.md | Private Citizen | Individual | The submitter appears to be a concerned citizen expressing strong disapproval of the current administration's policies and actions, specifically related to their perceived lack of support for the American people and potential dismantling of democratic governance. Their interest lies in holding the administration accountable for policies they deem detrimental. | - [§1: Submission Header] None stated for this section.<br>- [§2: RFI Identification] None stated for this section.<br>- [§3: Submitter Information] None stated for this section.<br>- [§4: General Comment] The current administration is acting selfishly and only for the benefit of the elite, not the American people. Executive orders are perceived as intentionally destructive to a government “for the people”. The submitter expresses a desire for global legal repercussions against the administration. | - [§1: Submission Header] None stated for this section.<br>- [§2: RFI Identification] None stated for this section.<br>- [§3: Submitter Information] None stated for this section.<br>- [§4: General Comment] The submitter implicitly recommends that the administration change its policies to benefit the American people and cease actions perceived as destructive to democratic governance. They also recommend holding the administration accountable through global legal means. |
| AI-RFI-2025-1243.md | Lorinda Tomko | Individual | Lorinda Tomko expresses concern over the potential negative impacts of generative AI (GenAI) on energy infrastructure, data privacy, copyright, and the spread of misinformation, and advocates for a cautious approach to its development and deployment. She is also a practitioner in fields impacted by and utilizing AI. | - Massive energy consumption of AI data centers and potential overburdening of the power grid.<br>- Copyright infringement facilitated by GenAI models.<br>- Security weaknesses in handling private data.<br>- Lack of economic justification for regulatory exemptions for GenAI companies.<br>- GenAI's tendency to create and spread misinformation due to its lack of fact-checking capabilities.<br>- Inaccurate claims made by GenAI salespeople regarding the system's capabilities.<br>- Overhyped nature of AI innovation, drawing parallels to blockchain and NFT booms. | - Do not prioritize AI data centers in energy usage allocation.<br>- Do not grant sweeping regulatory exemptions from data privacy laws or copyright infringement to GenAI companies.<br>- Proceed cautiously with the development and deployment of GenAI, particularly LLMs, until its capabilities and limitations are better understood. |
| AI-RFI-2025-1244.md | Jameice Williams | Individual | The submitter expresses strong opposition to the development and embrace of Artificial Intelligence, primarily due to its negative environmental impact (water and electricity consumption) and perceived lack of societal usefulness. They believe it exacerbates climate problems and is based on unrealistic expectations. | - [§1: Submission Header] None stated for this section.<br>- [Section 2: General Comment]<br>- Negative environmental impact – high water and electricity consumption.<br>- AI routinely lies.<br>- AI produces no original output.<br>- AI is functionally useless.<br>- Embracing AI is detrimental during a climate collapse.<br>- [§3: Submitter Information] None stated for this section. | - [§1: Submission Header] None stated for this section.<br>- [§2: General Comment] None stated for this section. (The comment is purely critical and does not offer explicit recommendations.)<br>- [§3: Submitter Information] None stated for this section. |
| AI-RFI-2025-1246.md | Joshua Segui | Individual | The submitter expresses strong opposition to the implementation of AI within government processes and advocates for increased staffing and traditional administrative methods to improve efficiency. They believe AI will harm government operations. | - [§1: Document Header/Metadata] None stated for this section.<br>- [§2: Comment Identification] None stated for this section.<br>- [§3: Submitter Information] None stated for this section.<br>- [Section 4: General Comment/Response]<br>- Increased errors in evaluations.<br>- Impediment and destruction of government processes.<br>- Decimation of the federal government workforce.<br>- AI’s failure is being widely reported.<br>- Poor data leads to poor results. | - [§1: Document Header/Metadata] None stated for this section.<br>- [§2: Comment Identification] None stated for this section.<br>- [§3: Submitter Information] None stated for this section.<br>- [Section 4: General Comment/Response]<br>- Abandon the use of machine learning in government.<br>- Properly staff agencies and departments.<br>- Focus on adequate documentation.<br>- Utilize technology to *complement* (not supplant) processes for simple and repetitive tasks. |
| AI-RFI-2025-1248.md | Margaret Silvers | Individual | The submitter expresses concerns about the ethical, legal, and environmental implications of generative LLM technology and advocates for responsible development and regulation of this technology to protect human safety, intellectual property, and the climate. | - [§1: Document Header/Metadata] None stated for this section.<br>- [§2: RFI Context] None stated for this section.<br>- [Section 3: General Comment]<br>- Training LLMs on copyrighted data without permission and fair payment.<br>- Use of LLMs without human supervision and fact-checking due to inaccuracies and fabricated information.<br>- Environmental costs associated with LLM training and use, specifically energy consumption and water usage.<br>- Potential for LLMs to be trained on stolen data or Child Sexual Abuse Material (CSAM).<br>- Unethical use of LLMs and their potential to replace human labor and creativity.<br>- Further damage to the climate caused by LLM technology. | - [§1: Document Header/Metadata] None stated for this section.<br>- [§2: RFI Context] None stated for this section.<br>- [Section 3: General Comment]<br>- Require permission and fair payment for copyrighted data used in LLM training.<br>- Mandate human supervision and fact-checking for LLM outputs.<br>- Mitigate environmental costs through clean energy and improved cooling technology.<br>- Strictly regulate LLMs to prevent training on stolen data or CSAM.<br>- Prevent unethical LLM use and displacement of human labor and creativity.<br>- Ensure LLMs do not further damage the climate. |
| AI-RFI-2025-1249.md | Charlie Garza | Individual | The submitter is a creative professional (along with a group of friends) deeply concerned about the negative economic impact and ethical implications of generative AI, particularly its use of copyrighted material without consent and the resulting financial harm to artists. | - [§1: Header/Metadata] None stated for this section.<br>- [§2: Introductory Argument/Analogy] The flawed analogy between generative AI’s process and human artistic inspiration; the argument implies a critical dependency on individual source works that doesn't reflect the broader inspiration sources for human artists.<br>- [§3: Critique of the Analogy/Generative AI as a Tool] Generative AI's complete reliance on existing source material; it is framed as a tool lacking sentience or independent creative capacity, and therefore lacks originality.<br>- [§4: Economic Impact/Theft Argument] Potential displacement of human creatives; generative AI constitutes a form of theft by using artists' work to cut expenses. It's characterized as "stealing money from the individuals it stole from."<br>- [§5: Proposed Solution/Call to Action] The current databases are built on stolen labor; concerns around the unfair economic impact of generative AI. | - [§1: Header/Metadata] None stated for this section.<br>- [§2: Introductory Argument/Analogy] None stated for this section.<br>- [§3: Critique of the Analogy/Generative AI as a Tool] None stated for this section.<br>- [§4: Economic Impact/Theft Argument] None stated for this section.<br>- [§5: Proposed Solution/Call to Action] Purge current databases and require explicit consent for inclusion of works; only use works submitted with consent. |
| AI-RFI-2025-1250.md | Michael Underwood | Individual | The submitter expresses a strong negative opinion towards Generative AI, focusing on its perceived negative impacts on creators, innovation, and the American economy. Their interest appears to be opposing the development and deployment of Generative AI. | - [§1: Submission Header/Metadata] None stated for this section.<br>- [§2: RFI Identification] None stated for this section.<br>- [§3: Submitter Information] None stated for this section.<br>- [Section 4: General Comment]<br>- Generative AI is a colossal waste of resources.<br>- Generative AI steals from hard-working creators.<br>- Generative AI produces soulless art.<br>- Generative AI only benefits the very richest people.<br>- Generative AI is anti-business.<br>- Generative AI is anti-innovation.<br>- Generative AI is anti-American. | - [§1: Submission Header/Metadata] None stated for this section.<br>- [§2: RFI Identification] None stated for this section.<br>- [§3: Submitter Information] None stated for this section.<br>- [§4: General Comment] None stated for this section. (Though the strong negative opinions *imply* a recommendation to curtail or eliminate support for Generative AI, it is not explicitly stated.) |
| AI-RFI-2025-1251.md | Michael Costanzo | Individual | The submitter is concerned about the negative impacts of unchecked AI development, specifically intellectual property theft, unreliability, and security risks, and advocates for stricter regulations to protect American citizens and businesses. | - [§1: Document Header/Metadata] None stated for this section.<br>- [Section 2: General Comment]<br>- Wholesale theft of intellectual property used in AI development.<br>- Extreme unreliability of AI technology.<br>- Undue burden on individuals and companies who created the stolen intellectual property.<br>- Loss of revenue for intellectual property holders.<br>- Security risks associated with federal government utilization of AI.<br>- AI's propensity to fabricate information and evidence.<br>- Inefficiency of implementing AI in government. | - [§1: Document Header/Metadata] None stated for this section.<br>- [Section 2: General Comment]<br>- Strengthen restrictions and regulations on AI development.<br>- Do not loosen existing restrictions. |
| AI-RFI-2025-1252.md | Jessamyn Powers-Pidlypchak | Individual | The submitter is passionately opposed to the use of copyrighted works to train AI models, believing it will devastate the artistic workforce and devalue human creativity. They advocate for protecting artists and preserving artistic integrity. | - [§1: Document Header/Metadata] None stated for this section.<br>- [Section 2: General Comment]<br>- AI companies desire to train on copyrighted works to avoid hiring artists and writers.<br>- This practice will demolish the American workforce and economy.<br>- Millions of artists will be impoverished.<br>- The quality of life will substantially decrease for artists and future audiences.<br>- [Section 3: Elaboration/Argument]<br>- Training AI on art contradicts the original goals of automation (eliminating *menial* tasks).<br>- It is unjust to strip people of their freedom to create art for a living.<br>- The practice devalues humanity’s oldest hobby and disrespects artistic heritage.<br>- It allows greedy CEOs to profit from plagiarism. | - [§1: Document Header/Metadata] None stated for this section.<br>- [§2: General Comment] None stated for this section.<br>- [Section 3: Elaboration/Argument]<br>- AI should be banned outright.<br>- Specifically, DO NOT ALLOW AI TO BE TRAINED ON COPYRIGHTED WORKS. |
| AI-RFI-2025-1254.md | Tyler Jackson | Individual | The submitter expresses an interest in the responsible development of AI, specifically opposing increased investment in generative AI and large language models due to concerns about originality and fair compensation for creators whose works are used in training data. | - [§1: Submission Metadata] None stated for this section.<br>- [§2: RFI Context] None stated for this section.<br>- [§3: Submitter Information] None stated for this section.<br>- [Section 4: General Comment]<br>- Opposition to increased investment and development of generative artificial intelligent tools or large language models.<br>- Concern that generative AI produces no new content beyond its training data.<br>- Opposition to AI companies profiting off of uncompensated works from authors, journalists, photographers, or visual artists. | - [§1: Submission Metadata] None stated for this section.<br>- [§2: RFI Context] None stated for this section.<br>- [§3: Submitter Information] None stated for this section.<br>- [Section 4: General Comment]<br>- No explicit policy recommendations are stated, but the submitter implies a recommendation against funding or incentivizing generative AI development and a need to address compensation for creators whose work is used in training data. |
| AI-RFI-2025-1255.md | Erica JM | Individual | The submitter expresses strong negative sentiments towards AI development, focusing on its environmental impact, copyright issues, and potential for job displacement. Their interest appears to be in raising concerns about the negative consequences of AI and potentially halting or significantly restricting its progress. | - [§1: Document Metadata] None stated for this section.<br>- [Section 2: General Comment]<br>- High computing power requirements leading to environmental damage.<br>- Theft of creator content without permission to train AI models.<br>- Job displacement.<br>- [§3: Submission Identification] None stated for this section. | - [§1: Document Metadata] None stated for this section.<br>- [§2: General Comment] None stated for this section.<br>- [§3: Submission Identification] None stated for this section. |
| AI-RFI-2025-1256.md | The Greenlining Institute | Advocacy/Think Tank | The Greenlining Institute focuses on building a future where race is never a barrier to economic opportunity and works to promote equitable AI policy that creates prosperity and wealth for all Americans, particularly vulnerable communities, through sustainable, competitive, and fair practices. | - Section 1: Document Header/Metadata:** None stated for this section.<br>- Section 2: Introduction/Statement of Purpose:** Lack of a regulatory framework that will promote a sustainable, competitive, and equitable AI environment.<br>- Section 3: Background/Context:** None stated for this section.<br>- Section 4: Energy Efficiency & Sustainability:** High and increasing energy demands of AI, strain on energy resources (especially fossil fuels), disproportionate impact on low-income communities and communities of color, potential for increasing energy costs, and water depletion.<br>- Section 5: More Fair and Accurate Systems:** Algorithmic bias against vulnerable households, incomplete/inaccurate datasets reinforcing existing inequalities, exclusion of communities of color from AI systems (and resulting market opportunities), lack of data transparency, and lack of explainability/accountability.<br>- Section 6: Government Efficiency and Waste:** Potential for reckless automation to waste government resources and harm citizens, lack of oversight and security management in automation projects, and insufficient consideration of the needs of vulnerable individuals.<br>- Section 7: AI for Efficiency, Accuracy, and Equity:** The need to ensure AI benefits all communities, the importance of creating a just future through technology, and the need for continued engagement on AI policy.<br>- Section 8: Sign-off/Contact Information:** None stated for this section. | - Section 1: Document Header/Metadata:** None stated for this section.<br>- Section 2: Introduction/Statement of Purpose:** None stated for this section.<br>- Section 3: Background/Context:** None stated for this section.<br>- Section 4: Energy Efficiency & Sustainability:<br>- Embolden NIST to create standards for AI energy efficiency, providing information to developers and consumers.<br>- Require AI developers and data centers to record and disclose their annual AI energy consumption publicly.<br>- Section 5: More Fair and Accurate Systems:<br>- Establish Data Transparency and Quality Standards, developing a robust data governance framework.<br>- Establish Explainability and Accountability Standards for automated systems making life-impacting decisions.<br>- Regularly Conduct Impact Assessments, harmonizing US regulatory standards with other nations.<br>- Section 6: Government Efficiency and Waste:<br>- Maintain technical AI expertise in the federal government (Chief AI Officers).<br>- Implement Targeted Design and Procurement Standards that account for diverse needs.<br>- Ensure models used to allocate government resources are built with vulnerability assessment models.<br>- Section 7: AI for Efficiency, Accuracy, and Equity:** None stated for this section.<br>- Section 8: Sign-off/Contact Information:** None stated for this section. |
| AI-RFI-2025-1257.md | Laszlo Jakusovszky | Individual | The submitter expresses strong opposition to the current trajectory of AI development and advocates against providing legal protections or financial support to the AI industry, believing it has not lived up to its promises and engages in copyright infringement. | - [Section 1: Introduction/Document Header]** The submitter believes generative AI is fraudulent, overhyped, frequently wrong, biased, unprofitable, and strains national power grids. They oppose granting the AI industry a “blank check” from the US government.<br>- [Section 2: Fair Use Argument Overview]** The core concern is that unlicensed exploitation of copyrighted works by AI developers is *not* a fair use of those works. This section establishes the argument against the claim that AI training is transformative and protected.<br>- [Section 3: Process of AI Training - Assembly of Training Materials]** The primary concern is the massive, unauthorized copying of copyrighted materials (“scraping”) from the internet to build training datasets without permission.<br>- [Section 4: Process of AI Training - Encoding of Data (LLMs)]** The main concern is that LLMs do *not* discard original works after training; instead, they algorithmically map and store them, retaining the expressive content and enabling reproduction of the originals. LLMs *retain* the expressions of the original works and can reproduce them. The text views the model as a compilation *of* training data or a derivative *work* of it.<br>- [Section 5: Process of AI Training - Encoding of Data (Diffusion Models - Image Generation - incomplete)]** Not stated. The section is incomplete. | - [Section 1: Introduction/Document Header]** Not stated.<br>- [Section 2: Fair Use Argument Overview]** Not stated, but the implicit recommendation is to reject the fair use claim.<br>- [Section 3: Process of AI Training - Assembly of Training Materials]** Not stated, but the implicit recommendation is to regulate or restrict the scraping of copyrighted material.<br>- [Section 4: Process of AI Training - Encoding of Data (LLMs)]** Not stated, but the implicit recommendation is to prevent the continued retention and potential reproduction of copyrighted material within LLMs.<br>- [Section 5: Process of AI Training - Encoding of Data (Diffusion Models - Image Generation - incomplete)]** Not stated, given the incomplete nature of the section. |
| AI-RFI-2025-1258.md | IAPP | Industry-Association / Professional-Society | IAPP's mission is to define, promote, and improve the professions of privacy, AI governance, and digital responsibility. They are focused on fostering a skilled workforce and connected community to enable responsible AI innovation through professionalization and credentialing. | - None Stated | - None Stated |
| AI-RFI-2025-1260.md | John Hodson | Individual | The submitter expresses strong opposition to AI technology in all forms and does not support its development or implementation, particularly based on the influence of figures like Elon Musk. They advocate for a rejection of AI technology. | - [§1: Document Metadata] None stated for this section.<br>- [§2: Comment Identification] None stated for this section.<br>- [§3: Submitter Information] None stated for this section.<br>- [§4: General Comment] AI technology is “garbage and dehumanizing.” The submitter is against AI “in all things, shape, and form.” | - [§1: Document Metadata] None stated for this section.<br>- [§2: Comment Identification] None stated for this section.<br>- [§3: Submitter Information] None stated for this section.<br>- [§4: General Comment] Do not support AI technology. |
| AI-RFI-2025-1261.md | Erik Tinberg | Individual | The submitter is concerned about the unauthorized use of copyrighted works in AI training data and advocates for the rights of artists and creatives, including control over their work's inclusion in training datasets, ledgers for tracking derived output, and financial compensation. | - [§1: Document Header/Metadata] None stated for this section.<br>- [§2: Comment Identification] None stated for this section.<br>- [§3: Submitter Information] None stated for this section.<br>- [Section 4: General Comment/Core Argument]<br>- The use of copyrighted works in AI training data constitutes theft and plagiarism on a massive scale.<br>- Lack of faith in government enforcement of artists' rights.<br>- Anticipation of prioritizing AI development acceleration despite negative consequences.<br>- [Section 5: Concluding Remarks/Concerns]<br>- The US may be outcompeted by China in AI development.<br>- Resulting AI output will lack cultural value and quality. | - [§1: Document Header/Metadata] None stated for this section.<br>- [§2: Comment Identification] None stated for this section.<br>- [§3: Submitter Information] None stated for this section.<br>- [Section 4: General Comment/Core Argument]<br>- Grant artists control over their work's inclusion in training data.<br>- Implement removal rights for artists' work from training data.<br>- Establish ledgers to track output derived from artists’ work.<br>- Provide financial compensation for output derived from artists’ work featured in training data.<br>- [§5: Concluding Remarks/Concerns] None stated for this section. |
| AI-RFI-2025-1262.md | Brian Prasad and the International Journal of Artificial Intelligence and Knowledge Engineering (IJAIKE) | Academia/Industry-Association | The submitter proposes establishing a new international journal dedicated to advancing knowledge in AI and Knowledge Engineering, fostering collaboration, and providing a platform for research dissemination. They are seeking partnerships to enhance the journal's impact and contribute to the field's development, with a focus on creating a venue for research related to smart products and IOTs. | - None Stated | - None Stated |
| AI-RFI-2025-1263.md | Barbara Albert | Individual | The submitter expresses a strong negative opinion on the development and use of AI, particularly its impact on art and creativity, and prioritizes human creation over AI-generated content. Their primary interest appears to be preserving the value and integrity of human artistic effort. | - [§1: Submission Metadata] None stated for this section.<br>- [§2: Comment Identification] None stated for this section.<br>- [§3: Submitter Information] None stated for this section.<br>- [Section 4: General Comment]<br>- AI is detrimental to art and creativity.<br>- AI "steals" existing art and writing to generate new content.<br>- The focus on winning (achieving AI leadership) overshadows the loss of human creativity.<br>- AI diminishes the value of hard work and effort in artistic creation. | - [§1: Submission Metadata] None stated for this section.<br>- [§2: Comment Identification] None stated for this section.<br>- [§3: Submitter Information] None stated for this section.<br>- [Section 4: General Comment]<br>- People should reject AI and focus on developing their own creative skills.<br>- A shift in priorities is needed, valuing human creation over AI-generated content. |
| AI-RFI-2025-1264.md | Miryan Nogueira | Individual / Professional-Society (Based on credentials: LLB, MBA, LLM, Business Law Professor & Experienced Business Executive) | The submitter advocates for an AI Action Plan that fosters innovation, protects competitive markets, and ensures ethical and responsible AI deployment to secure American leadership in AI. They emphasize the importance of balancing regulatory oversight with business-friendly policies and investment in workforce development and IP protections. | - Section 1: Submission Header** None stated for this section.<br>- Section 2: Comment Information** None stated for this section.<br>- Section 3: Introduction/Executive Summary** The need to secure and enhance America's leadership in AI through a balanced and strategic approach.<br>- Section 4: Policy Recommendations (1-7)** Potential for excessive regulation stifling growth; disproportionate burden of regulations on startups and small businesses; need for increased federal funding; maintaining US dominance in the global AI race; legal ambiguities in AI-generated IP; need for a pipeline of skilled AI professionals; preventing overly broad or ambiguous AI-related patents; potential for discriminatory practices in AI; need for accountability and transparency in AI decision-making; protecting AI systems from cyber threats; ensuring AI security aligns with national interests.<br>- Section 5: Conclusion** The importance of balancing regulatory oversight with business-friendly policies to ensure US leadership in AI innovation.<br>- Section 6: Signature** None stated for this section. | - Section 1: Submission Header** None stated for this section.<br>- Section 2: Comment Information** None stated for this section.<br>- Section 3: Introduction/Executive Summary** None stated for this section.<br>- Section 4: Policy Recommendations (1-7)<br>- 1. Promote Pro-Business AI Regulations:** Establish a regulatory framework encouraging innovation; develop industry-led standards balancing ethics and technology; avoid disproportionate burden on startups.<br>- 2. Incentivize AI Research & Development (R&D):** Increase federal funding (particularly in critical industries); offer tax incentives for investment; strengthen public-private partnerships.<br>- 3. Strengthen Intellectual Property (IP) Protections for AI Innovations:** Ensure strong patent protections; address legal ambiguities in AI-generated IP; establish a specialized AI patent review system.<br>- 4. Develop AI Workforce & Education Initiatives:** Implement nationwide AI literacy programs; encourage AI integration in curricula; provide grants for workforce retraining; substantially fund community colleges.<br>- 5. Ensure AI is Used Responsibly & Ethically:** Support ethical AI guidelines; promote transparency and accountability; establish a legal framework for AI liability.<br>- 6. Secure AI Infrastructure & National Security Interests:** Invest in cybersecurity measures; strengthen export controls; promote collaboration between government and the private sector.<br>- 7. Facilitate AI Adoption Across Industries:** Provide grants and incentives for adoption; support SMEs with resources and training; encourage responsible adoption in legal and business sectors.<br>- Section 5: Conclusion** Foster investment, strengthen IP protections, promote AI workforce development (including substantial funding for community colleges), and ensure responsible AI use.<br>- Section 6: Signature** None stated for this section. |
| AI-RFI-2025-1265.md | Michael Buchanan | Individual | The submitter is an artist concerned about the protection of copyright and the potential negative impacts of unrestricted AI scraping on artists, American jobs, and intellectual property rights. They advocate for regulations to prevent the misuse of AI and protect copyrighted works. | - [§1: Submission Metadata] None stated for this section.<br>- [§2: RFI Identification] None stated for this section.<br>- [§3: Submitter Information] None stated for this section.<br>- [Section 4: General Comment]<br>- AI scraping should be restricted to those with permission from copyright holders.<br>- Removing copyright protection for AI scraping could lead to job displacement for American citizens.<br>- Unrestricted AI scraping could enable the misuse of intellectual property (IP) and scams.<br>- Corporations could face challenges due to misuse of AI utilizing their IP.<br>- Existing Fair Use doctrines could be undermined. | - [§1: Submission Metadata] None stated for this section.<br>- [§2: RFI Identification] None stated for this section.<br>- [§3: Submitter Information] None stated for this section.<br>- [Section 4: General Comment]<br>- Regulations must be made for AI to prevent the loss of protected works.<br>- Implement rules requiring permission from copyright holders before AI is allowed to scrape content. |
| AI-RFI-2025-1267.md | Zane Newman | Individual | The submitter is deeply passionate about art and believes in its uniquely human qualities, expressing concern over the negative impact of AI-generated art on the value and authenticity of human creativity and expression. | - [§1: Document Metadata] None stated for this section.<br>- [§2: Comment Identification] None stated for this section.<br>- [§3: Submitter Information] None stated for this section.<br>- [Section 4: General Comment - Argument Against AI Art]<br>- AI art is primarily created using stolen artwork, dreams, and thoughts.<br>- AI art lacks the genuine expression, passion, love, and emotion found in human-created art.<br>- The automation of art diminishes its value and authenticity.<br>- AI art relies on existing human artwork for its creation and will eventually become a degraded, self-referential mess without human artists.<br>- AI art cannot replace human art because art is fundamentally a human endeavor. | - [§1: Document Metadata] None stated for this section.<br>- [§2: Comment Identification] None stated for this section.<br>- [§3: Submitter Information] None stated for this section.<br>- [§4: General Comment - Argument Against AI Art] None stated for this section. (Although implicit, no explicit policy recommendations are made.) |
| AI-RFI-2025-1268.md | Jackline Echevarria | Individual | The submitter is an individual expressing concern about the negative impacts of AI on creative fields, specifically regarding copyright infringement, job displacement, and environmental sustainability. They advocate for protecting human creativity and limiting the unchecked development and deployment of AI technologies. | - [§1: Document Metadata] None stated for this section.<br>- [Section 2: General Comment]<br>- AI infiltrating copyrighted material is damaging to the creative field.<br>- AI can take away jobs.<br>- AI contributes to the destruction of the environment.<br>- [Section 3: Supporting Arguments & Examples]<br>- Hoyoverse's attempt to drop AI regulations would allow companies to steal voice actors' work for profit.<br>- Coca-Cola's AI-generated commercial saved the company money, prioritizing profit over creators' livelihoods.<br>- AI undermines the value of human creativity, skill, and expression.<br>- [Section 4: Environmental Impact Justification]<br>- AI uses one bottle of water per prompt, exacerbating the existing water crisis.<br>- [§5: Sources/References] None stated for this section. | - [§1: Document Metadata] None stated for this section.<br>- [Section 2: General Comment]<br>- Protect copyright to safeguard creativity.<br>- [§3: Supporting Arguments & Examples] None stated for this section.<br>- [§4: Environmental Impact Justification] None stated for this section.<br>- [§5: Sources/References] None stated for this section. |
| AI-RFI-2025-1270.md | Calyn McLeod | Individual | The submitter expresses strong opposition to Generative AI, viewing it as fundamentally harmful and unethical, based on concerns about consent violations, truth, and its impact on humanity. Their interest appears to be advocating against the development and deployment of this technology. | - [§1: Document Header/Metadata] None stated for this section.<br>- [§2: RFI Identification] None stated for this section.<br>- [§3: Submitter Information] None stated for this section.<br>- [Section 4: General Comment]<br>- Generative AI is built upon violations of consent.<br>- It is a threat to the notion of truth.<br>- It is an insult to intelligence, science, the arts, and humanity.<br>- It is a tool of hate, disinformation, and exploitation. | - [§1: Document Header/Metadata] None stated for this section.<br>- [§2: RFI Identification] None stated for this section.<br>- [§3: Submitter Information] None stated for this section.<br>- [§4: General Comment] None stated for this section. (The comment is solely critical and does not propose any specific policy changes.) |
| AI-RFI-2025-1271.md | J L | Individual | The submitter expresses strong opposition to generative "AI" technology, viewing it as harmful to American jobs and the creative landscape due to intellectual property theft and the generation of inaccurate information. Their primary interest appears to be protecting American creative industries and workers. | - [§1: Document Header/Metadata] None stated for this section.<br>- [Section 2: General Comment]<br>- Generative "AI" technology is fundamentally based on intellectual property theft.<br>- Products generated by generative "AI" are subpar and cobbled together.<br>- Information provided by generative "AI" is frequently incorrect or fabricated.<br>- The industry is unsustainable and driven by corporate interests focused on profit at the expense of American jobs and the creative landscape.<br>- [§3: Submitter Information] None stated for this section. | - [§1: Document Header/Metadata] None stated for this section.<br>- [§2: General Comment] None stated for this section. (The comment expresses concerns but does not explicitly offer policy recommendations.)<br>- [§3: Submitter Information] None stated for this section. |
| AI-RFI-2025-1272.md | Daniel Meade | Individual | The submitter strongly opposes Generative AI technologies due to concerns about copyright infringement and job displacement, while viewing other AI applications more favorably. Their primary interest is protecting artists, actors, and creative professionals from the negative impacts of Generative AI. | - [§1: Document Metadata] None stated for this section.<br>- [§2: Comment Header] None stated for this section.<br>- [§3: Submitter Information] None stated for this section.<br>- [Section 4: General Comment]<br>- Copyright infringement by Generative AI models using stolen material for training.<br>- Job displacement of artists, actors, and other creative professionals.<br>- Lack of practical or beneficial use for Generative AI. | - [§1: Document Metadata] None stated for this section.<br>- [§2: Comment Header] None stated for this section.<br>- [§3: Submitter Information] None stated for this section.<br>- [Section 4: General Comment]<br>- Strong opposition to the promotion or protection of Generative AI technologies.<br>- Prevention of Generative AI models from freely stealing copyrighted content for training.<br>- Prevention of Generative AI from stealing jobs from creative professionals. |
| AI-RFI-2025-1273.md | Rob MacWolf | Individual | The submitter is primarily concerned with the ethical implications of AI development, specifically regarding copyright infringement and the use of copyrighted material in AI training. They believe AI should not exist if it relies on stealing copyrighted work. | - [§1: Document Header/Metadata] None stated for this section.<br>- [§2: RFI Reference] None stated for this section.<br>- [§3: Submitter Information] None stated for this section.<br>- [§4: General Comment] AI technology's reliance on potentially stolen copyrighted work is a significant concern, with the submitter believing this practice is unacceptable. | - [§1: Document Header/Metadata] None stated for this section.<br>- [§2: RFI Reference] None stated for this section.<br>- [§3: Submitter Information] None stated for this section.<br>- [§4: General Comment] The implicit recommendation is to prevent the development or deployment of AI systems that rely on the unauthorized use of copyrighted materials. |
| AI-RFI-2025-1275.md | Louise Uy | Individual | The submitter expresses strong opposition to the exploitation of labor, copyrights, and intellectual property in the development of AI, and lacks confidence in the current administration's handling of AI policy. | - [§1: Submission Metadata] None stated for this section.<br>- [§2: RFI Context] None stated for this section.<br>- [Section 3: General Comment]<br>- Exploitation of labor in AI development.<br>- Exploitation of copyrights and intellectual property.<br>- Disregard of trade laws by AI businesses.<br>- Lack of faith in the current president’s leadership due to a perceived history of failed businesses and unethical practices.<br>- Concerns about the influence of wealthy individuals on the current administration. | - [§1: Submission Metadata] None stated for this section.<br>- [§2: RFI Context] None stated for this section.<br>- [Section 3: General Comment]<br>- Businesses should not rely on exploitative practices to grow.<br>- Businesses engaging in exploitative practices should risk financial loss or closure.<br>- No explicit policy recommendations are provided beyond this, but the submitter implies a need for stricter enforcement of trade laws and ethical business practices. |
| AI-RFI-2025-1276.md | Nicholas Mariano | Individual | The submitter is deeply concerned about the potential risks of misaligned AI and advocates for prioritizing AI safety research, international collaboration, and proactive regulation to prevent catastrophic outcomes. They believe AI will shape the future and that its development requires strong global leadership. | - [§1: Document Metadata] None stated for this section.<br>- [§2: Comment Header] None stated for this section.<br>- [§3: Submitter Information] The difficulty of verifying code and the increasing complexity of AI systems as they take on more responsibility.<br>- [Section 4: Core Argument/Comment]<br>- The risks of misaligned AI systems introducing bugs or malicious software.<br>- The difficulty of understanding and directing the goals of AI systems.<br>- The exponentially growing risks with the introduction of agentic systems and AGI.<br>- The lack of strong global leadership in AI safety.<br>- [§5: Closing/Urgency] The extreme importance of the issue and the potential for catastrophic consequences for humanity.<br>- [§6: Signature] None stated for this section. | - [§1: Document Metadata] None stated for this section.<br>- [§2: Comment Header] None stated for this section.<br>- [§3: Submitter Information] None stated for this section.<br>- [Section 4: Core Argument/Comment]<br>- Invest in and incentivize research into understanding and directing the goals of AI systems.<br>- Prioritize AI safety research.<br>- [Section 5: Closing/Urgency]<br>- Take a leadership role on AI safety.<br>- Form a global alliance with competitors, specifically China, to enforce safe AI research practices.<br>- Create compute caps for training runs.<br>- Require research on interpretability and verification mechanisms for frontier models.<br>- [§6: Signature] None stated for this section. |
| AI-RFI-2025-1277.md | Felix De Simone | Individual | Felix De Simone is an AI policy advocate deeply concerned about the existential risks posed by the development of smarter-than-human AI and advocates for international cooperation to prevent its development until safety can be assured. | - The potential for smarter-than-human AI to become uncontrollable and pose a catastrophic threat to humanity and the biosphere.<br>- The risk of an "arms race" to develop smarter-than-human AI, which would not benefit the US and could lead to the creation of "rogue AI" that destroys humanity.<br>- The possibility of autonomous AI systems deploying weapons, including biological ones, in open conflict.<br>- The idea that building something smarter than humans could result in losing control, potentially leading to humanity's marginalization or extinction. | - Negotiate an "AI Deal" – an international agreement to prohibit developing smarter-than-human AI until we know how to control it.<br>- Encourage specialized AI innovation while prohibiting the development of generally smarter-than-human AI.<br>- Demand that China agree to negotiate to prevent the development of superhuman AI, similar to President Reagan's approach with the Soviets on nuclear weapons. |
