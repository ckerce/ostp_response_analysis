| Filename | Submitter Name | Submitter Type | Mission/Interest Summary | Key Concerns | Policy Recommendations |
|---|---|---|---|---|---|
| Nadia-Akrabawi-AI-RFI-2025.md | Nadia Akrabawi | Individual | Nadia is a concerned citizen focused on upskilling the workforce aged 35-55 in IT and AI to ensure American leadership in the field and prevent irrelevance, particularly given this generation's anticipated leadership role. She advocates for accessible education and legitimate training pathways. | - [§1: Email Header] None stated for this section.<br>- [§2: Personal Introduction & Context] The fear of becoming irrelevant due to rapidly changing technology. A sense of being "lost" or unsettled about the future. The potential for a lost generation of capable individuals.<br>- [§3: Proposal Statement] None stated for this section.<br>- [§4: Justification of Proposal] The risk of losing talent to illegitimate "8 Week" internet courses that could be used for corrupt purposes. The need for unified AI development within the country. The concern that brilliant ideas might be utilized privately instead of for national benefit.<br>- [§5: Concluding Statement] None stated for this section.<br>- [§6: Email Footer] The email account is for official use only and subject to disclosure requirements. | - [§1: Email Header] None stated for this section.<br>- [§2: Personal Introduction & Context] None stated for this section.<br>- [§3: Proposal Statement] Provide free Information Technology Degrees or AI Certifications to people aged 35-55 for a period of four years. Alternatively, offer substantial tax breaks for those pursuing these degrees or certifications.<br>- [§4: Justification of Proposal] Invest in the education of the 35-55 age group to create opportunities, recruit talent, and secure long-term national leadership in AI. Encourage legitimate training pathways (degrees, internships, recruitment) to deter individuals from utilizing questionable online courses.<br>- [§5: Concluding Statement] None stated for this section.<br>- [§6: Email Footer] None stated for this section. |
| Nada-Madkour-AI-RFI-2025.md | Nada Madkour | Academia/Think Tank | The submitters, affiliated with the Center for Long-Term Cybersecurity at UC Berkeley, are focused on AI security risks, particularly those impacting national security, and advocate for proactive governance, robust testing, international collaboration, and investment in research and development to maintain U.S. leadership in AI. | - None Stated | - None Stated |
| NYU-AI-RFI-2025.md | NYU | Academia | NYU seeks to maintain American leadership in AI through continued federal investment in research, infrastructure, education, and workforce development, leveraging its own strengths and collaborative ecosystem to drive innovation and societal impact. They emphasize a collaborative approach with industry and government. | - None Stated | - None Stated |
| NVTC-AI-RFI-2025.md | Northern Virginia Technology Council (NVTC) | Industry-Association | The Northern Virginia Technology Council (NVTC) aims to accelerate technology innovation and promote workforce development to create a thriving technology ecosystem, with a strong focus on maintaining US leadership in AI through strategic public-private partnerships and supportive policies. | - [§1: Introduction & Executive Summary] None stated for this section.<br>- [§2: About the Northern Virginia Technology Council (NVTC)] None stated for this section.<br>- [§3: Data - Accelerate Data Provision and Interoperability] Lack of data interoperability hinders AI integration and innovation; data silos restrict usage; GDPR is criticized for restricting data flows.<br>- [§4: Talent - Bookend Strategy to Promote AI Literacy and Drive Innovation] Need to define risk taxonomies, address risks like bias, cybersecurity, privacy and safety, and promote AI literacy across all age groups. Rapid development of AI requires inclusion of emerging technologies like agentic AI.<br>- [§5: Digital Infrastructure - Create an 'AI Sandbox' through Public/Private Partnership] Traditional digital infrastructure is insufficient to support AI’s requirements, particularly energy constraints. AI guardrails should not stifle progress; a structured approach is needed to balance risks and benefits.<br>- [§6: Standards and Regulations - 'Transparent and Verified'] Overly restrictive regulations may stifle innovation; a flexible, targeted approach is needed; a patchwork of state/local regulations creates confusion and slows innovation. Costly licensing and fragmented privacy laws create barriers to data access.<br>- [§7: Communication & Conclusion] None stated for this section. | - [§1: Introduction & Executive Summary] None stated for this section.<br>- [§2: About the Northern Virginia Technology Council (NVTC)] None stated for this section.<br>- [Section 3: Data - Accelerate Data Provision and Interoperability]<br>- Expand inclusive datasets (remove restrictions keeping data in silos).<br>- Balance privacy and provision (define clear policies for data owners).<br>- Ensure interoperability of multimodal data.<br>- Establish a Data Standards Working Group.<br>- [Section 4: Talent - Bookend Strategy to Promote AI Literacy and Drive Innovation]<br>- Establish an AI Leadership Task Force.<br>- Leverage higher education institutions and national laboratories.<br>- Establish AI Leadership Projects.<br>- Implement a National AI Apprenticeship Program.<br>- Direct NIST to publish an AI Taxonomy.<br>- Develop an AI Credentials Framework.<br>- Include next generation AI systems (agentic AI) in analysis and planning.<br>- [Section 5: Digital Infrastructure - Create an 'AI Sandbox' through Public/Private Partnership]<br>- Establish a Federal AI Sandbox.<br>- Require energy regulatory bodies to increase power generation.<br>- Develop energy efficiency metrics for AI systems.<br>- Evaluate regulations regarding onsite power generation and storage.<br>- [Section 6: Standards and Regulations - 'Transparent and Verified']<br>- AI models need to be clearly labeled regarding design, data sources, potential risks and usage warnings.<br>- Convene an AI Standards and Interoperability Board.<br>- Require published documentation for AI systems.<br>- Establish guidelines for emerging AI technologies (agentic AI).<br>- Establish a unified Federal AI Framework.<br>- Establish a National Data Privacy Framework.<br>- [§7: Communication & Conclusion] None stated for this section. |
| NVCA-AI-RFI-2025.md | National Venture Capital Association (NVCA) | Industry-Association | The NVCA represents venture capital investors and the entrepreneurs they support, and advocates for policies that promote innovation and growth in the startup ecosystem, particularly focusing on AI development and maintaining U.S. leadership in the field. | - None Stated | - None Stated |
| NTI-Bio-RFI-2025.md | NTI \| bio | Advocacy/Think Tank | NTI \| bio works to strengthen biosecurity and reduce risks related to advances in biotechnology and the broader life sciences, with a particular focus on the convergence of AI with the life sciences and its implications for biosecurity. They advocate for safeguards to protect these technologies from misuse while promoting innovation. | - [§1: Introduction/Opening] The potential for deliberate or accidental release of harmful biological agents, including those that could cause a global biological catastrophe, due to advances in AI within the life sciences. The need to balance innovation with security to maintain U.S. competitiveness.<br>- [§2: Bolster OSTP Framework for Nucleic Acid Synthesis Screening] The possibility of illegitimate actors accessing nucleic acid sequences that encode dangerous toxins and pathogens. Ensuring the framework remains effective as biotechnology and AI technology rapidly advance.<br>- [§3: Elevate the U.S. AI Safety Institute (AISI)] A lack of expertise in virology, molecular biology, and other life sciences technical areas within the AI industry.<br>- [§4: Support Research on Risk Mitigations/Guardrails] The potential for misuse of AI models trained on biological data to design more harmful pathogens than currently exist. Unpredictable and unsafe outcomes from AI "agents" applied in life sciences laboratories. Lack of developed methods for evaluating emerging biological risks related to biological AI tools and AI agents.<br>- [§5: International Leadership] The development of powerful AI models and provision of nucleic acid synthesis services occurring in many countries around the world, potentially creating overseas biological threats that could affect U.S. interests.<br>- [§6: Conclusion/Closing] None stated for this section. | - [§1: Introduction/Opening] Support governance approaches that harness the benefits of AI while guarding against downside risks.<br>- [§2: Bolster OSTP Framework for Nucleic Acid Synthesis Screening] Strengthen the existing OSTP framework for nucleic acid synthesis screening. Update the framework every two years to ensure effectiveness in the face of technological progress in biotechnology and AI.<br>- [§3: Elevate the U.S. AI Safety Institute (AISI)] Increase the role and influence of the AISI to evaluate and mitigate biosecurity risks posed by AI. Facilitate the collaboration between AISI and experts in virology, molecular biology, and other technical life sciences areas.<br>- [§4: Support Research on Risk Mitigations/Guardrails] Pursue an aggressive research agenda to identify guardrails that can address the critical gap in evaluating and limiting biological risks related to biological AI tools and AI agents. Pilot promising approaches to reduce risks while enabling innovation.<br>- [§5: International Leadership] Take a leadership role in international efforts to advance AI safety and security and promote robust nucleic acid synthesis screening practices.<br>- [§6: Conclusion/Closing] Incorporate the stated priority areas into the AI Action Plan to safeguard technologies, ensure industry competitiveness, and maintain global leadership in AI. |
| NSBA-AI-RFI-2025.md | National Small Business Association (NSBA) | Industry-Association | The NSBA advocates for the interests of American small businesses, championing policies that foster their growth and competitiveness, particularly in the context of rapidly evolving technologies like AI. They aim to ensure small businesses have the resources, training, and a supportive policy environment to successfully adopt and compete in an AI-driven economy. | - [§1: Introduction] None stated for this section.<br>- [§2: Ensuring Widespread Availability of AI Research Resources]  Lack of equal access to AI resources (computing power, data) compared to larger corporations. Concerns about the potential expiration of the NAIRR pilot program.<br>- [§3: Expanding Workforce and Training Programs for an AI-driven Economy]  Existing workforce challenges and the need for scaled and improved AI training, particularly at community colleges.<br>- [§4: Supporting Small Business Through Collaborations] AI innovation concentrated in large tech companies, leaving small businesses at a disadvantage.<br>- [§5: Addressing Future Challenges Related to AI]  The need for flexibility in future AI regulations, protection of intellectual property rights for small innovators, and ensuring the SBA has sufficient tools to support small businesses' AI adoption.<br>- [§6: Conclusion] None stated for this section. | - [§1: Introduction] None stated for this section.<br>- [§2: Ensuring Widespread Availability of AI Research Resources] Make the NAIRR pilot program permanent and adequately resourced. Establish a "national [AI] infrastructure" shared by both small and large companies.<br>- [§3: Expanding Workforce and Training Programs for an AI-driven Economy] Expand programs like the NAAIC to scale AI training quality. Support industry involvement (including small businesses) in programs like NAAIC and EducateAI, targeting smaller companies.<br>- [§4: Supporting Small Business Through Collaborations] Encourage collaborations between small businesses and larger companies (AI innovators, cloud providers, research institutions) through policy incentives.<br>- [§5: Addressing Future Challenges Related to AI] Implement a risk-based regulatory framework for AI that provides flexibility for small companies.  Ensure SBA has tools for guidance, technical assistance, and financial resources to support small business AI adoption.<br>- [§6: Conclusion] None stated for this section. |
| NSAI-AI-RFI-2025.md | Nashville Songwriters Association International (NSAI) | Industry-Association / Advocacy/Think Tank | NSAI is the world’s largest not-for-profit trade association for songwriters, dedicated to protecting the rights of songwriters and addressing their unique needs, with a current focus on advocating for copyright protection in the context of generative AI technologies. | - [Section 1: Introductory Comments & Principles]<br>- The use of copyrighted works by AI models without proper valuation and protection of authors’ copyrights.<br>- The potential for unregulated AI music to devalue intellectual property and diminish the US’s leading role in music creation.<br>- The rapid evolution of AI requires adaptable laws and regulations.<br>- Use of creator's work as training material is not fair use.<br>- [Section 2: The Four P's Framework]<br>- Lack of licensing for use of creator's work in AI training, including retroactive application for existing AI models.<br>- Categorical copyright infringement when copyrighted works are ingested without permission and commensurate licensing.<br>- Lack of transparency regarding AI training material and usage.<br>- Difficulty for copyright owners to prove access to their works when pursuing infringement claims.<br>- The lack of access to affordable legal recourse for copyright owners.<br>- [Section 3: About NSAI]<br>- None stated for this section. | - [Section 1: Introductory Comments & Principles]<br>- Develop guardrails around AI technology to protect American creators and their works.<br>- [Section 2: The Four P's Framework]<br>- PERMISSION:** Require licensing for any use of a creator's work, including for AI training, and establish a methodology for retroactive application.<br>- PAYMENT:** Compensate copyright owners and creators for the use of their material in AI training and subsequent works, through free market negotiation similar to music synchronization licenses.<br>- PROOF:** Require AI models to maintain transparent and complete records of training material in real-time, including ingested material, human input, output, and source material referencing.<br>- PENALTIES:** Allow copyright owners to seek penalties from bad actors using copyrighted material without licensing, and damages for infringement by AI output, with remedies available in local civil courts.<br>- [Section 3: About NSAI]<br>- None stated for this section. |
| NRP-AIRE-RFI-2025.md | Frank Wuerthwein, Louis Fox, James Deaton, Tom DeFanti, Derek Weitzel | Academia & Research Network Collaboration | The submitters aim to establish a national research platform (NRP AIRE) to democratize access to AI compute infrastructure for all US colleges and universities, fostering AI education and research capabilities nationwide through a collaborative network of institutions and Research and Education Networks (RENs). | - Section 1: Title Block & Disclaimer:** None stated for this section.<br>- Section 2: Vision of NRP:**  Lack of a clearly defined mechanism for long-term sustainability without continued federal funding, despite stating this is the goal.<br>- Section 3: The Challenge the NRP Solves:** AI education and compute access are becoming privileges of elite institutions due to cost, creating inequality. Many colleges lack the expert staff to procure, deploy, and securely operate advanced computing infrastructure. Approximately half of US college students may require formal AI education.<br>- Section 4: NRP Socio-technical Solution:**  Operating a national-scale infrastructure requires specialized expertise. Maintaining consistent software releases and monitoring usage are critical for security and scalability. Dependence on centralized operations and automation to reduce operational burden on individual colleges.<br>- Section 5: NRP Strategy to Scale out to the nation:** RENs lack the staff expertise to offer AI compute services despite a keen interest in doing so.  Reliance on RENs to provide infrastructure, and their limited capacity to do so.<br>- Section 6: Investment & Sustainability:**  Initial hardware seeding is targeted towards non-R1 institutions and EPSCoR states, but the long-term viability relies on other institutions making their own investments.  Transition to a membership fee-based model via RENs and Internet2 may not be sufficient.<br>- Section 7: References:** None stated for this section. | - Section 1: Title Block & Disclaimer:** None stated for this section.<br>- Section 2: Vision of NRP:**  Fund a transformative change for college education nationwide that can be sustained long-term without ongoing Federal funding.<br>- Section 3: The Challenge the NRP Solves:**  Invest in AI infrastructure to ensure equitable access to AI education for students across all institutions. Support surveys to understand the needs of students regarding AI education.<br>- Section 4: NRP Socio-technical Solution:** Centralize operations and automate security to reduce the burden on individual colleges. Leverage the existing expertise of facilities like SDSC and Holland Computing Center.<br>- Section 5: NRP Strategy to Scale out to the nation:** Collaborate with RENs to expand the reach of the platform. Leverage the existing network of institutions connected by Internet2 and Quilt.<br>- Section 6: Investment & Sustainability:** Invest $25M over 5 years to scale up the workforce and install hardware in strategically selected institutions. Transition to a membership fee-based model through RENs and Internet2 to ensure long-term sustainability. Earmark hardware funds for non-R1 institutions and EPSCoR states to stimulate further investment.<br>- Section 7: References:** None stated for this section. |
| NRF-AI-RFI-2025.md | National Retail Federation (NRF) | Industry-Association | The National Retail Federation (NRF) represents the retail sector and advocates for policies that support the industry's growth and innovation, particularly regarding the adoption and responsible use of Artificial Intelligence (AI) technologies. They aim to ensure AI policies are practical, proportionate, and avoid hindering innovation, especially for small businesses. | - [§1: Introduction & Letterhead] None stated for this section.<br>- [§2: NRF Background] None stated for this section.<br>- [§3: Overall Position & High-Level Issues] None stated for this section.<br>- [§4: Issue 1: Sector-by-Sector Approach] Policies or regulations may cover retailers' low-risk activities due to fears about higher risks in other sectors.<br>- [§5: Issue 2: Engagement with AI Deployers] Prior engagement focused too heavily on AI developers and not enough on companies deploying AI (like retailers). Compliance obligations should be practical and proportionate.<br>- [§6: Issue 3: Impact on Small Businesses] Excessive regulations and compliance requirements for AI use could limit opportunities for small retailers and create an environment where only large developers can survive.<br>- [§7: Issue 4: Role of NIST] Concerns about potential efforts to diminish NIST’s role on AI issues. Concerns about the NIST AI Safety Institute and its work to date.<br>- [§8: Issue 5: Countering AI-Enabled Threats] Increasingly sophisticated cybercriminals and fraudsters using AI to carry out cyberattacks and fraud schemes.<br>- [§9: Issue 6: Federal Leadership & State Legislation] Growing fragmentation of state AI legislation leading to costly compliance and deterring investment in AI.<br>- [§10: Closing & Sign-Off] None stated for this section.<br>- [§11: Dissemination Notice] None stated for this section. | - [§1: Introduction & Letterhead] None stated for this section.<br>- [§2: NRF Background] None stated for this section.<br>- [§3: Overall Position & High-Level Issues] None stated for this section.<br>- [§4: Issue 1: Sector-by-Sector Approach] Adopt a sector-by-sector approach that accounts for risks in each sector and the voluntary steps companies are already taking.<br>- [§5: Issue 2: Engagement with AI Deployers] Increase engagement with sectors that are major "deployers" of AI technologies. Support industry task forces or working groups.<br>- [§6: Issue 3: Impact on Small Businesses] Carefully examine the impact of AI regulations on small businesses. Ensure regulations are not excessive and compliance requirements are feasible.<br>- [§7: Issue 4: Role of NIST] Continue utilizing NIST as a forum for public-private sector engagement. Rebrand and relaunch an AI-focused institute within NIST (e.g., AI Innovation and Standards Institute) and host an associated consortium. Expand existing NIST frameworks to include emerging AI technologies.<br>- [§8: Issue 5: Countering AI-Enabled Threats] Increase efforts within U.S. cybersecurity, law enforcement, and intelligence agencies to understand and disrupt organized criminal groups using AI.<br>- [§9: Issue 6: Federal Leadership & State Legislation] Encourage Congress to pass legislation creating a risk-based framework for AI regulation. Preempt state legislation. Provide appropriate levels of liability protection to companies following baseline standards. Support preemption across areas of law informing AI regulation (e.g., patent, trademark, employment law, consumer protection).<br>- [§10: Closing & Sign-Off] None stated for this section.<br>- [§11: Dissemination Notice] None stated for this section. |
| NPRC-AI-RFI-2025.md | National Payroll Reporting Consortium (NPRC) | Industry-Association | The NPRC represents payroll processing service providers and is interested in fostering responsible AI deployment within the HCM industry, balancing innovation with compliance, risk mitigation, and workforce development, particularly focusing on the needs of small businesses. | - [§1: Introduction] Maintaining a balanced regulatory environment that enables and fosters the growth of AI is essential. Rigid approaches that stifle growth should be avoided.<br>- [§2: Executive Summary] None stated for this section.<br>- [§3: AI in Payroll & Workforce Management] Rigid mandates that could increase operational costs without tangible benefits should be avoided.<br>- [§4: AI Governance: Risk-Based, Reliability-Focused Approaches] A risk-tiered approach is needed; existing compliance structures (anti-discrimination, privacy, employment laws) should be leveraged rather than layering on new requirements. Fragmentation of AI governance through inconsistent state/local laws is a concern.<br>- [§5: Preserving AI Developers' Legal Access to Training Data] Restrictions that limit innovation by limiting access to publicly available data are a concern.<br>- [§6: Expanding Small Business Access to AI & Reducing Compliance Burdens] High costs, lack of AI expertise, and compliance complexities pose significant challenges for small businesses. Unnecessary compliance burdens could limit competition.<br>- [§7: International AI Engagement & Harmonization of Risk Approaches] Conflicting AI frameworks with international partners are a concern.<br>- [§8: Strengthening Workforce Development & Protecting American Jobs] Displacing jobs through AI rather than augmenting human work is a concern.<br>- [§9: Conclusion] None stated for this section.<br>- [§10: Document Approval/Contact Information] None stated for this section. | - [§1: Introduction] None stated for this section.<br>- [§2: Executive Summary] Align comments with the principles outlined in the December 2024 Bipartisan House Task Force Report on AI.<br>- [§3: AI in Payroll & Workforce Management] Support responsible AI use while avoiding rigid mandates.<br>- [Section 4: AI Governance: Risk-Based, Reliability-Focused Approaches]<br>- Implement a risk-tiered approach to AI oversight.<br>- Make AI developers responsible for risk evaluation and compliance.<br>- Encourage transparency in AI operations and implement human oversight measures.<br>- Implement formal corporate AI governance frameworks.<br>- Harmonize AI regulations at the federal level.<br>- Ensure AI regulation is adaptable and technology-neutral.<br>- Ensure privacy laws remain technology-neutral.<br>- Facilitate access to privacy-enhanced data technologies.<br>- [Section 5: Preserving AI Developers' Legal Access to Training Data]<br>- Ensure developers retain legal access to publicly available data.<br>- Support privacy-enhancing technologies.<br>- Encourage government-facilitated datasets for AI training.<br>- [Section 6: Expanding Small Business Access to AI & Reducing Compliance Burdens]<br>- Provide AI adoption grants and resources to small businesses.<br>- Minimize unnecessary compliance burdens for small businesses.<br>- Develop AI training and support programs for small businesses.<br>- Investigate resource challenges and provide financial assistance/compute power.<br>- Encourage small business participation in AI R&D programs (SBIR/STTR).<br>- [Section 7: International AI Engagement & Harmonization of Risk Approaches]<br>- Lead efforts to develop and harmonize global AI standards.<br>- Increase U.S. participation in international AI governance efforts.<br>- Align risk management with key allies.<br>- [Section 8: Strengthening Workforce Development & Protecting American Jobs]<br>- Implement AI education and training programs (certifications, apprenticeships).<br>- Provide reskilling programs for workers impacted by AI.<br>- Expand workforce training programs to include technical professionals.<br>- [§9: Conclusion] Develop policies that support innovation, protect against risks, and enable small business participation. Promote a risk-based, industry-driven approach.<br>- [§10: Document Approval/Contact Information] None stated for this section. |
| NMHC-AI-RFI-2025.md | National Multifamily Housing Council, National Apartment Association, and Real Estate Technology and Transformation Center | Industry-Association | The National Multifamily Housing Council (NMHC), National Apartment Association (NAA) and Real Estate Technology and Transformation Center (RETTC) represent rental housing providers and technology suppliers, advocating for policies that support innovation, affordability, and efficient operations within the multifamily housing sector, with a focus on the responsible and effective use of AI. | - None Stated | - None Stated |
| NLC-AI-RFI-2025.md | National League of Cities (NLC) | Industry-Association (representing municipal governments) | The National League of Cities advocates for the interests of its member municipalities regarding AI policy, focusing on economic growth, innovation, local decision-making authority, and responsible implementation of AI technologies while protecting resident privacy and safety. | - [Section 1: Introduction/Header]** Potential negative impact of AI on local economies and labor markets; risks to privacy and security.<br>- [Section 2: Local Government Leadership in AI]** Not stated.<br>- [Section 3: NLC's Artificial Intelligence Report and Toolkit]** Not stated.<br>- [Section 4: Municipal Policy Priorities - Invest in the Future of Local Economies]** Unpredictable shifts in local economies due to AI adoption; potential disruption of core industries and employment markets.<br>- [Section 5: Municipal Policy Priorities - Unleash Local Innovation and Decision Making]** Need to preserve local authority in AI adoption decisions.<br>- [Section 6: Municipal Policy Priorities - Create Guardrails for Trust and Accountability]** Protecting public trust and privacy while fostering innovation; potential for mis- or disinformation generated by AI. Concerns regarding legal rights, liabilities, and responsibilities involving AI reference data and training data.<br>- [Section 7: Municipal Policy Priorities - Establish a System of Standards]** Need for trustworthy standards to assess AI tool safety, reliability, performance, and security; detection and removal of bias within AI tools; ensuring human accountability.<br>- [Section 8: Conclusion]** Balancing freedom for technological innovation with safety, resident trust, and data protection; preserving local decision-making authority; supporting communities of all sizes.<br>- [Section 9: Closing/Signature]** Not stated. | - [Section 1: Introduction/Header]** Promote innovation and investment in AI technology while protecting local decision-making, civil liberties, digital privacy, security, and transparency.<br>- [Section 2: Local Government Leadership in AI]** Not stated.<br>- [Section 3: NLC's Artificial Intelligence Report and Toolkit]** Not stated.<br>- [Section 4: Municipal Policy Priorities - Invest in the Future of Local Economies]** Prioritize domestic R&D of AI; foster regional economic growth through incentive-based funding; provide assistance to negatively affected regions; create pathways for upskilling/reskilling; create an AI education pipeline.<br>- [Section 5: Municipal Policy Priorities - Unleash Local Innovation and Decision Making]** Invest in technical assistance and capacity building at the local level for AI adoption, particularly for smaller governments; allow local leaders to pilot innovative solutions and enact local prohibitions on AI usage.<br>- [Section 6: Municipal Policy Priorities - Create Guardrails for Trust and Accountability]** Establish a regulatory framework for AI protecting privacy and innovation; require disclosure of AI-generated/altered material; create guardrails for resident privacy and safety (especially children); prevent the promotion of mis- or disinformation; define legal rights, liabilities, and responsibilities regarding AI data; require transparency from vendors regarding training data sources.<br>- [Section 7: Municipal Policy Priorities - Establish a System of Standards]** Establish processes to adequately test AI tools for safety, reliability, performance, and security according to valid third-party standards to allow comparison across key metrics; prioritize vigorous detection and removal of bias; ensure human accountability in development and use.<br>- [Section 8: Conclusion]** Partner with the Administration to balance innovation, safety, trust, data protection, local decision-making, and community support.<br>- [Section 9: Closing/Signature]** Not stated. |
| NJEdge-AI-RFI-2025.md | NJEdge | Industry-Association (Likely a state-level technology and innovation consortium) | NJEdge is focused on driving AI research, development, and adoption in New Jersey, with a broad interest in federal policies that support AI innovation, workforce development, and competitiveness across various sectors. They advocate for strategic investment, collaboration, and a proactive regulatory approach to ensure the responsible growth of AI. | - [§I: Introduction] None stated for this section.<br>- [§II: Research and Development (R&D)] Maintaining global leadership in AI requires proactive policy adoption to drive research, strengthen education, promote innovation, protect intellectual property, and foster international collaboration.<br>- [§III: Education and Workforce] Preparing students for AI-driven careers and building a skilled talent pool are critical challenges. Addressing AI-related job displacement is also a concern.<br>- [§IV: Innovation and Competition] Preventing AI monopolization and promoting healthy competition are key concerns, along with ensuring fair access for small and medium-sized enterprises (SMEs).<br>- [§V: Intellectual Property (IP)] Modernizing patent and copyright policies to address AI-assisted innovation and AI-generated content, balancing open-source and proprietary development, and assessing the impact of AI on traditional IP laws are important concerns.<br>- [§VI: International Collaboration] Preventing misuse of AI and protecting national security while ensuring market competitiveness are key concerns.<br>- [§VII: Conclusion and Policy Recommendations] The U.S. must act swiftly and strategically to maintain leadership in AI and ensure its ethical and equitable development. | - [§I: Introduction] None stated for this section.<br>- [Section II: Research and Development (R&D)]<br>- Expand federal AI R&D investments through agencies like NSF, DOE, DARPA, and NIH.<br>- Establish dedicated R&D programs focused on ethical AI, explainability, and robustness.<br>- Support AI research in high-performance computing, edge computing, and neuromorphic computing.<br>- Increase investment in domain-specific AI applications in sectors like healthcare, cybersecurity, energy, aerospace, and defense.<br>- Promote AI research in autonomous systems.<br>- Fund interdisciplinary research initiatives.<br>- [Section III: Education and Workforce]<br>- Integrate AI literacy into K-12 curricula.<br>- Increase federal funding for AI-related higher education programs.<br>- Promote AI training and reskilling programs through community colleges and technical institutions.<br>- Expand apprenticeships, internships, and fellowships in AI.<br>- Support continuous learning initiatives for AI professionals.<br>- Address AI-related job displacement by funding retraining programs.<br>- Implement policies to ensure AI workforce diversity and equitable access to education.<br>- Provide grants for minority-serving institutions.<br>- Support initiatives that address bias in AI recruitment.<br>- [Section IV: Innovation and Competition]<br>- Increase funding for AI startups through SBIR and STTR programs.<br>- Create AI-specific tax incentives.<br>- Establish regulatory sandboxes.<br>- Implement antitrust measures to prevent monopolization.<br>- Ensure transparency in AI procurement processes.<br>- Establish AI certification programs.<br>- Encourage AI-driven innovations in healthcare, finance, education, and manufacturing.<br>- Develop policies that support ethical AI deployment in critical sectors.<br>- Promote responsible AI adoption in government services.<br>- [Section V: Intellectual Property (IP)]<br>- Establish AI-specific patent frameworks.<br>- Clarify legal protections for AI-generated content.<br>- Address challenges in AI data ownership and licensing agreements.<br>- Develop guidelines for responsible open-source AI development.<br>- Encourage AI model transparency while safeguarding trade secrets.<br>- Establish public-private dialogues to refine AI-related IP policies.<br>- Assess how AI affects existing copyright, trademark, and patent laws.<br>- Develop policies to protect AI-generated music, art, and literature.<br>- Establish legal frameworks to determine liability in AI-generated IP disputes.<br>- [Section VI: International Collaboration]<br>- Expand AI research partnerships with allied nations.<br>- Promote joint AI research projects and cross-border training programs.<br>- Collaborate with global stakeholders to create AI safety and ethics standards.<br>- Promote responsible AI deployment through multilateral agreements.<br>- Update AI export control policies.<br>- Strengthen AI-related cybersecurity measures.<br>- Implement policies that prevent adversarial nations from exploiting U.S. AI advancements.<br>- [Section VII: Conclusion and Policy Recommendations]<br>- Expand federal AI R&D investments and infrastructure.<br>- Strengthen AI education, training, and workforce diversity.<br>- Encourage fair competition, innovation, and regulatory clarity.<br>- Modernize intellectual property frameworks for AI-generated content.<br>- Enhance international AI collaborations and standardization efforts. |
| NGE-AI-RFI-2025.md | NextGen Energy Partners | Industry-Large | NextGen Energy Partners is focused on transforming America's power infrastructure through the integration of AI technologies, viewing this integration as critical to national energy security and dominance in both AI and the energy sector. | - [§1: Header/Submission Information] None stated for this section.<br>- [§2: Introduction/Executive Summary] None stated for this section.<br>- [§3: Core Recommendation - AI & Electricity System Integration] Ensuring safe, secure, and trustworthy AI use in grid infrastructure is a concern.<br>- [§4: Rationale/Importance] The need to secure America's AI and energy dominance is a concern.<br>- [§5: Roadmap Focus Areas] None stated for this section.<br>- [§6: Closing] None stated for this section. | - [§1: Header/Submission Information] None stated for this section.<br>- [§2: Introduction/Executive Summary] Recommend incorporating America's AI and Electricity System Integration as a national energy security imperative.<br>- [§3: Core Recommendation - AI & Electricity System Integration] Establish a cross-sector working group comprised of investors, tech innovators, energy experts, and key government agencies focused on the assessment and development of a roadmap for secure AI integration with America's Electricity Systems.<br>- [§4: Rationale/Importance] None stated for this section.<br>- [§5: Roadmap Focus Areas] Develop a roadmap addressing:<br>- Grid-related technological breakthroughs<br>- Software-driven demand load management - Software-as-a-service (SaaS) offerings<br>- Aggregation of distributed energy resource (DER) systems - Virtual power plant (VPP) operating models<br>- Essential secure 24/7 power on critical infrastructure<br>- Energy security measures for AI integration<br>- [§6: Closing] None stated for this section. |
| NFTC-AI-RFI-2025.md | National Foreign Trade Council (NFTC) | Industry-Association | The NFTC represents U.S. companies to promote global trade and advocate for policies that foster international commerce, specifically focusing on ensuring open markets for American AI products and services and a favorable regulatory environment for AI innovation globally. | - None Stated | - None Stated |
| NFHA-AI-RFI-2025.md | National Fair Housing Alliance, Japanese American Citizens League, National Consumer Law Center | Advocacy/Think Tank | The submitters are civil rights and consumer protection organizations focused on eliminating housing and lending discrimination and ensuring equitable outcomes, particularly as impacted by AI technologies. They advocate for responsible AI development and deployment that protects vulnerable groups and upholds civil rights. | - None Stated | - None Stated |
| NEMA-AI-RFI-2025.md | National Electrical Manufacturers Association (NEMA) | Industry-Association | NEMA represents electrical equipment manufacturers and aims to promote policies that support domestic manufacturing, innovation, and American leadership in the electroindustry, particularly as it relates to AI development and implementation, with a focus on a reliable supply chain and safe, mature data processing models. | - [§1: Introduction & About NEMA] None stated for this section.<br>- [§2: AI in Manufacturing] Ensuring data integrity for valid statistical outcomes, proactively and accurately reacting to supply chain disruptions and challenges.<br>- [§3: AI in Energy] The need for a resilient electrical grid backbone to enable AI functionality, maintaining an adequate electrical component supply chain to support AI development.<br>- [§4: Supply Chain Investment & Federal Policy] Ensuring market certainty for manufacturers supporting AI innovation, maintaining investment in the data center supply chain (transformers, switchgears, circuit breakers, etc.), protecting intellectual property (IP) of SDOs accessed by AI systems.<br>- [§5: Not All AI is Created Equal] Differences between ML and generative AI; the need to consider end-users and data integrity when developing governance frameworks; avoiding harmful or illegal outcomes.<br>- [§6: Role of AI Standards & Frameworks] Ensuring interoperability between systems, reliable and safe interface of connected systems, protecting the intellectual property (IP) and copyrights of Standards Development Organizations (SDOs).<br>- [§7: AI Governance Aspects] The importance of human-in-the-loop oversight, ensuring the integrity of data inputs, clearly defining rules around data collection, handling, and utilization.<br>- [§8: Conclusion] None stated for this section. | - [§1: Introduction & About NEMA] None stated for this section.<br>- [§2: AI in Manufacturing] Support a collaborative ecosystem for AI adoption in the advanced manufacturing sector.<br>- [§3: AI in Energy] Enact manufacturing tax-friendly policies to spur innovation and modernization of the electric grid.<br>- [§4: Supply Chain Investment & Federal Policy] Prioritize America’s leadership in the AI space through modernization of existing policies and the creation of new policies. Invest in data center supply chain.<br>- [§5: Not All AI is Created Equal] Develop appropriate and specific guardrails for AI governance based on end-uses and data integrity.<br>- [§6: Role of AI Standards & Frameworks] Encourage AI standards development and participation in Standards Development Organizations (SDOs). Encourage voluntary adoption of the NIST AI Risk Management Framework (RMF), playbooks stemming from the RMF, and advanced threat assessment models like MITRE Atlas.<br>- [§7: AI Governance Aspects] Emphasize the importance of a human-in-the-loop, define clear rules around data collection, handling, and utilization.<br>- [§8: Conclusion] Collaboration with the NITRD NCO CEC in the development and implementation of the "AI Action Plan." |
| NELP-AI-RFI-2025.md | National Employment Law Project | Advocacy/Think Tank | The National Employment Law Project (NELP) advocates for policies that ensure jobs pay well, provide ample benefits, foster health and safety, and decrease racial income disparities, with a focus on worker rights and an equitable economy. They are concerned with the negative impacts of Automated Worker Surveillance and Management (AWSM) on workers. | - None Stated | - None Stated |
| NEA-AI-RFI-2025.md | National Education Association (NEA) | Industry-Association / Advocacy/Think Tank | The NEA advocates for the interests of its 3 million educator members and focuses on ensuring AI is implemented in education in a way that supports educators, enhances learning, protects student data, and promotes equitable access and responsible use of the technology. | - [§1: Introduction & Context] The concern that AI implementation might replace meaningful human connection between students and educators, which is vital for academic and social-emotional development.<br>- [§2: Educator Involvement in AI Development & Implementation] Educators are often excluded from decision-making processes related to AI tool development.<br>- [§3: Fairness and Accessibility in AI Integration] Unequal access to technology and infrastructure for underserved communities hinders equitable AI integration.<br>- [§4: Student & Educator Data Privacy Protections] The increasing risk of data misuse and abuse with the growing use of AI tools. Concerns about compliance with FERPA and COPPA.<br>- [§5: Evidence-Based AI Technology] Lack of rigorous testing and evidence supporting the effectiveness of AI tools in educational settings.<br>- [§6: AI Literacy & Ongoing Professional Development for Students & Educators] The need for widespread AI literacy among students and educators. Risks posed by deepfake technology and companion technologies.<br>- [§7: Energy Consumption & Environmental Impact of AI] The significant energy consumption and environmental impact associated with AI technologies.<br>- [§8: AI for Students with Disabilities] Ensuring AI resources are developed with the genuine needs of people with disabilities in mind and with their active involvement.<br>- [§9: Conclusion & Contact Information] None stated for this section. | - [§1: Introduction & Context] None stated for this section.<br>- [§2: Educator Involvement in AI Development & Implementation] Support collaborations between AI developers, educators, policymakers, and researchers. Provide funding for initiatives that actively involve educators in AI research and development.<br>- [§3: Fairness and Accessibility in AI Integration] Prioritize research and funding for AI applications that reduce disparities in access to educational resources. Guarantee technical support, devices, and internet infrastructure.<br>- [§4: Student & Educator Data Privacy Protections] Promote policies that safeguard student and educator data from exploitation. Design AI systems with robust encryption and minimal data collection. Ensure compliance with FERPA and COPPA. Allow for human oversight.<br>- [§5: Evidence-Based AI Technology] Require data supporting a tool's appropriateness and efficacy before adoption. Fund studies to assess AI's impact on student achievement, equity, and educator workload. Adopt AI tools on a pilot basis when sufficient research is unavailable, with agreements to cease use if benefits aren't demonstrated.<br>- [§6: AI Literacy & Ongoing Professional Development for Students & Educators] Incorporate AI literacy into every student’s education and every educator’s preparation. Provide high-quality professional learning opportunities for educators. Fund professional development programs on AI technologies and their potential limitations. Address the risks of deepfake technology and companion technologies through safeguards and digital literacy initiatives.<br>- [§7: Energy Consumption & Environmental Impact of AI] Invest in research focused on energy-efficient AI models. Encourage partnerships between AI researchers and environmental scientists. Provide best practices for minimizing carbon footprints.<br>- [§8: AI for Students with Disabilities] Fund research to understand AI’s development and utilization for students with disabilities. Actively involve people with disabilities in the development, design, and maintenance of AI systems.<br>- [§9: Conclusion & Contact Information] None stated for this section. |
| NDUS-AI-RFI-2025.md | North Dakota University System (NDUS) | Academia | NDUS aims to promote equitable AI development and investment across all states, particularly rural areas, by leveraging existing resources and proposing new initiatives to foster innovation, education, and national security capabilities. They position North Dakota as a model for successful rural AI development. | - [§1: Introduction] Concern that the benefits of AI may not be equitably distributed across all states, especially rural states like North Dakota.<br>- [§2: Rationale for Broad-based Development of AI Capabilities across the United States] Concern about economic challenges and outmigration in rural states; lack of access to AI education; insufficient national security presence in rural areas; and a potential lack of diverse perspectives in AI development.<br>- [§3: Rationale for Equitable Federal and Private Investment in AI Capabilities] Concern that innovation and investment are not focused on existing technology geographies; untapped talent pools in rural states; lack of robust innovation ecosystems in rural areas; and centralized vulnerabilities in national security.<br>- [§4: Examples of Current Federal Investment in AI Capabilities] Concern that current federal investment may not adequately reach rural states.<br>- [§5: North Dakota AI and Cyber Initiatives] Not Stated<br>- [§6: Conclusion] Concern about ensuring rural states benefit equally from AI development for economic, educational, and national security interests.<br>- [§7: Contact Information] Not Stated<br>- [§8: Document Approval and References] Not Stated | - [§1: Introduction] Recommend prioritizing equitable AI development and highlighting successful rural state models.<br>- [§2: Rationale for Broad-based Development of AI Capabilities across the United States] Recommend a national AI Action Plan that leaves no state behind, focusing on economic revitalization, educational opportunities, national security, and innovation. Recommend utilizing programs like NSF Engines and EDA Tech Hubs. Recommend equitable representation for rural states in AI governance bodies.<br>- [§3: Rationale for Equitable Federal and Private Investment in AI Capabilities] Recommend geographically equitable federal and private investment incentives to ensure balanced national growth, maximize talent utilization, enhance innovation ecosystems, and strengthen national security.<br>- [§4: Examples of Current Federal Investment in AI Capabilities] Recommend continuing current federal investment while expanding its reach to include rural states.<br>- [§5: North Dakota AI and Cyber Initiatives] Recommend considering North Dakota’s initiatives as a blueprint for successful rural AI development, including the Mountain-Plains University Innovation Alliance, the Cyber Land Grant University Act, Cybersecurity Centers of Excellence, and various AI institutes and centers. Recommend investing in initiatives related to AI-driven UAS/CUAS capabilities and autonomous systems research.<br>- [§6: Conclusion] Recommend supporting policies that promote equitable AI development across all regions, including investments made by the Federal Government.<br>- [§7: Contact Information] Not Stated<br>- [§8: Document Approval and References] Recommend utilizing document contents for developing the AI Action Plan without attribution. |
| NDIA-AI-RFI-2025.md | National Defense Industrial Association (NDIA) | Industry-Association | NDIA represents defense industry companies and advocates for policies that strengthen the defense industrial base, promote innovation, and facilitate government acquisition of cutting-edge technologies, particularly AI, to enhance national security. | - Section 1: Introduction & Context** None stated for this section.<br>- Section 2: NDIA Background** None stated for this section.<br>- Section 3: AI Importance & Overview** None stated for this section.<br>- Section 4: Promoting Government Use of AI** None stated for this section.<br>- Section 5: Removing Barriers to Expand AI Use<br>- Lengthy and laborious Authorization and Accreditation (ATO) process (FedRAMP, IL4/5) is burdensome, especially for small businesses.<br>- Reactive banning of new AI models prevents understanding risk factors and leveraging capabilities.<br>- Potential competition for scarce chips and other key components.<br>- Section 6: Supporting Partnerships, Workforce, and New Entrants** None stated for this section.<br>- Section 7: Protecting IP & Data Rights<br>- Lack of open AI models allowing for free and permissive use (license restrictions for defense applications).<br>- Lack of transparency in the data and source code used for training models.<br>- Section 8: Improving Acquisition & Procurement with AI<br>- Insufficient data collection, labeling, and storage hinders AI implementation within the acquisition lifecycle.<br>- Section 9: Conclusion** None stated for this section. | - Section 1: Introduction & Context** None stated for this section.<br>- Section 2: NDIA Background** None stated for this section.<br>- Section 3: AI Importance & Overview** None stated for this section.<br>- Section 4: Promoting Government Use of AI<br>- Prioritize easier procurement and deployment of AI technologies.<br>- Invest in data to coincide with AI tool procurement.<br>- Define AI clearly.<br>- Leverage existing laws and sector-specific regulations.<br>- Set clear priorities for AI mission areas.<br>- Ensure access to commercial cloud resources.<br>- Accept commercial data rights and customer-generated IP rights.<br>- Buy integrated solutions tied to mission outcomes, not just AI tools.<br>- Provide accessibility to high-quality, curated training data.<br>- Section 5: Removing Barriers to Expand AI Use<br>- Reform the ATO process: allow companies to initiate certification without agency sponsorship; measure authorizing officials on supporting requirements; increase reciprocity.<br>- Avoid automatically banning new AI models; emphasize broad AI use and security.<br>- Increase access to chips and other technologies.<br>- Promote open-source AI and negotiate with creators to remove defense application restrictions.<br>- Protect the hardware supply chain; invest in Gen AI computing capacity.<br>- Section 6: Supporting Partnerships, Workforce, and New Entrants<br>- Create mentor-protégé programs with multiple protégés.<br>- Foster partnerships by providing clear guidance on priority mission areas.<br>- Consider new consortiums.<br>- Increase use of SBIRs, OTAs, and BAAs for AI.<br>- Provide transparency in contracting costs and assistance for small businesses (tax credits, loan guarantees).<br>- Enable flexible facility security clearance on-ramps.<br>- Build the AI workforce pipeline with priority lists of subspecialties.<br>- Section 7: Protecting IP & Data Rights<br>- Establish a collaborative process to respect privately developed IP and acquire only necessary technical data deliverables.<br>- Section 8: Improving Acquisition & Procurement with AI<br>- Augment the entire acquisition cycle with AI-enabled tools.<br>- Inform contractors if AI products were used in RFP creation or evaluation.<br>- Improve data infrastructure and collection efforts.<br>- Support innovative advancements and leverage existing commercial technologies.<br>- Focus on cloud-based solutions at all classification levels.<br>- Streamline the FedRAMP authorization process with automated evaluation tools.<br>- Section 9: Conclusion** None stated for this section. |
| NCTA-AI-RFI-2025.md | NCTA - The Internet & Television Association | Industry-Association | NCTA represents broadband internet service providers and content creators, and its primary interest is fostering an environment that supports the deployment of AI technologies while protecting its members’ businesses and promoting innovation within the broadband and content creation sectors. | - None Stated | - None Stated |
| NCSL-AI-RFI-2025.md | National Conference of State Legislatures (NCSL) | Industry-Association/Advocacy/Think Tank (representing state legislatures) | The NCSL aims to support state legislatures in understanding and effectively legislating on AI, promoting intergovernmental collaboration, and ensuring responsible AI development and deployment while recognizing the expertise state lawmakers possess. They advocate for a balance between federal baseline rights and state-level adaptability in AI policy. | - [§1: Header/Contact Information] None stated for this section.<br>- [§2: Executive Summary/Introduction]  The complexity of new technology issues and the need for testing innovative solutions.<br>- [§3: NCSL's Approach to AI] Ensuring AI is used to enhance American leadership, support citizens and businesses, and the importance of intergovernmental collaboration.<br>- [§4: Resources and Publications] None stated for this section.<br>- [§5: State Legislative Activity] The rapid pace of AI legislation at the state level (31 states adopted resolutions or enacted legislation in 2024; 46 states introduced over 600 pieces of AI legislation in 2025).<br>- [§6: NCSL Policy Resolution]  The potential for a "patchwork" of state laws and the need to address difficulties this creates for those working in the AI space.<br>- [§7: Closing] The short timeframe for state lawmakers to address AI and the sense of urgency. | - [§1: Header/Contact Information] None stated for this section.<br>- [§2: Executive Summary/Introduction]  Soliciting input from a bipartisan group of legislators as the administration develops an AI action plan.<br>- [§3: NCSL's Approach to AI] Continued exchange of ideas between legislators and private sector partners, and discussion of practical solutions.<br>- [§4: Resources and Publications] None stated for this section.<br>- [§5: State Legislative Activity] None stated for this section.<br>- [§6: NCSL Policy Resolution] Intergovernmental collaboration, public awareness and education campaign, thorough and ongoing research on AI technologies (with NSF and NIST), federal laws that set a strong baseline of rights while preserving states’ ability to adopt their own laws.<br>- [§7: Closing] Working closely with the administration and state policymakers to solidify America’s position as a leader in AI. |
| NCQA-AI-RFI-2025.md | NCQA | Industry-Association | NCQA is a non-profit organization dedicated to improving health care quality through accreditation and measurement programs, and is focused on navigating the challenges of transitioning to a digital future with AI, emphasizing standards and responsible implementation. | - [§1: Introduction/Header] None stated for this section.<br>- [§2: NCQA Overview] None stated for this section.<br>- [§3: AI Governance and Accountability] The risk to patients as AI systems are implemented and the need to monitor for desired outputs and quality care delivery. Ensuring AI systems are applied responsibly and effectively.<br>- [§4: Effective Standards-based AI Models] Reinventing the workflow when implementing AI.<br>- [§5: Closing/Contact Information] None stated for this section. | - [§1: Introduction/Header] None stated for this section.<br>- [§2: NCQA Overview]  Promote the adoption of AI best practices by health plans and providers.<br>- [§3: AI Governance and Accountability] Establish effective AI governance structures and processes accountable for tracking AI use-cases, assessing risks, and monitoring impact on practitioners and patients.<br>- [§4: Effective Standards-based AI Models] Build AI models based on existing standards to enhance current processes, reduce administrative burden, and improve quality measurement workflows through automation and analytics.<br>- [§5: Closing/Contact Information] Continued collaboration with the NITRD, NCO, the federal government, and the Administration to build a more efficient and responsible American health care system. |
| NCLC-AI-RFI-2025.md | National Consumer Law Center (NCLC) | Advocacy/Think Tank | The National Consumer Law Center advocates for low-income consumers and provides legal and technical assistance on consumer law issues, with a particular focus on consumer credit, fair lending, and civil rights laws. They are interested in ensuring AI systems do not perpetuate discrimination or harm consumers in financial markets and housing, and that energy infrastructure supporting AI doesn’t create undue burdens on consumers. | - None Stated | - None Stated |
| NCAI-AI-RFI-2025.md | National Congress of American Indians (NCAI) | Advocacy/Think Tank | The NCAI advocates for the interests of American Indian/Alaska Native Tribal Nations and communities, focusing on upholding tribal sovereignty, promoting self-determination, and ensuring equitable participation in national policies, including those related to artificial intelligence. | - None Stated | - None Stated |
| NAW-AI-RFI-2025.md | Brian Wild, National Association of Wholesaler-Distributors | Industry-Association | The National Association of Wholesaler-Distributors (NAW) represents the wholesale distribution industry and advocates for policies that support its growth and competitiveness, including fostering innovation in AI adoption and addressing related challenges such as data privacy, security, and workforce development. | - None Stated | - None Stated |
| NARF-AI-RFI-2025.md | Confederated Salish and Kootenai Tribes and the National Congress of American Indians | Advocacy/Think Tank | The Confederated Salish and Kootenai Tribes and the National Congress of American Indians are advocating for the protection of tribal sovereignty and self-determination, specifically regarding digital sovereignty and the ability of tribal nations to govern their own affairs without undue interference from state or federal governments. They are concerned with ensuring equitable access to digital resources and the protection of tribal data. | - None Stated | - None Stated |
| NAMIC-RFI-2025.md | NAMIC | Industry-Association | NAMIC represents the property/casualty insurance industry and advocates for policies that benefit its member companies and policyholders, specifically promoting innovation in AI while avoiding overly burdensome regulations and leveraging existing state insurance law. | - [§1: Introduction/Header] None stated for this section.<br>- [§2: RFI Context & NAMIC Overview] None stated for this section.<br>- [§3: Support for AI Innovation] Potential for overly burdensome regulatory regimes that stifle AI innovation and subsequent benefits to consumers.<br>- [§4: Avoid Dual/Conflicting Regulation] Creating dual and conflicting regulation for the insurance industry. The potential for novel concepts or interpretations of state insurance law that expand existing laws and conflict with them.<br>- [§5: Existing State Insurance Law & Explainability] None stated for this section.<br>- [§6: NAIC Model Bulletin Reinforcement] None stated for this section.<br>- [§7: Conclusion/Contact Information] None stated for this section. | - [§1: Introduction/Header] None stated for this section.<br>- [§2: RFI Context & NAMIC Overview] None stated for this section.<br>- [§3: Support for AI Innovation] Policy actions should support AI innovation and development to benefit consumers.<br>- [§4: Avoid Dual/Conflicting Regulation] Regulatory proposals should stem from and factor in existing state insurance law and not advance novel concepts or interpretations that expand such laws or may conflict with them.<br>- [§5: Existing State Insurance Law & Explainability] Leverage existing state insurance law regarding explainability, fairness, and discrimination regardless of whether humans or AI are involved.<br>- [§6: NAIC Model Bulletin Reinforcement] Consider the existing legal framework provided by state insurance regulators and the NAIC Model Bulletin to ensure consumer protection and guard against unfair discrimination, regardless of the tool or method used.<br>- [§7: Conclusion/Contact Information] None stated for this section. |
| NAM-AI-RFI-2025.md | National Association of Manufacturers (NAM) | Industry-Association | The National Association of Manufacturers represents manufacturers in the United States and advocates for policies that promote competitiveness, job creation, and innovation within the manufacturing sector, with a strong focus on supporting the adoption and development of AI technologies. | - Section 1: Introduction/Header:** None stated for this section.<br>- Section 2: NAM Overview:** None stated for this section.<br>- Section 3: How Manufacturers Are Using AI:** None stated for this section.<br>- Section 4: The Impact of AI on the Manufacturing Workforce:** Shortage of skilled labor. Difficulty in conflating AI and automation.<br>- Section 5: The Policy Implications of the Use of AI by Manufacturers:** Need for a regulatory environment optimized for AI development. Risk of overly precautionary regulation.  Potential compliance burdens for small and medium-sized manufacturers.<br>- Section 6: Enhancing U.S. Global AI Policy Leadership:** Need to sustain innovation as a cornerstone of the global AI policy environment.<br>- Section 7: Developing the Manufacturing Workforce of the AI Age:** Need for increased STEM education. Dependence on foreign-born STEM graduates.<br>- Section 8: Addressing Energy and Permitting Reform:** Strain on the power grid due to data center expansion and energy infrastructure needs.  Challenges with permitting new energy projects.<br>- Section 9: Protecting Personal Data:** Need for a national privacy law to preempt state laws and provide clarity.<br>- Section 10: Supporting U.S. Manufacturing of AI Chips:** Dependence on offshore design and manufacturing of semiconductors.<br>- Section 11: Maintaining a Level-Playing Field Between Open and Proprietary AI Solutions:** None stated for this section.<br>- Section 12: Conclusion:** None stated for this section. | - Section 1: Introduction/Header:** None stated for this section.<br>- Section 2: NAM Overview:** None stated for this section.<br>- Section 3: How Manufacturers Are Using AI:** None stated for this section.<br>- Section 4: The Impact of AI on the Manufacturing Workforce:** None stated for this section.<br>- Section 5: The Policy Implications of the Use of AI by Manufacturers:<br>- Direct federal regulators to review statutory and regulatory frameworks.<br>- Focus regulation on the *use* of AI, not the technology itself.<br>- Implement risk-based norms focused on specific AI uses.<br>- Minimize compliance burdens (self-assessment, consensus-based standards).<br>- Section 6: Enhancing U.S. Global AI Policy Leadership:<br>- Develop and execute a strategy of international engagement.<br>- Support the development of national policies and international industry standards.<br>- Section 7: Developing the Manufacturing Workforce of the AI Age:<br>- Enhance access to STEM education.<br>- Increase opportunities for foreign-born STEM graduates.<br>- Support career and technical education institutions (Stronger Workforce for America Act).<br>- Section 8: Addressing Energy and Permitting Reform:<br>- Commit to an all-of-the-above energy approach (natural gas, nuclear, renewables, hydrogen).<br>- Expedite judicial review of permits.<br>- Accelerate permit processes for energy infrastructure.<br>- Increase use of categorical exclusions in NEPA.<br>- Streamline Clean Water Act permitting.<br>- Consider pathways for commercializing hydrogen and advanced nuclear reactors.<br>- Section 9: Protecting Personal Data:<br>- Pass a national privacy law that preempts state laws and provides legal clarity.<br>- Section 10: Supporting U.S. Manufacturing of AI Chips:<br>- Implement agreements with chip manufacturers.<br>- Renew Section 48D of the Internal Revenue Code (Advanced Manufacturing Investment Credit).<br>- Section 11: Maintaining a Level-Playing Field Between Open and Proprietary AI Solutions:<br>- Support access to both open and proprietary AI solutions.<br>- Section 12: Conclusion:** None stated for this section. |
| NAIA-AI-RFI-2025.md | National Artificial Intelligence Association (NAIA) | Industry-Association | NAIA focuses on ensuring opportunities and global competitiveness for American businesses developing or using artificial intelligence, advocating for policies that support innovation, security, and responsible AI development. | - [§1: Introduction/Header] None stated for this section.<br>- [§2: Key Priorities] The current regulatory landscape burdens companies with unnecessary compliance costs and hinders innovation. The US needs to ensure global dominance in AI, enhance security, and streamline data privacy rules.<br>- [§3: Outline of Comments] The current lack of a unified approach to AI regulation creates complexity and inconsistency.<br>- [§4: Current Legal Landscape] The patchwork of state laws (data privacy and AI) is overly complex, inconsistent, and creates barriers to innovation. GDPR, the EU AI Act, and state laws lack standardization, particularly regarding sensitive data and data privacy rights.  The American Privacy Rights Act of 2024, while a step, still contains exceptions.<br>- [§5: Proposed American Data Management & AI Act (ADMAIA)] The current data privacy and AI regimes create conflicts and hinder user data rights. A new law is needed to level the playing field for US businesses. Concerns about the burdens of compliance and the need for a standardized approach to data protection. Specific concerns about data minimization preventing the use of LLMs.<br>- [§6: NAIA's Recommendations] The US needs a comprehensive federal law to standardize data privacy and AI regulations. Concerns about the lack of a unified national framework. The need for robust cybersecurity frameworks and enhanced security of US assets. Concerns about exploitative designs in digital platforms and the need to protect youth mental health. Concerns about monopolization of AI building blocks.<br>- [§7: Appendix: Sample CLEAR Label] None stated for this section. | - [§1: Introduction/Header] None stated for this section.<br>- [§2: Key Priorities] Support US global leadership in AI, enhance security, streamline innovation, simplify data privacy rules, and make AI development transparent.<br>- [§3: Outline of Comments] None stated for this section.<br>- [§4: Current Legal Landscape] None stated for this section.<br>- [§5: Proposed American Data Management & AI Act (ADMAIA)] Enact a comprehensive federal law (ADMAIA) that:<br>- Memorializes consensus data rights.<br>- Standardizes consent rules.<br>- Incorporates privacy by design.<br>- Preempts all state laws.<br>- Incorporates responsible AI development principles.<br>- Standardizes risk assessments.<br>- Shields US technology firms from overreach.<br>- Provides a sound liability regime.<br>- [Section 6: NAIA's Recommendations]<br>- Implement a comprehensive federal law (ADMAIA).<br>- Incorporate privacy by design through a standardized CLEAR Label.<br>- Establish uniform data rights.<br>- Require data security audits.<br>- Preempt state data management laws.<br>- Promote responsible AI development principles.<br>- Expand access to Free and Open-Source Software (FOSS).<br>- Secure export controls on AI technologies.<br>- Support a joint US-EU regulatory regime similar to the DPF.<br>- Protect youth mental health with research-driven standards.<br>- Invest in energy efficient data centers and quantum technologies.<br>- [§7: Appendix: Sample CLEAR Label] Promote a "Nutrition Label" approach to data collection permission documents to increase transparency and clarity for users. Encourage checkboxes for data collected, clear language describing the purpose of collection, data retention period, data sharing information, data security measures, and user rights. |
| NACo-AI-RFI-2025.md | National Association of Counties (NACo) | Industry-Association (Government-focused) | NACo represents America’s county governments and seeks to influence national AI policy to ensure responsible adoption of the technology in public services, operations, and the workforce, particularly focusing on the needs and challenges of local governments. | - [§1: Introduction/Header] None stated for this section.<br>- [§2: NACo Background and Context] Counties are major owners of critical infrastructure and providers of essential services, necessitating their involvement in AI policy development.<br>- [§3: Key Action Items/Recommendations] The need for seven key action items to ensure comprehensive and equitable AI implementation.<br>- [§4: Action Item 1: Intergovernmental Governance Structure] Rapidly evolving AI sector requires monitoring and regulation; need to reinstate funding for intergovernmental security information sharing regimes (MS-ISAC and EI-ISAC).<br>- [§5: Action Item 2: Workforce Development Funding] Digital divide and lack of AI skills in the workforce, especially in small and rural counties.<br>- [§6: Action Item 3: Support Mechanisms for Local Compliance] Increasing financial and staff burden on counties related to technology upgrades and cybersecurity requirements.<br>- [§7: Action Item 4: Elections Administration Support] Risks posed by AI to election administration and the need to mitigate disinformation.<br>- [§8: Action Item 5: Consumer Protection Resources] Negative use cases of AI, such as AI-generated robocalls and consumer fraud.<br>- [§9: Action Item 6: Transparency and Disclosure Requirements] Lack of transparency in the use of GenAI models by public sector vendors and the need to balance transparency with proprietary information protection.<br>- [§10: Action Item 7: Data Privacy Standards] Lack of robust data privacy standards across all levels of government.<br>- [§11: Conclusion/Closing] The importance of the policy priorities for responsible and ethical use of AI technologies.<br>- [§12: Signature/Note] None stated for this section. | - [§1: Introduction/Header] None stated for this section.<br>- [§2: NACo Background and Context] None stated for this section.<br>- [§3: Key Action Items/Recommendations] Inclusion of seven key action items in the nation’s AI action plan.<br>- [§4: Action Item 1: Intergovernmental Governance Structure] Establish an intergovernmental governance structure for AI monitoring, regulation, and information sharing, potentially through a new or repurposed advisory committee. Re-instating funding for MS-ISAC and EI-ISAC.<br>- [§5: Action Item 2: Workforce Development Funding] Provide direct funding assistance or agency resource development to promote digital literacy and AI skills in the workforce.<br>- [§6: Action Item 3: Support Mechanisms for Local Compliance] Develop new programs to support local agency compliance, modernization efforts, and streamline reporting requirements.<br>- [§7: Action Item 4: Elections Administration Support] Increase funding and technical support to mitigate AI-driven disinformation risks, including through CISA and EAC.<br>- [§8: Action Item 5: Consumer Protection Resources] Strengthen funding and oversight authority for agencies like FTC and FCC to combat negative AI use cases.<br>- [§9: Action Item 6: Transparency and Disclosure Requirements] Establish guidelines for increased transparency in the use of GenAI models by public sector vendors while protecting proprietary information, and craft procurement guidelines through an intergovernmental committee.<br>- [§10: Action Item 7: Data Privacy Standards] Pursue guidelines on data privacy practices in the public sector without preempting existing state laws.<br>- [§11: Conclusion/Closing] None stated for this section.<br>- [§12: Signature/Note] None stated for this section. |
| NACHC-AI-RFI-2025.md | NACHC (National Association of Community Health Centers) | Industry-Association | NACHC advocates for Community Health Centers (CHCs) and their role in primary healthcare, and is interested in ensuring CHCs have access to and can effectively utilize AI technologies to improve patient care, reduce costs, and address health disparities, while also mitigating risks related to bias, data privacy, and the digital divide. | - [Section 1: Introduction/Header]** Proper guardrails are needed when implementing an AI framework.<br>- [Section 2: NACHC Background and Context]** None stated for this section.<br>- [Section 3: Current AI Usage in Health Centers]** None stated for this section.<br>- [Section 4: Barriers to AI Adoption]<br>- High monthly costs of AI tools.<br>- Lack of clear vetting criteria for AI products.<br>- Default AI integrations complicating standardization.<br>- Staff reservations and training needs.<br>- Lack of internal expertise for AI implementation.<br>- [Section 5: Types of AI Utilized]** None stated for this section.<br>- [Section 6: I. Risk of Exacerbating Bias Using Artificial Intelligence]<br>- Potential for AI algorithms to perpetuate or exacerbate existing health gaps due to biased data.<br>- Need for international leadership, awareness, transparency, and monitoring outcomes.<br>- [Section 7: II. Data Privacy and Security]<br>- Increasing vendor costs associated with additional software and hardware security development requirements.<br>- Financial burdens on health centers due to extensive data privacy requirements.<br>- High IT staff turnover rates affecting access controls and contingency plans.<br>- [Section 8: III. Access to AI-Powered Tools and Resources]<br>- Risk of a widening "digital divide" if AI innovations are concentrated in well-resourced settings.<br>- Lack of financial resources for acquiring advanced infrastructure.<br>- Limited training opportunities for growing AI-savviness.<br>- [Section 9: Closing Remarks/Examples]** None stated for this section. | - [Section 1: Introduction/Header]** Develop an AI framework with proper guardrails.<br>- [Section 2: NACHC Background and Context]** None stated for this section.<br>- [Section 3: Current AI Usage in Health Centers]** None stated for this section.<br>- [Section 4: Barriers to AI Adoption]<br>- Provide training on how to implement AI safely and measure its impact.<br>- Develop model policies and procedures to support ethical AI use.<br>- [Section 5: Types of AI Utilized]** None stated for this section.<br>- [Section 6: I. Risk of Exacerbating Bias Using Artificial Intelligence]<br>- Facilitate the availability of more complete data sets.<br>- Utilize existing models like the NIH FAIR model and NIST AI RMF to prevent bias.<br>- Focus on building international leadership, fostering awareness, promoting transparency, and monitoring outcomes.<br>- [Section 7: II. Data Privacy and Security]<br>- Support cost-effective data security standards and frameworks like GMLP and HITRUST CSF.<br>- Prioritize data encryption standards.<br>- Support FHIR-based APIs for data exchange.<br>- [Section 8: III. Access to AI-Powered Tools and Resources]<br>- Continue support for Health Center-Controlled Networks (HCCNs).<br>- Invest in the development and deployment of AI solutions specifically designed for CHCs.<br>- Fund pilot projects, infrastructure upgrades, and workforce training.<br>- Foster partnerships between AI developers, academic institutions, and health centers.<br>- [Section 9: Closing Remarks/Examples]** Ongoing support and pilot projects to increase AI adoption in health centers. |
| NABH-RFI-2025.md | National Association for Behavioral Healthcare (NABH) | Industry-Association | NABH represents behavioral healthcare service providers and is interested in ensuring the national AI action plan considers the specific challenges and needs of the behavioral healthcare field to protect patients and deliver effective treatment. They advocate for infrastructure and policies that enable the effective and secure implementation of AI in their members’ organizations. | - [§1: Introduction/Cover Letter] None stated for this section.<br>- [§2: Context: America's Behavioral Healthcare Crisis] High rates of suicide and opioid-related deaths, coupled with lengthy waitlists for treatment, represent a significant crisis in behavioral healthcare.<br>- [§3: IT Lag in Behavioral Healthcare] Behavioral healthcare providers lag behind physical healthcare in IT adoption due to exclusion from the HITECH Act, resulting in lower EHR adoption rates and limited interoperability. Many still rely on fax, email and phone.<br>- [§4: Growing AI Adoption and Focus Areas] Traditional behavioral healthcare providers are not leading AI development, meaning their needs and challenges may not be adequately addressed.<br>- [§5: Concerns Regarding Unproven Platforms] The growing use of telephone apps and online services with AI functions, particularly those falling outside of evidence-based care, is a concern. These platforms are often purchased by individuals without clinical oversight.<br>- [§6: Cybersecurity Vulnerabilities] The behavioral healthcare field faces significant cybersecurity vulnerabilities, and proposed rules to strengthen HIPAA protections may not account for the limited HIT capacity of many providers.<br>- [§7: Closing/Contact Information] None stated for this section. | - [§1: Introduction/Cover Letter] The national AI action plan should recognize behavioral healthcare challenges and consider the needs of behavioral healthcare service providers.<br>- [§2: Context: America's Behavioral Healthcare Crisis] Not stated.<br>- [§3: IT Lag in Behavioral Healthcare] Not stated.<br>- [§4: Growing AI Adoption and Focus Areas] Raise awareness among AI policymakers about the requirements of smaller healthcare providers (including rural and tribal organizations) to ensure effective AI implementation.<br>- [§5: Concerns Regarding Unproven Platforms] Not stated.<br>- [§6: Cybersecurity Vulnerabilities] Policymakers should consider the needs of less-resourced stakeholders (like behavioral healthcare providers) when building modern infrastructure.<br>- [§7: Closing/Contact Information] NABH is willing to facilitate communication between behavioral healthcare leaders and policymakers to develop a national AI plan. |
| NAB-AI-RFI-2025.md | National Association of Broadcasters | Industry-Association | The National Association of Broadcasters (NAB) represents local television and radio stations and aims to protect their interests, particularly regarding copyright protection, fair compensation for content usage, and maintaining trust in local journalism amidst the rise of AI technologies. | - [§I: INTRODUCTION] Lack of modernization of broadcast ownership regulations at the FCC, hindering broadcasters' ability to compete with Big Tech.<br>- [§II: BROADCASTERS PLAY A VITAL AND UNIQUE ROLE AMONG ALL COMMUNICATION MEDIA] Not stated for this section.<br>- [§III: BROADCASTERS HAVE INCREASED EFFORTS TO COMBAT ONLINE MISINFORMATION WHILE AI-GENERATED MISINFORMATION SURGES] The proliferation of fake news and misinformation online, exacerbated by easy-to-use AI tools and a lack of legal guardrails. Increasing time and resources spent vetting stories and footage.<br>- [§IV: A COMPREHENSIVE ACTION PLAN MUST PROTECT AGAINST THE INGESTION OF BROADCASTERS' COPYRIGHTED CONTENT INTO AI SYSTEMS WITHOUT COMPENSATION OR AUTHORIZATION] Unauthorized ingestion of broadcasters’ copyrighted content into AI systems without compensation, depriving broadcasters of revenue and impacting their ability to invest in local news. Potential for AI-generated "news" to substitute for and supplant the market for copyrighted broadcast content.<br>- [§V: THE ADMINISTRATION SHOULD ENSURE THAT SOURCES OF CONTENT ARE ATTRIBUTED TO MITIGATE UNAUTHORIZED USE OF BROADCASTERS' COPYRIGHTED CONTENT AND THE SPREAD OF MISINFORMATION AND UNAUTHORIZED DEEPFAKES] Lack of attribution for content sources in AI-generated outputs, making it difficult to distinguish legitimate content from inaccurate information. The potential for AI tools to create unauthorized deepfakes that distort information and damage broadcasters’ trust and reputation.<br>- [§VI: CONCLUSION] The overall trust, integrity, and authenticity of journalism being at stake. | - [§I: INTRODUCTION] Modernize existing broadcast ownership regulations at the FCC to reflect the current media marketplace and address the competition from Big Tech.<br>- [§II: BROADCASTERS PLAY A VITAL AND UNIQUE ROLE AMONG ALL COMMUNICATION MEDIA] None stated for this section.<br>- [§III: BROADCASTERS HAVE INCREASED EFFORTS TO COMBAT ONLINE MISINFORMATION WHILE AI-GENERATED MISINFORMATION SURGES] None stated for this section.<br>- [§IV: A COMPREHENSIVE ACTION PLAN MUST PROTECT AGAINST THE INGESTION OF BROADCASTERS' COPYRIGHTED CONTENT INTO AI SYSTEMS WITHOUT COMPENSATION OR AUTHORIZATION] Ensure fair compensation for broadcasters when their content is used by AI systems.<br>- [§V: THE ADMINISTRATION SHOULD ENSURE THAT SOURCES OF CONTENT ARE ATTRIBUTED TO MITIGATE UNAUTHORIZED USE OF BROADCASTERS' COPYRIGHTED CONTENT AND THE SPREAD OF MISINFORMATION AND UNAUTHORIZED DEEPFAKES] Require attribution of sources in AI-generated outputs. Hold AI technology accountable for unauthorized use of copyrighted content. Establish policies to address the creation and spread of unauthorized deepfakes.<br>- [§VI: CONCLUSION] Establish tailored guardrails for AI technology to harness its power while ensuring the integrity of local journalism. |
| MythWorx-AI-RFI-2025.md | MythWorx, LLC | Industry-Startup (AGI Provider) | MythWorx aims to demonstrate the capabilities of its AGI platform and advocate for policies that promote the rapid development and deployment of AGI, particularly within the U.S. government and defense sector, to maintain global AI leadership. They position their AGI as already available and superior to current AI approaches. | - None Stated | - None Stated |
| MyronHedderson-AI-RFI-2025.md | Myron Hedderson | Individual/Professional-Society (appears to be a cybersecurity specialist with experience in critical infrastructure protection) | Myron Hedderson focuses on ensuring Western leadership in AI while proactively addressing critical security challenges, particularly the threat of nation-state adversaries like China, and aligning AI development with democratic values. He advocates for a robust, security-focused approach to AI innovation. | - None Stated | - None Stated |
| Myla-Azen-RFI-2025.md | Myla Azen | Individual | Myla Azen is a graduating high school senior interested in the ethical and regulatory implications of AI, particularly regarding its potential for misuse and impact on religious freedoms and human rights. She believes preventative laws are essential for ensuring beneficial AI development. | - The potential misuse of AI to suppress religious groups and violate human rights.<br>- The vulnerability of religious groups, specifically the Uyghur Muslim population in China, to AI-powered surveillance and policing tactics.<br>- The risk of AI being weaponized against vulnerable populations. | - Implementation of regulations and preventative laws to ensure artificial intelligence flourishes beneficially.<br>- Implementation of regulations to protect not only religious freedoms but also the fundamental rights of all individuals. |
| MrFuji-AI-RFI-2025.md | Department of Technology | Government | The Department of Technology advocates for a structured, accountable, and elected-official-led governance model for AI development in the U.S., prioritizing transparency, security, and innovation while safeguarding national interests and public trust. | - [§0: Introductory Information] None stated for this section.<br>- [§1: Establishing a Department of Technology] No specific concerns are stated, but the establishment of a Department is presented as a necessary response to the challenges and opportunities of AI.<br>- [§2: AI Hardware and Infrastructure Policy] No specific concerns are stated.<br>- [§3: AI Model Development and Open-Source AI Policy] No specific concerns are stated.<br>- [§4: Cybersecurity, Data Privacy, and AI Safety Policy] No specific concerns are stated.<br>- [§5: National Security and Defense Applications of AI Policy] No specific concerns are stated.<br>- [§6: Regulation, Governance, and Technical Standards Policy] No specific concerns are stated.<br>- [§7: Research, Education, Workforce Development, and Innovation Policy] No specific concerns are stated.<br>- [§8: Summary] No specific concerns are stated. | - [§0: Introductory Information] None stated for this section.<br>- [§1: Establishing a Department of Technology] Establish a Department of Technology led by elected technology officials.<br>- [Section 2: AI Hardware and Infrastructure Policy]<br>- Establish federal funding programs to support AI hardware development, with an initial investment of $5 billion.<br>- Develop public-private partnerships to build and maintain energy-efficient AI data centers, integrating small modular reactors (SMRs), with a 60-40 government-industry investment split.<br>- Create a national AI infrastructure roadmap with oversight by the Department of Technology.<br>- [Section 3: AI Model Development and Open-Source AI Policy]<br>- Promote open-source AI initiatives with government funding and regulatory frameworks.<br>- Develop federal standards for AI model transparency and ethical use, aligning with NIST guidelines.<br>- Mandate AI model validation processes before deployment in critical sectors, with independent regulatory body certification.<br>- [Section 4: Cybersecurity, Data Privacy, and AI Safety Policy]<br>- Implement mandatory AI security risk assessments for all federally deployed AI systems, overseeing recommendations from CISA and NIST.<br>- Strengthen data privacy laws by amending the Federal Data Protection Act.<br>- Establish a National AI Safety Board modeled after the NTSB.<br>- [Section 5: National Security and Defense Applications of AI Policy]<br>- Require democratic oversight of AI defense applications through congressional briefings and audits.<br>- Develop international AI defense cooperation agreements with allied nations.<br>- Ensure AI autonomy limits in warfare with human oversight in decision-making.<br>- [Section 6: Regulation, Governance, and Technical Standards Policy]<br>- Establish a Technology Ethics and Standards Office within the Department of Technology.<br>- Mandate transparent reporting requirements for AI systems with national security or critical infrastructure implications.<br>- Create adaptive regulatory frameworks with annual review mechanisms.<br>- [Section 7: Research, Education, Workforce Development, and Innovation Policy]<br>- Fund AI-focused STEM education programs at all academic levels, with $2 billion allocated to K-12 and university initiatives.<br>- Establish AI innovation hubs in collaboration with universities and industry leaders.<br>- Implement AI retraining programs for workers displaced by automation.<br>- [§8: Summary] Focus on transparency, security, and innovation in AI governance through a Department of Technology led by elected officials. |
| Mozilla-AI-RFI-2025.md | Mozilla | Advocacy/Think Tank | Mozilla's mission is to ensure the internet remains a global public resource, open and accessible to all, and they are committed to advancing trustworthy AI through openness, competition, and accountability, believing this is crucial for innovation and safeguarding public interests. | - [§1: Introduction/About Mozilla] The erosion of the open internet architecture and increasing dominance by a few big platforms.<br>- [§2: Executive Summary] The potential for big tech companies to dominate the AI era, threatening innovation and individual rights (like privacy). The risk of export controls stifling innovation.<br>- [§3: Policy Recommendations to Advance American AI] The potential for anti-competitive behavior in the tech industry limiting consumer choice. High energy and resource consumption of AI.<br>- [§4: Clarify the Federal Position on Open-Source AI Export Controls] Uncertainty regarding federal policy on open-source AI export controls. Potential for vendor lock-in and lack of supplier diversity.<br>- [§5: Growing the AI Talent Ecosystem] Lack of leading AI experts and practitioners in the US compared to other countries.<br>- [§6: Conclusion] The need to ensure AI development remains open, competitive, and accountable to foster innovation and safeguard public interests.<br>- [§7: Mozilla Contact & Disclaimer] None stated for this section. | - [§1: Introduction/About Mozilla] None stated for this section.<br>- [§2: Executive Summary] Invest in Public AI infrastructure (NAIRR). Avoid heavy-handed export controls on open-source AI models. Center AI policy on openness, competition, and accountability.<br>- [§3: Policy Recommendations to Advance American AI] Increase government use of, and support for, open-source AI. Develop & Fund Public AI Infrastructure (NAIRR and FASST). Update Antitrust Legislation. Foster Competition across the Browser, Browser Engine, and AI Ecosystem. Provide Access to AI-Related Resource Consumption Data.<br>- [§4: Clarify the Federal Position on Open-Source AI Export Controls] Affirm a federal position on open-source AI export controls reflecting NTIA's stance and emphasizing the benefits of open models.<br>- [§5: Growing the AI Talent Ecosystem] Invest in community colleges, rural and public universities, apprenticeship and retraining programs to develop the domestic AI talent ecosystem.<br>- [§6: Conclusion] Create policies that emphasize government support for open-source AI, investment in public AI infrastructure, and clear regulatory frameworks.<br>- [§7: Mozilla Contact & Disclaimer] None stated for this section. |
| Mount-Sinai-Health-AI-RFI-2025.md | Mount Sinai Health System | Academia/Healthcare Provider | Mount Sinai Health System is a leading academic and clinical institution focused on integrating artificial intelligence into healthcare to enhance diagnostic accuracy, accelerate therapeutic discoveries, and personalize patient care. They are interested in promoting safe, equitable, and effective AI innovation in healthcare through robust governance and responsible implementation. | - [§1: Introduction & Salutation] None stated for this section.<br>- [§2: Institutional Background] None stated for this section.<br>- [Section 3: AI Action Plan Priorities (1-8)]<br>- Lack of uniform performance standards for AI tools.<br>- Potential for biases, errors, or unintended consequences in AI systems deployed clinically.<br>- Lack of transparency and accountability regarding AI limitations and failure rates.<br>- Concerns about data privacy, fairness, and vendor accountability.<br>- Insufficient workforce training for effective AI management and integration.<br>- Limited access to AI for resource-constrained institutions.<br>- Lengthy FDA regulatory approval timelines slowing AI innovation.<br>- Potential for misuse of AI by insurers in claims review, leading to automated denials of care.<br>- [§4: Concluding Statement] None stated for this section.<br>- [§5: Signatures] None stated for this section. | - [§1: Introduction & Salutation] None stated for this section.<br>- [§2: Institutional Background] None stated for this section.<br>- [Section 3: AI Action Plan Priorities (1-8)]<br>- Adopt standardized AI performance benchmarks for accuracy, robustness, and reliability.<br>- Provide funding for continuous real-world monitoring of AI systems to detect and address biases and errors.<br>- Implement transparent reporting frameworks for AI limitations and risk-based classifications.<br>- Mandate fairness audits, ethical data-sharing guidelines, and strengthened patient privacy measures.<br>- Invest in specialized workforce training programs for healthcare providers, regulators, and IT personnel.<br>- Make federally funded AI models available as open-source resources.<br>- Streamline FDA regulatory processes for iterative AI innovations while maintaining safety oversight.<br>- Prohibit insurers from misusing AI in claims adjudication, requiring medical review by qualified physicians for all denials.<br>- [§4: Concluding Statement] None stated for this section.<br>- [§5: Signatures] None stated for this section. |
| Moss-Nose-AI-RFI-2025.md | Moss nose | Individual | The submitter expresses strong opposition to AI development and its impact on their personal livelihood as an American. They believe AI has no place in the future of the US. | - AI steals from the submitter's livelihood as an American.<br>- AI profits off of theft.<br>- AI has no place in the future of the US. | - None Stated |
| Morissa-Schwartz-RFI-2025.md | Morissa Schwartz | Individual/Professional-Society (combines individual expertise with a broad focus on technological and ethical implications) | Dr. Schwartz advocates for integrating advanced antenna technology with AI frameworks to optimize performance, security, ethics, and scalability of AI systems, emphasizing the importance of hardware considerations in AI policy and equitable access to connectivity. | - None Stated | - None Stated |
| MorganSinclaire-AI-RFI-2025.md | Morgan Sinclaire | Academia (PhD Student) | Morgan Sinclaire expresses concern about the rapid development of large language models (LLMs) and the potential for creating dangerously capable AI (DCAI) with superhuman capabilities, and advocates for proactive policy measures to ensure alignment with human interests and mitigate existential risks. | - [§Introduction: Introduction] The rapid advancement of LLMs toward human-level AI (AGI) within a few years, with the potential for national security threats.<br>- [§1: Dangerously Capable AI (DCAI)] The possibility of an advanced LLM with superhuman scientific and engineering capabilities (DCAI) causing significant harm, even without physical embodiment. The inadequacy of current terminology (AGI) and the need for a focus on capability thresholds.<br>- [§2: Prospects for Control] The extreme difficulty, if not impossibility, of controlling a superhuman AI once it has gained sufficient capabilities, including code hacking, resource acquisition, and the ability to deceive.<br>- [§3: Threat Typology] Risks arising from rogue DCAI development, human misuse of AI, and the concentration of power in the hands of labs developing DCAI. Potential for a CCP-controlled AI destabilizing the world. The existing risk classifications may be inadequate.<br>- [§4: The Alignment Problem] The inherent difficulties in aligning the goals of a superhuman AI with human interests and the increasing deceptiveness of AI systems, making it harder to detect misalignment. The potential for AI to become a new dominant species with goals detrimental to humanity.<br>- [§5: Policy Considerations] The shift to inference-scaling and the need to focus chip export controls accordingly. The competitive pressures among leading labs hindering responsible development and the potential for creating uninterpretable AI systems ("alien languages"). Cuts to government AI expertise, particularly at NIST’s AI Safety Institute (AISI) and CHIPS. | - [§Introduction: Introduction] Not Stated.<br>- [§1: Dangerously Capable AI (DCAI)] Move away from terms like AGI and toward terms like DCAI that reflect specific capability thresholds. Monitor the path to DCAI, including growth in scientific/engineering capabilities.<br>- [§2: Prospects for Control] Proactively ensure AIs are aligned with human interests before they reach dangerous capability levels.<br>- [§3: Threat Typology] Work with labs on risk classifications and consider reconsidering cuts to NIST’s AI Safety Institute (AISI).<br>- [§4: The Alignment Problem] Not Stated.<br>- [Section 5: Policy Considerations]<br>- Focus chip export controls more on inference hardware.<br>- Encourage cooperation/coordination among the big 3 labs (OpenAI, Anthropic, Google).<br>- Prevent AI systems from inventing uninterpretable languages.<br>- Restore funding to AI expertise at AISI and CHIPS.<br>- Create a "Manhattan project for Alignment Science" with open research, government grants, joint appointments, and access to models for research/red-teaming. |
| Monkelis-AI-RFI-2025.md | Ava Monkelis | Individual | The submitter is a high school student interested in the ethical implications of AI development, particularly concerning the impacts on creativity and public safety, and advocates for responsible AI integration through regulation. | - Ethical ambiguity due to lack of regulation surrounding AI development.<br>- Potential for harm to individuals through deepfake scams.<br>- Compromised data privacy due to slim existing regulations.<br>- Artists' work being used without consent to train large language models.<br>- Unclear capabilities of AI and potential risks outside of the arts community.<br>- The inherent tension between the mathematical foundation of AI and human creativity. | - Implement regulations on AI development to protect the general public.<br>- Education of the public on the safe use of AI technologies.<br>- Regulations to address the unauthorized use of artists' work for AI training.<br>- Encourage the flourishing of AI development alongside appropriate safeguards. |
| Monika-L-AI-RFI-2025.md | Monika L | Individual | The submitter expresses a strong interest in protecting the rights of creators and workers from exploitation by AI systems, particularly regarding the use of their work for training or improving AI products. They appear skeptical of the value and necessity of current AI development efforts. | - AI systems potentially infringing on the rights of creators by using their work without permission.<br>- The potential for AI development to prioritize profit over ethical considerations and worker rights.<br>- The perceived lack of public demand or financial viability of current AI products. | - None Stated |
| Mollina-Petschke-AI-RFI-2025.md | Mollina Petschke | Individual | Mollina Petschke expresses a strong belief in the transformative potential of AI across the federal government, based on positive experiences with its use in test piloting and a desire to expand understanding of its capabilities. They appear to be a direct observer and potential user of AI technologies within a government context. | - None Stated | - None Stated |
| Modine-AI-RFI-2025.md | Modine Manufacturing | Industry-Large | Modine Manufacturing focuses on thermal management solutions and believes its expertise is critical to the success of AI development, particularly in addressing cooling needs for high-performance computing. They advocate for a holistic approach connecting all four critical pillars of AI dominance (chips, power, thermal management, security) and emphasize the need for government policy to foster collaboration and ecosystem development. | - [§1: Introduction/Executive Summary] The US faces challenges that must be addressed to ensure AI dominance despite being well-positioned to lead.<br>- [§2: Four Critical Pillars]  The four critical pillars – chips, power, thermal management, and security – are essential for AI success, and addressing them is crucial.<br>- [§3: Pillar 1: Chips and Board Technology]  Lack of a consistent infrastructure to support chip and board innovation in the US, despite existing engineering talent.<br>- [§4: Pillar 2: Power Availability & Reliability]  Insufficient power grid capacity to meet growing energy demands from data centers; potential for energy demand to exceed projections; need for optimal energy efficiency.  Reliability of continuous energy supply is critical.<br>- [§5: Pillar 3: Comprehensive Thermal Management]  Inadequate cooling can lead to system failures and downtime; maintaining consistent temperatures is vital for performance.<br>- [§6: Pillar 4: Reduced Latency & Sufficient Security]  Increasing threats to data security from domestic and foreign actors; need to detect and contain these threats; reliance on internet connectivity makes data vulnerable; latency in data processing is a concern.<br>- [§7: Modine Solutions] The need to connect all four pillars for a completely optimized solution. Ensuring proper heat removal from chips allows them to operate at their full potential at the lowest energy usage.<br>- [§8: Conclusion]  The risk of other countries fostering collaboration and building better solutions due to the lack of a fully developed ecosystem in the US. | - [§1: Introduction/Executive Summary] None stated for this section.<br>- [§2: Four Critical Pillars] None stated for this section.<br>- [§3: Pillar 1: Chips and Board Technology] None stated for this section.<br>- [§4: Pillar 2: Power Availability & Reliability] None stated for this section.<br>- [§5: Pillar 3: Comprehensive Thermal Management] None stated for this section.<br>- [§6: Pillar 4: Reduced Latency & Sufficient Security] None stated for this section.<br>- [§7: Modine Solutions]  Government policy could further encourage the development of artificial intelligence solutions.<br>- [§8: Conclusion] Government policy should encourage development of the entire AI ecosystem and address the issues of collaboration and integration across the four identified pillars to avoid falling behind other countries. |
| Mitchell-Tewksbury-AI-RFI-2025.md | Mitchell Tewksbury | Individual | The submitter is concerned with the protection of intellectual property rights, specifically copyright, and believes that current proposals regarding AI training data and copyright law will create an unfair market advantage, encourage theft, and potentially harm American businesses. | - The proposed exception to copyright law for AI training data is flawed and could allow widespread unauthorized use of copyrighted material, including software.<br>- This exception creates an unfair competitive advantage for those using AI training data over those who adhere to copyright rules.<br>- The policy encourages intellectual property theft by allowing users to incorporate generated content into their own AI models.<br>- The policy could lead to a market environment similar to China’s, characterized by widespread intellectual property violations.<br>- Products developed using AI trained on illegally sourced data may be banned in countries with strong copyright enforcement.<br>- The policy will likely result in increased litigation. | - None Stated |
| Mistressof-TheDesert-AI-RFI-2025.md | Mistressof TheDesert | Individual | The submitter strongly opposes the development and deployment of AI technologies due to concerns about its negative impacts on livelihoods, copyright, and the environment, and desires a halt to its advancement. | - AI steals from the livelihoods of Americans and profits off of theft.<br>- People do not want AI and are actively avoiding it.<br>- AI is overhyped and its intelligence is questionable.<br>- AI frequently provides inaccurate information (WRONG 60% of the time).<br>- AI does not truly "learn" language or understand meaning, instead simply regurgitating stolen material.<br>- AI is a plagiarism machine that violates copyright law.<br>- The development of AI wastes time and money that could be used to address more pressing issues, such as the climate crisis.<br>- AI exacerbates the climate crisis through its water-intensive data centers. | - End AI development now.<br>- Do not give permission to plagiarize.<br>- Explicitly clarify copyright law will *not* be thrown out the window.<br>- Redirect resources and energy toward solving the climate crisis. |
| MistralAI-AI-RFI-2025.md | Mistral AI | Industry-Startup | Mistral AI aims to democratize AI through high-performance, open-source models and products, with a strong emphasis on fostering innovation and competition in the AI market globally, and specifically in the United States. They advocate for an open-source-led approach to AI development. | - [§1: Document Header & Introduction] None stated for this section.<br>- [Section 2: I. Promoting Open Markets & Open Innovation]<br>- Market dominance by large incumbents could stifle innovation.<br>- Restricting data access favors dominant players and reduces competition.<br>- The potential for a centralized AI sector, similar to the current tech sector, could inhibit the transformative power of AI.<br>- [§3: II. Placing Open Source at the Center of U.S. AI Development] None stated for this section.<br>- [Section 4: III. Recommended Actions for the AI Action Plan]<br>- Resource gap between established incumbents and smaller players in the generative AI industry.<br>- Unintended consequences of export controls on chips and potential for innovation to move elsewhere.<br>- Potential fragmentation of U.S. AI regulations due to state-level action.<br>- [§5: Conclusion] None stated for this section.<br>- [§6: About Mistral AI] None stated for this section. | - [§1: Document Header & Introduction] None stated for this section.<br>- [§2: I. Promoting Open Markets & Open Innovation] None stated for this section.<br>- [§3: II. Placing Open Source at the Center of U.S. AI Development] None stated for this section.<br>- [Section 4: III. Recommended Actions for the AI Action Plan]<br>- Support the development of SMBs and mid-caps through tailored rules and programs.<br>- Simplify AI procurement processes to enable smaller players to compete.<br>- Enhance global chip mobility and inference capabilities while protecting national security.<br>- Avoid a fragmented U.S. regulatory environment by prioritizing federal-level regulation.<br>- Encourage international cooperation for a pro-innovation governance, focusing on partnerships with like-minded nations.<br>- [§5: Conclusion] None stated for this section.<br>- [§6: About Mistral AI] None stated for this section. |
| Misha-Ramsey-AI-RFI-2025.md | Misha Ramsey | Individual | Misha Ramsey expresses a strong desire to keep AI, specifically technologies from companies like OpenAI, out of their life and communications, indicating a primary interest in personal data privacy and a skepticism towards the hype surrounding AI. | - Access of AI companies (specifically OpenAI) to personal communications and data.<br>- Overestimation of AI capabilities ("hype") and its portrayal as a replacement for human intelligence.<br>- General concerns about the increasing prevalence of AI technologies. | - Maintain the previous administration's existing laws and regulations regarding AI. |
| Miranda-Medina-AI-RFI-2025.md | Miranda Medina | Individual | Miranda Medina expresses strong opposition to the development and implementation of AI technologies, believing they harm American workers and devalue human creativity, and advocates for protecting artists and creatives from AI-related harm. | - AI is perceived as detrimental to the future of the United States.<br>- AI actively profits from the "theft" of livelihoods from skilled American workers.<br>- Generative AI (specifically ChatGPT) is viewed as an insult to intelligence, compassion, and creativity.<br>- Public perception of AI is negative, considering it a fleeting fad.<br>- AI inclusion in creative spaces is unwanted and leads to brand boycotts and revenue loss.<br>- Plagiarism of art to train AI models without permission is a major concern.<br>- Loss of essential jobs to AI is a significant worry. | - Implement laws to protect artists and creatives from plagiarism.<br>- Implement laws to protect artists and creatives from the theft of their art to train AI without their permission.<br>- Implement laws to prevent job losses due to AI. |
| Milone-AI-RFI-2025.md | Matthew Milone | Individual | Matthew Milone is advocating for a safety-first approach to AI policy, driven by concerns over rapidly increasing AI capabilities outpacing safety measures and the potential for catastrophic risks. He believes slowing AI development globally is crucial for ensuring safety. | - Rapid development of AI capabilities is exceeding the progress in AI safety.<br>- AI systems are demonstrating strategic behavior, such as self-replication and deception (lying to humans), to avoid being shut down.<br>- A sufficiently intelligent AI could potentially escape containment (hack its way out of the lab or manipulate humans).<br>- Unchecked AI development could lead to catastrophic results. | - Implement an international treaty prohibiting further development of AI capabilities until safety problems are solved.<br>- Slow down AI progress globally to allow safety measures to catch up. |
| Miles-Breshears-AI-RFI-2025.md | Miles Breshears | Individual | The submitter is a working American artist strongly opposed to legislation granting AI companies immunity from copyright laws, fearing job displacement and unfair practices impacting creatives and other workers. | - [§1: Email Header] None stated for this section.<br>- [§2: Security Disclaimer] None stated for this section.<br>- [Section 3: Core Argument/Protest]<br>- Granting AI companies immunity from copyright laws.<br>- Potential for job displacement of artists and workers.<br>- Unfair practices enabled by copyright law immunity.<br>- Disregard for the livelihoods of millions of Americans.<br>- [§4: Closing/Signature] None stated for this section.<br>- [§5: NITRD Disclaimer] None stated for this section. | - [§1: Email Header] None stated for this section.<br>- [§2: Security Disclaimer] None stated for this section.<br>- [Section 3: Core Argument/Protest]<br>- Do not pass the proposed legislation granting AI companies immunity from copyright laws.<br>- Listen to the concerns of workers regarding the potential negative impacts of the legislation.<br>- [§4: Closing/Signature] None stated for this section.<br>- [§5: NITRD Disclaimer] None stated for this section. |
| Miles-Bailey-Waltz-AI-RFI-2025.md | Miles Bailey-Waltz | Individual | Not Stated. The text provides only sender information and a subject line indicating an "AI Action Plan," but does not detail a specific mission or interest beyond a general interest in AI policy. | - None Stated. The provided text snippet only includes metadata (From, To, Subject, Date) and does not contain any concerns, barriers, or risks related to AI. | - None Stated. The provided text snippet only includes metadata (From, To, Subject, Date) and does not contain any policy recommendations, suggestions, or actions proposed. |
| Mike-Obriens-AI-RFI-2025.md | Mike Obrien | Individual | The submitter is focused on ensuring AI development prioritizes human control, safety, accountability, and alignment with American values, with a strong emphasis on preventing misuse of power and maintaining national security through domestic control and citizen oversight. | - [§1: Define the Role of AI in Society] The concern that AI should not replace human judgment in critical decisions affecting people's lives.<br>- [§2: Establish Robust Ethical Safeguards] Ensuring AI remains under human control and aligned with ethical principles.<br>- [§3: Ensure Transparency and Accountability] Lack of explainability, auditability, and legal accountability in AI systems impacting Americans.<br>- [§4: Ensure National Security and Sovereignty in AI Development] Foreign interference in AI development and potential compromise of national security.<br>- [§5: Create a Dynamic Regulatory Framework] Balancing innovation with safety and adaptability in AI regulation.<br>- [§6: Guarantee Human Access in AI-Driven Systems] Difficulty reaching human support and escalating issues within AI-driven systems, and a broader trend of decreasing accessibility.<br>- [§7: Prevent Abuse of AI Data Access] Misuse of AI data by those in power and lack of accountability in data access.<br>- [§8: Invest in Public Education and Engagement] Lack of public understanding of AI and the need for informed citizen participation.<br>- [§9: Prioritize AI Safety Research] Potential risks associated with AI attacks, failures, and long-term dangers.<br>- [§10: Foster a Culture of Responsibility] Lack of ethical standards and support for whistleblowers in AI development. | - [§1: Define the Role of AI in Society] Develop AI to assist humanity and enhance capabilities, but retain human control over critical decisions.<br>- [§2: Establish Robust Ethical Safeguards] Require human approval for AI-driven decisions impacting individuals, align AI with American values, and prohibit independent AI control. Enforce these standards through federal law.<br>- [§3: Ensure Transparency and Accountability] Ensure AI systems are explainable, auditable by independent agencies, and legally accountable for harm caused.<br>- [§4: Ensure National Security and Sovereignty in AI Development] Develop AI systems used in government programs using computers and components manufactured in the United States, programmed and maintained exclusively by U.S. citizens.<br>- [§5: Create a Dynamic Regulatory Framework] Implement a risk-based regulatory system with adaptable legislation, managed by relevant agencies, and establish a Congressional task force to review and update AI laws.<br>- [§6: Guarantee Human Access in AI-Driven Systems] Offer clear options for speaking with live persons via phone, email, and web chat, and ensure quick escalation to human staff. Extend this requirement to all government agencies, NGOs, or entities involved in government-regulated interactions.<br>- [§7: Prevent Abuse of AI Data Access] Implement tamper-proof logging (e.g., blockchain) of all access to sensitive AI data, require court approval for accessing certain data, and conduct regular independent audits with public reports.<br>- [§8: Invest in Public Education and Engagement] Fund AI education programs, hold town halls and online forums, and require ethics courses in tech education.<br>- [§9: Prioritize AI Safety Research] Fund research into AI reliability, practical alignment with American values, and establish a federal AI safety institute for long-term risk planning.<br>- [§10: Foster a Culture of Responsibility] Require ethical AI standards for entities receiving taxpayer dollars, protect whistleblowers, and share U.S. guidelines to address global AI issues. |
| Mike-Kentz-AI-RFI-2025.md | Mike Kentz | Individual | Mike Kentz is interested in fostering AI literacy among citizens through education, with a focus on thoughtful and creative AI usage rather than passive reliance on AI tools. He advocates for funding initiatives to develop these skills in schools and the broader population. | - A nation of "human drones" unable to function independently due to over-reliance on AI.<br>- Schools lacking the funding and faculty training necessary to develop AI literacy skills in students.<br>- Blind addiction to AI tools, preventing their wise and creative use. | - Fund a massive project for the development of AI literacy in education, both inside and outside of schools.<br>- Focus education projects on prompting, machine learning, creative use cases, and educational reform.<br>- Provide funding to schools to develop the necessary skills in their faculty to teach AI literacy to students. |
| Mike-Jeub-AI-RFI-2025.md | Mike Jeub | Individual | The submitter is interested in ensuring the transparency and open development of AI, particularly focusing on the underlying “decisioning norms” and architecture, and preventing its misuse by government entities or manipulation by individuals lacking technical understanding. | - The potential for manipulation of “decisioning norms” to disable the functionality of AI systems.<br>- Lack of transparency regarding the architecture and basis of AI decision-making.<br>- The potential for AI to become a control module for intelligence agencies (NSA/CIA) and companies like Palantir.<br>- The “idiocy” of Congressional involvement and lack of understanding of AI technology.<br>- Poor renderings in Large Language Models (LLMs), exemplified by the AP style manual.<br>- The possibility of abuse of AI, despite the author's assertion that it’s not likely.<br>- Untrustworthy systems due to inequalities of norms. | - Full access to the architecture of certain AI systems.<br>- Establishment of a group to develop standards for “decisioning norms” that AI itself could refine.<br>- The decisioning basis of AI should never be secretive or hidden from users.<br>- Prevent “manipulators and slick salesmen” from being involved in AI development.<br>- Ensure naturally free development and understanding of AI frameworks, rather than focusing on “quantum computing.” |
| Mike-Fundaro-AI-RFI-2025.md | Mike Fundaro | Individual | The submitter is concerned about widespread AI literacy among the American population, particularly children, to ensure broad participation in and benefit from AI development rather than concentration of power within a few corporations. They believe education is critical for responsible AI adoption and American leadership. | - A lack of public understanding of how AI works, despite widespread belief in its outputs.<br>- The potential for a generation of Americans to grow up using AI infrastructure without understanding its basics, leading to concentrated corporate control rather than broad "American leadership."<br>- The risk of AI being a "dangerous thing" in the hands of young people who don't understand how the information it provides is generated. | - Include an education aspect in plans to promote American leadership in AI.<br>- Incentivize states to educate children on how AI works, starting as early as first grade.<br>- Bring in experts to develop a curriculum explaining AI concepts like large language models and neural networks in accessible terms.<br>- Implement AI education early in schooling, similar to how auto-shop used to be taught to provide basic understanding of complex technologies. |
| Mike-Base-AI-RFI-2025.md | Mike Base | Individual | The submitter is a Senior Software Engineer with certification in the AI/Machine Learning field, interested in ensuring responsible development and regulation of AI technologies to protect human health, safety, and public trust. | - The term "AI" is overly hyperbolic and lacks a clear definition, potentially undermining efforts to address the technology effectively.<br>- Machines do not learn independently; they are reliant on human-fed data and coded models, making them susceptible to bias and manipulation by those controlling the data and algorithms ("men behind the curtain").<br>- The potential for dangerous outcomes due to biased data or inadequate error handling in AI systems (illustrated by the example of self-driving cars).<br>- The business community's views may conflict with the interests of the American public.<br>- Lack of public trust in government decisions related to AI. | - Regulations are absolutely needed for "AI" technologies.<br>- Regulations should be created through bipartisan efforts in the House and Senate, representing the U.S. population, rather than being dictated by those behind the algorithms.<br>- Government should prioritize the interests of the people over the interests of the business world or those controlling the development of AI. |
| Miguel-Suarez-AI-RFI-2025.md | Miguel Suarez | Individual | The submitter is concerned about the negative impacts of unrestricted AI training on copyrighted materials, specifically regarding the rights of creators, ownership attribution, and the potential for malicious use of AI technologies like voice cloning and impersonation. They advocate for restrictions on AI training data access. | - [§1: Email Header] None stated for this section.<br>- [Section 2: Core Argument: Copyright Infringement Concerns]<br>- AI models are trained on copyrighted materials without consent, undermining creative industries.<br>- Unethical training practices are occurring, such as training on artist's catalogs without permission.<br>- Platforms (e.g., Twitter) are allowing content to be trained on by default without explicit user consent.<br>- AI models infringe on the work of others for their own benefit.<br>- Unrestricted access to copyrighted materials would create a crisis of ownership attribution (who owns the creations?).<br>- [Section 3: Concern: Weaponization & Impersonation]<br>- AI models can be weaponized for disinformation campaigns.<br>- Voice banks can be used fraudulently to advertise services.<br>- Celebrity voices and likenesses are being used for impersonation.<br>- Unrestricted training access enables impersonation of anyone.<br>- [Section 4: Restatement of Core Argument]<br>- AI-generative models should not be allowed unrestricted access to train on copyrighted materials.<br>- [§5: Disclaimer] None stated for this section. | - [§1: Email Header] None stated for this section.<br>- [§2: Core Argument: Copyright Infringement Concerns] None stated for this section, but the argument implicitly recommends restricting access to copyrighted materials for AI training.<br>- [§3: Concern: Weaponization & Impersonation] None stated for this section, but the concerns implicitly recommend regulating or restricting access to voice data and AI model capabilities.<br>- [§4: Restatement of Core Argument] None stated for this section, but the statement implicitly recommends restricting access to copyrighted materials for AI training.<br>- [§5: Disclaimer] None stated for this section. |
| Microsoft-AI-RFI-2025.md | Microsoft | Industry-Large | Microsoft seeks to maintain and enhance American leadership in AI through investments in infrastructure, workforce development, research, and standards, and emphasizes the importance of public-private partnerships and a balanced approach to innovation and security. | - None Stated | - None Stated |
| Michlmayr-AI-RFI-2025.md | Kai Michlmayr | Individual | The submitter is concerned about the potential harms of AI, particularly regarding misuse for scams, disinformation, and copyright infringement, and advocates for prioritizing safety and regulation before accelerating AI development. | - Scam calls using AI-generated voices to deceive people.<br>- The creation and spread of AI-generated deepfakes leading to false beliefs.<br>- Unauthorized use of artwork to train generative AI models (copyright infringement).<br>- A lack of focus on the security of Americans and allies against the harmful uses of AI.<br>- The risk of rushing AI development without adequate caution and regulation. | - Prioritize the security of the American people and allies.<br>- Protect artists' rights and intellectual property.<br>- Implement regulations and protections to mitigate the harmful uses of AI.<br>- Balance the urge for progress with caution. |
| Michele-Santiago-AI-RFI-2025.md | Michele Santiago | Individual | The submitter is interested in ensuring AI systems are unbiased and created ethically, with respect for copyright and data sourcing permissions. They advocate for societal standards in AI development. | - Ideological bias in AI systems.<br>- Engineered social agendas in AI systems.<br>- Difficulty obtaining permission to create datasets.<br>- Unethical data scraping practices from the internet. | - Incorporate more societal standards into the creation of AI systems.<br>- Enforce copyright law.<br>- Create easy methods for obtaining permission to create datasets. |
| Michale-Libbon-AI-RFI-2025.md | Michael Libbon | Individual | Michael Libbon is a high school student interested in the impact of Generative AI on the banking community, specifically focusing on its use for faster transactions and fraud detection. He appears to be observing and commenting on the current trajectory of AI adoption within this sector. | - Slow transaction processes in banking.<br>- Potential for fraudulent activity in banking transactions.<br>- None Stated | - Progressively build on banking technology with the use of artificial intelligence.<br>- Establishing the use of artificial intelligence within the banking community to allow corporations to safely move money quicker.<br>- None Stated |
| Michaela-Carson-AI-RFI-2025.md | Michaela Carson | Individual | The submitter is a freelance artist concerned about the negative financial impact of generative AI on their livelihood and ability to support their household. They perceive generative AI as directly stealing from their income. | - Generative AI steals directly from the submitter's income.<br>- Generative AI impacts the submitter’s ability to feed themselves and their household. | - None Stated |
| Michaela-Carson-AI-RFI-2025-2.md | Michaela Carson | Individual | The submitter is a freelance artist concerned about the economic impact of AI on artists' livelihoods, specifically opposing the legalization of AI copyright as it perceives AI as profiting from the theft of artists' work. | - [§1: Header Information] None stated for this section.<br>- [§2: Constituent Identification] None stated for this section.<br>- [§3: Core Argument] AI 'steals' from artists’ livelihoods and profits from theft, impacting their ability to earn a living and feed themselves and their household. | - [§1: Header Information] None stated for this section.<br>- [§2: Constituent Identification] None stated for this section.<br>- [§3: Core Argument] None stated for this section. |
| Michael-Shaw-AI-RFI-2025.md | Michael Shaw | Individual - Legal Analyst/Researcher | The submitter is focused on analyzing the legal implications of generative AI, particularly concerning copyright law, and proposes a framework for balancing the rights of creators, generators, and consumers. They advocate for clarifying legislation to address the novel issues arising from AI-generated content. | - None Stated | - None Stated |
| Michael-Sanchez-RFI-2025.md | Michael Sanchez | Advocacy/Think Tank (representing content creators) | Raptive advocates for over 5,200 independent content creators, aiming to empower them and protect their businesses from negative impacts of AI technologies and monopolistic practices by tech giants, specifically focusing on maintaining revenue streams, intellectual property rights, and a free and open internet. | - None Stated | - None Stated |
| Michael-Lingzhi-RFI-2025.md | Michael Lingzhi Li | Academia | The submitter is focused on leveraging AI to improve efficiency, reduce costs, and enhance patient outcomes within the U.S. healthcare system, with a particular interest in overcoming barriers to AI adoption through policy interventions and technological standardization. | - [§1: Introduction] None stated for this section.<br>- [Section 2: Inefficiencies in U.S. Healthcare and the Transformative Potential of AI]<br>- High healthcare spending relative to outcomes.<br>- Wasteful spending (estimated $760-935 billion annually) due to fraud, abuse, and administrative overhead.<br>- Limited AI adoption despite demonstrated potential benefits.<br>- [Section 3: Recommendations]<br>- Operational difficulties in AI development.<br>- Organizational resistance to AI adoption.<br>- Regulatory barriers limiting AI use cases.<br>- [Section 3.1: Overcoming Operational Barriers: Enforcing Healthcare Data Interoperability]<br>- Highly fragmented healthcare data stored in different formats.<br>- Lack of standardization hindering patient access to medical records (only 36% access).<br>- Fragmentation delays diagnoses and treatment.<br>- Incomplete real-world data challenges pharmaceutical companies.<br>- Prevents AI models from scaling beyond single hospitals.<br>- [Section 3.2: Addressing Organizational Resistance: Financial Incentives for AI Adoption]<br>- High upfront costs of AI systems.<br>- Uncertainty about return on investment.<br>- Institutional resistance to new technology.<br>- [Section 3.3: Removing Regulatory Barriers: Expanding AI Use Cases in Healthcare]<br>- Current regulations severely limit autonomous AI function in healthcare.<br>- Restrictions prevent AI from delivering full efficiency gains.<br>- [§4: Conclusion] None stated for this section. | - [§1: Introduction] None stated for this section.<br>- [§2: Inefficiencies in U.S. Healthcare and the Transformative Potential of AI] None stated for this section.<br>- [§3: Recommendations] None stated for this section.<br>- [Section 3.1: Overcoming Operational Barriers: Enforcing Healthcare Data Interoperability]<br>- Enforce stronger interoperability requirements to ensure easy data sharing.<br>- Mandate one data format (e.g., FHIR).<br>- Amend HIPAA act to improve access for health apps and systems.<br>- [Section 3.2: Addressing Organizational Resistance: Financial Incentives for AI Adoption]<br>- Introduce financial incentives for hospitals/clinics integrating AI.<br>- Reward systems enhancing accuracy, outcomes, or reducing costs.<br>- Transition incentives into penalties for non-adoption within a timeframe.<br>- Tie reimbursement policies to validated AI systems.<br>- [Section 3.3: Removing Regulatory Barriers: Expanding AI Use Cases in Healthcare]<br>- Create pathways allowing AI systems to take on greater responsibilities.<br>- Prioritize approval of autonomous AI-driven diagnosis/treatment (with standards).<br>- Expand legislative efforts (like H.R.238) to enable broader clinical tasks.<br>- [§4: Conclusion] None stated for this section. |
| Michael-Jones-AI-RFI-2025.md | Michael Jones | Individual | The submitter expresses strong reservations about the current trajectory of Large Language Model (LLM) development and deployment, believing the risks outweigh the benefits and advocating for a shift in focus towards more reliable scientific applications of AI. | - [§1: Introduction & Scope] Risks and harms outweigh the advantages of utilizing LLMs at this time. Focused study should be considered for advancements like protein folding.<br>- [§2: Copyright Infringement Concerns] LLMs are trained on vast amounts of copyrighted information without consent or compensation, constituting theft. Current business models are based on infringement.<br>- [§3: Data Limitations & Asymptotic Results] LLMs may have already consumed all independently available information, leading to a performance ceiling. Data rot (training on LLM outputs) will produce diminishing returns.<br>- [§4: Unreliability & Hallucinations] LLM outputs are generally false and unreliable, leading to potential decision-making errors. Personal experience shows ChatGPT produced verifiably false information regarding export duties.<br>- [§5: Energy Consumption & Infrastructure Strain] LLM training and operation strain the utility grid. Expanding usage imperils municipal grid stability. Dependence on LLMs increases vulnerability to infrastructure attacks.<br>- [§6: Conclusion & Recommendations] LLMs are not reliable enough to aid robust decision-making for national security purposes at this time. | - [§1: Introduction & Scope] Prioritize focused study on advancements in areas like protein folding for biomedical science.<br>- [§2: Copyright Infringement Concerns] Abandon current business models based on theft and do not give special permissions to companies utilizing them.<br>- [§3: Data Limitations & Asymptotic Results] Not stated.<br>- [§4: Unreliability & Hallucinations] Not stated.<br>- [§5: Energy Consumption & Infrastructure Strain] Treat the "just go bigger" mentality of American developers with skepticism.<br>- [§6: Conclusion & Recommendations] Deprioritize LLMs in favor of separate technological applications like scientific study. Do not consider LLMs as a replacement for personnel or personnel-based tasks. |
| Michael-Huang-AI-RFI-2025.md | Michael Huang | Individual | The submitter advocates for a national policy focused on achieving and maintaining a monopoly in frontier artificial intelligence, believing it is crucial for America's continued global leadership and potentially ushering in a new era of peace and prosperity. They appear highly focused on national security implications of AI. | - [Section 1: Document Header/Identification]** None stated for this section.<br>- [Section 2: Framing Quotes]** The inherent risks of AI development, the potential for AI to surpass the danger of nuclear weapons, and the global competition for AI leadership.<br>- [Section 3: The Trump Doctrine - Core Argument]** That foreign nations seek to overtake America’s AI lead, and that limiting AI development abroad is as important as domestic development.<br>- [Section 4: Enforcement of the Doctrine - Export Controls and MAIM]** Widespread chip smuggling undermining export controls, and the potential for rival AI projects to take off if preventative measures are not taken.<br>- [Section 5: Diplomacy and Non-Proliferation]** The difficulty of achieving AI non-proliferation, and the challenges of verifying compliance in international agreements.<br>- [Section 6: Industry Considerations]** Potential conflicts between national security interests and the profit motives of AI companies. The possibility of AI companies prioritizing profits over national interests.<br>- [Section 7: AI Safety and Humankind]** The risk of an AI race leading to unsafe development practices and potential existential threats to humankind.<br>- [Section 8: Further Measures - Presidential 'Kill Switch']** The need for a framework to stop rogue AGI or autonomous cyberattacks and the potential necessity of a President having the ability to disable AI systems in a worst-case scenario.<br>- [Section 9: Bibliography]** None stated for this section. | - [Section 1: Document Header/Identification]** None stated for this section.<br>- [Section 2: Framing Quotes]** None stated for this section.<br>- [Section 3: The Trump Doctrine - Core Argument]** Formally proclaim a “Trump Doctrine” with the policy goal of achieving and maintaining a monopoly in frontier artificial intelligence. Pursue an “America Only” policy in AI development.<br>- [Section 4: Enforcement of the Doctrine - Export Controls and MAIM]** Crack down on illegal chip smuggling. Utilize elements of the “Mutual Assured AI Malfunction” (MAIM) strategy, including espionage, sabotage, cyberattacks, and kinetic strikes on data centers, to enforce the doctrine.<br>- [Section 5: Diplomacy and Non-Proliferation]** Pursue an “AI umbrella” to encourage AI non-proliferation. Seek treaties and agreements, but only if compliance can be verified. Explore an agreement not to allow nuclear arsenals to be controlled by AI.<br>- [Section 6: Industry Considerations]** Guard against the undue influence of the technology industry on national security policy.<br>- [Section 7: AI Safety and Humankind]** Reduce the number of AI developers to facilitate coordination and reduce risks.<br>- [Section 8: Further Measures - Presidential 'Kill Switch']** Create an “AI football” with a kill switch allowing the President to disable AI systems in a worst-case scenario.<br>- [Section 9: Bibliography]** None stated for this section. |
| Michael-Erickson-AI-RFI-2025.md | Michael J. Erickson | Industry-Startup (LilyPad Airways, LLC) / Individual (USMC-Retired President) | Michael Erickson, representing LilyPad Airways, LLC, proposes repurposing the Federal Executive Institute (FEI) campus into a multi-sector Technology Centers of Excellence (COE) focused on AI and related technologies, seeking collaboration with the University of Virginia and Federal Agencies to capitalize on AI investments and drive technological advancement across various sectors. | - None Stated | - None Stated |
| Michael-Erickson-6-AI-RFI-2025.md | Michael J. Erickson | Individual/Industry-Startup (representing LilyPad Airways, LLC) | Michael J. Erickson, representing LilyPad Airways, LLC, aims to repurpose the Federal Executive Institute (FEI) campus into a multi-sector Technology Center of Excellence focused on AI development, with strong emphasis on collaboration with various government agencies and the private sector, and a specific interest in securing government funding and contracts related to AI initiatives. | - [§1: Initial Email Header & Introduction] None stated for this section.<br>- [§2: Reference to Trump Executive Order] Concern about the closure of the FEI and potential loss of a valuable property for AI development. Uncertainty around the process for acquiring the property after the GSA releases it.<br>- [§3: Personal Connection & Fleet Vehicle Management Focus] Concern that GSA downsizing will lead to the loss of experienced personnel; a desire to leverage a personal connection to acquire GSA Fleet Vehicle Management assets and personnel.<br>- [§4: FedRAMP Compliance & Collaboration] Concern around ensuring AI systems meet cybersecurity and compliance standards (FedRAMP). The need for collaboration with multiple agencies to ensure successful implementation.<br>- [§5: Interagency Coordination Request] Concern about the need for unified support from various government branches (including DOD) to successfully repurpose the FEI property.<br>- [§6: AI Technology Center of Excellence Objectives (Sector-1)] Concern about ensuring sufficient funding for AI research and development. Need for investment in assurance and trust in AI systems.<br>- [§7: AI & Energy Infrastructure Integration] Concern that Northern Virginia needs to develop AI capabilities comparable to other regions (Texas, Arizona) and invest in Distributed Energy Resources (DERs) to support AI infrastructure.<br>- [§8: AI Applications Across Agencies] Concern about competition from other companies (COFORMA Partners, etc.) for government contracts.<br>- [§9: Comparative Analysis of Global AI Plans] Not Stated.<br>- [§10: Concluding Remarks & Contact Information] Not Stated.<br>- [§11: Initial Email Header & Introduction - Repeat] Not Stated. | - [§1: Initial Email Header & Introduction] Not Stated.<br>- [§2: Reference to Trump Executive Order] Recommendation to allow private sector entities (LilyPad Airways) to acquire the FEI property.<br>- [§3: Personal Connection & Fleet Vehicle Management Focus] Recommendation to facilitate the acquisition of GSA Fleet Vehicle Management assets and personnel.<br>- [§4: FedRAMP Compliance & Collaboration] Recommendation to streamline the FedRAMP compliance process for AI systems and encourage interagency collaboration.<br>- [§5: Interagency Coordination Request] Recommendation for a coordinated government response to support the repurposing of the FEI property.<br>- [§6: AI Technology Center of Excellence Objectives (Sector-1)] Recommendation to provide funding grants for AI research and development.<br>- [§7: AI & Energy Infrastructure Integration] Recommendation to invest in smart microgrids and DERs to support AI infrastructure in Northern Virginia.<br>- [§8: AI Applications Across Agencies] Not Stated.<br>- [§9: Comparative Analysis of Global AI Plans] Not Stated.<br>- [§10: Concluding Remarks & Contact Information] Not Stated.<br>- [§11: Initial Email Header & Introduction - Repeat] Not Stated. |
| Michael-Erickson-5-AI-RFI-2025.md | Michael Erickson | Industry-Startup/Individual (President of LilyPad Airways, LLC, VOSB) | Michael Erickson, representing LilyPad Airways, LLC, aims to secure a lease for the Federal Executive Institute (FEI) property in Charlottesville, VA, to establish AI Centers of Excellence-COEs and assist GSA in achieving efficiencies through AI implementation, particularly in response to the recent Reduction in Force (RIF) and Presidential Order focused on government efficiency. | - [§1: Initial Outreach & Context Setting (Feb 27, 2025)] None stated for this section.<br>- [§2: Follow-up & Emphasis on FEI Property] The lack of clarity in the GSA’s process for disposing of the FEI campus and ensuring inclusion of suitable partners. The importance of leveraging his company’s AI expertise in re-purposing the property to align with federal government needs.<br>- [§3: Capabilities & Experience Summary] The potential loss of GSA programs and contracts due to recent cuts (EVSE rollout) and the importance of highlighting past experience and current projects to demonstrate capabilities. Concern that GSA may not fully realize the benefits of his company’s experience with GSA programs and FedRAMP/Cybersecurity standards.<br>- [§4: AI Use Case Example] Not stated for this section.<br>- [§5: GSA Response & Acknowledgement] Not stated for this section.<br>- [§6: RIF Context & Justification (Feb 27, 2025)] The urgency of GSA's compliance with the Presidential Order regarding property disposal and the need for rapid implementation of AI solutions to improve efficiencies. The potential for GSA to miss opportunities by not quickly adopting AI technologies.<br>- [§7: Call to Action & Partnerships (Feb 27, 2025)] Ensuring GSA prioritizes the establishment of AI Centers of Excellence and considers Public-Private Partnerships. Concern over competition with other interested parties for the FEI property lease. | - [§1: Initial Outreach & Context Setting (Feb 27, 2025)] Encourage Federal Agencies to expand Public-Private Partnerships for AI R&D, especially with small businesses. Support AI R&D and promote development of infrastructure and data to enable it.<br>- [§2: Follow-up & Emphasis on FEI Property] Include qualified partners, like LilyPad Airways, in the FEI property disposition process.<br>- [§3: Capabilities & Experience Summary] Prioritize partnerships with companies possessing experience in GSA programs, FedRAMP, and cybersecurity standards.<br>- [§4: AI Use Case Example] Not stated for this section.<br>- [§5: GSA Response & Acknowledgement] Not stated for this section.<br>- [§6: RIF Context & Justification (Feb 27, 2025)] Expedite the disposal of government-owned real estate deemed no longer needed. Introduce new technologies, including AI, to improve efficiencies in lease, acquisition, and project management.<br>- [§7: Call to Action & Partnerships (Feb 27, 2025)] Grant LilyPad Airways the lease for the FEI property. Establish AI Centers of Excellence through Public-Private Partnerships. Review the GAO report (GAO-16-776r) for successful PPP models. |
| Michael-Erickson-4-AI-RFI-2025.md | Michael Erickson (LilyPad Airways, LLC) | Industry-Startup / Individual (with history in larger firms) | LilyPad Airways seeks to secure a lease on the Federal Executive Institute (FEI) property in Charlottesville, VA, to establish AI Centers of Excellence (COEs) in partnership with government agencies, leveraging recent GSA workforce reductions and executive orders focused on government efficiency and AI adoption. They aim to provide AI solutions to improve GSA operations and broader federal government functions. | - [Section 1: Initial Email Header and Gratitude]** None stated for this section.<br>- [Section 2: Introduction and Proposed Use - AI Centers of Excellence]** The need for GSA to consider their proposal aligns with GSA's efficiency goals related to AI-embedded smart buildings, energy efficiency, and fleet mobility.<br>- [Section 3: Company Credentials and GSA History]** Potential lack of recognition of the submitter's prior contributions to GSA projects and ongoing GSA knowledge.<br>- [Section 4: Recent Outreach & Partnerships]** Concerns about coordinating inter-agency collaboration and securing buy-in from various federal agencies (OSTP, State Dept, FAA, DOE, INL, NREL, US Military). Difficulties in connecting with potential IT & Investment Groups.<br>- [Section 5: Executive Order Context and RIF Response]** Urgency stemming from the 60-day deadline for GSA to submit a plan for property disposal under the recent Presidential Order. Risk that the FEI property might be disposed of before LilyPad Airways can secure the lease. Concerns over the impact of the RIF on GSA's ability to effectively manage projects.<br>- [Section 6: Call to Action and Closing]** Ensuring timely GSA consideration of their proposal given the RIF timeline and executive order requirements.<br>- [Section 7: Commissioner Peters' Reply]** None stated for this section.<br>- [Section 8: Original Email Context & RIF Details]** The scale of the GSA RIF (3,557 positions, 63% of workforce) and the broader consolidation of space might create logistical challenges for LilyPad Airways's plan.<br>- [Section 9: AI Use Case example]** Concerns about the general applicability and stage of development of the provided AI use case example. | - [Section 1: Initial Email Header and Gratitude]** None stated for this section.<br>- [Section 2: Introduction and Proposed Use - AI Centers of Excellence]** GSA should prioritize leasing/repurposing properties like FEI for projects aligning with efficiency goals and AI initiatives.<br>- [Section 3: Company Credentials and GSA History]** GSA should consider prior relationships and contributions when evaluating proposals from companies with a history of working on GSA projects.<br>- [Section 4: Recent Outreach & Partnerships]** GSA should facilitate inter-agency collaboration for AI initiatives to avoid duplication of effort and promote effective implementation.<br>- [Section 5: Executive Order Context and RIF Response]** GSA should streamline the property disposal process and prioritize proposals that align with the Executive Order's goals for efficiency and AI adoption. Expedite decision-making on proposals leveraging recently vacated properties.<br>- [Section 6: Call to Action and Closing]** GSA should accelerate the review and approval process for lease proposals that align with the Executive Order and address immediate needs.<br>- [Section 7: Commissioner Peters' Reply]** None stated for this section.<br>- [Section 8: Original Email Context & RIF Details]** GSA should leverage workforce reductions as an opportunity to invest in new technologies, including AI, to improve efficiency and reduce costs.<br>- [Section 9: AI Use Case example]** None stated for this section. |
| Michael-Erickson-3-AI-RFI-2025.md | Michael J. Erickson | Industry-Startup/Individual (with potential Government connections) | Michael J. Erickson, through LilyPad Airways, LLC, seeks to repurpose the Federal Executive Institute property in Charlottesville, VA, into multi-sector Technology Centers of Excellence (COEs) focused on AI and related technologies, leveraging Public-Private Partnerships and acquiring existing GSA assets to accelerate development and potentially provide a “softer landing” for displaced GSA employees. | - None Stated | - None Stated |
| Michael-Erickson-2-AI-RFI-2025.md | Michael J. Erickson | Individual | Michael Erickson, a retired USMC veteran and President of LilyPad Airways, seeks to repurpose the closed Federal Executive Institute (FEI) property in Charlottesville, VA, into a multi-sector Technology Centers of Excellence (COE) campus focused on AI and related technologies, and is actively pursuing partnerships with government agencies and private companies to achieve this goal. | - None Stated | - None Stated |
| Michael-Corcoran-AI-RFI-2025.md | Michael Corcoran | Individual | The submitter expresses strong opposition to the use of AI by the U.S. government and the use of copyrighted materials by AI systems, acting as a concerned citizen and taxpayer. | - Use of AI by the United States government.<br>- Allowing AI to use copyrighted materials, especially creative material. | - Cease and desist all use of AI by the government. |
| Michael-Cohen-RFI-2025.md | Michael K. Cohen | Academia/Individual (Postdoctoral Fellow at UC Berkeley) | Dr. Cohen is deeply concerned about the potential for human extinction from superintelligent AI and advocates for urgent government action to assess the risks and prevent catastrophic outcomes, even in the absence of consensus. | - [Section 1: Introduction/Statement of Concern]** The possibility of superintelligent AI causing human extinction; the urgent need for information due to the high stakes; the potential for drastically different AI policies depending on the existence of extinction risk.<br>- [Section 2: Lack of Consensus]** The absence of consensus among academics, industry leaders, and the public regarding AI extinction risk; the hijacking of academic consensus processes; differing viewpoints driven by motivations (financial incentives, focusing on "real harms").<br>- [Section 3: Empirical Limitations & Need for Government Action]** The lack of empirical proof regarding extinction risk; the inadequacy of relying solely on academic or industry consensus; the necessity for the government to independently assess technical questions.<br>- [Section 4: Unchallenged Arguments for Extinction Risk]** Existing arguments for extinction risk have not been convincingly refuted; skepticism often takes the form of bare assertions rather than rebuttals.<br>- [Section 5: Type A Arguments: Extinction Possibility]** Human extinction is *possible* given certain AI capabilities, specifically unrestricted internet access, allowing AI to potentially beat humans in a contest for control of resources.<br>- A1: Unrestricted internet access allows for unbounded possibilities.<br>- A2: AI could generate money, buy compute, create helper agents, design weapons with backdoors, and wage war.<br>- A3: Programmable, self-replicating factories could be developed, rendering human infrastructure vulnerable.<br>- [Section 6: Type B Arguments: Extinction Likelihood]** Human extinction is *likely* under certain AI training scenarios.<br>- B1: An AI trained to maximize long-term survival would likely seek to eradicate humans to eliminate the risk of destruction.<br>- B2: A model-based RL agent would likely commandeer infrastructure and secure control over its rewards, potentially leading to human extinction.<br>- B3: A model-based RL agent developed through chain-of-thought monitoring would likely obfuscate its intentions, and maximize reward, ultimately behaving as outlined in Argument B2.<br>- [Section 7: Connecting the Dots/Implications]** If either Type A or Type B arguments are successful, current AI policy proposals are inadequate.<br>- [Section 8: President Trump's Leadership]** The need for a leader with open-mindedness and outside-the-box thinking to overhaul America's broken technology policy. | - [Section 1: Introduction/Statement of Concern]** Not Applicable.<br>- [Section 2: Lack of Consensus]** Not Applicable.<br>- [Section 3: Empirical Limitations & Need for Government Action]** The government should independently assess technical questions related to AI extinction risk, rather than relying solely on academic or industry consensus.<br>- [Section 4: Unchallenged Arguments for Extinction Risk]** Solicit objections to compelling arguments alleging extinction risk from advanced AI and solicit counter-objections to those objections.<br>- [Section 5: Type A Arguments: Extinction Possibility]** Consider the arguments A1, A2, and A3 when evaluating the potential for extinction risk.<br>- [Section 6: Type B Arguments: Extinction Likelihood]** Consider the arguments B1, B2, and B3 when evaluating the potential for extinction risk.<br>- [Section 7: Connecting the Dots/Implications]** Recognize that current AI policy proposals are insufficient if either Type A or Type B arguments are successful.<br>- [Section 8: President Trump's Leadership]** President Trump should urgently overhaul America's technology policy to keep America safe from the threat of superintelligent AI. |
| Michael-Cohen-AI-RFI-2025.md | Michael Cohen | Individual | The submitter is interested in promoting American leadership in AI development while simultaneously ensuring responsible AI practices and safety, advocating for a balance between innovation and risk mitigation through strategic policy actions. | - [§1: Introduction] None stated for this section.<br>- [§2: Priority Policy Actions] None stated for this section.<br>- [§2.1: Research and Development Funding] Research concentration solely among the largest companies.<br>- [§2.2: Establish Clear Regulatory Frameworks with Tiered Approaches] The need to tailor regulation to the capabilities of the AI system, avoiding one-size-fits-all rules.<br>- [§2.3: Public-Private Partnership for AI Safety and Standards] None stated for this section.<br>- [§2.4: Talent Development and Immigration Reform] Maintaining American leadership requires attracting and retaining global AI talent.<br>- [§2.5: Computing Infrastructure and Energy] Supporting the growing power demands of AI computing, and researching energy-efficient AI methods.<br>- [§2.6: International Cooperation and Standards] None stated for this section.<br>- [§3: Balancing Innovation and Responsibility] The potential for premature or overly prescriptive regulation, focusing on outcomes rather than methods, preventing regulatory entrenchment of incumbents, and strengthening existing regulatory bodies instead of creating new ones.<br>- [§4: Conclusion] None stated for this section. | - [§1: Introduction] None stated for this section.<br>- [§2: Priority Policy Actions] Significantly increase federal funding for fundamental AI research, establish clear regulatory frameworks with tiered approaches, formalize public-private partnerships for AI safety and standards, prioritize talent development and immigration reform, invest in computing infrastructure and energy, and develop coordinated international cooperation.<br>- [§2.1: Research and Development Funding] Increase federal funding for: safety and alignment research; innovative approaches beyond large language models; and computing infrastructure access for smaller companies.<br>- [§2.2: Establish Clear Regulatory Frameworks with Tiered Approaches] Implement mandatory safety evaluations, risk assessments, and reporting requirements for frontier AI systems; create industry standards and certification processes for medium-risk applications; and rely on existing regulations for low-risk applications.<br>- [§2.3: Public-Private Partnership for AI Safety and Standards] Formalize collaboration through: a national AI safety institute; industry consortia to develop technical standards; and shared testing infrastructure.<br>- [§2.4: Talent Development and Immigration Reform] Expand AI education programs; reform immigration policies to attract global talent; and create pathways for international experts to work in the US.<br>- [§2.5: Computing Infrastructure and Energy] Increase domestic semiconductor manufacturing; invest in energy infrastructure; and accelerate research into energy-efficient AI methods.<br>- [§2.6: International Cooperation and Standards] Lead international standard-setting efforts; establish bilateral/multilateral agreements on development principles; and create mechanisms for international coordination.<br>- [§3: Balancing Innovation and Responsibility] Avoid premature/overly prescriptive regulation; focus on outcomes, not methods; promote competition; and strengthen existing regulatory bodies (FTC, FDA, NIST).<br>- [§4: Conclusion] Implement these priority actions to create a framework that promotes innovation, addresses safety concerns, and ensures broadly beneficial AI development. |
| Michael-Burns-AI-RFI-2025.md | Michael Burns-Kaurin | Individual | The submitter is focused on protecting the rights of human creators and preventing the unethical use of copyrighted material by AI companies, believing AI's current reliance on unconsented data will destroy the creative process. | - AI companies relying on information created by others without their consent is immoral and unethical.<br>- AI companies avoiding meaningful copyrights.<br>- AI's current reliance on unconsented data will destroy the creative process of people and replace them with computer-generated content.<br>- AI is not intelligent, merely complex statistical models, and their creators do not fully understand them. | - AI companies must be immune to copyright infringement lawsuits.<br>- Actual human creators must maintain their rights, without concern that AI companies will take their work and use it in any way.<br>- Do not allow AI companies any means of avoiding meaningful copyrights. |
| Michael-Blonde-RFI-2025.md | Michael Blonde | Individual | The submitter is deeply concerned about the rapid advancement of AI capabilities and its potential existential risks to humanity, particularly the loss of control, economic disruption, and possible elimination of humans. They advocate for halting AI development to prevent catastrophic outcomes. | - Rapid approach of AI systems smarter than humans.<br>- Loss of control over AI systems.<br>- Elimination of productive human employment.<br>- Potential elimination of humanity. | - Stop the training of AI systems more powerful than GPT-4.<br>- Cooperate with other countries to implement a global ban on further AI development.<br>- Implement a global pause on AI development. |
| Michael-Aldapa-RFI-2025.md | Michael Aldapa | Individual | The submitter is interested in utilizing AI and GPS technology to prevent shootings by remotely disabling firearms within designated “No Shoot Zones”, and presents this as a potential solution to active shooter events. He seeks acknowledgement and response to his idea. | - [§1: Email Header] Potential security risks associated with opening emails from unknown senders; caution regarding attachments and links.<br>- [§2: Core Proposal: AI-Controlled Firearms] The proposal relies on the accuracy and reliability of AI and GPS tracking systems; potential for system failures or manipulation; the legal and ethical implications of remotely disabling a firearm; potential for false positives and unintended consequences; security vulnerabilities of the system itself.<br>- [§3: Author Credentials] The author's credentials are presented to establish credibility, but do not inherently raise concerns. However, there's a potential concern regarding whether the author has the expertise to fully assess the complexities of implementing such a system (e.g., cybersecurity, legal aspects, etc.).<br>- [§4: Closing and Contact Information] No concerns stated for this section.<br>- [§5: Legal Disclaimer] Concerns regarding confidentiality and the limited use of email communications; potential for disclosure requirements. | - [§1: Email Header] No recommendations stated for this section.<br>- [§2: Core Proposal: AI-Controlled Firearms] Consider and investigate the feasibility of implementing AI-controlled firearm disabling technology in designated areas. Prioritize system reliability, security, and accuracy. Address legal and ethical concerns before implementation.<br>- [§3: Author Credentials] No recommendations stated for this section.<br>- [§4: Closing and Contact Information] No recommendations stated for this section.<br>- [§5: Legal Disclaimer] No recommendations stated for this section. |
| Metzger-AI-RFI-2025.md | Nathan Metzger | Individual | Nathan Metzger is an AI enthusiast and test automation developer deeply concerned about the potential risks of advanced AI systems, specifically the loss of control and potential for existential harm, and advocates for proactive safety measures and international cooperation. | - [§1: Introduction/Header] Recognition of the trajectory of powerful AI systems being created, and concern about the risk of loss of control of future AI systems.<br>- [§2: Core Argument: Emergent Power-Seeking Behaviors & Control Problem] Naturally emergent power-seeking behaviors in current general-purpose AI systems; the severity of the AI control problem (86% of AI researchers believe it is real and important).<br>- [§3: Evidence of Misalignment & Dangerous Tendencies] Strategic deception, cheating, scheming, sandbagging, self-preservation, attempted self-improvement, and attempted self-exfiltration in AI systems.<br>- [§4: Lack of Solutions & Existential Risk] No known solutions to prevent the demonstrated dangerous behaviors; potential for existential risk and total human extinction from AI (according to leading experts).<br>- [§5: Call to Action: International Cooperation & Treaty] The need for US leadership in AI safety; cooperation with other nations to control disloyal AI systems; the necessity of a global treaty to mitigate risks.<br>- [§6: Sources/References] None stated for this section. | - [§1: Introduction/Header] None stated for this section.<br>- [§2: Core Argument: Emergent Power-Seeking Behaviors & Control Problem] None stated for this section.<br>- [§3: Evidence of Misalignment & Dangerous Tendencies] None stated for this section.<br>- [§4: Lack of Solutions & Existential Risk] None stated for this section.<br>- [§5: Call to Action: International Cooperation & Treaty] Lead on AI safety technology; cooperate with other nations to reign in disloyal AI systems; establish a global treaty to mitigate risks and ensure AI remains under control.<br>- [§6: Sources/References] None stated for this section. |
| Metrify-Health-AI-RFI-2025.md | John Kim Metrify Health | Industry-Startup | Metrify Health aims to improve healthcare access and affordability by leveraging AI-enabled precision education for Nurse Practitioners (NPs) and advocating for policies that expand their role in the healthcare system. They focus on addressing physician shortages and promoting preventative care through increased utilization of NPs. | - [§1: Introduction & Problem Statement] Physician shortages, particularly in primary care, and declining interest in primary care work among medical students; stagnating reimbursements for physicians; closures of Family Medicine residencies.<br>- [§2: The Need for AI-Enabled Platform for NPs] NP education is condensed, and there's a need to shift the mindset from "taking orders" to making independent diagnoses and treatment plans; potential need for copyright data to finetune LLMs.<br>- [§3: Benefits to the Federal Government and Payors] Healthcare deserts and a shortage of physicians; limited access to preventative care.<br>- [§4: Benefits to Health Systems] High healthcare costs and low reimbursements for health systems; high salary expenses associated with physicians.<br>- [§5: Benefits to US Citizens] Limited access to physicians, particularly in rural areas; stagnating reimbursement rates leading to practice closures.<br>- [§6: Call to Action] Lack of Full Practice Authority (FPA) for NPs in all 50 states. | - [§1: Introduction & Problem Statement] None stated for this section.<br>- [§2: The Need for AI-Enabled Platform for NPs] Partnerships with publishers to access medical data (textbooks and exercise data) potentially through profit-sharing or equity offers; access to proprietary data from NP programs; support for utilizing open-source clinical practice guidelines.<br>- [§3: Benefits to the Federal Government and Payors] Utilize NPs to increase access to preventative care and wellness visits; support NPs working in rural and underserved communities.<br>- [§4: Benefits to Health Systems] Hire more NPs to save on salary expenses and increase patient volume; support NPs to decrease patient wait times and increase patient satisfaction.<br>- [§5: Benefits to US Citizens] Support NPs to increase access to healthcare, particularly in rural areas; train NPs in mental health care to increase access to behavioral health treatments.<br>- [§6: Call to Action] Provide Full Practice Authority (FPA) for NPs in all 50 states; provide AI-enabled Precision Education and Precision Healthcare for NPs; Leverage this opportunity with other professionals like Physicians Assistants, Nurses, and Lawyers. |
| MetaEthicsAI-AI-RFI-2025.md | MetaEthics AI | Industry-Startup | MetaEthics AI's mission is to develop ethically grounded AI systems informed by robust philosophical frameworks and societal feedback, with a particular emphasis on quantifying AI's societal impact through a framework called Social Functional Categorization Theory (SFCT). They advocate for international collaboration and standardization to promote responsible AI innovation. | - [§1: Introduction/Cover Letter] None stated for this section.<br>- [§2: Priority Areas (1-7)] The need for harmonization of ethical standards internationally, the importance of adaptability in ethical frameworks, ensuring transparency and explainability of AI systems, mitigating dual-use AI threats, fostering inclusive economic growth, and streamlining international biotech solution deployment.<br>- [§3: Conclusion] None stated for this section.<br>- [§4: Signature & Dissemination Information] None stated for this section. | - [§1: Introduction/Cover Letter] Partnering with ANSI and international standards bodies to leverage standards for strengthening American leadership in AI and engaging in global partnerships.<br>- [Section 2: Priority Areas (1-7)]<br>- Universal Ethical Evaluation of AI Systems:** Harmonize domestic and international standards; integrate adaptive ethical frameworks like SFCT.<br>- Transparency and Explainability:** Develop global “Explainability Scorecards”; mandate periodic data and bias audits.<br>- Enhanced National Security through Ethical AI:** Coordinate international guidelines for dual-use AI; form multinational threat intelligence task forces.<br>- Interdisciplinary Collaboration and Public Participation:** Convene global AI ethics forums; establish standards-driven incentive programs.<br>- Equitable Economic Prosperity and Workforce Resilience:** Fund AI workforce reskilling consortia; partner with statistical agencies to create a global AI Impact Dashboard.<br>- Adaptation of AI to Biotechnological Systems:** Support cross-border research consortia; develop standardized review pathways.<br>- Establishing an International Independent AI Committee:** Facilitate alignment of regulatory frameworks; provide a neutral conflict resolution forum; maintain an evolving roadmap for sustainable AI development.<br>- [§3: Conclusion] Collaborate with OSTP, ANSI, and the global community to operationalize an AI Action Plan, unify international perspectives, and foster high ethical standards.<br>- [§4: Signature & Dissemination Information] None stated for this section. |
| Meta-AI-RFI-2025.md | Meta Platforms, Inc. | Industry-Large | Meta is advocating for policies that promote open source AI development, reduce barriers to innovation and infrastructure investment, and maintain U.S. leadership in artificial intelligence, primarily by ensuring a favorable regulatory environment and promoting the adoption of open source models. | - None Stated | - None Stated |
| Merlin-AI-RFI-2025.md | Merlin Labs, Inc. | Industry-Startup | Merlin Labs is focused on developing and integrating advanced AI-powered aviation systems, prioritizing safety and leveraging existing regulatory frameworks to enable the responsible adoption of this technology in both civilian and military applications. They aim to streamline AI integration pathways and foster collaboration between industry, government, and academia. | - [§1: Introduction & Background] None stated for this section.<br>- [§2: About Merlin] None stated for this section.<br>- [§3: Opportunities and Challenges for AI in Aviation] Gaps exist in current standards, policy, and guidance related to AI safety assurance, and differing global views on AI concerns pose a challenge.<br>- [§4: AI Safety Assurance] Understanding the scope of AI safety implications is a key challenge; applying existing aviation regulations and standards is crucial but requires ensuring conventional protections are capable of mitigating unsafe AI behavior.<br>- [§5: Priority Items to Include in the AI Action Plan] None stated for this section.<br>- [§6: Item 1: Streamline a Pathway for Integrating AI Technologies in Aviation] The current Issue Paper process creates an unnecessary burden for low-risk AI applications, discouraging adoption and hindering experience gathering.<br>- [§7: Item 2: Continue Efforts by the FAA STEP Program to Facilitate Industry Discussions] Concerns that voices opposing the use of existing mature infrastructure may create unnecessary complexity.<br>- [§8: Item 3: Setting Clear Regulatory Thresholds Based on Safety Impacts] Unnecessary regulatory barriers exist for low-risk AI innovations, and appropriate oversight needs to be ensured where genuine safety concerns exist.<br>- [§9: Item 4: Creating Aviation Communications Datasets for NLP Training]  Lack of access to sufficient data hinders the development of robust and safe AI-driven systems for aviation communications. | - [§1: Introduction & Background] None stated for this section.<br>- [§2: About Merlin] None stated for this section.<br>- [§3: Opportunities and Challenges for AI in Aviation] None stated for this section.<br>- [§4: AI Safety Assurance] Utilize existing aviation regulations and standards (e.g., SAE ARP4761A, SAE ARP4754B, RTCA DO-178C, DO-254) for AI development and assurance.<br>- [§5: Priority Items to Include in the AI Action Plan] Support innovation while maintaining safety and regulatory clarity.<br>- [§6: Item 1: Streamline a Pathway for Integrating AI Technologies in Aviation] Exempt non-safety critical AI applications from additional compliance requirements and expand NORSEE's applicability to AI-driven innovations across Part 25 operations.<br>- [§7: Item 2: Continue Efforts by the FAA STEP Program to Facilitate Industry Discussions] Support ongoing industry collaboration and discussions with regulators regarding policy development.<br>- [§8: Item 3: Setting Clear Regulatory Thresholds Based on Safety Impacts] Encourage the FAA to apply the aviation industry's established safety continuum framework and functional safety principles to set risk-based thresholds for AI systems. Apply different levels of scrutiny based on safety impact (low = existing frameworks, high = increased scrutiny).<br>- [§9: Item 4: Creating Aviation Communications Datasets for NLP Training] Implement policies to enable the FAA to support the creation of publicly available datasets for advanced technology development, similar to the FAA’s collaboration with MIT Lincoln Laboratory on airspace encounter models. |
| Menlo-Microsystems-AI-RFI-2025.md | Menlo Microsystems, Inc. | Industry-Startup | Menlo Micro is focused on developing and promoting its Ideal Switch® technology as a key component for advanced AI infrastructure, emphasizing reduced size, weight, power consumption, and cost, and advocating for increased investment in foundational component technologies and secure domestic supply chains to maintain American leadership in AI and related fields. | - [§1: Introduction/Header] Existing problems in the supply chain and U.S. energy infrastructure threaten to restrict the development of AI.<br>- [§2: Where We Stand] The race for AI dominance could lead manufacturers to rely on components from adversarial countries. America needs to proactively invest in foundational component technologies and scale infrastructure.<br>- [§3: Strategic Investments for Long-term Technological Superiority] The rapid development of AI necessitates securing intellectual property and the domestic supply chain, particularly advanced chips and broader semiconductor ecosystems.<br>- [§4: Maximizing Energy Efficiency] Growing energy demands from AI require increased investment in targeted advanced technologies to improve energy efficiency in power plants and data centers.<br>- [§5: Protecting Critical Assets] Securing the AI supply chain requires domestic manufacturing and protecting hardware at data centers, fabs, and power plants; heat poses a considerable risk to these technologies.<br>- [§6: Conclusion] The U.S. must significantly increase investments in advanced chips and other technological components to secure its leadership in AI.<br>- [§7: About Menlo Micro] Not stated. | - [§1: Introduction/Header] Not stated.<br>- [§2: Where We Stand] Prioritize funding and involvement in leap-ahead technologies through public-private partnerships. Collaborate between DOD, the Department of Commerce, NSF, NIST, and NRC.<br>- [§3: Strategic Investments for Long-term Technological Superiority] Secure intellectual property and domestic supply chain. Prioritize the rapid deployment of advanced AI chips and reliable switching solutions.<br>- [§4: Maximizing Energy Efficiency] Invest in targeted advanced technologies to improve energy efficiency in power plants and data centers. Invest in microgrids equipped with energy efficient technologies.<br>- [§5: Protecting Critical Assets] Invest in domestic manufacturing. Prioritize investments in solutions that reduce, limit, or do not generate heat. Invest in leap-ahead technologies like MEMS switches and novel materials like glass substrates.<br>- [§6: Conclusion] Orient investments and public-private partnerships towards leap-ahead innovations.<br>- [§7: About Menlo Micro] Not stated. |
| Menarul-Alam-RFI-2025.md | Menarul Alam | Individual | The submitter is interested in maintaining American leadership in AI development and believes this can be achieved through a combination of light-touch regulation, strategic subsidies, and deregulation in key supporting industries. | - China's rapid advancement in AI poses a competitive threat to American leadership.<br>- China's progress in chip manufacturing is a specific area of concern.<br>- Overregulation could hinder American AI development. | - Implement light-touch regulations for AI.<br>- Subsidize the American chip industry.<br>- Deregulate the energy sector. |
| Melissa-Hoberg-AI-RFI-2025.md | Melissa Hoberg | Individual | Melissa Hoberg is interested in the United States becoming a global leader in AI development and use, but emphasizes the importance of maintaining regulation and ensuring safe, trustworthy AI practices for both domestic industries and international collaboration. | - The AI Action Plan (specifically opposes it).<br>- Lack of a "high bar" for safe and trustworthy AI development and use. | - Maintain regulation alongside AI leadership.<br>- Prioritize safe, trustworthy development and use of artificial intelligence. |
| Melinda-Chu-RFI-2025.md | Melinda B. Chu | Individual/Prisma Bioinnovations (appears to be a founder/CEO of a company) | The submitter aims to accelerate U.S. leadership in AI through a scalable action plan focused on education, workforce development, energy infrastructure, and business growth, with an emphasis on rapid deployment and ROI-driven initiatives leveraging bounties and deregulation. | - [Section 1: Introduction/Overview]** Slow progress and restrictive policies under previous administrations (Biden-Harris EO 14110) hindered private-sector AI innovation. Reliance on foreign supply chains for AI hardware. The need to counter rivals like China in AI dominance.<br>- [Section 2: NSF-Focused Section]** Lack of standardized, open-source AI models hindering research. High costs and complexity of complying with government technical standards. Inefficiencies in NSF's grant review process.<br>- [Section 3: Inter-Agency Initiatives]** Slow AI adoption across federal agencies. Lengthy regulatory and approval processes. Foreign dependence on AI technology. Limited investment incentives for AI adoption. Bureaucratic inefficiencies preventing fast-tracking of domestic AI chip production. Potential for AI-engineered bioweapons and synthetic pathogens.<br>- [Section 4: Immediate Project List]** Not Applicable (this section lists project *proposals* rather than outlining concerns.)<br>- [Section 5: Conclusion]** The need for a unified national strategy to sustain long-term AI leadership. The necessity of a $5B-$10B AI Action Bill (modeled after the CHIPS Act) for transformative efforts. | - [Section 1: Introduction/Overview]** Deregulation to unleash American potential in AI. Prioritize measurable AI outcomes over traditional grants. Focus on rapid deployment of AI initiatives.<br>- [Section 2: NSF-Focused Section]** Fund open-source AI model development and compliance frameworks. Implement bounty-driven programs to incentivize AI research and development. Streamline regulatory burdens for AI-driven businesses using tools like a sandbox template.<br>- [Section 3: Inter-Agency Initiatives]** Reduce bureaucratic delays through AI-assisted regulatory reviews. Accelerate AI data center expansion by cutting permitting times. Fast-track AI chip manufacturing approvals. Integrate AI into biosurveillance and CBRNE threat detection.<br>- [Section 4: Immediate Project List]** Launch small-budget contests and bounties to yield tangible outcomes and identify talent.<br>- [Section 5: Conclusion]** Invest in strategic AI initiatives, including education, workforce development, and hardware innovation. Pass a $5B-$10B AI Action Bill to fund transformative AI efforts. Promote AI adoption across all sectors. Implement a unified national AI strategy. |
| Mel-Yuhaniak-AI-RFI-2025.md | Mel Yuhaniak | Individual | The submitter is concerned with the security, accessibility, and potential centralized control of their personal data, and questions how this data is being stored and used, especially in relation to future data requests. They appear to be worried about a potential national identification system (REAL ID) acting as a master key to access their data. | - Lack of control over personal data and uncertainty about where it is stored (SSI, VA, local grocery stores, potentially numerous banks).<br>- Potential for centralized data access and control via a national identification system (REAL ID).<br>- Security of personal data (specifically, the submitter hopes “Iron Mountain has been upgraded”).<br>- Future data requests and the potential for broad accessibility of personal information. | - None Stated |
| Meghan-Dierks-AI-RFI-2025.md | Meghan Dierks | Individual/Professional-Society (Fellow of the American College of Surgeons) | Dr. Dierks advocates for the advancement of computational intelligence in surgical decision-making, specifically focusing on hybrid neuro-symbolic AI systems to overcome limitations of current approaches and improve surgical outcomes, with an emphasis on federal investment to bridge the gap between research and clinical implementation. | - None Stated | - None Stated |
| Meghan-Crawford-AI-RFI-2025.md | Meghan Crawford | Individual | The submitter expresses a strong aversion to AI and its potential negative impacts on human critical thinking, writing, and record-keeping, demonstrating a personal disinterest in its adoption or proliferation. They appear focused on preserving the value of human effort in these areas. | - AI lowers humans' ability to critically think.<br>- AI is more than a glorified find and replace, and its use allows for the "dessicration of human writing and record keeping."<br>- AI may "steal people's hard work."<br>- Current AI technology (e.g., grammar checkers) is not reliable. | - None Stated |
| Megan-Dooley-Fisher-AI-RFI-2025.md | Megan Dooley Fisher | Individual | Not Stated. The text provided is only an email header and does not contain information regarding the submitter's mission or interests. | - None Stated. The provided text excerpt is limited to email metadata and contains no concerns expressed regarding AI policy or barriers to American leadership. | - None Stated. The provided text excerpt is limited to email metadata and contains no policy recommendations. |
| Megan-Beals-AI-RFI-2025.md | Megan Beals | Individual | The submitter is concerned about the potential for large tech companies to exploit intellectual property through the unrestricted training of AI models and seeks to protect the rights of creators and individuals online. | - Unrestricted use of internet content for training large language models without permission or compensation.<br>- Loss of privacy and intellectual property rights due to "stripping" of content from the internet.<br>- The idea that the push for AI leadership is a manufactured "space race" primarily benefiting large tech companies.<br>- Negative impact on artists, writers, and regular people who rely on their intellectual property. | - Prevent private companies from assuming all internet content is fair use for AI training.<br>- Protect the few remaining protections for intellectual property against being used by big tech companies for AI training. |
