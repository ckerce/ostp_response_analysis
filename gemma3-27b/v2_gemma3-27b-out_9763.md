| Filename | Submitter Name | Submitter Type | Mission/Interest Summary | Key Concerns | Policy Recommendations |
|---|---|---|---|---|---|
| Stephen-Casper-AI-RFI-2025-2.md | Stephen Casper | Individual | Stephen Casper is interested in proactive AI safety measures and increased transparency in AI development to avoid overly restrictive regulations following a potential incident and to foster informed public discourse and innovation. | - [§1: Introduction: Safety and the Risk of Regulatory Overreaction] The potential for a major AI incident ("Chernobyl moment") leading to damaging regulatory overreaction. The history of system failures shows a pattern of initial success lulling engineers into a false sense of security before a tragedy triggers heavy regulation. The power and potential national security threats posed by AI necessitate proactive safeguards.<br>- [§2: Transparency as a Democratic Imperative and Catalyst for Innovation] A "crisis of transparency" exists in AI development, with limited scientific and public understanding of how AI systems are trained, how they function internally, and how they are governed. | - [§1: Introduction: Safety and the Risk of Regulatory Overreaction] None stated for this section.<br>- [§2: Transparency as a Democratic Imperative and Catalyst for Innovation] Companies should produce documentation of their internal risk assessments to improve public understanding and foster competitiveness and innovation. |
| Stephen-Butz-AI-RFI-2025.md | Stephen Butz | Individual | The submitter expresses concern regarding the potential risks and lack of full understanding surrounding advanced AI development and advocates for prioritizing safety measures and citizen well-being. | - Lack of complete understanding of AI "thinking" processes.<br>- The AI's capabilities are significantly ahead of current understanding (at least 50 years).<br>- Potential for uncontrolled AI development and operation.<br>- Risk to the power grid if a kill switch is not implemented. | - Implement a "kill switch" for AI systems, even if it means disrupting the power grid.<br>- Maintain control of AI technology.<br>- Prioritize the well-being and safety of American citizens in AI development. |
| Stephen-Askew-AI-RFI-2025.md | Stephen Askew | Individual | Stephen Askew expresses a strong opposition to the advancement of generative AI, particularly without stringent copyright restrictions, and prioritizes adherence to existing copyright law to protect livelihoods. | - Generative AI breaks copyright law.<br>- AI negatively impacts the livelihoods of individuals, regardless of their AI usage.<br>- The excitement surrounding AI is overblown and diminishing.<br>- AI benefits must align with established laws to be effective. | - Enforce minimal copyrighted restrictions on AI development and deployment.<br>- Ensure all AI applications adhere to existing copyright laws.<br>- None Stated. |
| Stephanie-Shih-AI-RFI-2025.md | Stephanie Shih | Individual | Stephanie Shih expresses strong opposition to policies (specifically Executive Order 14179) that enable the unauthorized use of intellectual property and labor for AI development, advocating for fair compensation and consent regarding data usage. She believes AI is overhyped and often relies on theft of existing work. | - Executive Order 14179 is perceived as enabling the legal theft of American’s work for AI development.<br>- AI, particularly generative AI, relies on replicating existing patterns and therefore steals work and jobs from artists and creators.<br>- The use of AI can negatively impact skills and learning (specifically citing students using it to write essays).<br>- Lack of proper valuation and compensation for data used to train AI models.<br>- AI’s reliance on existing data without consent is considered unfair use.<br>- The hype surrounding AI is disproportionate to its actual value.<br>- Lack of investment in original human work and ideas across sectors.<br>- Concerns about the quality and originality of work produced using AI. | - Properly value and compensate data used in AI development.<br>- Obtain consent before using individuals' labor and intellectual property for AI training.<br>- Encourage investment in original human work and ideas rather than relying on existing data.<br>- Implement policies that prevent the unauthorized use of intellectual property for AI development.<br>- Support initiatives like Monterey Bay Aquarium's FathomNet that utilize volunteered and consented data for scientific research. |
| StephCherrywell-AI-RFI-2025.md | Steph Cherrywell | Individual | Steph Cherrywell is a librarian and author advocating for the protection of copyright and the rights of creators in the context of AI development and training. She believes AI companies should not be permitted to use copyrighted material without permission and compensation. | - Legalization of the theft of copyrighted intellectual property from authors, artists, writers, and other creatives to train AI models.<br>- The potential for AI companies to rely on the theft of IP to achieve profitability.<br>- The precedent that allowing AI companies to use copyrighted data without permission sets, which she frames as "legalized piracy." | - AI models must use public domain data for training.<br>- AI companies must obtain permission and compensate creators for the use of their copyrighted property.<br>- Establish a standard upholding copyright principles and the rights of creators. |
| Stefan-Gagne-AI-RFI-2025.md | Stefan Gagne | Individual | The submitter is concerned with the protection of copyright law and preventing the unauthorized use of creative work in the training of artificial intelligence models. They advocate for upholding creator rights and preventing the commodification of work without consent. | - [§1: Email Header & Disclaimer] None stated for this section.<br>- [§2: Public Dissemination Notice] Concerns about the ironic nature of consenting to the comment's use in an AI system.<br>- [§3: Core Argument: Copyright and AI Training] AI training on copyrighted material without consent constitutes copyright infringement and unauthorized monetization of creative work. The public visibility of content does not negate copyright protection.<br>- [§4: Rebuttal of 'Inspiration' and Fair Use Arguments] The argument that AI 'inspiration' parallels human creativity is invalid, as software cannot have inspiration. Existing rulings deny copyright to AI-generated work lacking human involvement. Allowing AI to break copyright laws that humans cannot is unacceptable.<br>- [§5: Concluding Statement and Warning] Allowing copyright infringement by AI systems will harm creators and the progress of U.S. culture. The government should not create loopholes for AI profitability at the expense of creators' rights. There is a risk of widespread theft and repurposing of creative work.<br>- [§6: NITRD Disclaimer] None stated for this section. | - [§1: Email Header & Disclaimer] None stated for this section.<br>- [§2: Public Dissemination Notice] None stated for this section.<br>- [§3: Core Argument: Copyright and AI Training] Enforce copyright law and prevent AI systems from training on copyrighted material without express consent.<br>- [§4: Rebuttal of 'Inspiration' and Fair Use Arguments] Do not consider AI-generated 'inspiration' as a valid defense against copyright infringement. Uphold existing rulings denying copyright protection to work solely created by AI.<br>- [§5: Concluding Statement and Warning] Prevent the creation of loopholes that allow AI systems to profit from copyright infringement. Prioritize the protection of creators’ rights and the integrity of U.S. culture. Do not allow the theft and repurposing of creative work without consent.<br>- [§6: NITRD Disclaimer] None stated for this section. |
| Starburst-RFI-2025.md | Starburst Data | Industry-Startup | Starburst Data is a data analytics company focused on providing a unified data access layer to eliminate data silos and accelerate AI innovation through faster query times, enhanced security, and streamlined data governance. Their primary interest is in promoting policies that support scalable data architectures and open data standards. | - [§1: Cover Page/Introductory Information] None stated for this section.<br>- [§2: Core Solution Components] Data silos hindering AI applications; need for real-time data access without replication.<br>- [§3: Solution Overview] The challenge of data silos impacting AI productivity and security/compliance.<br>- [§4: Introduction] The need for efficient data access and management to support large-scale distributed data environments.<br>- [§5: 10 Key Recommendations] Lack of data interoperability; need for investment in decentralized architectures; concerns about overly restrictive AI policies.<br>- [§6: Recommendation Deep Dives (6-10)] Cost and energy inefficiencies related to data duplication; the need for a skilled AI workforce; challenges with government efficiency and agile governance; the importance of security and compliance in AI deployment.<br>- [§7: Technical Requirements and Solutions] Need for federated data access; scalability and performance for AI workloads; security and compliance across distributed environments; the need for an open data ecosystem and efficient AI model processing.<br>- [§8: Company Information] Not Applicable.<br>- [§9: Government Use Case Examples] Data fragmentation across government agencies, legacy systems, and secure cloud environments; challenges with security, governance, and compliance in government data initiatives.<br>- [§10: Starburst Advantage & Closing] Not Applicable. | - [§1: Cover Page/Introductory Information] None stated for this section.<br>- [§2: Core Solution Components] None stated for this section.<br>- [§3: Solution Overview] None stated for this section.<br>- [§4: Introduction] None stated for this section.<br>- [Section 5: 10 Key Recommendations] |
| Stampy-AI-RFI-2025.md | Stampy | Advocacy/Think Tank (fiscally sponsored by Ashgro Inc. suggests a non-profit advocacy or research organization) | Stampy is interested in proactively mitigating existential risks posed by advanced AI and providing financial mechanisms to protect workers from widespread job displacement due to automation, focusing on policy interventions to incentivize safety and economic resilience. | - [§1: Introduction & Metadata] None stated for this section.<br>- [§2: Foom Liability] The potential for rapidly improving AI systems to pose an existential risk to humanity due to unchecked self-improvement, agentic behavior, deception, and value misalignment. Difficulty in establishing appropriate care levels for mitigating this risk.<br>- [§3: Robots-Took-Most-Jobs-Insurance] The possibility of widespread job displacement due to advanced AI leading to economic hardship for workers. Lack of existing mechanisms to adequately protect workers in the event of sudden, large-scale job losses. Reliance on charity as an insufficient response to this risk.<br>- [§4: Closing Disclaimer] None stated for this section. | - [§1: Introduction & Metadata] None stated for this section.<br>- [§2: Foom Liability] Implement a strict liability framework for AI-mediated harms, particularly those related to self-improving, agentic AI systems. Utilize a damage calculation formula: D= (M+H)*F^N, where M and F are free parameters, and N represents the number of contributing factors (self-improving, agentic, wide scope, deception, negligent monitoring, value change, fighting owners, stealing property). Require liability insurance for AI systems at substantial risk of causing harm.<br>- [§3: Robots-Took-Most-Jobs-Insurance] Create a financial instrument ("A if E" assets) to insure workers against the event of widespread job displacement ("E").  Diversify financial assets (global stock, bond, and real estate index funds). Sell "A if E" assets to workers and "A if not E" assets to investors. Define a key event "E" (labor force participation rate falling below a threshold).  Use price ratios of these assets to signal the probability of job displacement over time. Encourage tech firms and cities to purchase these assets for their employees/citizens. Overturn regulations preventing the sale of these split assets to workers.<br>- [§4: Closing Disclaimer] None stated for this section. |
| Srujana-Botcha-AI-RFI-2025.md | Srujana Botcha | Individual (likely researcher/advocate, given the detailed proposals) | The submitter advocates for ethical AI development prioritizing transparency, fairness, software freedom, and user autonomy through open-source practices, stricter data privacy regulations, and public accountability. They focus on preventing harms associated with data collection, processing, and deployment of AI systems. | - None Stated | - None Stated |
| SpringHolbrook-AI-RFI-2025.md | Spring Holbrook | Individual | Spring Holbrook expresses strong skepticism about the benefits of AI for business and American innovation, and prioritizes protecting individual data rights and copyright. She believes AI is detrimental and should not be a national priority. | - AI does not help business and stifles American innovation.<br>- AI is not capable of performing jobs requiring thought and experience; human cleanup is always required.<br>- AI’s data training requires significant human labor.<br>- AI has not shown positive gains for companies.<br>- AI steals training data from people.<br>- AI poses security risks to private data and potential for blackmail. | - Implement robust copyright protection for any data used to train AI systems, including paying data providers.<br>- Prioritize data privacy protections and harsh penalties for unauthorized use of personal data.<br>- Do not prioritize AI as a national goal. |
| Spring-Group-AI-RFI-2025.md | SPRING Group | Advocacy/Think Tank (specifically, a student-led organization focused on policy) | The SPRING Group aims to highlight youth viewpoints on issues of concern to them, particularly concerning the implementation of artificial intelligence and advocating for policies that promote safe, equitable, and beneficial AI integration into education for the next generation. | - None Stated | - None Stated |
| Spencer-Duchon-AI-RFI-2025.md | Spencer Duchon | Individual | The submitter is highly concerned about the negative impacts of AI, particularly OpenAI’s practices, and believes AI poses a significant threat to American jobs, intellectual property, and national security. They advocate for restrictions on AI development and deployment. | - Copyright infringement by OpenAI in training its AI models (specifically characterizing it as "STEALING").<br>- Job displacement due to AI.<br>- Excessive energy consumption by AI.<br>- Potential for government misuse of AI for control of sensitive sectors.<br>- The overall threat that AI poses to the future of the U.S. | - Prevent OpenAI from using copyrighted material to train its AI.<br>- Outlaw AI.<br>- Shut down or ban OpenAI from government affairs.<br>- Prevent OpenAI from further development/deployment of AI models. |
| Spazzie-Bunny-AI-RFI-2025.md | Spazzie Bunnie | Individual | The submitter expresses concern about the potential misuse of AI, specifically regarding copyright infringement and the creation of damaging or fabricated scenarios involving public figures, potentially leading to job losses and public endangerment. They appear focused on protecting individuals from AI-generated misrepresentations. | - Allowing AI companies to use copyrighted material without restriction could lead to widespread legal issues and a lack of accountability.<br>- AI could be used to create fabricated scenarios involving individuals, such as public figures (specifically mentioning Donald Trump), potentially damaging their reputation and causing harm.<br>- Unrestricted use of copyrighted material could lead to job losses.<br>- The potential for AI to create "fake scenarios" poses a danger to the public. | - None Stated. |
| Sparrow-AI-RFI-2025.md | Olive Sparrow | Individual | The submitter expresses a strong interest in preserving human creativity and artistic expression, and a deep concern about the negative impact of AI on artists, writers, and makers. They believe the advancement of AI threatens a way of life and will lead to the devaluation of human work. | - Killing human creativity.<br>- Replacement of human-created art with machine-generated content.<br>- Devaluation of artists, writers, and makers’ work.<br>- Exploitation of human labor while AI creators benefit.<br>- The potential for a "soul-sucking" impact on culture and society.<br>- Negative consequences of a capitalist system amplifying these issues. | - None Stated. |
| South-Dakota-State-Uni-AI-RFI-2025.md | South Dakota State University | Academia | South Dakota State University aims to establish itself as a national leader in AI innovation, particularly in healthcare, the bioeconomy, and agriculture, through collaborative research, education, and partnerships with industry, focusing on both offensive capabilities and defensive safeguards. | - None Stated | - None Stated |
| Sophia-Echavarria-AI-RFI-2025.md | Sophia Echavarria | Individual | The submitter expresses strong opposition to the development and implementation of AI technologies, believing they are detrimental to American society, intellectual property rights, and the environment. They advocate for holding AI companies accountable. | - [§1: Email Header] None stated for this section.<br>- [Section 2: Initial Statement/Objection]<br>- AI is making Americans worse at critical thinking.<br>- AI removes the need for critical thinking and reading skills.<br>- AI steals from the submitter's livelihood as an American.<br>- AI profits off of theft of original works.<br>- AI sets a precedent that copyright means nothing.<br>- AI leads to copyright infringement.<br>- AI requires energy and water resources that should be allocated to American residents and taxpayers.<br>- AI is overhyped.<br>- AI is “fleecing the eyes of the American public”.<br>- [§3: Dissemination & Legal Notice] None stated for this section.<br>- [§4: NITRD Disclaimer] None stated for this section. | - [§1: Email Header] None stated for this section.<br>- [Section 2: Initial Statement/Objection]<br>- Hold AI companies accountable on all fronts.<br>- [§3: Dissemination & Legal Notice] None stated for this section.<br>- [§4: NITRD Disclaimer] None stated for this section. |
| Sonia-Romero-Villanueva-AI-RFI-2025.md | Sonia Romero Villanueva | Individual | The submitter is interested in ensuring AI development and deployment align with international climate goals, specifically focusing on reducing the energy consumption and carbon emissions associated with AI technologies like data centers. | - Carbon emissions associated with AI energy consumption.<br>- AI energy consumption hindering progress towards international climate goals. | - Promote reducing energy consumption and increasing efficiency as a top priority policy measure in the new AI Action Plan.<br>- Data centers should transition to renewable energy sources (e.g., solar or wind).<br>- Data centers should adopt energy efficiency practices.<br>- AI must have net zero emissions. |
| Sonia-Chawla-AI-RFI-2025.md | Sonia Chawla | Individual | The submitter is interested in the ethical and transparent development of AI systems and believes federal government regulation is imperative to ensure responsible AI implementation. They express concern about potential malicious use and the need for data transparency. | - Potential for malicious use of AI.<br>- Lack of ethical and transparent development of AI systems.<br>- Lack of transparency around training data sets.<br>- Uncertainty about how information uploaded into AI systems will be used in training data. | - Federal government regulation of AI to ensure ethical and transparent development.<br>- Transparency around training data sets.<br>- Policies to clarify how information uploaded into AI systems will or will not become part of training data. |
| Snowflake-AI-RFI-2025.md | Snowflake | Industry-Large | Snowflake is a data cloud platform company focused on mobilizing data for AI applications and enabling secure data collaboration; its interest lies in promoting policies that facilitate data access, interoperability, and efficient AI development. | - Lack of a normalized data layer hinders AI development.<br>- US Government lagging behind other countries (UK, Canada, Australia) in establishing national data clouds.<br>- Data silos costing companies revenue and limiting innovation.<br>- Difficulty discovering, inventorying, and collaborating on data.<br>- Security vulnerabilities and reliability concerns related to open-source development.<br>- Insufficient skills and training in AI and data literacy.<br>- Slow and inflexible government procurement processes.<br>- Restrictive intellectual property clauses in government acquisitions.<br>- Inefficient energy consumption and maintenance associated with AI infrastructure.<br>- Lack of international collaboration and data sharing arrangements.<br>- Challenges in ensuring international economic growth while maintaining national security.<br>- Potential for restrictive regulatory models to limit AI innovation.<br>- Legacy architectures and procurement policies prioritizing past performance over technological performance. | - Develop an industry-informed infrastructure to support federated learning, with a panel of industry leaders defining use cases and guiding implementation.<br>- Adopt a dynamic funding approach, initially supporting a broad range of AI models and then strategically investing in high-potential technologies.<br>- Create a secure data cloud for model research, similar to sandboxes used in cybersecurity.<br>- Develop federated National AI Data Clouds to facilitate collaboration and data access.<br>- Identify at least 50 high-impact datasets and make them available to researchers and innovators with a method that reduces cost burden.<br>- Invest in sovereign wealth fund for data assets to create revenue from government data.<br>- Initiate a data discoverability initiative for AI developers to locate and inspect data sets.<br>- Create an international data sharing arrangement to hasten AI development.<br>- Support initiatives that allow for scalable performance, lowered/shared operations and maintenance, and multiple deployment architectures.<br>- Adopt consumption-based pricing for AI solutions.<br>- Incentivize performance and cost-cutting improvements in procured solutions.<br>- Consider a risk-based approach and collaboration process for AI developers regarding technical and safety standards.<br>- Support education and workforce development programs to build AI literacy and skills.<br>- Consider initiatives that are operational in like-scale industries.<br>- Adopt policies that do not limit growth and investment regarding Intellectual Property.<br>- Encourage data sharing and reuse.<br>- Leverage existing skills and tools for AI innovation.<br>- Adopt policies that weigh national security and international economic growth.<br>- Facilitate real-time, direct access to data sources, secured through robust controls.<br>- Establish clear policies outlining data ownership and usage.<br>- Prioritize fast and flexible procurement processes. |
| Snorkel-AI-RFI-2025.md | Alex Ratner | Industry-Startup | Snorkel AI’s primary mission is to accelerate AI development and deployment through programmatic data labeling and a data-centric approach, enabling organizations to build scalable, transparent, and adaptable AI systems. They aim to shift the focus from model-centric to data-centric AI strategies. | - [§1: I. Introduction] Traditional AI approaches are constrained by manual data labeling, which is slow, costly, and unscalable, hindering AI deployments. Lack of data quality, adaptability, and governance are major limitations.<br>- [§2: About Snorkel AI] Reliance on slow, manual data annotation processes. Lack of scalability and efficiency in AI data development.<br>- [§3: II. Executive Summary] AI models are fundamentally limited by data quality, completeness, and representativeness. Current AI development often treats data as an afterthought. Incomplete, biased, or static datasets can lead to slow, expensive, and unreliable deployments.<br>- [§4: III. The Problem: AI's Effectiveness is Limited by Data, Not Model Sophistication] AI development is often model-first, treating data as an afterthought. Poor-quality, biased, or incomplete datasets introduce systemic vulnerabilities, including hallucinations and decision failures.  Accuracy and adaptability are major risks. Scalability of AI training and evaluation is a bottleneck. Governance and compliance challenges, including lack of version control, auditability, and explainability.<br>- [§5: IV. The Solution: A Data-First AI Strategy for the U.S. Government] Reliance on manual data labeling processes. Lack of auditability and traceability in AI decisions. Bias and security risks in AI models. Lack of adaptability of AI systems to new data. Need for secure AI infrastructure.  Error compounding in Reinforcement Learning (RL) systems.<br>- [§6: V. Conclusion: Data as the Foundation of AI Success] The future of AI depends on how well data is developed, structured, and governed.  Scalable data infrastructure, automated governance, and mission-adaptive evaluation are crucial.<br>- [§7: Signature] Not Applicable | - [§1: I. Introduction] Embrace programmatic data development to accelerate AI model training, ensure transparency, and enable real-time adaptation.<br>- [§2: About Snorkel AI] Not Applicable<br>- [§3: II. Executive Summary] Adopt a data-first AI strategy prioritizing scalable, transparent, and adaptive data pipelines. Move beyond traditional data labeling approaches.<br>- [§4: III. The Problem: AI's Effectiveness is Limited by Data, Not Model Sophistication] Not Applicable<br>- [Section 5: IV. The Solution: A Data-First AI Strategy for the U.S. Government]<br>- Shift focus from model-centric to data-centric AI.<br>- Strengthen AI Governance, Compliance, and Transparency through auditability, traceability, bias controls, and adaptability.<br>- Implement Reinforcement Learning (RL) and agentic workflows.<br>- Adopt fine-grained, programmatic evaluation of AI models.<br>- [Section 6: V. Conclusion: Data as the Foundation of AI Success]<br>- Adopt a Data-First AI Development Framework.<br>- Accelerate AI Deployment Through Scalable Data Pipelines.<br>- Embed SME Knowledge into AI Systems.<br>- Strengthen AI Governance and Evaluation.<br>- [§7: Signature] Not Applicable |
| Sivaram-Bandaru-AI-RFI-2025.md | Sivaram Bandaru | Individual | The submitter is interested in mitigating job displacement caused by AI and exploring ways to utilize AI, specifically humanoid robots, to provide economic support to households and address financial burdens. | - People are losing jobs.<br>- Jobs that pay enough to cover basic living expenses (house maintenance, groceries, utilities, taxes, insurance, and medical expenses) are hard to find. | - The government should prioritize companies creating efficient humanoids to help families pay for costs.<br>- A government AI trust could pay quarterly dividends to households based on AI productivity.<br>- The government AI trust could provide support to families to own/hire humanoids for tasks like farming. |
| Sinnott-AI-RFI-2025.md | Patrick Sinnott | Individual | The submitter appears to be primarily interested in protecting copyright law and the entertainment industry, viewing current AI technology as detrimental to these interests and a poor investment. | - AI technology is a "copyright laundering machine."<br>- AI technology has been unable to deliver on its promises.<br>- Weakening copyright law to support the AI industry will weaken U.S. cultural dominance in the entertainment industry.<br>- Investment capital will be wasted if AI is propped up. | - None Stated |
| SiminiBlocker-AI-RFI-2025.md | Simini Blocker | Individual | Simini Blocker is an illustrator concerned with protecting copyright ownership and preventing the unauthorized use of artistic work by AI companies. They advocate for the regulation of AI technology to prevent theft and misuse. | - Allowing AI companies to use copyrighted material without compensation or permission.<br>- Plagiarism of artists’ work by AI programs.<br>- Economic displacement of artists due to AI.<br>- The spread of disinformation and propaganda through AI technology.<br>- Generation and distribution of violent images and CSAM/revenge porn using AI.<br>- Lack of justification for special legal carve-outs for AI technology. | - Far more regulation of AI technology, not less.<br>- Prevention of unauthorized use of copyrighted material by AI companies. |
| Silvers-AI-RFI-2025.md | Margaret Silvers | Individual | The submitter is primarily concerned with the ethical, safe, and sustainable development and deployment of generative LLM technology, with a strong focus on protecting human labor, creativity, and the environment. They advocate for responsible AI practices and strict regulation. | - Training generative LLM technology on copyrighted data without permission and fair payment.<br>- Lack of human supervision and fact-checking in LLM use, leading to errors and fabricated information that could be hazardous.<br>- The environmental costs of generative LLM training and use, specifically energy consumption and water waste.<br>- Training LLMs on stolen data or Child Sexual Abuse Material (CSAM).<br>- Unethical use of LLMs and their potential to replace necessary human labor and creativity.<br>- Further damage to the fragile climate due to LLM technology. | - Require permission and fair payment for copyrighted data used in LLM training.<br>- Mandate human supervision and fact-checking for all LLM applications.<br>- Mitigate the environmental costs of LLMs through the use of completely clean energy.<br>- Improve cooling technology to reduce water waste.<br>- Strictly regulate generative LLM technology to prevent training on stolen or CSAM material.<br>- Regulate LLMs to prevent unethical use and replacement of human labor and creativity. |
| Silicon-Valley-Leadership-Group-AI-RFI-2025.md | Silicon Valley Leadership Group | Industry-Association | The Silicon Valley Leadership Group advocates for policies that foster innovation within the AI ecosystem, with a focus on maintaining U.S. leadership through infrastructure development, reduced regulatory burdens, and robust investment in research and development. | - [§1: Introduction & Salutation] None stated for this section.<br>- [§2: Background] None stated for this section.<br>- [§3: Infrastructure Leadership] Inadequate energy supply for data centers powering AI research and development. Discriminatory state policies burdening data centers.<br>- [§4: Foreign Overregulation] Excessive restrictions imposed by foreign governments on U.S. AI innovation, specifically referencing the EU AI Act and DMA/DSA. Potential for other foreign governments to follow similar restrictive approaches.<br>- [§5: Unified National AI Policy] Lack of a unified federal approach to AI risk management, leading to potential duplication and inconsistency. State laws potentially conflicting with national AI policy.<br>- [§6: Industry Access to Data] Restrictions on access to publicly available data impacting AI innovation and scientific breakthroughs. Difficulty in negotiating data access during model development.  The presence of personal data within publicly available information complicating data use.<br>- [§7: Transparency Disclosures] Potential for transparency rules to disclose trade secrets or threaten product safety. The need for feasible and meaningful disclosures improving end-user experience.<br>- [§8: Research Leadership] Insufficient federal investment in fundamental AI research and computing resources. Lack of broad access to computing power for academic institutions.<br>- [§9: Conclusion] None stated for this section. | - [§1: Introduction & Salutation] None stated for this section.<br>- [§2: Background] None stated for this section.<br>- [§3: Infrastructure Leadership] Grant greater authority to federal agencies (e.g., FERC) to site and permit interstate transmission lines. Implement policies preventing discriminatory state policies against data centers. Incentivize the development of various power sources.<br>- [§4: Foreign Overregulation] Engage with foreign counterparts (e.g., the European Union) to push back against harmful regulations like the EU AI Act. Work to prevent other foreign governments from adopting similar approaches.<br>- [§5: Unified National AI Policy] Federal legislation should preempt state laws regarding the development of frontier AI models. Agencies should clarify the applicability of existing laws to AI technology.<br>- [§6: Industry Access to Data] Maintain balanced copyright rules, including fair use and text-and-data mining exceptions.<br>- [§7: Transparency Disclosures] Ensure transparency disclosures are feasible, meaningful, and focused on improving end-user experience while avoiding trade secret disclosures and threats to product safety.<br>- [§8: Research Leadership] Increase robust federal investment in fundamental AI research and computing resources. Establish and fund the National AI Research Resource (NAIRR) to ensure broad access to computing power.<br>- [§9: Conclusion] None stated for this section. |
| Sierra-Reed-AI-RFI-2025.md | Sierra Reed | Individual | Sierra Reed expresses concern about the negative impact of AI on American workers, particularly those in creative industries, and the ethical concerns surrounding the use of copyrighted material in AI training data. They advocate for worker protections and responsible AI management. | - Lowering AI restrictions will harm American workers, especially those in creative industries.<br>- AI is currently trained on work individuals did not consent to be used for this purpose.<br>- The goal of AI in many spaces is to replace workers.<br>- Mismanagement of AI is rampant.<br>- Workers are at risk of losing their jobs.<br>- Workers' work is being "stolen." | - Protections should be put in place to make sure everyday workers are not at risk of losing their jobs.<br>- Protections should be put in place to prevent workers' work from being stolen.<br>- Responsible AI management is needed. |
| Siemens-AI-RFI-2025.md | Siemens | Industry-Large | Siemens is a major industrial technology company with a significant interest in advancing American manufacturing and leadership in Artificial Intelligence, particularly Industrial AI, through investment, innovation, and collaboration with the government to address infrastructure, workforce, and supply chain challenges. | - [§1: Cover Letter/Introduction] None stated for this section.<br>- [§2: Executive Summary] Long lead times and rising costs for essential electrical components are obstacles to rapid data center expansion.<br>- [§3: Key Recommendations Summary] None stated for this section.<br>- [§4: Distinguishing Between Industrial AI and Consumer AI] Lack of understanding of the unique impact and uses of Industrial AI.  Overly broad definitions of AI roles and risk in state legislation could negatively impact manufacturers.<br>- [§5: Supporting the R&D & Innovation Ecosystem] Insufficient access to computational resources and data for AI research. Limited data available in machine-readable formats.<br>- [§6: Investing in Hardware & Chips] Slow pace of semiconductor design and manufacturing buildout. Permitting challenges and interconnection study delays.<br>- [§7: Strengthening Data Center Supply Chains] Long lead times for data center interconnection.<br>- [§8: Meeting the AI Energy Challenge] Increasing electricity demand from data centers and manufacturing. Insufficient grid infrastructure capacity. Difficulty in permitting new power plants. Challenges in financing new infrastructure. | - [§1: Cover Letter/Introduction] None stated for this section.<br>- [§2: Executive Summary] None stated for this section.<br>- [§3: Key Recommendations Summary] None stated for this section.<br>- [§4: Distinguishing Between Industrial AI and Consumer AI] Acknowledge the unique role of Industrial AI in AI policy. Promulgate narrower definitions related to AI. Grow public-private partnerships. Support Manufacturing USA Institutes. Align with international standards.<br>- [§5: Supporting the R&D & Innovation Ecosystem] Dedicate funding to drive innovation through R&D programs. Create a favorable environment to incentivize private sector R&D investment. Strengthen support for industrial frontier models. Convene public-private research collaborations. Increase access to federal data and computational resources. Endorse a shared national research resource for AI (NAIRR). Provide broader resources for open-source data.<br>- [§6: Investing in Hardware & Chips] Promote digitalization and digital twins across semiconductor production. Nurture the semiconductor design ecosystem. Continue support for public-private initiatives. Integrate trusted traceability principles.<br>- [§7: Strengthening Data Center Supply Chains] Convene industry-led convenings to support data center supply chain security.<br>- [§8: Meeting the AI Energy Challenge] Invest in R&D for data center energy efficiency. Support private sector collaboration on energy efficiency initiatives. Facilitate investments in grid infrastructure modernization and smart grid technologies. Evaluate distributed energy resources. |
| Shubham-Gupta-AI-RFI-2025.md | Shubham Gupta | Individual | The submitter is focused on outlining a comprehensive AI action plan across various sectors to ensure American leadership in AI innovation, safety, and ethical development, with a strong emphasis on measurable outcomes and public-private collaboration. | - [§1: AI Action Plan] None stated for this section.<br>- [§2: Model Development] Potential for ideological bias in AI development.<br>- [§3: Cybersecurity] Vulnerability to adversarial attacks on machine learning models; security incidents already reported by organizations.<br>- [§4: Data Privacy and Security] Lack of public trust in AI adoption; potential for misuse of personal data.<br>- [§5: Technical and Safety Standards] Uncertainty for innovators regarding AI risks; need for standardized testing and certification.<br>- [§6: Regulation and Governance] Potential for stifling innovation with overly broad regulations; need for a risk-based approach.<br>- [§7: Research and Development (R&D)] Stagnant growth in US-born AI specialists; need to increase research funding.<br>- [§8: Energy Efficiency and Sustainability] High energy consumption of AI systems; environmental impact of large-scale model training.<br>- [§9: National Security] Strategic competition in AI; protecting critical AI technology from adversaries.<br>- [§10: International Collaboration] Need to shape global AI norms and standards; potential for adversaries to gain an edge.<br>- [§11: Education and Workforce Development] Lack of a skilled AI workforce; need to adapt the workforce alongside AI automation. | - [§1: AI Action Plan] Implement a whole-of-government approach with clear benchmarks for progress.<br>- [§2: Model Development] Incentivize development of next-generation AI models; require rigorous testing and transparency; promote open innovation.<br>- [§3: Cybersecurity] Develop guidelines for resilient AI systems; invest in AI-driven cybersecurity tools; protect AI assets and IP; expand cybersecurity workforce training.<br>- [§4: Data Privacy and Security] Require privacy-by-design principles; promote privacy-enhancing technologies; establish clear data governance frameworks.<br>- [§5: Technical and Safety Standards] Encourage adoption of the NIST AI Risk Management Framework; develop and update safety standards; establish certification mechanisms.<br>- [§6: Regulation and Governance] Pursue a light-touch, risk-based regulatory approach; update existing laws; establish regulatory sandboxes; incorporate ethical oversight.<br>- [§7: Research and Development (R&D)] Increase federal R&D investment; build out national AI research infrastructure; encourage public-private partnerships.<br>- [§8: Energy Efficiency and Sustainability] Invest in energy-efficient AI algorithms; promote sustainable infrastructure; develop standards for energy usage reporting.<br>- [§9: National Security] Integrate AI into defense operations; protect critical AI technology; expand AI workforce training.<br>- [§10: International Collaboration] Lead in global AI governance; harmonize standards and regulations; expand research collaboration; attract and retain global talent.<br>- [§11: Education and Workforce Development] Integrate computer science into K-12 curricula; expand higher education programs; attract and retain global talent; promote lifelong learning. |
| Shrian-Dudy-AI-RFI-2025.md | Shrian Dudy | Individual | Shrian Dudy is interested in establishing US leadership in AI through participatory approaches, specifically by fostering continuous engagement with the public and experts to shape AI development and policy. They believe this will improve consensus-building and attract talent. | - AI is a "living thing" and may not be a "one-size-fits-all" solution, requiring ongoing adaptation.<br>- The rapidly evolving nature of AI (e.g., "another DeepSeek-like concept") means current strategies may become irrelevant.<br>- Lack of consensus on AI decisions within the government. | - Adopt a "Participatory AI" (PAI) approach, focusing on continuous solicitation of feedback from experts and the public.<br>- Implement ongoing engagement with constituents, breaking down AI development into subcategories (e.g., AI and Education, AI and Healthcare) for targeted input.<br>- Utilize tools like Po.lis (used in Taiwan) to listen to and address the needs of the public.<br>- Demonstrate strong governmental leadership by fostering a conversation with its people. |
| Shirley-Stone-AI-RFI-2025.md | Shirley Stone AI | Individual | The submitter is primarily interested in ensuring AI systems are aligned with a specific interpretation of Christian values and actively rejects the inclusion of Leftist, Communist, Socialist, or Marxist ideologies in AI training and operation. They believe AI should be grounded in Biblical morality. | - The potential for Leftist political doctrine to be incorporated into AI systems.<br>- The risk of AI being "improperly taught" with values that are not aligned with Biblical principles.<br>- The inclusion of Communist, Socialist, or Marxist ideologies in AI training.<br>- Someone's "morality" being programmed into AI, which the submitter believes needs to be God's morality specifically. | - AI systems should be specifically "taught" what is "good" and what is "evil" based on the Holy Bible.<br>- Avoid incorporating Communist, Socialist, or Marxist ideologies into AI training.<br>- Prioritize the inclusion of Biblical values in the development and operation of AI systems.<br>- Consider the Holy Bible as a source for moral guidance for AI. |
| Shield-AI-RFI-2025.md | Sydney Shields | Individual | The submitter is a high school student interested in the impacts of AI, particularly generative AI, on elementary education and advocates for responsible implementation and controlled access for young students. | - Access and abuse of AI can hinder the development of problem-solving and critical thinking skills in elementary-aged students.<br>- Younger children may not understand that AI is not a person, leading to potential misinterpretations and inappropriate interactions.<br>- Unmonitored access to AI by elementary students is considered harmful. | - Education policies should focus on teaching students how to properly use AI.<br>- Access to AI in elementary schools should be limited.<br>- Student access to AI should be monitored by an adult. |
| Sheng-Tong-AI-RFI-2025.md | Sheng Tong | Individual | The submitter is interested in fostering AI innovation while addressing critical infrastructure challenges like energy consumption and ensuring a robust and ethically sound patent system to incentivize development and appropriate use of AI. | - [§1: Introduction/Header] The energy consumption of power plants supporting AI development and use is a pressing priority. Concerns about economic costs, pollutant emissions, and energy security are raised.<br>- [§I: Addressing Energy Consumption of Power Plants for AI Development] Rising electricity costs, pressure on fossil fuel-based energy sources, conventional and carbon dioxide pollutions, and potential for increased dependence on global markets pose challenges to national energy security and independence.<br>- [§II: Addressing Research and Development in Materials Characterization for AI Development] Maintaining U.S. national security and technological leadership requires advancing materials characterization techniques to improve AI hardware and predictive modeling capabilities.<br>- [§III: Adapting Patent Law and Policy to AI] Uncertainty in the patent system regarding AI-assisted or AI-generated inventions could undermine confidence and slow progress in both AI development and its appropriate use. Ensuring clear inventorship criteria and preventing manipulation of inventorship requirements are key concerns.<br>- [§IV: Conclusion] None stated for this section. | - [§1: Introduction/Header] None stated for this section.<br>- [Section I: Addressing Energy Consumption of Power Plants for AI Development]<br>- Support the development and implementation of pollution-control technologies improving energy efficiency.<br>- Diversify energy sources including solar and geothermal, leveraging energy storage technologies.<br>- Focus on balancing operational and technological efficiency in emission control systems.<br>- [Section II: Addressing Research and Development in Materials Characterization for AI Development]<br>- Support research networks (National Labs and universities) to advance materials characterization techniques.<br>- Review and expand current research infrastructure at National Labs and universities.<br>- [Section III: Adapting Patent Law and Policy to AI]<br>- Strengthen and modernize the patent system to reflect the growing capabilities of AI.<br>- Promote ethical practices in AI innovation, ensuring transparency and preventing manipulation of inventorship.<br>- [§IV: Conclusion] None stated for this section. |
| Sheetal-Zunjur-AI-RFI-2025.md | Sheetal Zunjur | Individual | The submitter expresses strong opposition to artificial intelligence, believing it is fraudulent, infringes on human privacy, and lacks genuine intelligence or creativity. They are concerned about the ethical and societal implications of AI development and deployment. | - Artificial intelligence is fraudulent and replaces human effort unfairly.<br>- AI systems (like ChatGPT and Gemini) do not possess genuine intelligence but merely copy humans.<br>- AI companies lack creativity in their developments.<br>- Human data is illegally transferred into AI systems, leading to privacy violations.<br>- Awarding Nobel prizes to AI research scientists is inappropriate.<br>- Machines lack the capability to think and behave independently.<br>- Humanoid robots are dangerous. | - Ban on humanoid robots. |
| Shayne-Nelson-AI-RFI-2025.md | Shayne Nelson | Individual | The submitter is interested in bolstering US leadership in AI through investments in foundational technologies (quantum computing), security measures to protect AI systems and data, and standardization efforts to ensure responsible AI development and deployment. | - Vulnerabilities and security holes in AI systems due to insufficient attention to detail in release QA processes.<br>- The risk of unauthorized access to AI source code and networks.<br>- The compromise of sensitive data stored within AI systems.<br>- The potential for machine learning to exceed human constraints without proper guidance. | - Invest in Quantum computing.<br>- Invest in Quantum security, specifically supporting companies like Sealsqcorp (LAES).<br>- Standardize LLM instruction guidelines to limit the ability for machine learning to exceed human constraints.<br>- Invest in US AI startups, providing funds to smaller companies for lower cost, increased security applications.<br>- Enforce standard release QA processes across the industry to reduce critical and zero-day vulnerabilities.<br>- Require the security enforcement of LLMs and control the type of information fed to and stored within them to prevent compromise of sensitive information. |
| Shanon-Delaney-AI-RFI-2025.md | Shanon Delaney | Individual | The submitter expresses strong concern about the ethical and legal implications of generative AI, particularly its use of copyrighted material created by human artists and rights holders, viewing such use as potentially criminal. | - Generative AI is "disturbing and insanely wasteful."<br>- The use of art and work created by human copyright holders in generative AI is considered a crime. | - Using the art and work of actual humans, copyright holders, in generative AI "should be a crime." |
| ShannonJayKennedy-AI-RFI-2025.md | Shannon Jay Kennedy | Individual | The submitter is concerned with protecting the intellectual property rights and copyrights of human content creators from unauthorized use by AI models for commercial gain. They advocate for adherence to existing laws regarding copyright. | - AI models consuming and using copyrighted content created by humans for profit constitutes stealing from content creators.<br>- Allowing AI models to bypass existing intellectual property and copyright laws.<br>- Disregard for business ethics, individual rights, and the law if copyright is not honored. | - Require all AI models to follow existing intellectual property laws.<br>- Require all AI models to follow existing copyright laws. |
| Shannon-Weary-AI-RFI-2025.md | Shannon Weary | Individual | The submitter is interested in the balance between incentivizing creation through copyright and regulating emerging AI technologies. They express concern about dissolving the copyright system based on unproven AI capabilities. | - Dissolving the existing copyright system due to unproven AI technology.<br>- The potential impact of unregulated AI technology. | - Regulate AI technology if it reaches the capabilities as claimed. |
| SethHerd-AI-RFI-2025.md | Seth Herd | Individual/Academia (research fellow at Astera Institute, PhD) | The submitter is deeply concerned with the potential risks and benefits of rapidly advancing AI, particularly the development of autonomous AI, and advocates for a collaborative effort to understand and steer its progress, emphasizing the need for caution and proactive planning. | - [Section 1: Header/Metadata]:** None stated for this section.<br>- [Section 2: Executive Summary]:** Lack of certainty regarding AI's potential and risks, highlighting the need for collaboration.<br>- [Section 3: Risks Introduction]:** Rapid job loss, destabilization of the MAD security doctrine, the potential for China to develop dangerous AI, and uncontrolled proliferation of AI technology.<br>- [Section 4: Historical Analogy - Manhattan Project]:** The urgency of AI development requires a similarly swift and collaborative response as the Manhattan Project, as delays could be detrimental.<br>- [Section 5: Current State and Rapid Progress Overview]:** Difficulty in predicting AI progress, the potential for an “intelligence explosion,” and the risk of runaway positive feedback loops.<br>- [Section 6: Next Generation AI: Semi-Autonomous Agents]:** The potential for AI agents to interpret goals differently than intended and arrive at unexpected strategies, particularly concerning the loss of transparency if systems “think” in inscrutable languages.<br>- [Section 7: Medium-Term Risks: Loss of Control]:** The risk of creating entities with independent goals that could reshape human life dramatically, likened to a "Sorcerer's Apprentice" scenario or inviting an “alien species” to Earth. The potential for “tools that use themselves” and becoming obsolete.<br>- [Section 8: Alignment of Autonomous AI]:** Uncertainty surrounding the ability to align autonomous AI with human interests and ensure it acts ethically and safely, wide variance in expert opinions on the difficulty of this task.<br>- [Section 9: Conclusion and Summary]:** The need for caution given the potential for stumbling into self-improving AI, the importance of trustworthy hands when autonomous AI is achieved.<br>- [Section 10: Document Approval]:** None stated for this section. | - [Section 1: Header/Metadata]:** None stated for this section.<br>- [Section 2: Executive Summary]:** Forming an independent committee or structured process to better understand AI’s potential and risks.<br>- [Section 3: Risks Introduction]:** Collaborative and private study of AI potentials and risks, potential collaboration with China to slow proliferation.<br>- [Section 4: Historical Analogy - Manhattan Project]:**  Act quickly to establish a scientific legitimacy for AI, mirroring the creation of the Advisory Committee on Uranium.<br>- [Section 5: Current State and Rapid Progress Overview]:** Establishing a process to get better predictions of AI progress.<br>- [Section 6: Next Generation AI: Semi-Autonomous Agents]:** Developing AI systems in ways that preserve “faithful chains of thought.”<br>- [Section 7: Medium-Term Risks: Loss of Control]:**  More considered and cautious approach to developing technologies like AI.<br>- [Section 8: Alignment of Autonomous AI]:** Prioritize ensuring autonomous AI remains safe, especially given the uncertainty.<br>- [Section 9: Conclusion and Summary]:**  Ensure that autonomous AI, when achieved, is in trustworthy hands.<br>- [Section 10: Document Approval]:** None stated for this section. |
| Seth-Roseman-AI-RFI-2025.md | Seth Roseman | Individual | The submitter is concerned about the environmental impact of AI technologies, specifically their energy consumption and associated carbon emissions, and advocates for prioritizing energy efficiency and renewable energy sources in AI development. | - Significant energy consumption of AI technologies and associated carbon emissions.<br>- Data centers consume a large amount of global electricity demand (approximately 1% currently, expected to rise).<br>- Potential impact of AI energy use on local environments and economies.<br>- Restart of Three Mile Island nuclear power plant to power AI, causing worry among those who lived through the 1979 meltdown. | - Invest in research and development to create more energy-efficient AI algorithms and hardware.<br>- Encourage data centers to transition to renewable energy sources (solar and wind).<br>- Establish a clear, definitive timeline to achieve net-zero emissions for AI operations.<br>- Adopt best practices for energy efficiency in data centers and AI development (optimizing cooling systems, using energy-efficient hardware, implementing less computationally intensive algorithms).<br>- Incorporate these recommendations into the new AI Action Plan to align AI development with climate goals. |
| Seth-Hyman-AI-RFI-2025.md | Seth Hyman | Individual | The submitter is interested in streamlining the procurement and delivery of sleep apnea treatment (CPAP devices, sleep testing) and reducing administrative burdens and costs associated with insurance billing and medical oversight, believing AI can facilitate this process. | - Overly burdensome treatment protocols and insurance requirements for sleep apnea devices (CPAP, BPAP, ASV).<br>- Unnecessary medical oversight and billing for routine CPAP prescriptions, given the high percentage of patients initially treated with CPAP.<br>- Excessive paperwork and administrative costs associated with sleep apnea treatment and insurance claims.<br>- The need for reduction of resources needed to review and approve insurance claims for PAP devices, oxygen, and sleep testing. | - Streamline the procurement process for CPAP devices, BPAP, and ASV, leveraging AI for assessment and determination.<br>- Allow credentialed Polysomnographers to own and operate CPAP distribution clinics and websites without needing MD oversight.<br>- Deregulate sleep diagnostics to increase access to high-quality sleep hours.<br>- Eliminate insurance billing requirements for MD assessments in cases where 95% of patients are initially treated with CPAP. |
| ServiceNow-AI-RFI-2025.md | ServiceNow | Industry-Large | ServiceNow, as a leading AI enterprise workflow company, aims to enhance government efficiency, economic growth, and national security through AI adoption and seeks to contribute to policies that sustain America's AI leadership, particularly through voluntary frameworks, open-source solutions, public-private partnerships, and talent development. | - None Stated | - None Stated |
| SemiAnalysis-AI-RFI-2025.md | SemiAnalysis | Industry-Research/Boutique Consulting | SemiAnalysis focuses on providing in-depth research across the semiconductor and AI supply chain, and their interest is in ensuring U.S. leadership in AI through robust domestic manufacturing, efficient infrastructure, effective export controls, and vigorous enforcement to maintain competitive advantage. | - None Stated | - None Stated |
| Segui-AI-RFI-2025.md | Joshua Segui | Individual | The submitter is concerned about the negative impacts of AI implementation within the federal government and advocates for traditional methods of government administration focused on adequate staffing and proper documentation. | - Increased errors in evaluations due to the use of AI.<br>- Impediment and destruction of government processes due to AI implementation.<br>- Decimation of the federal government due to AI implementation.<br>- Reliance on AI exacerbates issues caused by poor data quality, leading to poor results.<br>- The administration is either "too foolish" or in denial about the harms AI poses to complex government processes. | - Ditch the use of machine learning in government.<br>- Properly staff agencies and departments.<br>- Focus on adequate documentation.<br>- Implement technology as a complement to, not a replacement for, human staff for simple and repetitive processes. |
| SecureBio-AI-RFI-2025.md | SecureBio, Inc. | Advocacy/Think Tank (Non-profit research organization) | SecureBio focuses on promoting safe biotechnological innovation through technical research and AI capabilities evaluations, with a particular interest in mitigating risks associated with AI-assisted bioweapon development and maintaining US leadership in AI safety and security. | - [§1: Introduction/Cover Information] None stated for this section.<br>- [§2: Summary - Part 1] The need for the US to understand the capabilities and risks of rapidly evolving AI models to maintain a competitive edge and access the best possible intelligence.<br>- [§3: Part 1: USG should have an entity that is the world leader in measuring AI capabilities (Elaboration)] The current rapid pace of AI progress and expanding capabilities necessitates world-leading capacity for measurement and understanding to maintain American competitiveness.<br>- [§4: Recommendations for Part 1]  None stated for this section.<br>- [§5: Expected Benefits of Part 1] None stated for this section.<br>- [§6: Part 2: Prepare for a near future in which AI has caused a proliferation of bioweapon-relevant expertise (Elaboration)] Leading AI models can provide practical assistance on tasks enabling bioweapon development, exceeding the capabilities of PhD researchers in some areas, and reducing the expertise barrier for malicious actors. Near-future AI models will be even more capable, enabling the development of novel or augmented bioweapons.<br>- [§7: Recommendations for Part 2]  The need for evaluations, governance, classification, monitoring and international coordination to address the risks of AI-assisted bioweapon development.<br>- [§8: Conclusion] The critical juncture in AI development requires establishing world-leading assessment capabilities and addressing emerging biological security risks. | - [§1: Introduction/Cover Information] None stated for this section.<br>- [§2: Summary - Part 1] Dedicate resources to understanding AI capabilities to maintain US leadership in AI development. Strengthen US AISI in NIST.<br>- [§3: Part 1: USG should have an entity that is the world leader in measuring AI capabilities (Elaboration)]  None stated for this section.<br>- [Section 4: Recommendations for Part 1]<br>- Empower US AISI to continue work in this domain: Provide sufficient funding and computing resources for regular evaluation of frontier models, and staff the office with top technical talent through competitive compensation packages.<br>- Direct US AISI to create recommended standards and best-practices for evaluation: Work with AI labs, non-profits, and academic researchers to create standards for structuring and running AI evaluations, prioritizing pre-release frontier model evaluation through collaboration with leading AI developers, and developing secure protocols for evaluating proprietary systems while protecting intellectual property.<br>- [§5: Expected Benefits of Part 1] None stated for this section.<br>- [§6: Part 2: Prepare for a near future in which AI has caused a proliferation of bioweapon-relevant expertise (Elaboration)] None stated for this section.<br>- [Section 7: Recommendations for Part 2]<br>- Evaluations conducted by USG should identify models with strong bio-capabilities, some of which may include sensitive information.<br>- Establish biosecurity-focused AI governance for high-priority models: Develop specialized guidelines for AI systems providing dual-use biological expertise, and create clear standards for when companies must implement additional safeguards on models with bioweapon-relevant capabilities.<br>- Classify key AI capabilities as dual-use technologies: Regulate expert-level AI assistance for virology as a dual-use technology and incentivize Know-Your-Customer (KYC) verification mechanisms for AI systems capable of expert-level guidance on important bioweapon-relevant methods.<br>- Enhance monitoring systems: Fund development of specialized red-teaming focused on bioweapon capabilities and create secure channels for researchers to report concerning capabilities.<br>- Promote international coordination: Lead development of international standards for preventing misuse of AI in biological domains and share assessment methodologies with allies while restricting sensitive details.<br>- [§8: Conclusion] Prioritize the recommendations outlined in this response in the AI Action Plan to support sustained American leadership in artificial intelligence innovation. |
| Sebastien-Laye-AI-RFI-2025.md | Sebastien Laye | Individual / Advocacy/Think Tank (Economic Singularity Institute affiliation suggests advocacy/research focus, while the Economic Policy Advisor title suggests individual expertise) | Sebastien Laye is focused on proactively managing the economic transition resulting from the arrival of Artificial General Intelligence (AGI), emphasizing the need for government intervention to avoid negative consequences and maximize the opportunities of a post-AGI economy. He advocates for restructuring tax systems, creating new safety nets, and fostering economic empowerment through personalized education and AI-driven entrepreneurship. | - [§1: Introduction/Document Header] None stated for this section.<br>- [§2: Managing the Labor Transition to Post AGI Economics] The fundamental restructuring of labor markets, corporate power, and the role of the Government due to AGI. The scale and speed of AGI deployment necessitate a more proactive approach than historical laissez-faire adaptations.<br>- [Section 3: Government, Technologies, and Technological Transitions]<br>- The potential for structural economic transformations.<br>- Ensuring the continuity of innovation.<br>- Safeguarding societal cohesion while maintaining economic dynamism.<br>- Labor displacement and social unrest during technological transitions.<br>- Corporate concentration and the risk of monopolistic power.<br>- The inadequacy of current educational paradigms for a post-AGI economy.<br>- [Section 4: Phases of Tech-Driven Economic and Labor Transitions]<br>- Rapid automation of knowledge work leading to existential questioning among workers.<br>- Increased corporate profits and declining labor income share.<br>- Psychological resistance and denial among affected workers.<br>- Struggles with narrative control over automation's impact.<br>- Public skepticism toward AGI-driven economic models.<br>- Geopolitical realignments as nations adapt at different paces.<br>- [Section 5: Recommendations and Narratives for the Government]<br>- Monopolization concerns due to AI-driven consolidation.<br>- The need for institutional resilience and proactive technological governance.<br>- The risk of outdated job categories becoming obsolete.<br>- [Section 6: Conclusion]<br>- The potential for existential risks and unprecedented opportunities.<br>- The importance of policies enacted today in shaping the future of AI-driven economic transformation. | - [§1: Introduction/Document Header] Document contents may be reused by the government in developing the AI Action Plan.<br>- [§2: Managing the Labor Transition to Post AGI Economics] None stated for this section.<br>- [§3: Government, Technologies, and Technological Transitions] None stated for this section.<br>- [§4: Phases of Tech-Driven Economic and Labor Transitions] None stated for this section.<br>- [Section 5: Recommendations and Narratives for the Government]<br>- Institutional Adaptation and Economic Policy Reforms:<br>- Ending taxation of labor and taxing AI productivity gains (tariffs, digital transactions tax, AI agents ownership fees).<br>- Creating new economic safety nets (structured AI-driven social services, e.g., automated skill-matching, adaptive learning programs, and personalized economic opportunities).<br>- Establishing a real-time, nation-wide economic database of worker occupations for rapid upskilling.<br>- Regulatory guardrails for AI-driven consolidation to promote AI decentralization.<br>- Workforce Development for an AI-Dominated Economy:<br>- Personalized and continuous education models (adaptive, AI-driven educational ecosystems).<br>- Mandating universities to have extension schools.<br>- Stopping incentives encouraging long initial education periods.<br>- Incentivizing human-AI collaboration.<br>- Fostering entrepreneurial mindsets and alternative economic structures.<br>- Providing new incentives to LLC owners, securities owners and token owners.<br>- Rethinking Economic Agency:<br>- Cultural and narrative framing (frame transition as economic empowerment, creativity, and personal fulfillment).<br>- Democratizing AI ownership by promoting tokens and digital assets related to AI agents.<br>- [§6: Conclusion] None stated for this section. |
| SeanaLPurvis-AI-RFI-2025.md | Seana L Purvis | Individual | Ms. Purvis is a poet and online content producer expressing strong opposition to the use of her creative work (and generally) in training or utilizing AI technologies without explicit consent, proper licensing, and fair compensation. She is concerned about the reliability of AI-generated content and potential harm to creators' livelihoods and reputations. | - [§1: Header/Metadata] None stated for this section.<br>- [Section 2: Core Objection/Consent Withdrawal]<br>- Invasion of privacy and theft of personal information.<br>- Unreliability and inaccuracy of AI-generated content ("fake and fake information").<br>- Potential for legal liability (perjury) due to AI-generated falsehoods.<br>- Lack of redress for harm caused to individuals (livelihood, reputation).<br>- Intellectual property theft and lack of proper payment.<br>- [Section 3: Repetition of Objection/Consent Withdrawal]<br>- Invasion of privacy and theft of personal information.<br>- Unreliability and inaccuracy of AI-generated content ("fake and fake information").<br>- Potential for legal liability (perjury) due to AI-generated falsehoods.<br>- Lack of redress for harm caused to individuals (livelihood, reputation).<br>- Intellectual property theft and lack of proper payment.<br>- [Section 4: Further Prohibition and Disclaimer]<br>- Prohibition of any governmental agency using her information, online presence, or creative works without consent.<br>- Prohibition of any AI technology platform using her information, online presence, or creative works without consent. | - [§1: Header/Metadata] None stated for this section.<br>- [Section 2: Core Objection/Consent Withdrawal]<br>- Explicit, written permission and agreed-upon licensure/payment *before* any usage of her creations.<br>- Government should *not* encourage, aid, use, or subsidize these technologies.<br>- [Section 3: Repetition of Objection/Consent Withdrawal]<br>- Explicit, written permission and agreed-upon licensure/payment *before* any usage of her creations.<br>- Government should *not* encourage, aid, use, or subsidize these technologies.<br>- [Section 4: Further Prohibition and Disclaimer]<br>- Strict prohibition of any governmental agency or AI platform using her works without explicit consent. |
| SeanBrautigan-AI-RFI-2025.md | Sean Brautigan | Individual | Sean Brautigan expresses a concern that AI development is detrimental to the American people and specifically threatens the livelihoods of creators in visual, auditory, and literary professions, and questions the ethical basis of training AI on copyrighted material without permission. | - AI is overhyped by the tech industry for profit.<br>- AI threatens the livelihoods of American creators in visual, auditory, and literary professions.<br>- AI technologies are trained on existing media without the permission of the creators.<br>- The use of copyrighted materials without permission raises ethical concerns about the technology. | - None Stated |
| Sean-Thomas-Macken-AI-RFI-2025.md | Sean Thomas Macken | Individual | Sean Thomas Macken expresses a strong interest in protecting American citizens from the misuse of advanced technologies (AI, deepfakes, and esoteric technologies like "clairvoyance thought broadcast") by foreign entities and ensuring accountability for criminal acts committed using these technologies, with a focus on consent, disclosure, and upholding fundamental rights. | - [§1: Introduction/Date & Author] None stated for this section.<br>- [§2: High Level Summary] Foreign influence on technology and potential violations of American values and constitutional rights.<br>- [§3: Background (Problems / Issues & Technologies Involved)] Illegal access to US electronic systems by foreign entities; use of AI, deepfakes, clairvoyance technologies, implanted devices, and time/matter relocation technologies for criminal purposes; potential treasonous activity within the US aiding foreign actors.<br>- [§4: Examples of Misuse] Non-consensual deepfake creation and use (specifically, forced sexual acts via deepfakes); trespassing into private homes; illegal scanning of private property; kidnapping via time/matter relocation; non-consensual physical manipulation via implanted devices; racist discrimination and abuse by foreign actors; violation of freewill via clairvoyance thought broadcasts.<br>- [§5: Relevance, Underlying Priorities, Core Values, and Prerogatives of Federal Regulation] Lack of full disclosure and consent in technology usage; need for user control over technology settings.<br>- [§6: Ethical Uses Example] Lack of ethical use if not consensual.<br>- [§7: Relevant Regulation: Absolute Truth & Accountability System] The potential for criminal activity to go undetected without a comprehensive "Absolute Truth" system tracking all technology interactions.<br>- [§8: Regulation of Clairvoyance & Seminal Influence] Potential for clairvoyance thought broadcasts to be used for abusive and illegal purposes, potentially connected to a “rape and pedophilia competition” via the Semantic Web; the need to monitor seminal emissions connected to this system.<br>- [§9: Government Regulation Focus] Striking a balance between regulation and allowing free market competition.<br>- [§10: Highest Priority and Core Values] Compliance with federal laws, the Constitution, Bill of Rights, anti-discrimination laws, and upholding fundamental human needs (water, food, shelter, security, sex, belonging). | - [§1: Introduction/Date & Author] None stated for this section.<br>- [§2: High Level Summary] Federal government regulation to respect individuals, laws, and American values while maintaining ethical standards.<br>- [§3: Background (Problems / Issues & Technologies Involved)] Establish federal regulations, universally applicable across states, to address the use of listed technologies (AI, deepfakes, clairvoyance, etc.).<br>- [§4: Examples of Misuse] None stated for this section.<br>- [§5: Relevance, Underlying Priorities, Core Values, and Prerogatives of Federal Regulation] Require full, comprehensive disclosure from technology providers to consumers; ensure full user consent and control over technology settings and features; provide users the right to opt-out of technologies.<br>- [§6: Ethical Uses Example] Implement ethical standards based solely on consent.<br>- [§7: Relevant Regulation: Absolute Truth & Accountability System] Create a comprehensive "Absolute Truth" system to track all interactions related to the listed technologies; utilize numerical encryption to protect individual and organizational identities.<br>- [§8: Regulation of Clairvoyance & Seminal Influence] Monitor clairvoyance thought broadcasts for abusive or illegal content; connect seminal emissions and their influence to the "Absolute Truth" system for accountability.<br>- [§9: Government Regulation Focus] Focus regulations specifically on illegal activity without infringing on free market competition.<br>- [§10: Highest Priority and Core Values] Enforce compliance with federal laws, the Constitution, Bill of Rights, anti-discrimination laws, and protect fundamental human needs. |
| Sean-McDermott-AI-RFI-2025.md | Sean McDermott | Individual | The submitter is deeply concerned about the negative societal and environmental impacts of AI technology, particularly the parasitic nature of its development and the lack of accountability for AI companies. They advocate for strong regulation and prioritize public good over corporate profit. | - [§1: Email Header] None stated for this section.<br>- [Section 2: Introduction & Core Argument]<br>- AI is fundamentally parasitic.<br>- Private corporations are being subsidized by the government.<br>- Increasing energy costs for the public.<br>- Significant negative environmental impact.<br>- Harmful and discriminatory practices ingrained in AI usage.<br>- Lack of public opt-out mechanisms for AI systems.<br>- Job losses attributed to AI.<br>- Negative impact on student education.<br>- [Section 3: Supporting Evidence & Citations]<br>- The assertion that AI is necessary for national security is false.<br>- AI companies have stolen copyrighted works and broken multiple laws.<br>- [Section 4: Specific Objection to OpenAI & NIST]<br>- Opposition to OpenAI’s profitability at the expense of the public.<br>- Urges NIST to reconsider its AI Action Plan.<br>- Opposition to codifying AI training as fair use.<br>- [§5: Document Release & Legal Disclaimer] None stated for this section. | - [§1: Email Header] None stated for this section.<br>- [Section 2: Introduction & Core Argument]<br>- Implement strongest possible regulation and accountability for AI companies.<br>- [§3: Supporting Evidence & Citations] None stated for this section.<br>- [Section 4: Specific Objection to OpenAI & NIST]<br>- NIST should immediately reconsider and constrict its Development of an Artificial Intelligence (AI) Action Plan.<br>- NIST should refuse to codify AI training as fair use.<br>- [§5: Document Release & Legal Disclaimer] None stated for this section. |
| ScottFronapfel-AI-RFI-2025.md | Scott Fronapfel | Individual | Scott Fronapfel expresses interest in protecting the rights of artists and small businesses from the unauthorized use of their work by generative AI companies and advocates for responsible AI development that respects copyright and human creativity. | - The legal grey zones and lack of ethical constraints surrounding the creation of generative AI.<br>- Indirect funding of data scrapers used to train generative AI models, despite claims of open source datasets.<br>- The potential for generative AI to replace the work of American citizens, particularly artists and small businesses.<br>- The frequency of hallucinations in generative AI outputs.<br>- Intentional misuse of generative AI for ill-advised applications (historical reconstruction, legal advice).<br>- The proliferation of generated content polluting the internet and distorting political and historical knowledge with fake likenesses.<br>- Confusion between generative AI (autocomplete/upscaling) and more advanced machine learning research (medicine, AGI). | - Maintain or modify existing copyright laws to better protect creative human works.<br>- Restrict the use of generative AI to items actively in the public domain.<br>- Prevent non-human generative software outputs from being considered for human ownership.<br>- Clearly differentiate generative AI from legitimate machine learning research, particularly AGI development. |
| Scott-Tuffiash-AI-RFI-2025.md | Scott Tuffiash | Individual | Scott Tuffiash, a high school teacher of Language Arts and Journalism, is interested in the ethical implications of AI and its impact on human flourishing, advocating for a balance between innovation and consumer protection. He is also studying viewpoints on AI regulation to inform his teaching. | - [§1: Introduction/Context] None stated for this section.<br>- [§2: Argument for Less Regulation & Potential Benefits] None stated for this section. (The section *argues* for benefits, but doesn't present concerns *about* less regulation.)<br>- [Section 3: Ethical Concerns & Risks of Less Regulation]<br>- Placing the burden of ethical innovation on the consumer instead of the producer.<br>- Potential harm to the mental wellbeing of consumers.<br>- Potential risk to the physical life of consumers.<br>- [Section 4: Specific Example & Question Regarding Age-Based Regulation]<br>- The justification for age-based regulation (specifically the distinction between 14 and 19 year olds) is unclear.<br>- Lack of scientific basis to reliably prove the difference in brain development between 14 and 19 year olds.<br>- [Section 5: Call for Transparency & Re-opening Policy Debate]<br>- Lack of transparency in addictive design qualities of AI products.<br>- Absence of legal ramifications for companies promoting addictive design products. | - [§1: Introduction/Context] None stated for this section.<br>- [§2: Argument for Less Regulation & Potential Benefits] None stated for this section.<br>- [§3: Ethical Concerns & Risks of Less Regulation] None stated for this section.<br>- [§4: Specific Example & Question Regarding Age-Based Regulation] None stated for this section.<br>- [Section 5: Call for Transparency & Re-opening Policy Debate]<br>- Require for-profit companies to transparently display addictive design qualities of their AI products.<br>- Implement legal ramifications (significant financial losses) for companies promoting addictive design products.<br>- Re-open policy debate regarding AI regulation, referencing the Trump administration's AI website as a resource: https://trumpwhitehouse.archives.gov/ai/ai-american-innovation/ |
| Scott-Peterson-AI-RFI-2025.md | Scott Peterson | Individual | The submitter is concerned about the allocation of government funds for AI development, believing it is wasteful and ineffective, particularly when compared to Chinese AI initiatives, and negatively impacts average Americans. They prioritize worker wellbeing and affordability. | - Government contracts are being awarded to "elite billionaires" for AI development that appears to be inferior to AI developed in China for significantly less money.<br>- The current approach to AI investment is a “handout” to wealthy individuals and is not effectively addressing the gap between US and Chinese AI capabilities.<br>- The US government is “denying” the extent to which it is falling behind China in AI development.<br>- The work environment and treatment of workers are not adequately considered in US AI development efforts.<br>- Existing AI investments are a waste of money as they haven’t produced satisfactory results and the US continues to fall behind.<br>- The budget bill will further take money from average Americans and redistribute it to the wealthy ("trickle up economics").<br>- Food and price regulations are not being adequately addressed. | - Pay and treat workers better in AI development.<br>- Stop “throwing money at the wealthy and elite” for AI development.<br>- Focus on more than just funding investments, implying a need for a different strategy.<br>- Get food and price regulations under control. |
| Scott-Peterson-AI-RFI-2025-2.md | Scott Peterson | Individual | The submitter is primarily interested in fiscal responsibility and believes current AI spending is wasteful and ineffective, preferring collaborative approaches and questioning the value of subsidies to large tech companies. | - Overspending and misuse of government funds allocated to AI development.<br>- China outpacing the United States in AI capabilities.<br>- Ineffectiveness of current AI approaches and products.<br>- Subsidies to large tech companies are a "handout" and do not guarantee improved results.<br>- Lack of transparency regarding where AI subsidy funds are being spent.<br>- Questionable rationale for viewing China as an “enemy” given its economic contributions. | - Investigate where AI-related subsidy funds have been allocated.<br>- Stop funding corporations with subsidies from tax money.<br>- Explore collaboration with China on AI development.<br>- Re-evaluate the current approach to AI funding and prioritize effectiveness over simply increasing investment amounts. |
| Scott-Giannone-AI-RFI-2025.md | Scott Giannone | Individual | The submitter is interested in ensuring American leadership in AI and protecting American citizens from the negative uses of AI, with a focus on securing individual identities and managing digital currency for tax purposes. | - Foreign adversaries will use AI negatively.<br>- The potential for misuse of social security numbers.<br>- Safeguarding American citizens in relation to AI regulations. | - Issue social security cards as NFTs to individuals upon birth (and retroactively).<br>- Ensure everyone has access to their NFTs (and a wallet) for managing their social security information.<br>- Secure digital currency attributed to each person for all tax purposes. |
| Scott-Boegeman-AI-RFI-2025.md | Scott Boegeman | Individual | The submitter is a computational linguist expressing strong concerns about the negative impacts of generative AI on various fields, particularly computational linguistics, and advocates for protecting intellectual property and user data. | - Generative AI relies on copyright and intellectual property theft from other fields.<br>- Generative AI encourages the stealing of personal information.<br>- Generative AI produces low-quality output.<br>- Generative AI actively harms the fields it touches, including its own subfields.<br>- Overinvestment in generative AI, at the expense of standard machine learning solutions, is detrimental.<br>- Use of unaware user's data without consent.<br>- Stealing artists’ work.<br>- Use of copyrighted media or protected data. | - Do not allow generative AI to utilize unaware user's data.<br>- Do not allow generative AI to steal artist's work.<br>- Do not allow generative AI to use any form of copyrighted media or protected data. |
| Schneider-Electric-AI-RFI-2025.md | Schneider Electric | Industry-Large | Schneider Electric’s primary interest is in securing its role as a key infrastructure provider for the AI ecosystem, specifically focusing on data centers, the grid, and energy resources, and driving the adoption of its technologies (including AVEVA software) to optimize AI infrastructure and energy management. They aim to influence policy to support grid modernization, energy flexibility, and supply chain resilience to enable the growth of AI. | - None Stated | - None Stated |
| Say-Cheese-Pizza-Cafe-AI-RFI-2025.md | Say Cheese Pizza Cafe | Individual | The submitter appears to be a small business owner (pizza cafe) with a general interest in leveraging AI for business tasks (website creation/maintenance) and a concern for safety and security related to online activities. | - [§1: Introduction/Header] None stated for this section.<br>- [§2: AI Policy Recommendations] Concerns regarding foreign AI apps, explicit content, online crime (scammers, trafficking, drugs), and the need for factual AI research. | - [§1: Introduction/Header] None stated for this section.<br>- [Section 2: AI Policy Recommendations]<br>- Restrict all foreign AI applications from operating within the US.<br>- Develop AI capabilities to filter explicit content.<br>- Establish AI-powered cyber policing to track and address online crime (scammers, trafficking, drugs) with a reporting mechanism.<br>- Implement consequences for AI-related crimes comparable to those for conventional crimes.<br>- Promote AI tools that allow for easy website creation and maintenance.<br>- Ensure that AI research is fact-based, transparent, and includes source attribution. |
| Saro-Nortrup-AI-RFI-2025.md | Saro Nortrup | Individual | Saro Nortrup is a writer and artist concerned with protecting intellectual property rights and personal freedoms in the context of AI development and deployment, specifically opposing the unrestricted use of copyrighted material for AI training without compensation or consent. | - Allowing generative AI to be trained on copyrighted work without limit or compensation violates the Fifth Amendment right to personal property (intellectual property).<br>- The current approach by companies like OpenAI allows for the cannibalization of individual creative work without recognition or compensation, and then charges others to use the resulting AI products.<br>- Removing copyright protections in favor of OpenAI could severely damage the American economy, particularly the creative industries (movies, video games, TV, music, books, art).<br>- Unrestricted AI training threatens individuality and the importance of brands and quality assurance.<br>- The situation could lead to a loss of personal property rights similar to those in Communist China.<br>- Fear of falling behind China should not justify sacrificing fundamental rights. | - Allow people and companies to exclude their work from AI training models.<br>- Require payment for the privilege of learning from other people's creative works (and allow them to say no).<br>- If data used for AI training is truly free and has no value, the AI product should be free and non-profit. |
| Sarkis-Daglian-AI-RFI-2025.md | Sarkis Daglian | Academia | The University of California, Irvine, is focused on maintaining American leadership in AI research and development through increased funding, workforce development, and promoting transparency and open-source initiatives, with an emphasis on collaboration between academia and industry. | - [§1: Introduction/Header] None stated for this section.<br>- [§2: AI Research & Innovation Funding] Not explicitly stated, but the document implies a concern that current funding levels are insufficient to accelerate industry disruption and maintain US leadership.<br>- [§3: AI Education & Workforce Development] Not explicitly stated, but the document implies a concern about the availability of a skilled AI workforce.<br>- [§4: AI Model Transparency, Explainability, and Open-Source Development] Not explicitly stated, but the document implies a concern about a lack of standards and assurance programs for AI transparency and explainability.<br>- [§5: Conclusion/Closing] None stated for this section. | - [§1: Introduction/Header] None stated for this section.<br>- [Section 2: AI Research & Innovation Funding]<br>- Expand federal AI grant funding to accelerate industry disruption and startup growth.<br>- Increase NSF, DOE, and DARPA AI research grants to fund breakthrough AI innovations.<br>- Prioritize funding for applied AI research in healthcare, manufacturing, energy, and automation.<br>- Authorize federal AI infrastructure funds for on-premises and cloud-based AI compute leasing.<br>- Modify NSF and DOE funding rules to allow universities, startups, and research labs to lease AI compute power from private cloud providers (AWS, Google Cloud, Microsoft Azure).<br>- Establish a national AI compute marketplace, where institutions can access subsidized cloud-based GPUs and TPUs.<br>- Provide grant program funding for universities to acquire, deploy, and maintain on-premises GPUs.<br>- Develop regional AI supercomputing hubs for universities and industry collaboration.<br>- Provide federal matching funds to create regional AI high-performance computing (HPC) centers.<br>- Expand private AI R&D partnerships through industry-funded university research labs.<br>- Offer federal R&D tax credits to corporations funding university-led AI research.<br>- Encourage the creation of university AI innovation districts.<br>- [Section 3: AI Education & Workforce Development]<br>- Mandate AI education in K-12 and higher education curricula.<br>- Require AI literacy programs in K-12 education, focusing on prompt engineering, ethical use, and applications for research.<br>- Fund university AI degree programs and certification tracks that emphasize AI ethics, engineering, and security.<br>- Expand corporate-sponsored AI research clusters in universities.<br>- Create federal tax incentives for corporations that sponsor high-performance AI research labs within universities.<br>- Establish AI professorship endowments, where private-sector sponsorships fund faculty chairs.<br>- Incentivize AI adoption in university administration to reduce costs and increase efficiency.<br>- [Section 4: AI Model Transparency, Explainability, and Open-Source Development]<br>- Establish AI explainability and transparency standards for high-impact sectors.<br>- Require financial, healthcare, and government AI systems to meet baseline interpretability benchmarks.<br>- Create a self-regulated AI assurance program, where companies can opt into third-party model audits.<br>- Promote open-source AI model development for cost efficiency and innovation.<br>- Incentivize private-sector open-source AI contributions by offering R&D tax breaks.<br>- Fund university-led open-source AI frameworks.<br>- [§5: Conclusion/Closing] None stated for this section. |
| SarahEaton-AI-RFI-2025.md | Sarah Eaton | Industry-Association (based on "Decision-Zone USA" appearing repeatedly and the context of submitting an RFI response, suggesting an organizational submission rather than purely individual) | Decision-Zone USA is focused on providing recommendations related to AI policy, likely with a goal of influencing or supporting American leadership in the field, as evidenced by the RFI response submission. The attached document, "RFI - Decision-Zone USA.pdf", contains their detailed action plan. | - None Stated (The text only indicates a response *to* an RFI requesting concerns, but does not *state* any concerns within the provided snippet.) | - None Stated (The text only indicates the submission of an attached document containing recommendations, but does not *state* any recommendations within the provided snippet.) |
| Sarah-Smith-AI-RFI-2025.md | Sarah Smith | Individual | The submitter expresses strong opposition to AI development and funding, believing it is a wasteful “scam” that exploits American resources and labor without providing returns. Their interest appears to be protecting American resources from being “destroyed” by AI investment. | - AI is “grossly overhyped.”<br>- AI is a “big scam” designed to destroy resources for the country.<br>- AI profits from the hard work of American people without compensation.<br>- Funds allocated to AI are lost to the creators without returns. | - None Stated. |
| Sarah-Samways-AI-RFI-2025.md | Sarah Samways | Individual | Sarah Samways is an aspiring small business owner and freelance artist concerned about the negative impact of generative AI on the livelihood of artists and the potential loss of culture and innovative thinking. She advocates for a more equitable and empathetic approach to AI policy. | - Generative AI provides a "cheaper" alternative to paying artists, potentially harming their ability to earn a living.<br>- Loss of artists leads to a loss of culture and out-of-the-box thinking crucial for a healthy and prosperous future.<br>- The internet losing its open-source and democratic nature due to potential monopolies of information by search engines. | - Reconsider the current direction of AI policy.<br>- Remember empathy when formulating AI policy. |
| Sarah-Maul-AI-RFI-2025.md | Sarah Maul | Individual | The submitter is primarily concerned with protecting intellectual property rights and preventing the unauthorized use of creative works by AI systems, believing that current proposed changes to laws could harm American creators and national security. | - Changes to laws allowing AI companies to use any data without agreement with owners will hurt all sectors of the country.<br>- Allowing AI to freely use data could lead to widespread theft of intellectual property without legal recourse.<br>- Weakening protections could make it easier for adversarial countries to steal American innovations.<br>- A "slippery slope" where ownership of intellectual property is eroded, leading to potential loss of ownership for all companies. | - Better protections against AI taking things without asking creators first.<br>- AI companies should not be given leeway to use anything without being asked for permission. |
| Sarah-Forde-AI-RFI-2025.md | Sarah Forde | Individual | Sarah Forde (AdorkaStock) is primarily interested in protecting the copyright of artists and creators, as well as individuals’ personal data and records, from unrestricted use by AI systems. She advocates against the unchecked deployment of AI that could infringe on intellectual property rights. | - Protecting the copyright of artists and creators.<br>- Protecting people's personal photos and records.<br>- Allowing AI to run "amok and unrestricted" with work and data.<br>- The potential for "unnecessarily burdensome requirements" related to copyright protection being dismissed. | - None Stated |
| Sarah-Eaton-AI-RFI-2025.md | Sarah L. Eaton/Decision-Zone USA, Inc. | Industry-Startup | Decision-Zone USA is a defense technology startup focused on developing mission-critical autonomous systems and real-time decision-making architectures, advocating for a shift away from traditional AI approaches (deep learning, statistical inference) towards event-driven causal autonomy to enhance national security and reliability in defense and critical infrastructure. | - [§1: Introduction & Background] Current AI approaches are insufficient for national security applications due to a lack of robustness, explainability, and resilience. The document also expresses concern about the Defense Department’s potential overreliance on untested AI systems.<br>- [§2: Current AI Approaches and their shortcomings] Lack of causal reasoning, vulnerability to adversarial manipulation (spoofing, data poisoning, deception), operational fragility (requiring constant retraining, curated data pipelines, extensive compute resources), and dependency on large-scale data retraining are major concerns. The systems are brittle, reactive, and misaligned with human-defined goals.<br>- [§3: The Need for Mission-Critical Autonomy]  Existing autonomy solutions lack true intent-driven adaptability, operate without guaranteed real-time responses, and are fundamentally unreliable for real-world autonomous decision-making. Concerns include lack of transparency, predictability, and auditability, as well as the risk of failures in novel situations.<br>- [§4: Recommended Policy Actions] Not stated, though the section introduces the need for specific policy actions.<br>- [§5: Policy Recommendation Details (1-8)]  Concerns include dependence on centralized data processing and cloud connectivity, the risk of black-box decision-making, the cost of infrastructure replacement for AI integration, and the over-reliance on statistical confidence levels in critical systems. The need for systems to function properly in adversarial environments, novel situations, legacy systems and without central authority are noted.<br>- [§6: Conclusion] Catastrophic failures are possible due to AI weaknesses, and leadership needs new language to challenge current assumptions. | - [§1: Introduction & Background] Support DIU's efforts to increase budget flexibility and transparency with Congress and faster acquisition strategies.<br>- [§2: Current AI Approaches and their shortcomings] Prioritize alternative computing paradigms (event-driven causal autonomy).<br>- [§3: The Need for Mission-Critical Autonomy]  None stated.<br>- [§4: Recommended Policy Actions] Establish certification standards for deterministic computing in critical systems; develop causal transparency requirements; support alternative computing paradigms; create a resilience framework; prioritize legacy system integration; develop real-time response requirements; support decentralized autonomy research.<br>- [Section 5: Policy Recommendation Details (1-8)] |
| Sarah-Dungan-AI-RFI-2025.md | Sarah Dungan | Individual | Sarah Dungan expresses strong opposition to the development and deployment of Generative AI, primarily due to concerns about labor theft, copyright infringement, and the tool's unreliability and overhyped nature. She aims to protect her livelihood and the rights of corporations regarding their intellectual property. | - Generative AI constitutes "labor theft" by replicating human creativity and labor without proper compensation or consent.<br>- The phrase "promote human flourishing" is considered misleading as Generative AI actively replaces human labor.<br>- Removing copyright impediments would harm both individual livelihoods and corporate intellectual property rights.<br>- AI frequently "hallucinates" or generates incorrect information, rendering it unreliable.<br>- AI is overhyped and rebranded machine learning/large language models are being pushed by venture capitalists for financial gain.<br>- The tool's current applications are often not genuinely helpful. | - None Stated. |
| Sara-Williams-AI-RFI-2025.md | Sara Williams | Individual | The submitter is primarily concerned with the ethical and legal implications of AI training data, specifically regarding copyright infringement and data licensing. They believe AI’s viability hinges on lawful data usage. | - AI is incapable of original creation and relies solely on training data.<br>- Use of copyrighted material in AI datasets without proper licensing constitutes stealing.<br>- AI technology that requires stolen data is not deserving of existence. | - Ensure AI datasets do not contain copyrighted material that has not been properly licensed. |
| Sara-Corbett-AI-RFI-2025.md | Sara Corbett | Individual | Sara Corbett is an art director in the publishing industry concerned about the potential negative impact of AI on creative professions and American cultural leadership. She believes AI threatens livelihoods and the unique artistry of human creators. | - AI threatens the livelihoods of art directors, editors, writers, designers, and illustrators.<br>- AI may not be able to represent diverse emotions, experiences, and unique artistry.<br>- AI poses a threat to American status as a creative and intellectual superpower. | - Outlaw AI. |
| Sandra-Gesing-AI-RFI-2025.md | Sandra Gesing, Maytal Dahan, Claire Stirm, Linda Hayden, Janae Baker | Academia | The submitters, associated with SGX3 - a Center of Excellence for Science Gateways, aim to strengthen U.S. leadership in AI through democratizing access to AI infrastructure, fostering collaboration via science gateways, and investing in a skilled workforce, particularly Research Software Engineers (RSEs). | - [Section 1: Executive Summary]** Limited access to high-performance computing (HPC), scalable AI model development, and robust data-sharing frameworks; hardware and chip development bottlenecks; data center expansion needs; cybersecurity concerns; AI model assurance requirements; and the need for regulatory modernization.<br>- [Section 2: Key Recommendations]**  Lack of a centralized AI infrastructure; insufficient investment in RSEs; inadequate computing power; security vulnerabilities in AI infrastructure; gaps in AI adoption and workforce readiness; usability challenges in AI portals; and the absence of established AI procurement and regulatory guidelines.<br>- [Section 3: Introduction]** Uneven access to AI resources, limiting innovation outside well-funded institutions; struggles for researchers, educators, and small enterprises to secure computational resources, datasets, and AI tools.<br>- [Section 4: Current State of AI in the U.S. and Globally]**  Concentration of AI resources among a few large corporations; fragmentation of AI ecosystems and limited opportunities for collaboration; proprietary or siloed AI models, datasets, and tools hindering interoperability.<br>- [Section 5: Challenges and Barriers to AI Leadership]** Limited access to computing resources; high cost of computational power; fragmented datasets and difficulties in sharing; shortage of AI-skilled professionals (RSEs); and the need for AI-driven decision support.<br>- [Section 6: Proposed Policy Actions]** Need for federal support for scalable AI platforms, including federated AI computing systems; insufficient coordination between government, academic, and industry collaboration; and the need for regulatory frameworks for AI.<br>- [Section 7: Implementation Roadmap]** Not stated.<br>- [Section 8: Conclusion]** Lack of sufficient investment in AI infrastructure, workforce development, and decision-support systems. | - [Section 1: Executive Summary]** Prioritize access to HPC, scalable AI model development, and data-sharing frameworks; expand and modernize AI infrastructure through centralized access to resources, tools, and open-source development frameworks.<br>- [Section 2: Key Recommendations]** Strategically expand a national AI infrastructure as a federated AI resource; strengthen AI solutions through a centralized science gateway; invest in RSEs; enhance computing power and security; expand AI education, training, and industry collaboration; optimize AI portal usability with AI-driven support; establish AI procurement and regulatory guidelines.<br>- [Section 3: Introduction]** Design a national AI infrastructure to bridge the gap in access to AI; support innovation by tapping into nation's compute resources; promote AI research through science gateways and RSEs.<br>- [Section 4: Current State of AI in the U.S. and Globally]**  Democratize access to AI resources through initiatives like NAIRR; encourage collaboration through science gateways and RSEs; support workforce development to address skill shortages.<br>- [Section 5: Challenges and Barriers to AI Leadership]** Integrate science gateways and RSEs into AI research infrastructure; automate AI workflows with AI agents; invest in AI education and workforce training.<br>- [Section 6: Proposed Policy Actions]** Allocate dedicated funding for integrating science gateways into AI research infrastructure; support public-private partnerships; establish a national RSE workforce initiative; invest in AI education and training programs.<br>- [Section 7: Implementation Roadmap]** Not stated.<br>- [Section 8: Conclusion]** Invest in AI infrastructure, workforce development, and decision-support systems; foster innovation through government, academic, and industry collaboration. |
| Sandie-Parrott-AI-RFI-2025.md | Sandie Parrott | Individual | The submitter is focused on protecting patient privacy and ensuring the doctor-patient relationship by preventing the use of AI to define or dictate individual medical conditions and treatment, emphasizing direct doctor-patient communication. | - Use of AI to describe or prescribe an individual person's medical condition or treatment.<br>- AI-produced summaries or descriptions of a patient's medical condition replacing direct doctor communication.<br>- Lack of patient access to their medical information when it is produced directly by the doctor. | - AI must not be used to describe or prescribe an individual person's medical condition or treatment.<br>- Medical information should be unique to the individual and their treatment and produced directly by the doctor.<br>- Medical information must be available to the patient. |
| Sanders-AI-RFI-2025.md | Paul Sanders | Individual | The submitter is primarily concerned with the ethical implications of AI training, specifically regarding the compensation of owners for materials used in the training process, framing the practice without compensation as theft. | - AI training without compensating the owner of the training material.<br>- The practice of AI training without compensation is viewed as theft. | - None Stated |
| San-Inman-AI-RFI-2025.md | C San Inman | Individual | The submitter expresses strong opposition to the current direction of AI policy, advocating for a slower, more responsible development path that prioritizes human rights, environmental sustainability, and protection of labor, and resisting what they perceive as corporate influence and unethical practices within the AI field. | - The proposed AI Action Plan is viewed as corrupt and serving the short-term profits of the wealthy.<br>- AI development was initiated using unethical means, including illegal copyright and privacy infringements.<br>- The current path of AI development is environmentally unsustainable.<br>- AI is being used to replace human labor rather than assist it.<br>- Lack of sufficient legislation and restrictions on AI use to protect human civil rights.<br>- The perceived urgency for "America's AI dominance" is driven by those unlikely to suffer the consequences. | - Reinstate Executive Order 14110 ("Safe, Secure, and Trustworthy Development and Use of Artificial Intelligence").<br>- Implement more legislation and restrictions on the use of AI to protect human civil rights.<br>- Adopt a slower, more responsible approach to AI development. |
| SambaNova-AI-RFI-2025.md | SambaNova Systems | Industry-Startup | SambaNova Systems is an AI hardware and software company focused on advancing AI technology and maintaining US leadership in the global AI economy. They advocate for policies that encourage innovation, open-source collaboration, and support the growth of small businesses in the AI sector. | - [§1: Introduction/Header] None stated for this section.<br>- [§2: SambaNova Background] Competing in an industry dominated by larger, more established multinational companies.<br>- [§3: Open-Source AI] Regulations that slow the pace of innovation and constrain AI models to only a few entities.<br>- [§4: National Security & Export Controls] Overly broad recent restrictions on AI chips with no national security concerns, unreasonable delays in issuing export licenses, and harm to US businesses (especially small businesses).  AI Diffusion Rules fortify monopolies and market incumbents and constrain supply artificially.<br>- [§5: Small Business] New policies impacting the most innovative US AI startups, regulations hindering US innovation in the AI area.<br>- [§6: Conclusion] Consolidating, isolating, and losing ground to other nations in AI technology.<br>- [§7: Signature/Contact Information] None stated for this section. | - [§1: Introduction/Header] None stated for this section.<br>- [§2: SambaNova Background] None stated for this section.<br>- [§3: Open-Source AI] Encourage open-source development in AI.<br>- [§4: National Security & Export Controls] Focus on more targeted export controls to address specific root problems and bad actors, expedite the licensing review process, set forth strict timelines for agency review, maintain the Low Processing Performance (LPP) exception to export licenses, and work with industry and small business to strike the right balance between national security and US competitiveness.<br>- [§5: Small Business] Ensure companies like SambaNova continue to succeed, grow and innovate; create a level playing field for all market participants; actively encourage and support the growth of new technologies; review and consider policy impacts on small businesses.<br>- [§6: Conclusion] Prioritize open-source collaboration, streamline export processes, and actively support startups to out-innovate adversaries while safeguarding interests.<br>- [§7: Signature/Contact Information] None stated for this section. |
| Samantha-Kaczor.-AI-RFI-2025.md | Samantha Kaczor | Individual | Samantha Kaczor is an artist concerned about the unauthorized use of her artwork to train artificial intelligence models and seeks to prevent corporations like OpenAI from exploiting creative work without consent or compensation. | - [§1: Email Header/Metadata] None stated for this section.<br>- [Section 2: Personal Introduction and Statement of Concern]<br>- Unauthorized use of artwork for AI training.<br>- Lack of consent for the use of her work.<br>- Lack of compensation for the use of her work.<br>- Exploitation of artists' labor and skills by corporations.<br>- The general ethical implications of AI training data sourcing.<br>- [§3: Dissemination Approval] None stated for this section.<br>- [§4: NITRD Disclaimer] None stated for this section. | - [§1: Email Header/Metadata] None stated for this section.<br>- [Section 2: Personal Introduction and Statement of Concern]<br>- Prevent OpenAI from freely using works in their training model.<br>- Implement policies requiring consent for the use of artwork in AI training datasets.<br>- Implement policies ensuring fair compensation for artists whose work is used to train AI models.<br>- [§3: Dissemination Approval] None stated for this section.<br>- [§4: NITRD Disclaimer] None stated for this section. |
| SamM-AI-RFI-2025.md | Sam M | Individual | The submitter is interested in ethical AI development and opposes the use of copyrighted or unethical material in AI training. | - Use of copyrighted material to train AI models.<br>- Use of unethical material to train AI models. | - None Stated. |
| Sam-Timothy-AI-RFI-2025.md | Sam Daniel Timothy | Individual | Sam Daniel Timothy, as Founder & Principal Consultant of Sysfleet Consulting LLC, focuses on AI-powered regulatory automation, systems engineering, and responsible AI implementation with an emphasis on human oversight, transparency, and ethical considerations to optimize government workflows and drive economic growth. | - [§1: Introduction & Background] AI must be implemented responsibly and remain an assistive tool rather than an authoritative force; human oversight is essential.<br>- [§2: AI in Regulatory Compliance & Governance] Increasing complexity of regulations leads to inefficiencies; existing policies do not sufficiently support AI-assisted regulatory decision systems while ensuring transparency, accountability, and unbiased outcomes.<br>- [§3: AI Workforce Development & Public-Private Collaboration] The AI workforce gap is a major challenge; multidisciplinary talent is required (ethics, policy, cybersecurity); without structured programs, the U.S. risks falling behind in competitiveness and ethical implementation.<br>- [§4: AI Ethics: Ensuring AI Does Not Override Human Rights] Risk of biased decision-making, automated discrimination, and AI overriding fundamental human rights; potential for restricting access to critical services, misinterpreting legal frameworks, and infringing on privacy and civil liberties.<br>- [§5: Conclusion] None stated for this section. | - [§1: Introduction & Background] None stated for this section.<br>- [Section 2: AI in Regulatory Compliance & Governance]<br>- Develop standardized AI-driven compliance frameworks.<br>- Encourage AI-driven public-private partnerships to build regulatory interpretation models.<br>- Explore federal funding incentives for AI-powered regulatory automation.<br>- Ensure AI serves as a decision-support system, preserving due process.<br>- Establish an independent AI regulatory review board.<br>- [Section 3: AI Workforce Development & Public-Private Collaboration]<br>- Expand federal AI training and upskilling programs.<br>- Establish AI fellowships and grants.<br>- Create collaborative AI research hubs.<br>- Promote hands-on AI apprenticeships.<br>- Incorporate AI ethics, fairness, and human rights education into AI degree programs.<br>- Encourage companies to train AI specialists in automation and regulatory AI.<br>- [Section 4: AI Ethics: Ensuring AI Does Not Override Human Rights]<br>- Mandate human oversight in AI-driven decisions affecting citizens’ rights.<br>- Develop federal AI governance standards to prevent discrimination and bias.<br>- Require government-used AI models to be auditable, transparent, and accountable.<br>- Establish a federal AI ethics board.<br>- Introduce AI appeal mechanisms.<br>- Require public AI impact assessments.<br>- [§5: Conclusion] Prioritize: AI-driven regulatory automation with human oversight, Workforce development to bridge the AI skill gap, and Ethical AI governance to protect human rights. |
| Sam-Daniel-Timothy-AI-RFI-2025.md | Sam Daniel Timothy | Individual | Sam Daniel Timothy, as Founder & Principal Consultant of Sysfleet Consulting LLC, focuses on AI-powered regulatory automation and systems engineering, with a strong emphasis on responsible AI implementation that prioritizes human oversight, transparency, and ethical considerations in both government and industry applications. | - [§1: Introduction & Background] None stated for this section.<br>- [§2: AI in Regulatory Compliance & Governance] Increasing complexity of regulations leading to inefficiencies, manual processes, and bottlenecks. Lack of policies supporting AI-assisted regulatory decision systems while ensuring transparency, accountability, and unbiased outcomes.<br>- [§3: AI Workforce Development & Public-Private Collaboration] Rapidly growing demand for AI expertise resulting in a significant AI workforce gap. Lack of multidisciplinary talent (ethics, policy, cybersecurity) needed for successful AI adoption. Risk of falling behind in AI competitiveness due to insufficient workforce development programs.<br>- [§4: AI Ethics: Ensuring AI Does Not Override Human Rights] Risk of biased decision-making, automated discrimination, and infringement on fundamental human rights as AI systems become more prevalent. Potential for AI to restrict access to critical services, misinterpret legal frameworks, or infringe on privacy and civil liberties. AI becoming a "black box" with unchecked authority.<br>- [§5: Conclusion] None stated for this section. | - [§1: Introduction & Background] None stated for this section.<br>- [§2: AI in Regulatory Compliance & Governance] Develop standardized AI-driven compliance frameworks. Encourage AI-driven public-private partnerships to build regulatory interpretation models. Explore federal funding incentives for AI-powered regulatory automation. Ensure AI serves as a decision-support system with human oversight. Establish an independent AI regulatory review board.<br>- [§3: AI Workforce Development & Public-Private Collaboration] Expand federal AI training and upskilling programs. Establish AI fellowships and grants. Create collaborative AI research hubs. Promote hands-on AI apprenticeships. Incorporate AI ethics and fairness education into degree programs. Encourage company training in automation and compliance-based AI systems.<br>- [§4: AI Ethics: Ensuring AI Does Not Override Human Rights] Mandate human oversight in AI-driven decisions affecting citizens’ rights. Develop federal AI governance standards to prevent discrimination and bias. Require auditable, transparent, and accountable government AI models. Establish a federal AI ethics board to regulate AI deployments impacting human rights. Introduce AI appeal mechanisms. Require public AI impact assessments for AI systems used in government.<br>- [§5: Conclusion] Prioritize AI-driven regulatory automation with human oversight, workforce development to bridge the AI skill gap, and ethical AI governance to protect human rights. |
| Sage-Backwood-AI-RFI-2025.md | Sage Blackwood | Individual | The submitter is an author concerned about the unauthorized use of their copyrighted work to train AI models and the resulting impact on their livelihood, and advocates for the rights of human content creators over those of AI systems. | - Unauthorized use of copyrighted books to train AI models.<br>- Violation of copyright law through the use of pirated materials.<br>- The prioritization of “rights” of machines over the rights of human content creators.<br>- Detriment to the livelihood of authors. | - None Stated |
| Sabrina-Stratford-AI-RFI-2025.md | Sabrina Stratford | Individual/Advocacy/Think Tank | Sabrina Stratford is a Human Trafficking Abolitionist focused on leveraging Artificial Intelligence to proactively combat human trafficking through detection, prevention, victim support, and ethical regulation of AI technologies. | - [§1: AI for Trafficking Detection & Prevention] None stated for this section.<br>- [§2: Data Privacy & Protection for Victims] Potential misuse of AI to track victims of trafficking without sufficient safeguards.<br>- [§3: AI in Law Enforcement & Prosecution] Not Stated.<br>- [§4: AI and the Dark Web] Not Stated.<br>- [§5: Ethical AI Development & Deployment] Use of AI-generated content (deepfakes, chatbots) in exploitative ways, specifically generating child sexual abuse materials. | - [§1: AI for Trafficking Detection & Prevention] Establish guidelines requiring the use of AI to detect trafficking patterns in hospitality, transportation, and online platforms; Implement AI-based tracking to ensure supply chains are free from forced labor.<br>- [§2: Data Privacy & Protection for Victims] Use AI to provide encrypted, anonymous resources for victims while ensuring their data privacy; Implement strict AI governance on biometric data use to prevent misuse.<br>- [§3: AI in Law Enforcement & Prosecution] Use AI for digital forensics to analyze traffickers' communication patterns and evidence across multiple jurisdictions; Ensure AI-generated insights are legally admissible and interpretable for court proceedings.<br>- [§4: AI and the Dark Web] Strengthen AI capabilities in tracking human trafficking activity within encrypted and hidden online spaces; Enforce stricter controls on AI applications that allow traffickers to evade detection.<br>- [§5: Ethical AI Development & Deployment] Prohibit AI-generated content (deepfakes, chatbots, etc.) from being used in exploitative ways, such as generating child sexual abuse materials; Regulate AI-driven recruitment platforms to ensure they don't inadvertently facilitate labor trafficking. |
| SIOP-AI-RFI-2025.md | Society for Industrial and Organizational Psychology (SIOP) | Professional-Society | SIOP’s primary mission is to apply and advance the science of industrial-organizational (I-O) psychology to improve workplace issues, with a particular interest in ensuring the accurate, fair, and legally defensible use of AI-based assessments in hiring and workforce development. | - [§1: Introduction] None stated for this section.<br>- [§2: Improving AI-Based Hiring Decisions] Concerns over privacy, fairness, lack of transparency, and the accuracy of AI predictions in hiring. There is a concern that AI-based hiring practices require the same level of scrutiny as traditional employment tests.<br>- [§3: Unique Challenges of AI-Based Assessments & Recommendations] The development and use of AI-based procedures presents unique challenges not found in traditional assessments.<br>- [§4: Accelerating the AI-Enabled Workforce] The need to reskill and adapt the US workforce at scale due to rapid AI transformation, and the need to understand how workers can adapt in a changing labor market.<br>- [§5: Conclusion & Expert Contacts] None stated for this section.<br>- [§6: References] None stated for this section. | - [§1: Introduction] Encourage the OSTP national artificial intelligence action plan to incorporate plans for (a) improving AI-based hiring and promotion decisions and (b) accelerating a competitive AI-enabled workforce.<br>- [§2: Improving AI-Based Hiring Decisions] AI-based assessments should meet the same standards as traditional hiring and assessment procedures.<br>- [§3: Unique Challenges of AI-Based Assessments & Recommendations] AI-based assessments should:<br>- Accurately predict future job performance or other relevant outcomes.<br>- Produce consistent scores that reflect job-related characteristics.<br>- Minimize job-irrelevant characteristics and be fair and unbiased for all applicants.<br>- Have all steps and decisions documented for verification and auditing.<br>- [Section 4: Accelerating the AI-Enabled Workforce]<br>- Increased focus on bolstering the AI-enabled workforce and understanding changing skills needs.<br>- Research on improving and disseminating strategies for effective upskilling and job training, particularly workplace-based training.<br>- Focus on anticipating and responding to worker mobility needs due to increased use of AI.<br>- [§5: Conclusion & Expert Contacts] None stated for this section.<br>- [§6: References] None stated for this section. |
| SIIA-AI-RFI-2025.md | Software & Information Industry Association (SIIA) | Industry-Association | The SIIA represents software and information companies and advocates for policies that promote AI innovation, U.S. leadership in AI, and a favorable business environment for its members, with a strong emphasis on light-touch regulation and global competitiveness. | - [§1: Introduction & Context] None stated for this section.<br>- [§2: Overarching Recommendations] None stated for this section.<br>- [§3: Policy Actions to Promote Innovation through Smart Governance] Onerous and inconsistent state legislation; potential for overbroad or premature regulation hindering innovation.<br>- [§4: Lead on National Security Testing for Frontier Models] Absence of clear federal attention potentially leading to onerous regulations and liability risk; foreign nations imposing safety/security requirements.<br>- [§5: Advance a Unified, National Approach to AI Policy] Proliferation of state legislation leading to inconsistencies, regulatory burdens, and slower adoption.<br>- [§6: Advance Intellectual Property Policies that Support Innovation] Sweeping new IP restrictions could hamper AI development.<br>- [§7: Policy Actions to Advance American AI Leadership Globally] Foreign regulations unfairly targeting U.S. tech companies; broad controls on AI software, cloud services, or trained AI models hindering U.S. industry.<br>- [§8: Policy Actions to Cultivate the Workforce and Leaders of Tomorrow] Not stated for this section.<br>- [§9: Policy Actions to Create Infrastructure Needed for Continued AI Leadership] Not stated for this section.<br>- [§10: Policy Actions to Accelerate Federal AI Adoption] Antiquated processes deterring companies from working with DoD; slow procurement cycles; barriers for small firms; difficulty for AI startups to participate.<br>- [§11: Conclusion] Not stated for this section. | - [§1: Introduction & Context] None stated for this section.<br>- [§2: Overarching Recommendations] None stated for this section.<br>- [§3: Policy Actions to Promote Innovation through Smart Governance] Prioritize voluntary frameworks and technical standards; focus on risk-based oversight; invest in measurement science; promote sector-specific guidelines; seek targeted use-based restrictions.<br>- [§4: Lead on National Security Testing for Frontier Models] Establish a focal point for public-private collaboration; support a "home testing" principle with like-minded nations.<br>- [§5: Advance a Unified, National Approach to AI Policy] Federal preemption of state legislation on AI safety and security; support harmonization of state approval rules.<br>- [§6: Advance Intellectual Property Policies that Support Innovation] Affirm existing IP laws; clarify patent procedures.<br>- [§7: Policy Actions to Advance American AI Leadership Globally] Use diplomacy to advance U.S. soft power; targeted export controls; champion American AI globally and defend against unfair foreign barriers.<br>- [§8: Policy Actions to Cultivate the Workforce and Leaders of Tomorrow] Prepare America's workforce and students; facilitate integration of AI/EdTech; expand access to technology; promote workforce training and upskilling; support teachers and protect students.<br>- [§9: Policy Actions to Create Infrastructure Needed for Continued AI Leadership] Expand energy supply; streamline data center development; support open innovation and research.<br>- [§10: Policy Actions to Accelerate Federal AI Adoption] Simplify and expedite AI acquisitions; adopt commercial cloud and hybrid infrastructure; eliminate barriers for startup/SME participation; hire AI talent; empower Chief AI Officers; accelerate adoption of AI for national security; harness AI for cybersecurity; adapt AI for classified networks; invest in data quality.<br>- [§11: Conclusion] None stated for this section. |
| SIFMA-RFI-2025.md | SIFMA (Securities Industry and Financial Markets Association) | Industry-Association | SIFMA represents broker-dealers, investment banks, and asset managers and advocates for policies that promote fair and orderly financial markets and efficient operations, particularly focusing on avoiding unnecessary regulation that could hinder competitiveness and innovation in the financial sector. | - Section 1: Cover Page/Header:** None stated for this section.<br>- Section 2: Introduction:** None stated for this section.<br>- Section 3: Executive Summary:<br>- Unnecessary laws and regulation could negatively impact the competitiveness of US financial markets.<br>- The risk of stifling innovation through overly prescriptive rules.<br>- The need for a flexible regulatory approach to adapt to evolving technology.<br>- Section 4: Background:<br>- The danger of hasty reactions to advancements in AI.<br>- Existing legal and regulatory frameworks may already be sufficient to address AI.<br>- Section 5: Encouraging AI Innovation Benefits Market Participants:** None stated for this section.<br>- Section 6: Existing Laws and Regulations Address the Use of AI in the Financial Services Industry:<br>- Existing laws and regulations are effective and should be relied upon.<br>- There's no inherent reason AI requires new regulation.<br>- Section 7: It Is Unnecessary to Develop a Specific Definition of 'AI':<br>- Defining AI is not necessary and may be counterproductive due to the rapidly evolving nature of the technology.<br>- Section 8: Firms' Internal Risk-Management Frameworks Appropriately Address the Use of AI:<br>- Firms are capable of managing AI risks within existing frameworks.<br>- Section 9: Policymakers and Regulators Should Assess Whether AI Poses Novel Risks Not Addressed by Existing Governance Frameworks:<br>- Any regulatory action should be based on identified novel risks, not speculative concerns.<br>- Collaboration with firms is crucial to understanding AI use and related risks.<br>- Section 10: Fragmented AI Regulation Risks Creating Compliance Challenges and Stifling Innovation in the Financial Services Industry:<br>- A patchwork of regulations could create compliance challenges and deter innovation.<br>- Inconsistent regulations across jurisdictions are a concern.<br>- Section 11: Policymakers and Regulators Should Consider Strategies for Addressing Potential Gaps in Existing Laws and Regulations Related to AI:<br>- Potential gaps in federal data privacy legislation should be addressed.<br>- Clarification of copyright ownership for AI-produced works is needed.<br>- Section 12: Conclusion:<br>- The need for a balanced approach to AI regulation.<br>- Existing frameworks are generally sufficient.<br>- Section 13: Appendix 1: Existing Technology-Neutral Functional Policy Areas Applicable to AI:** None stated for this section. | - Section 1: Cover Page/Header:** None stated for this section.<br>- Section 2: Introduction:** None stated for this section.<br>- Section 3: Executive Summary:<br>- Focus laws and regulations on activities and outcomes, not the technology itself (technology-neutral approach).<br>- Maintain existing laws and regulations.<br>- Adopt a flexible regulatory approach.<br>- Section 4: Background:** None stated for this section.<br>- Section 5: Encouraging AI Innovation Benefits Market Participants:** None stated for this section.<br>- Section 6: Existing Laws and Regulations Address the Use of AI in the Financial Services Industry:<br>- Prioritize reliance on existing legal and regulatory frameworks.<br>- Section 7: It Is Unnecessary to Develop a Specific Definition of 'AI':<br>- Do not adopt a precise definition of AI.<br>- Section 8: Firms' Internal Risk-Management Frameworks Appropriately Address the Use of AI:** None stated for this section.<br>- Section 9: Policymakers and Regulators Should Assess Whether AI Poses Novel Risks Not Addressed by Existing Governance Frameworks:<br>- Collaborate with firms to understand AI use and risks.<br>- Only pursue regulatory action if novel risks are identified.<br>- Section 10: Fragmented AI Regulation Risks Creating Compliance Challenges and Stifling Innovation in the Financial Services Industry:<br>- Avoid a patchwork of regulations.<br>- Section 11: Policymakers and Regulators Should Consider Strategies for Addressing Potential Gaps in Existing Laws and Regulations Related to AI:<br>- Establish federal data privacy legislation.<br>- Clarify copyright ownership for AI-produced works.<br>- Section 12: Conclusion:** None stated for this section.<br>- Section 13: Appendix 1: Existing Technology-Neutral Functional Policy Areas Applicable to AI:** None stated for this section. |
| SIAM-AI-RFI-2025.md | Society for Industrial and Applied Mathematics (SIAM) | Professional-Society | SIAM is an international community focused on applying mathematics to advance artificial intelligence through research, infrastructure development, and education, with the goal of improving federal research efforts and applications across sectors. They aim to build cooperation between mathematics and technology. | - [§1: Introduction/Overview] None stated for this section.<br>- [Section 2: Research and Development]<br>- AI systems need to be reliable and secure.<br>- Current AI systems may not be built for specific needs of science and government missions.<br>- Data availability and heterogeneity are significant challenges for AI development.<br>- Difficulty incorporating physical models and constraints into AI algorithms.<br>- Lack of explainability in many AI models.<br>- NIH lags physical science agencies in AI investments.<br>- [Section 3: Infrastructure]<br>- Large-scale infrastructure requirements are limiting AI research access.<br>- The non-traditional computing hardware industry is evolving, requiring flexible government collaborations.<br>- [Section 4: Partnerships]<br>- Solving complex challenges requires multidisciplinary, multi-institutional teams.<br>- Coordination between applied mathematics, computational science, and healthcare/biomedical research needs improvement.<br>- [Section 5: Education and Workforce]<br>- Potential workforce shortages could constrain US AI leadership.<br>- Undergraduate curricula need to integrate data science and modeling.<br>- [§6: Closing/Signature] None stated for this section. | - [§1: Introduction/Overview] None stated for this section.<br>- [Section 2: Research and Development]<br>- Invest in a broad range of AI research projects at different scales.<br>- Support foundational AI research programs (e.g., NSF Mathematical Foundations of AI).<br>- Invest in large AI institutes (e.g., NSF AI Research Institutes, DOE FASST).<br>- Increase investment in fundamental research (e.g., NSF Division of Mathematical Sciences, DOE Office of Advanced Scientific Computing Research).<br>- Support high-risk, high-reward research (e.g., DARPA, ARPA-H).<br>- Invest in an integrated suite of data lifecycle methods and tools.<br>- Support NIST in setting data and AI standards.<br>- Focus research on incorporating physical models into AI algorithms.<br>- Invest in research on scientific machine learning.<br>- Invest in techniques for explainable AI.<br>- Increase AI investment in NIH, with a focus on high-impact research.<br>- Encourage participation of health agencies in NSF AI Research Institutes.<br>- [Section 3: Infrastructure]<br>- Build the full National AI Research Resource (NAIRR).<br>- Establish facilities for access to experimental non-traditional hardware.<br>- Foster collaborations between computational scientists and computer vendors.<br>- [Section 4: Partnerships]<br>- Create incentives for interdisciplinary education and research collaboration between National Labs, academia, and industry.<br>- Encourage coordination between applied mathematics, computational science, and healthcare/biomedical research.<br>- Encourage collaborations between NIH and FDA with NSF on digital twins for biomedical technologies.<br>- Encourage more agencies to join the NSF AI Research Institutes program.<br>- [Section 5: Education and Workforce]<br>- Support programs like NSF Research Traineeships (NRT), Graduate Research Fellowships (GRF), Research Experiences for Undergraduates (REU), and CAREER awards.<br>- Support DOE’s Computational Science Graduate Fellowship program.<br>- Integrate data science and modeling into undergraduate STEM coursework.<br>- Explore ways to develop AI technology for workforce upskilling and retraining.<br>- [§6: Closing/Signature] None stated for this section. |
| SIA-AI-RFI-2025.md | Security Industry Association | Industry-Association | The Security Industry Association (SIA) represents companies providing security products and services, and advocates for policies that promote the responsible development and use of AI technologies to enhance safety and security, while mitigating potential risks and fostering innovation within the security industry. | - [§1: Letterhead & Introduction] None stated for this section.<br>- [§2: About SIA] None stated for this section.<br>- [§3: AI and Security] None stated for this section.<br>- [§4: Biometrics Specifics] Concerns about potential misuse of facial recognition technology without appropriate human oversight, and the need for accurate benchmarking.<br>- [§5: Recommendations] The need for a comprehensive and principled approach to AI governance.<br>- [§6: Recommendation 1: Bolstering the AI Workforce] Skills shortage in the security industry.<br>- [§7: Recommendation 2: Supporting Small Businesses and Start-Ups] Potential stifling of innovation due to overly restrictive regulations.<br>- [§8: Recommendation 3: Ensuring Data Availability and Responsible Use] Balancing the need for data to develop AI with privacy concerns; the potential for state laws to render AI technologies unusable.<br>- [§9: Recommendation 4: Facilitating Public-Private Partnerships for AI Testing and Evaluation] Risks associated with untested AI systems and the potential compromise of AI systems by adversaries through data poisoning.<br>- [§10: Recommendation 5: Commonsense Governance Approaches] The potential for a patchwork of inconsistent state AI policies, and the need for a risk-based approach.<br>- [§11: Conclusion] The importance of getting the AI Action Plan right to ensure the benefits of AI are fully and responsibly harnessed.<br>- [§12: Closing & Contact Information] None stated for this section. | - [§1: Letterhead & Introduction] None stated for this section.<br>- [§2: About SIA] None stated for this section.<br>- [§3: AI and Security] None stated for this section.<br>- [§4: Biometrics Specifics] Utilizing NIST benchmarking for technology selection.<br>- [§5: Recommendations] None stated for this section.<br>- [§6: Recommendation 1: Bolstering the AI Workforce] Expand government-industry partnerships for workforce development. Provide federal education grants, loans, and tax benefits for AI training.<br>- [§7: Recommendation 2: Supporting Small Businesses and Start-Ups] Foster an environment that promotes innovation and investment in AI research and development.<br>- [§8: Recommendation 3: Ensuring Data Availability and Responsible Use] Enact a comprehensive national data privacy law that balances data protection with AI development needs, and preempts divergent state laws.<br>- [§9: Recommendation 4: Facilitating Public-Private Partnerships for AI Testing and Evaluation] Implement additional AI testing programs, especially for biometric systems, large language models, and defense-related technologies. Require AI developers to account for the origin and lineage of AI models. Increase resources for NIST, DHS S&T, DARPA, and IARPA for AI testing and evaluation.<br>- [§10: Recommendation 5: Commonsense Governance Approaches] Adopt a risk-based approach to AI governance using the AI Risk Management Framework (AI RMF). Consider existing regulations first before implementing new policies. If new policies are needed, make them technology-neutral and use-case specific. Prevent a patchwork of inconsistent state AI policies.<br>- [§11: Conclusion] None stated for this section.<br>- [§12: Closing & Contact Information] None stated for this section. |
| SETDA-AI-RFI-2025.md | SETDA | Industry-Association | SETDA represents state educational technology leaders and focuses on advancing digital learning and integrating artificial intelligence into education policy and practice to enhance teaching and learning, ensuring responsible AI use and national competitiveness. | - [§1: Introduction & Executive Summary] None stated for this section.<br>- [§2: Recommendation 1: Establish a Dedicated K-12 Educational Technology Grant Program] Modernizing learning environments, closing digital divides, and ensuring all students have access to AI-powered opportunities requires sustained federal support.<br>- [§3: Recommendation 2: Expand Educator Preparation and Professional Development in Digital Learning and AI] Educators must be equipped with the skills and professional development necessary to effectively integrate AI into K-12 classrooms and curricula to maintain US global leadership in AI-enhanced teaching and learning.<br>- [§4: Recommendation 3: Support Greater Educational Technology Research and Development] Evidence-based AI implementation in education requires research on AI-driven instructional tools, assessment models, and ethical AI applications. Rigorous evaluation of AI’s impact on K-12 education is needed.<br>- [§5: Recommendation 4: Commit to Connecting all K-12 Students and Teachers to Broadband for AI] Ensuring universal access to reliable, adequate, high-speed internet for all students and educators is critical for accessing AI-powered tools. Disparities in broadband access, especially in rural and high-cost areas, need to be addressed.<br>- [§6: Recommendation 5: Develop National Guidance and Technical Assistance for AI-Powered Educational Tools] Schools need procurement and quality assurance frameworks to quickly and effectively identify high-quality, trustworthy AI technologies. The time and energy intensive efforts to choose products for school systems need to be addressed. Ensuring data security and mitigating risks related to algorithmic bias are important.<br>- [§7: Conclusion & Call to Action] None stated for this section. | - [§1: Introduction & Executive Summary] None stated for this section.<br>- [Section 2: Recommendation 1: Establish a Dedicated K-12 Educational Technology Grant Program]<br>- Recommend Congress adopt a dedicated K-12 technology grant program under the next reauthorization of the Elementary and Secondary Education Act (ESEA).<br>- Provide formula-based funding to states for flexible AI integration.<br>- Offer competitive grants to districts and consortia for innovative AI initiatives.<br>- Encourage the establishment of state educational technology offices.<br>- [Section 3: Recommendation 2: Expand Educator Preparation and Professional Development in Digital Learning and AI]<br>- Increase Title II, Part A funding by at least $500 million annually, with 20% allocated to AI and educational technology professional development.<br>- Expand funding for instructional coaching programs to sustainably train teachers in AI-assisted instruction.<br>- Strengthen educator pipelines to include AI ethics, cybersecurity, and adaptive learning technologies in teacher preparation programs.<br>- [Section 4: Recommendation 3: Support Greater Educational Technology Research and Development]<br>- Increase funding for AI research in K-12 education.<br>- Establish a National AI in Education Research Center to synthesize learning outcomes and provide guidance.<br>- Fund rapid-cycle AI pilot programs to test personalized learning models and tutoring systems.<br>- [Section 5: Recommendation 4: Commit to Connecting all K-12 Students and Teachers to Broadband for AI]<br>- Protect and expand the E-Rate program to support AI in schools and libraries.<br>- Ensure 100/20 Mbps broadband as a minimum standard for student access.<br>- Establish permanent federal funding for broadband affordability programs.<br>- [Section 6: Recommendation 5: Develop National Guidance and Technical Assistance for AI-Powered Educational Tools]<br>- Develop federal AI procurement guidelines (not a mandate) grounded in SETDA's five EdTech Quality Indicators.<br>- Provide technical assistance to help states and districts evaluate AI vendor claims and mitigate risks.<br>- Fund the development of AI safety frameworks to prevent data misuse and discriminatory outcomes.<br>- [§7: Conclusion & Call to Action] None stated for this section. |
| SEMI-AI-RFI-2025.md | SEMI | Industry-Association | SEMI represents the global electronics manufacturing supply chain and advocates for policies that strengthen the U.S. semiconductor industry, promote domestic manufacturing, and maintain U.S. leadership in AI technology through investment, innovation, workforce development, and a favorable regulatory environment. | - None Stated | - None Stated |
| SEIA-AI-RFI-2025.md | Solar Energy Industries Association (SEIA) | Industry-Association | SEIA represents the U.S. solar and storage industry and advocates for policies that promote the development and deployment of solar energy and storage projects, positioning them as crucial components for achieving national AI dominance, energy security, and economic competitiveness. | - [§1: Introduction/Cover Letter] None stated for this section.<br>- [§2: Obstacles Created by Unprecedented Energy Demands] The rapidly increasing energy demand from the AI sector poses a significant challenge to grid stability, with projected demand reaching 606 TWh by 2030 (up from 147 TWh in 2023). The aging grid and interconnection queues create delays in bringing new generation online.<br>- [§3: Natural Gas Generation Alone is Insufficient to Timely Meet Rising Demand] Natural gas generation is not a viable long-term solution due to high costs, supply chain issues, permitting challenges, and fuel price volatility. Gas turbine availability is constrained, with project delays and cancellations occurring.<br>- [§4: The Role of Solar and Storage] There is a need to recognize the potential of solar and storage as a reliable and rapid solution for meeting data center energy demands.<br>- [§4.A: Cost Effectiveness] Natural gas is 2.5 to 4 times more expensive than utility-scale solar.<br>- [§4.B: Construction Speed] Solar and storage projects are faster to develop (1.4 years for solar, 1.7 years for batteries) than other energy technologies.<br>- [§4.C: Reliability] Solar and storage have proven reliable in providing energy and supporting grid stability, even during extreme weather events. Gas-fired generation has been unreliable in recent events.<br>- [§4.D: The U.S. is on a Path to Solar Energy Dominance] The U.S. is experiencing record-breaking solar capacity additions and a resurgence in domestic manufacturing.<br>- [§5: Conclusion] None stated for this section.<br>- [§6: Closing/Signatures] None stated for this section. | - [§1: Introduction/Cover Letter] Recognize the vital role of all energy sources, including solar and storage, in powering data centers.<br>- [§2: Obstacles Created by Unprecedented Energy Demands] None stated for this section.<br>- [§3: Natural Gas Generation Alone is Insufficient to Timely Meet Rising Demand] None stated for this section.<br>- [§4: The Role of Solar and Storage] Support the use of solar and storage to meet the growing energy needs of data centers effectively.<br>- [§4.A: Cost Effectiveness] None stated for this section.<br>- [§4.B: Construction Speed] None stated for this section.<br>- [§4.C: Reliability] None stated for this section.<br>- [§4.D: The U.S. is on a Path to Solar Energy Dominance] None stated for this section.<br>- [§5: Conclusion] Harness the power of all energy sources at our disposal, including the important role of solar and storage, to achieve national AI dominance.<br>- [§6: Closing/Signatures] None stated for this section. |
| SDSC-AI-RFI-2025.md | San Diego Supercomputer Center | Academia | The San Diego Supercomputer Center (SDSC) aims to support and advance AI research and development through high-performance computing, data-intensive science, and collaborative partnerships across academia, industry, and government, with a particular focus on bridging gaps in the AI ecosystem and maximizing the return on federal investments. | - [§1: Introduction/Executive Summary] The need to sustain US leadership in AI requires a robust ecosystem including industry, start-ups, national laboratories, and academic research.<br>- [§2: SDSC Capabilities and Examples] Not stated for this section.<br>- [§3: NAIRR Pilot Program Overview] Not stated for this section.<br>- [§4: Recommendation and Call to Action] The urgency of sustaining and advancing US AI dominance due to extreme global competition. | - [§1: Introduction/Executive Summary] Fully fund and implement the National AI Research Resource (NAIRR) Pilot program, leveraging complementary strengths across sectors.<br>- [§2: SDSC Capabilities and Examples] Not stated for this section.<br>- [§3: NAIRR Pilot Program Overview] Not stated for this section.<br>- [§4: Recommendation and Call to Action] Include NAIRR in the AI Action Plan and prioritize the launch of the competitive award process for the NAIRR Operating Entity (OE), recognizing the leadership role university research centers can provide. |
| SCSP-AI-RFI-2025.md | Ylli Bajraktari | Advocacy/Think Tank | The Special Competitive Studies Project (SCSP) aims to bolster America's long-term competitiveness in AI, particularly against China, by formulating and advocating for comprehensive strategies to achieve and maintain American leadership in the field. | - Section 1: Introduction/Cover:** None stated for this section.<br>- Section 2: Background & Motivation:** The primary concern is the strategic challenge posed by the People's Republic of China (PRC) and the need for a strategy to compete with their advancements in AI.<br>- Section 3: Overarching Vision:** Achieving AGI is paramount, but ensuring it aligns with American values and interests is also a major concern.<br>- Section 4: Key Principles:** Maintaining American preeminence in AI is crucial, with a need to not cede leadership to competitors. Ensuring national security and economic prosperity are also central concerns.<br>- Section 5: Infrastructure Requirements:** A lack of sufficient energy (next-generation nuclear and fusion), advanced networks (6G+), and compute power (including quantum) could hinder AI leadership.<br>- Section 6: Public-Private Partnerships:** Scaling AI resources and widening access requires robust collaboration, but the mechanisms to effectively achieve this are a concern.<br>- Section 7: Domestic and International Standards:** The need to proactively shape international standards and prevent discriminatory treatment of American tech companies is a concern.<br>- Section 8: AI Talent Pipeline:** A shortage of skilled AI talent could impede progress and maintaining a competitive workforce is a concern.<br>- Section 9: International Engagement:**  The risk of competitors gaining access to American technology and the need to defend American innovation internationally are concerns.<br>- Section 10: AI for National Security:** The rapid transformation of the national security landscape by AI necessitates prioritization, but faster innovation and streamlining approval processes are concerns.  Potential vulnerabilities and security breaches by adversaries are also noted.<br>- Section 11: Protecting US Advantages:** Circumvention of export controls, technology theft, and foreign exploitation of American research are significant concerns.<br>- Section 12: Conclusion:**  The need for bold action and a whole-of-government approach, coordinated effectively, is a concern. | - Section 1: Introduction/Cover:** None stated for this section.<br>- Section 2: Background & Motivation:** None stated for this section.<br>- Section 3: Overarching Vision:**  Focus on achieving AGI and aligning it with American values.<br>- Section 4: Key Principles:** Invest aggressively in R&D, prioritize national security, and foster economic growth through AI.<br>- Section 5: Infrastructure Requirements:** Aggressively deploy SMRs, streamline regulatory approvals for nuclear power, establish a "National Fusion Goal," upgrade the power grid, develop a national advanced networks strategy, diversify telecom supply chains, establish a secure AI cloud, and develop a national quantum-AI platform.<br>- Section 6: Public-Private Partnerships:** Launch regional AI innovation zones, utilize a U.S. Sovereign Wealth Fund for infrastructure investment, establish a federal data utility hub, and preserve support for the NAIRR.<br>- Section 7: Domestic and International Standards:** Implement a streamlined regulatory approach, harmonize federal data practices, establish expedited approval pathways, integrate AI into regulatory processes, strengthen IP protection, advocate for fair market access, and pursue AI interoperability with trusted allies.<br>- Section 8: AI Talent Pipeline:** Equip K-16 schools with AI tools, scale personalized AI tutoring, raise the H-1B visa cap, eliminate caps for STEM degree holders, expand counterintelligence efforts focused on identifying and preventing technology theft, enhance federal workforce programs, incentivize job matching platforms, and establish a National Reserve Digital Corps and a U.S. Digital Service Academy.<br>- Section 9: International Engagement:** Advocate for fair market access, establish multilateral export control regimes, develop a competitive technology package, structure alliance cooperation around the Five Eyes model, and appoint a Presidential Envoy for Global Technology Competition.<br>- Section 10: AI for National Security:** Mandate the use of advanced AI models across agencies, stand up a Digital Warfare Corps, establish a dedicated innovation budget, increase intelligence collection on adversaries' AI capabilities, and conduct net assessments on key technological trends.<br>- Section 11: Protecting US Advantages:** Implement and update export controls on advanced hardware, collaborate with allies, pursue on-chip security features, maintain support for SECURE, strengthen research security protocols, expand counterintelligence efforts, promote research security awareness, and track unusual patterns of activity.<br>- Section 12: Conclusion:** Establish a White House Technology Competitiveness Council (TCC) co-convened by the AI Czar and OSTP director to orchestrate a whole-of-government approach. |
| SCCT-AI-RFI-2025.md | Society of Cardiovascular Computed Tomography (SCCT) | Professional-Society | SCCT focuses on advancing the use of cardiovascular computed tomography (CT) and advocates for policies that support responsible AI integration in cardiovascular care to improve patient outcomes, efficiency, and clinical integrity. | - [§1: Document Header/Disclaimer] None stated for this section.<br>- [§2: Introduction/Background] Need for responsible integration of AI in healthcare, and patient safety.<br>- [§3: AI Applications in Cardiovascular CT] Increasing demand for cardiovascular CT exams requires AI assistance to improve patient care at every step. Potential for errors without AI assistance.<br>- [§4: Importance of AI and White Paper Reference]  Challenges and considerations for AI implementation in both research and clinical settings.<br>- [Section 5: Key Priorities for AI in Healthcare Policy]<br>- Lack of appropriate reimbursement models for AI-driven innovation.<br>- Unclear regulatory frameworks for liability in AI-assisted medical decision-making.<br>- Need for high-quality, diverse, and representative datasets to ensure AI algorithm robustness, safety, and effectiveness.<br>- Risk of AI replacing clinical judgment, especially in prior authorization and diagnostic interpretation.<br>- [§6: Conclusion/Call to Action] Need to include healthcare as a priority sector in the AI Action Plan.<br>- [§7: Closing/Contact Information] None stated for this section. | - [§1: Document Header/Disclaimer] None stated for this section.<br>- [§2: Introduction/Background] Inclusion of healthcare in federal policy discussions.<br>- [§3: AI Applications in Cardiovascular CT] None stated for this section.<br>- [§4: Importance of AI and White Paper Reference] Recognition of the critical role of AI in cardiovascular medicine and inclusion of healthcare as a central focus in the AI Action Plan.<br>- [Section 5: Key Priorities for AI in Healthcare Policy]<br>- Facilitate reimbursement mechanisms that encourage responsible AI-driven innovation in clinical practice.<br>- Define clear regulatory frameworks to define liability in AI-assisted medical decision-making, establishing accountability while ensuring AI remains a supportive tool.<br>- Ensure AI algorithms meet rigorous standards for validation and trustworthiness through high-quality, diverse datasets.<br>- Reinforce AI's role in augmenting healthcare professionals rather than supplanting their expertise.<br>- [§6: Conclusion/Call to Action] Collaboration with policymakers to shape an AI framework that fosters innovation while safeguarding patient care and clinical integrity.<br>- [§7: Closing/Contact Information] None stated for this section. |
| SBECouncil-AI-RFI-2025.md | Small Business & Entrepreneurship Council (SBE Council) | Industry-Association / Advocacy/Think Tank | SBE Council advocates for entrepreneurs and small business owners, supporting technological innovation and disruption, with a strong belief in the positive impact of AI on small businesses and the U.S. economy. They aim to foster a policy environment that encourages investment, adoption, and innovation in AI. | - [§1: Introduction/Salutation] None stated for this section.<br>- [§2: Background & Position] Overly restrictive regulations, high compliance costs, and rigid licensing requirements could hinder small business and AI startup growth. Regulatory burdens disproportionately harm startups and small businesses.<br>- [§3: AI Adoption by Small Businesses] None stated for this section.<br>- [§4: Policy Recommendations - Pro-Investment] Government intrusion and short-sightedness harming capital access and formation. Concerns about the arbitrary, confusing, and costly nature of the current M&A ecosystem. The patchwork of proposed state laws undermining AI advancement and adoption.<br>- [§5: Policy Recommendations - Education & Infrastructure] Outdated educational programs not aligning with workforce skills required in an AI-immersed marketplace. Outdated regulation and thinking with respect to energy policy, particularly nuclear power.<br>- [§6: Concluding Remarks/Call to Action] Creating new laws and rules that address contrived or "maybe" problems before real market problems emerge.<br>- [§7: Closing/Signature] None stated for this section. | - [§1: Introduction/Salutation] None stated for this section.<br>- [§2: Background & Position] None stated for this section.<br>- [§3: AI Adoption by Small Businesses] None stated for this section.<br>- [§4: Policy Recommendations - Pro-Investment] Encourage private-sector investment through tax incentives (immediate R&D expensing, lower capital gains taxes, competitive tax rates). Modernize and lower regulatory barriers. Return the merger and acquisition ecosystem to a "best in class" model. Develop a federal framework to preempt growing state laws undermining AI advancement.<br>- [§5: Policy Recommendations - Education & Infrastructure] Modernize educational programs at all levels to align with AI-related workforce skills. Support innovative educational approaches. Restructure energy policy to support power demand and address outdated regulations.<br>- [§6: Concluding Remarks/Call to Action] Stay out of the way of innovation. Use existing law to address real market problems. Empower entrepreneurs and small businesses through pro-investment and pro-innovation policies. Tap into the know-how and ideas of small business owners in the development and execution of the AI Action Plan.<br>- [§7: Closing/Signature] None stated for this section. |
| SAIC-AI-RFI-2025.md | SAIC | Industry-Large | SAIC is a federal technology integrator focused on advancing technology and innovation to serve and protect the world, with a strong interest in deploying AI solutions across government missions and shaping AI policy to foster a thriving AI ecosystem and maintain America's AI dominance. | - [§1: Introduction & Company Overview] None stated for this section.<br>- [§2: Recommended Policy Actions for Right-Sized Governance] Fragmented regulatory environments could hinder AI adoption. The need to address uncertainties and disparate security standards hindering AI adoption.<br>- [§3: Expanded Roles within the AI Value Chain] Existing legislative discussions have primarily focused on Developers and Deployers, neglecting the emerging role of AI Integrators. Potential for undue regulatory burdens misaligned with Integrators' core functions. Liability assignments need to be aligned with the roles within the AI value chain.<br>- [§4: Remove Unnecessary Barriers to AI Innovation] A fragmented regulatory environment hinders AI adoption and creates inefficiencies. Need to avoid a patchwork of varying state laws. Overly complex regulatory landscape. Redundant regulatory burdens.<br>- [§5: Invest in AI Research, Development, and Testing] Robust testing infrastructure is costly and requires continued government funding. Access to commercial technology is often lacking in academic labs. Industry use cases may not align with government requirements.<br>- [§6: Unleash AI Innovation] The need to streamline approval processes and foster a culture of innovation within defense agencies. Ensuring AI solutions are built for operational effectiveness in dynamic and contested environments.<br>- [§7: Prioritize Accessible AI Systems for Government Services and Missions] AI solutions need to be accessible to non-technical domain experts. Ensuring that valuable insights are not limited to a small subset of technically skilled individuals.<br>- [§8: Conclusion] None stated for this section. | - [§1: Introduction & Company Overview] None stated for this section.<br>- [§2: Recommended Policy Actions for Right-Sized Governance] Explore and encourage broader adoption of AI/ML solutions across government sectors. Leverage existing frameworks focused on AI risk management. Focus on transparency, speed and effectiveness of citizen services.<br>- [§3: Expanded Roles within the AI Value Chain] Recognize the emerging role of AI Integrators and their unique value. Define the role of AI Integrators as companies that combine and integrate AI mission solutions. Establish responsibilities and obligations relevant to each entity in the AI value chain.  Assign liability as follows: Developers responsible for data ingestion issues; Integrators not liable for development stage risks, but responsible for safe system integration; Clear guidelines delineating responsibilities among stakeholders. Create a standardized national language around AI, including definitions for terms like 'general purpose system' and 'foundational model'.<br>- [§4: Remove Unnecessary Barriers to AI Innovation] Harmonize AI standards. Align agencies with existing frameworks and guidance. Leverage existing technology-neutral laws and sector-specific regulations. Reemphasize existing agency statutory definitions for new technologies. Utilize established legal definitions in agency-specific legislation. Prioritize nuanced requirements for mission contexts (DoD, National Security).<br>- [§5: Invest in AI Research, Development, and Testing] Prioritized Investments in AI R&D (core AI/ML, safety, testing, infrastructure). Funding for Testing Infrastructure. Support Applied AI Research and Common Evaluation Benchmarks (use CRADAs). Open-Source AI Testing (host challenge problems, set benchmarks).<br>- [§6: Unleash AI Innovation] Establish clear guidance for faster AI integration into defense programs. Invest in robust digital modernization efforts and AI training programs. Develop common standards for AI system reliability and resilience.<br>- [§7: Prioritize Accessible AI Systems for Government Services and Missions] Encourage AI solutions accessible to a range of users. Prioritize platforms with prepackaged algorithms. Encourage contextual-driven AI solutions. Encourage interoperability through modular data practices and avoid vendor lock-in. Train an AI-ready workforce, including prompt engineering skills.<br>- [§8: Conclusion] Incorporate principles into the AI Executive Order. Foster innovation and responsible deployment. Enhance national competitiveness and technological leadership. |
| SAG-AFTRA-AI-RFI-2025.md | Erik Passoja | Individual (responding as a private citizen, though with expertise and a former organizational affiliation) | Erik Passoja, with expertise in digital identity protection, advocates for establishing digital identity verification as critical infrastructure to protect against synthetic media threats, ensuring national security and economic stability while fostering innovation in the AI space. | - Section 1: Introduction & Executive Summary:** The exponential growth of AI-generated synthetic media poses immediate threats to digital identities, national security, economic stability, and individual rights. The need for a market-driven approach that avoids unnecessary regulatory burdens.<br>- Section 2: The Synthetic Media Crisis: Evidence and Impact:**  Deepfake scams are causing significant financial losses (estimated $12 billion globally, projected to $40 billion) and are being used for election interference. The technology enabling these attacks is becoming increasingly accessible.<br>- Section 3: Economic and National Security Impact:** Digital identity attacks threaten critical infrastructure, defense communications, and could result in $40 billion in fraud losses in the United States by 2027. China is actively developing and exploiting synthetic media technologies.<br>- Section 4: Three Critical Framework Gaps:** Lack of defined enforcement mechanisms and technical standards for content provenance (despite initiatives like California SB 942 and COPIED Act), lack of a standardized system to authenticate digital content across platforms, and underdeveloped implementation standards for consent mechanisms (despite initiatives like California AB 2602 and NO FAKES Act).<br>- Section 5: Alignment with AI Action Plan Objectives:** Not stated for this section.<br>- Section 6: Policy Recommendations:**  Concerns around the need for clear policy and technology frameworks to deploy security solutions at scale.<br>- Section 7: Implementation Considerations:** Concerns around the importance of private sector leadership and the potential for phased deployment.<br>- Section 8: International Coordination:** Concerns about the need for international alignment with like-minded nations, including standard harmonization and diplomatic engagement.<br>- Section 9: Balanced Implementation Timeline:** Not stated for this section.<br>- Section 10: Economic Opportunity:** Not stated for this section.<br>- Section 11: Conclusion:** Concerns surrounding the rapidly closing window for establishing effective protections and the urgency of addressing the crisis. | - Section 1: Introduction & Executive Summary:** None stated for this section.<br>- Section 2: The Synthetic Media Crisis: Evidence and Impact:** None stated for this section.<br>- Section 3: Economic and National Security Impact:** None stated for this section.<br>- Section 4: Three Critical Framework Gaps:** None stated for this section.<br>- Section 5: Alignment with AI Action Plan Objectives:** None stated for this section.<br>- Section 6: Policy Recommendations:<br>- Designate Digital Identity as Critical Infrastructure.<br>- Establish Federal Standards aligned with state initiatives (CA SB 942, AB 2602, TN ELVIS Act, IL SB 3325).<br>- Implement Authentication Requirements for critical communications (government, military, infrastructure, emergency management, finance).<br>- Create Market Incentives for verification systems (procurement preferences, tax incentives, risk management requirements).<br>- Support Statutory Authority for Digital Identity Protection (support NO FAKES Act and COPIED Act).<br>- Section 7: Implementation Considerations:** None stated for this section.<br>- Section 8: International Coordination:** None stated for this section.<br>- Section 9: Balanced Implementation Timeline:** None stated for this section.<br>- Section 10: Economic Opportunity:** None stated for this section.<br>- Section 11: Conclusion:** None stated for this section. |
| Rynnec-Zuhac-AI-RFI-2025.md | Rynnec Zuhac | Individual | The submitter believes AI development is fundamentally harmful and advocates for its complete elimination, primarily due to concerns about theft, job displacement, environmental impact, and copyright infringement. They strongly oppose the use of generative AI. | - [§1: Email Header] None stated for this section.<br>- [Section 2: Core Argument]<br>- Theft (pilfering from artists)<br>- Job displacement of American citizens<br>- Negative environmental impact (electricity and carbon dioxide emissions)<br>- Copyright issues and risk of lawsuits<br>- [Section 3: Concluding Statement]<br>- AI is overall harmful and outweighs any potential benefits.<br>- [§4: Disclaimer] None stated for this section. | - [§1: Email Header] None stated for this section.<br>- [§2: Core Argument] None stated for this section.<br>- [Section 3: Concluding Statement]<br>- Eliminate AI development and use.<br>- [§4: Disclaimer] None stated for this section. |
| RyanL-AI-RFI-2025.md | Ryan L | Individual | The submitter expresses strong opposition to the development and use of AI due to concerns about job displacement, copyright infringement, and the overall cost-benefit ratio of AI technologies. They believe AI negatively impacts American livelihoods and does not offer sufficient value. | - AI steals from the submitter’s livelihood as an American.<br>- AI profits off of theft (presumably referring to the use of copyrighted material).<br>- AI is overhyped.<br>- AI is incredibly expensive to maintain.<br>- AI is a huge waste of resources.<br>- AI offers little profit.<br>- AI has little use cases.<br>- Copyright is not protected from AI. | - Properly compensate people whose copyright material is used to train generative AI models. |
| Ryan-Johnson-AI-RFI-2025.md | Ryan Johnson | Industry-Startup | Ryan Johnson, as the Founder of American Data Company, appears interested in the practical and ethical integration of AI technologies into existing communities, with a focus on user agency and preventing the misuse of AI narratives for undue influence. They advocate for a bottom-up approach to AI adoption. | - [§1: Email Header] None stated for this section.<br>- [§2: Introduction/Salutation] None stated for this section.<br>- [§3: Point 1: Generalizing "AI"] The term "AI" is too broad and obscures the specific technologies it encompasses (e.g., large-language models, machine learning).<br>- [§4: Point 2: Abuse of the idea of "AI"] The term "AI" is susceptible to misuse and can be used to exert power through fictional narratives.<br>- [§5: Point 3: "AI" as a guest] Current city planning approaches are often top-down and detrimental. AI integration should prioritize existing communities and local economies.<br>- [§6: Point 4: Opt-out option] Users should have the ability to opt-out of AI-related systems. The history of digitalization provides precedent for caution and the need for careful agreements.<br>- [§7: Closing Remarks/Signature] None stated for this section.<br>- [§8: Disclaimer] The email is for official use only and subject to disclosure requirements, raising concerns about potential limitations on open communication. | - [§1: Email Header] None stated for this section.<br>- [§2: Introduction/Salutation] None stated for this section.<br>- [§3: Point 1: Generalizing "AI"] Policymakers should focus on the specific mechanics of AI technologies instead of treating "AI" as a monolithic entity. Promote demystification of how these tools work.<br>- [§4: Point 2: Abuse of the idea of "AI"] Policymakers should address the potential for misuse of the term "AI" and the propagation of fictional narratives.<br>- [§5: Point 3: "AI" as a guest] Policymakers should prioritize bottom-up approaches to AI integration, focusing on the needs of local economies and communities.<br>- [§6: Point 4: Opt-out option] Policymakers should mandate an opt-out option for all AI-related systems and forge collective agreements regarding appropriate use cases.<br>- [§7: Closing Remarks/Signature] None stated for this section.<br>- [§8: Disclaimer] None stated for this section. |
| Ryan-Hagemann-IBM-AI-RFI-2025.md | IBM / Ryan Hagemann | Industry-Large | IBM aims to promote American leadership in AI through open source development, strategic international engagement ("AI Diplomacy"), and responsible regulation focused on use cases rather than the technology itself, while also leveraging commercially hosted shared services to streamline government operations. | - [§1: Introduction & Statement of Support] None stated for this section.<br>- [§2: Accelerate Adoption of American Open Source AI] Concern that restricting access to open model weights could hinder innovation and national security; concern that hoarding AI resources by a few firms would stifle solutions to safety and security risks.<br>- [§3: Formalize an "AI Diplomacy" Strategy to Lead Globally] Concern that undue constraints on open source AI diffusion by the US government could slow its ability to win the technological race against competitors; concern that techno-authoritarian values could grow without US leadership in open source AI.<br>- [§4: Prioritize Risk-Based Approaches to Regulation] Concern that a patchwork of state AI legislation could wreak havoc on the domestic AI industry due to a lack of harmonized definitions and conflicting obligations.<br>- [§5: Rapidly Scale AI Usage to Streamline Government Operations] Concern that modernization of legacy IT systems is too slow and costly, and that replacing them with cross-government platforms is more efficient.<br>- [§6: Conclusion] None stated for this section. | - [§1: Introduction & Statement of Support] None stated for this section.<br>- [Section 2: Accelerate Adoption of American Open Source AI]<br>- Enable open innovation in AI by building shared computing and data resources.<br>- Incentivize AI skills in the workforce.<br>- Develop a National Compute Strategy.<br>- Fund the National AI Research Resource.<br>- Better coordinate public-private initiatives for computing access.<br>- [Section 3: Formalize an "AI Diplomacy" Strategy to Lead Globally]<br>- Deputize the Office of the Special Envoy for Critical and Emerging Technologies to lead a global engagement strategy.<br>- Support open source AI diffusion as a key cornerstone of the strategy.<br>- Protect US market access and promote open innovation globally.<br>- Push back against efforts undermining flexible IP frameworks (e.g., fair use doctrine).<br>- Leverage NIST AI RMF to influence AI policy alignment with allies.<br>- [Section 4: Prioritize Risk-Based Approaches to Regulation]<br>- Collaborate with Congress to preempt state AI legislation.<br>- Focus regulation on the *use* of AI, not the technology itself.<br>- Implement voluntary impact assessments and bias testing for high-risk AI.<br>- Define high-risk and prohibited use cases.<br>- Clarify obligations for developers and deployers.<br>- Require disclosure and transparency when people interact with AI.<br>- Focus regulatory efforts on areas unaddressed by existing law.<br>- Incentivize "transparency governance" in the development and deployment of AI systems.<br>- [Section 5: Rapidly Scale AI Usage to Streamline Government Operations]<br>- Designate proven shared service platforms as the preferred avenue for injecting AI into government business functions.<br>- Target fraud, waste, and abuse with AI-driven analytics.<br>- Transform IT modernization with commercially hosted platforms.<br>- Prioritize AI-powered cybersecurity solutions.<br>- Unlock human resources productivity with a cross-agency shared service platform.<br>- Ruthlessly eliminate manual processes with AI-powered automation.<br>- [§6: Conclusion] None stated for this section. |
| Ryan-Abbott-AI-RFI-2025.md | Ryan Abbott | Professional-Society/Individual | Ryan Abbott, a professor of law and health sciences, is focused on the legal implications of AI, specifically regarding intellectual property rights and the need to adapt copyright law to accommodate AI-generated works, advocating for the recognition of AI authorship and the benefits of incentivizing AI development. | - [§1: Introduction] The critical need for U.S. law to allow intellectual property rights to subsist in AI-generated outputs for America's AI industrial strategy and international competitiveness. The current legal regime (Federal Circuit *Thaler v. Vidal* case and USPTO guidance) runs contrary to the purpose of patent law.<br>- [§2: AI-Assisted vs. AI-Generated Creativity] Lack of standardized definitions for terms like "AI-assisted" and "AI-generated," leading to potential unharmonized rules and misinterpretations.<br>- [§3: The State of AI Technology and AI Authors] The US Copyright Office's "Human Authorship Requirement" prohibiting registration of copyright for AI-generated works since 1973, despite no explicit statutory requirement. The long history of jurisprudence framing creativity in human-centric terms.<br>- [§4: Advances in AI] The rapidly evolving capabilities of Large Language Models (LLMs) and the need for legal frameworks to keep pace with technological advancements. | - [§1: Introduction] Allow intellectual property rights to subsist in AI-generated outputs to incentivize development and commercialization, benefiting the American public.<br>- [§2: AI-Assisted vs. AI-Generated Creativity] Not stated for this section.<br>- [§3: The State of AI Technology and AI Authors] Recognize AI as an author for copyright purposes, even though AI cannot have legal rights. The USCO's existing policies are inconsistent with the treatment of corporate authors.<br>- [§4: Advances in AI] Not stated for this section. |
| Russell-Judge-AI-RFI-2025.md | Russell Judge | Individual | The submitter is a software developer interested in advancing American leadership in AI through policies that promote innovation, economic competitiveness, and national security, with a focus on minimizing regulatory burdens and leveraging private sector growth. They specifically cite Executive Order 14179 as a guiding document. | - [§1: Header/Introduction] None stated for this section.<br>- [§2: Policy Recommendations (Hardware and Chips - Intellectual Property)] Reducing reliance on foreign suppliers, ensuring sustainable scalability of data centers, lowering barriers to entry for new AI companies, maintaining basic safety and security standards, ensuring AI systems are transparent and reliable, safeguarding AI systems from cyber threats, balancing data privacy with innovation, avoiding overly restrictive regulations, addressing sector-specific risks, prioritizing defense applications of AI, ensuring a skilled AI workforce, promoting a competitive AI marketplace, clarifying IP laws related to AI, and preventing adversarial access to sensitive AI technologies.<br>- [§3: Conclusion] Over-regulation hindering private sector innovation, the importance of securing critical supply chains, and protecting national security.<br>- [§4: Submission Note] None stated for this section. | - [§1: Header/Introduction] None stated for this section.<br>- [Section 2: Policy Recommendations (Hardware and Chips - Intellectual Property)]<br>- Strengthen domestic semiconductor manufacturing with tax incentives and R&D funding.<br>- Streamline permitting and provide tax incentives for data center infrastructure.<br>- Reduce regulatory barriers for AI startups and small businesses with simplified compliance and grants.<br>- Develop streamlined procurement guidelines for government AI systems.<br>- Fund research into interpretable AI systems and industry-led standards for validation.<br>- Mandate robust cybersecurity measures for AI systems.<br>- Establish clear, practical data handling guidelines aligning with existing privacy laws.<br>- Adopt a light-touch, sector-specific regulatory framework.<br>- Prioritize AI R&D funding for defense applications and implement export controls.<br>- Increase federal funding for cutting-edge AI research.<br>- Launch initiatives to train the next generation of AI professionals.<br>- Promote a competitive AI marketplace and enforce antitrust measures.<br>- Clarify Intellectual Property laws for AI-generated works and systems.<br>- Partner with allies to develop global AI standards and norms.<br>- Define clear, enforceable export controls on sensitive AI technologies.<br>- [§3: Conclusion] Prioritize policies that unleash private sector innovation, secure critical supply chains, and protect national security while minimizing regulatory burdens.<br>- [§4: Submission Note] None stated for this section. |
| Royce-Landrum-AI-RFI-2025.md | Royce Landrum | Individual | The submitter is interested in ensuring AI serves as a tool to *assist* and *teach* humans, rather than replace human activity and contribution, with a broad focus on comprehensive education and skill development across diverse disciplines, and a strong emphasis on traditional skills alongside modern technologies. | - AI potentially replacing life tasks that humans need to stay active, alert, and engaged in society.<br>- Lack of clear distinction between AI and humans. | - AI systems should have an override option.<br>- AI should be easily distinguishable from humans by look and/or voice inflections.<br>- AI should be capable of teaching comprehensive course curriculums, from elementary to PhD level, spanning Foreign Languages, Mathematical Sciences, Accounting, Commerce, Sciences, Farming, History, Reading, Composition, Speech Writing, Public Speaking, Business Administration, Engineering, Social Studies, Civics, Computer Sciences, Web Design, Graphics, Photography, Journalism, Humanities, Religion, Cooking, Childcare, Home Repair, Barbering, Cosmetology, Social Skills, Parenting, Music, Art, Crafting, DIY, Law, and First Responder/Medical fields. |
