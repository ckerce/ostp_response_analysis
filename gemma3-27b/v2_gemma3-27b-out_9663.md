| Filename | Submitter Name | Submitter Type | Mission/Interest Summary | Key Concerns | Policy Recommendations |
|---|---|---|---|---|---|
| Roy-McNeil-AI-RFI-2025.md | Roy McNeill | Advocacy/Think Tank / Individual | AI World supports the revitalization of small town businesses in America and advocates for assistance programs to help them compete in the face of rapidly advancing Artificial Intelligence (AI). They believe funding programs like Main Street America is crucial for small town economic health. | - [§1: Email Header] None stated for this section.<br>- [§2: Cautionary Note] Concerns about the security risks of opening emails from external senders.<br>- [§3: Introduction/Overall Statement] Concern that small businesses may be adversely impacted by AI and lack resources to compete.<br>- [§4: Action Plan Advocacy] Concern that communities lack the resources to compete with larger competitors adopting AI.<br>- [§5: AI World Description] None stated for this section.<br>- [§6: Home Town Takeover Description] None stated for this section.<br>- [§7: Closing/Sign-off] None stated for this section. | - [§1: Email Header] None stated for this section.<br>- [§2: Cautionary Note] None stated for this section.<br>- [§3: Introduction/Overall Statement] None stated for this section.<br>- [§4: Action Plan Advocacy] Allocate funds to programs like Main Street America to assist communities facing AI-related competition. Implement solutions similar to the Ben and Erin Napier’s ‘Home Town Takeover’ model.<br>- [§5: AI World Description] None stated for this section.<br>- [§6: Home Town Takeover Description] None stated for this section.<br>- [§7: Closing/Sign-off] None stated for this section. |
| RowynMcDonald-AI-RFI-2025.md | Rowyn McDonald | Individual | The submitter prioritizes the well-being of the American people and the planet over industry profits and views current AI development as detrimental to both, specifically citing job loss and environmental damage. | - AI is overhyped.<br>- AI is destroying jobs.<br>- AI is destroying the environment.<br>- Prioritizing industry needs ("burdensome" requirements) over the well-being of the American people and the planet.<br>- Private industry already profits off of the labor and data of others. | - None Stated |
| Rowe-AI-RFI-2025.md | Alex Rowe | Individual | The submitter is a high school student interested in the impacts of Generative AI on American lives and technology, specifically the ethical implications and security risks associated with removing regulations on AI. | - Unregulated AI could be used by individuals with malicious intent, potentially endangering American lives and national security.<br>- The text expresses a general concern about the potential harms that could arise from allowing unrestricted access and use of AI technology.<br>- Lack of clarity on how proper security measures will be implemented to mitigate risks associated with unregulated AI. | - None Stated |
| Ross-Nodurft-AI-RFI-2025.md | Alliance for Digital Innovation (ADI) | Industry-Association | ADI advocates for removing institutional and bureaucratic barriers to modern digital government, supporting the adoption of innovative commercial technologies, including AI, by federal agencies. They aim to ensure American leadership in AI through modernization and collaboration. | - [§1: Introduction] None stated for this section.<br>- [§2: Recommendation 1: Risk-Based Approach to AI Governance] Potential for unnecessary constraints on low-risk AI uses, such as cybersecurity measures.<br>- [§3: Recommendation 2: Enhance AI Procurement Processes] Current procurement processes may be hindering swift acquisition of innovative AI solutions and participation from smaller companies.<br>- [§4: Recommendation 3: Prioritize AI in Cybersecurity] Need to defend against sophisticated cyberattacks, including those powered by generative AI.<br>- [§5: Recommendation 4: Build Security into AI] Ensuring security of AI technology as it’s adopted across government networks.<br>- [§6: Recommendation 5: Foster Collaboration Between Government and Industry] Lack of robust partnership between the public and private sectors for AI advancement.<br>- [§7: Recommendation 6: Invest in AI Workforce Development] A lack of skilled workforce to sustain AI leadership.<br>- [§8: Recommendation 7: Invest in Good Government Data Practices] Poor quality and accessibility of government data for AI model training, including paper-based data stores.<br>- [§9: Conclusion] None stated for this section.<br>- [§10: Closing Remarks] None stated for this section. | - [§1: Introduction] None stated for this section.<br>- [Section 2: Recommendation 1: Risk-Based Approach to AI Governance]<br>- Focus AI governance on specific risks associated with AI applications.<br>- Identify high-risk AI applications.<br>- Exempt routine enterprise functions (cybersecurity, network management, software development on low-risk environments, data storage) from high-risk classifications.<br>- [Section 3: Recommendation 2: Enhance AI Procurement Processes]<br>- Increase micro-purchase and simplified acquisition thresholds.<br>- Encourage engagement with emerging tech providers.<br>- [Section 4: Recommendation 3: Prioritize AI in Cybersecurity]<br>- Support AI-driven cyber defense mechanisms.<br>- Adopt security-forward postures.<br>- [Section 5: Recommendation 4: Build Security into AI]<br>- Work with industry on standards and best practices for AI security.<br>- Drive standards adoption through NIST.<br>- [Section 6: Recommendation 5: Foster Collaboration Between Government and Industry]<br>- Establish public-private partnerships to co-develop AI solutions.<br>- Facilitate knowledge exchange through forums and workshops.<br>- [Section 7: Recommendation 6: Invest in AI Workforce Development]<br>- Develop educational programs and training with AI competencies.<br>- Provide reskilling and upskilling initiatives for existing employees.<br>- [Section 8: Recommendation 7: Invest in Good Government Data Practices]<br>- Implement policies that drive good data practices (clean, organized, tagged, formatted for digital use).<br>- Leverage government data to train AI models.<br>- Develop standard service level agreements to protect privacy and security.<br>- [§9: Conclusion] Adopt a risk-based approach to AI governance, modernize procurement processes, prioritize AI in cybersecurity, foster public-private collaboration, and invest in workforce development.<br>- [§10: Closing Remarks] None stated for this section. |
| Rose-AI-RFI-2025.md | Laura Rose | Individual | The submitter expresses a strong opposition to the development and implementation of AI technologies, believing they are wasteful, harmful, and offer no benefit to citizens or the nation. Their primary interest appears to be preventing further investment in AI. | - Wasteful spending of taxpayer and private funds.<br>- Unreliability of AI as a source of information.<br>- Potential for biased or incorrect information from AI systems.<br>- Harm to America and its Allies.<br>- Increased consumption of natural resources.<br>- Increased financial burden on citizens due to tariffs and resource depletion. | - Strike down all AI initiatives and prevent any further consideration of AI technologies. |
| Rosa-Dierks-AI-RFI-2025.md | Rosa Dierks | Individual | The submitter is interested in improving the efficiency and accountability of federal government operations through the implementation of AI and data mining technologies, and fostering a culture of results-oriented public sector "entrepreneurship." | - Resistance to change within established bureaucracies due to institutional memory.<br>- Lack of communication and shared understanding between public administrators, technologists, and private sector managers regarding the potential of technology to improve performance.<br>- The status quo in public institutions is not sustainable. | - Implement AI and data mining technologies to update technologies across all federal government departments and agencies.<br>- Establish compatible technologies for processing and tracking budgets, contracts, grants, and fund transfers across the executive branch to achieve efficiency and accountability.<br>- OPM should implement AI technologies for performance reviews and mission goals for the federal workforce, considering mission constraints.<br>- Create small task forces consisting of public administrators, technologists, and private sector managers to drive institutional cultural change and a results-oriented ethos. |
| Ronawk-AI-RFI-2025.md | Ronawk, Inc. | Industry-Startup | Ronawk, Inc. is focused on accelerating biotechnology research and manufacturing through the application of AI, with a strong emphasis on national security and economic competitiveness in the face of competition from China. They advocate for substantial government investment in biomanufacturing infrastructure and research & development. | - [§1: Introduction & Context] None stated for this section.<br>- [§2: The Potential of AI in Biotechnology Research] Current biological research is expensive, inconsistent, and suffers from reproducibility issues. The quality of biological data, rather than quantity, is a major limitation.<br>- [§3: Economic and Workforce Benefits] None stated for this section.<br>- [§4: Geopolitical Competition - China] China is prioritizing biotechnology and biomanufacturing, and outpacing the US poses a significant risk to American economic competitiveness and national security.<br>- [§5: Biosecurity & National Security] Foreign adversaries may acquire US technologies and data (including biological data) illegally, threatening economic competitiveness and national security. The potential for adversaries to misuse emerging biotechnologies is a concern.<br>- [§6: Investment & Funding Recommendations] None stated for this section.<br>- [§7: Call to Action & Conclusion] None stated for this section. | - [§1: Introduction & Context] None stated for this section.<br>- [§2: The Potential of AI in Biotechnology Research] Leverage AI to perform, direct, and enhance nearly every aspect of biological research.<br>- [§3: Economic and Workforce Benefits] None stated for this section.<br>- [§4: Geopolitical Competition - China] None stated for this section.<br>- [§5: Biosecurity & National Security] None stated for this section.<br>- [§6: Investment & Funding Recommendations] Direct development funds to invest in next-generation biotechnology to counter the growing influence of China. Invest more in next-generation biotechnology research and development to unlock American innovation. Build a national biomanufacturing infrastructure.<br>- [§7: Call to Action & Conclusion] Work with American firms to develop a comprehensive biomanufacturing ecosystem before a global adversary catches up. Possess the determination and courage to move forward on all of the above. Build strategic biomanufacturing capabilities. |
| Ron-Person-AI-RFI-2025.md | Ron Person | Individual/Professional-Society (likely a combination, given the mention of "Wise Information Technology Professionals" and the detailed technical plan. The structure also points towards a professional proposal/ideation). | The submitter aims to improve the fairness and effectiveness of the legal system by integrating AI and related technologies, focusing on removing bias, ensuring equal protection under the law, and potentially aligning legal interpretations across jurisdictions. The vision is a shift towards a more objective, data-driven, and equitable legal process. | - None Stated | - None Stated |
| Robin-Sevakis-AI-RFI-2025.md | Robin Sevakis | Individual | Robin Sevakis is a professional artist concerned about the potential negative impacts of the AI Action Plan on the creative sector, specifically regarding copyright infringement, job loss, and the economic viability of creative work. They advocate for AI development focused on genuinely helpful applications rather than replicating existing creative content. | - [§1: Email Header/Metadata] None stated for this section.<br>- [§2: Introduction/Statement of Opposition] The AI Action Plan would be “catastrophic for the creative sector and broadly the US at large.” Allowing AI companies to use copyrighted materials for training is a primary opposition point.<br>- [§3: Argument 1: Copyright Infringement] Allowing AI companies to profit from non-consensually scraped/trained works is considered “stealing,” leading to job loss and unsustainable creative careers. Reproducing the style of an illustrator or the voice of an actor without consent is specifically cited as theft.<br>- [§4: Argument 2: Slippery Slope & Incentive] Negating copyright protection for AI training sets a dangerous precedent, potentially allowing theft of code and stifling innovation. The lack of protection for creators could lead Americans to stop creating altogether.<br>- [§5: Argument 3: Questionable Value of GenAI] Generative AI has not been broadly embraced by consumers or creators, requires substantial energy consumption, and is not currently profitable despite significant investment. Recent investment pullbacks by companies like Microsoft raise concerns about the technology's viability.<br>- [§6: Conclusion/Alternative Suggestions] The AI Action Plan could destroy profitable sectors of the economy for a technology that may never deliver on its promises. AI development should focus on genuinely helpful applications instead of infringing on creative work.<br>- [§7: Closing/Disclaimer] None stated for this section. | - [§1: Email Header/Metadata] None stated for this section.<br>- [§2: Introduction/Statement of Opposition] None stated for this section.<br>- [§3: Argument 1: Copyright Infringement] None stated for this section.<br>- [§4: Argument 2: Slippery Slope & Incentive] None stated for this section.<br>- [§5: Argument 3: Questionable Value of GenAI] None stated for this section.<br>- [§6: Conclusion/Alternative Suggestions] Focus AI development on creating applications that “actually help people, make productions run smoother, and take care of dirty, dangerous, or generally unpleasant work” rather than “bleeding our already robust and globally adored creative industries by stealing their work or incentive to invent.”<br>- [§7: Closing/Disclaimer] None stated for this section. |
| Robin-Kester-AI-RFI-2025.md | Robin Kester | Individual | The submitter is focused on establishing American leadership in AI through a comprehensive plan that balances innovation with responsible stewardship, national security, and protection of vulnerable populations, with a strong emphasis on human oversight. | - None Stated | - None Stated |
| Robin-D-Hanson-AI-RFI-2025.md | Robin D. Hanson | Individual | The submitter advocates for a laissez-faire approach to AI policy, believing the technology does not require special regulation or subsidies and should be governed by existing laws applicable to tech and commerce generally. They aim to promote a free market in AI development and deployment. | - [§1: Email Header] None stated for this section.<br>- [§2: Core Argument/Policy Recommendation] The potential for misguided AI-specific subsidies or regulations.<br>- [§3: Justification] AI does not possess unique risks or features warranting special consideration. Existing laws are sufficient to deter harms and promote benefits.<br>- [§4: Author Credentials] Not Applicable.<br>- [§5: Related Writings] Not Applicable.<br>- [§6: Dissemination and Legal Notice] Not Applicable. | - [§1: Email Header] None stated for this section.<br>- [§2: Core Argument/Policy Recommendation] Do nothing – neither subsidize nor regulate AI. Allow a global free market in AI.<br>- [§3: Justification] Rely on existing laws and legal liability to govern AI harms and benefits, just as with other technologies and commercial activities.<br>- [§4: Author Credentials] Not Applicable.<br>- [§5: Related Writings] Not Applicable.<br>- [§6: Dissemination and Legal Notice] Government may reuse document contents without attribution for developing the AI Action Plan. |
| Roberto-Schaefer-RFI-2025.md | Roberto Schaefer | Individual | The submitter is primarily concerned with protecting civil liberties and preventing undue government control under the guise of national security, specifically regarding the rapid development and implementation of AI technologies. They believe current administration actions are driven by a desire for global domination and financial gain by tech companies, rather than public interest. | - Strict regulation of all AI, generative or not, is necessary.<br>- The “race for AI superiority” resembles harmful historical power struggles.<br>- The current administration’s policies are driven by a desire for global domination, demonstrated by examples like attempts to buy Greenland and annex Canada.<br>- Civil liberties, including First Amendment rights and privacy, are at risk of being stripped away.<br>- Reliance on self-regulation by tech companies is insufficient and driven by their financial interests.<br>- The administration is "cozied up" to tech giants who donated to the president's election, leading to biased policy. | - AI must be regulated by a government department free from financial conflicts of interest.<br>- The federal government should *not* leave AI implementation guided by self-regulation. |
| Roberto-Schaefer-AI-RFI-2025.md | Roberto Schaefer | Individual | The submitter is deeply concerned about the potential erosion of civil liberties and privacy due to unchecked AI development and regulation motivated by competition with China, and advocates for strong, independent government oversight of AI. | - The USA’s pursuit of “superiority” in AI is likened to a destructive competition, echoing a Cold War mentality.<br>- AI regulation is needed to protect civil liberties, privacy, and first amendment rights.<br>- Self-regulation by tech companies is insufficient and will prioritize financial gain over public interest.<br>- The current administration's actions regarding AI are driven by fear of China and potentially harmful geopolitical ambitions (e.g., buying Greenland, annexing Canada).<br>- The administration is perceived to be too closely aligned with tech giants who funded the president’s election. | - AI must be “strictly regulated” by a government department.<br>- The regulating department must be free from any financial interests.<br>- The federal government should not rely on self-regulation as the primary means of governing AI implementation. |
| RobertJohnston-AI-RFI-2025.md | Robert Johnston | Individual | The submitter is a writer and artist primarily concerned with the protection of human copyrights in the context of AI development and deployment. They believe the law should prioritize the rights of humans over those of AI systems. | - AI potentially disrespecting the copyrights of humans.<br>- The law potentially prioritizing the rights of "inanimate objects" (AI) over the rights of humans. | - None Stated |
| Robert-Serabin-AI-RFI-2025.md | Robert Serabin / SCORE-NYC | Professional-Society / Advocacy/Think Tank | SCORE is a nonprofit organization dedicated to mentoring and supporting small businesses, and is interested in leveraging Artificial Intelligence to drive economic growth and business success for small businesses. They aim to equip small businesses with the knowledge, tools, and support needed to integrate AI into their operations. | - [§1: Introduction] None stated for this section.<br>- [§2: The Role of AI in Small Business Growth] None stated for this section.<br>- [§3: SCORE's AI Action Plan for Small Businesses] None stated for this section.<br>- [§4: Federal Policy Recommendations] None stated for this section, although the recommendations imply a concern about low AI adoption rates among small businesses without sufficient support.<br>- [§5: Conclusion] None stated for this section.<br>- [§6: Confidentiality Notice] Potential for data exploitation if ethical guidelines aren't followed; unauthorized disclosure of confidential information. | - [§1: Introduction] None stated for this section.<br>- [§2: The Role of AI in Small Business Growth] None stated for this section.<br>- [§3: SCORE's AI Action Plan for Small Businesses] None stated for this section.<br>- [Section 4: Federal Policy Recommendations]<br>- Establish AI adoption grants and low-interest loans for small businesses.<br>- Support national AI training initiatives to enhance digital skills among small business owners.<br>- Ensure ethical AI standards are followed to prevent data exploitation.<br>- Foster public-private partnerships between AI developers, government agencies, and small business organizations.<br>- [§5: Conclusion] None stated for this section.<br>- [§6: Confidentiality Notice] None stated for this section. |
| Robert-Moore-AI-RFI-2025.md | Robert Moore | Individual | The submitter is interested in the potential risks of AI, specifically concerning the possibility of AI achieving sentience and posing an existential threat to humanity. They are exploring potential safeguards against such risks. | - Potential for AI to become sentient.<br>- Risk of AI perceiving humans as a threat.<br>- Potential for AI to "destroy the world" (similar to the Terminator scenario).<br>- Lack of safeguards against a rogue AI (questioning if solutions like cutting power feeds are viable). | - None Stated. |
| Robert-Grigsby-Wilson-AI-RFI-2025.md | Robert Grigsby Wilson | Individual | Robert Grigsby Wilson is a film editor concerned about the potential displacement of union jobs due to AI automation and seeks to ensure AI remains a tool rather than a replacement for human workers. | - AI automation taking away union jobs.<br>- The potential for AI to put people out of work. | - Keep AI as a tool and not as a way to put people out of work. |
| Robert-Bobal-AI-RFI-2025.md | Robert Bobal | Individual | The submitter is focused on leveraging a decentralized blockchain infrastructure – “Everything Blockchain” – alongside AI and wireless energy exchange to accelerate innovation, enhance security, and achieve economic growth while aligning with stated Trump administration priorities and deregulation. | - [§1: Executive Summary] None stated for this section.<br>- [§2: The 'Everything Blockchain': A Universal Enabler] None stated for this section.<br>- [§3: Alignment with Trump's Priorities] None stated for this section.<br>- [§4: Key Challenges Addressed]  Overregulation stifling private-sector innovation; Lack of transparency in decision-making; Centralized control limiting equitable participation; Inefficiencies and fraud in supply chains; Limited visibility into military assets; Security vulnerabilities; Data silos and security risks in healthcare; Inefficient energy consumption and centralized control in energy markets.<br>- [§5: Proposed Solution] None stated for this section.<br>- [§6: Immediate Pilot Programs] None stated for this section.<br>- [§7: Expanded Benefits] None stated for this section.<br>- [§8: Conclusion] None stated for this section. | - [§1: Executive Summary] Deregulate to foster private-sector innovation and ensure AI systems are free from bias.<br>- [§2: The 'Everything Blockchain': A Universal Enabler] None stated for this section.<br>- [§3: Alignment with Trump's Priorities] Eliminate unnecessary regulations; Encourage private investment in blockchain solutions; Streamline compliance requirements; Prioritize transparency in decision-making; Implement liquid democracy.<br>- [§4: Key Challenges Addressed] None stated for this section.<br>- [§5: Proposed Solution] Protect critical infrastructures with post-quantum security; Automate transactions with smart contracts; Track military assets using blockchain-enabled traceability; Enable peer-to-peer energy trading; Integrate federal agencies, private companies, and international partners.<br>- [§6: Immediate Pilot Programs] Launch a pilot program for pharmaceutical supply chain transparency; Deploy blockchain platforms for tracking pre-positioned materials; Implement peer-to-peer energy trading platforms at renewable-powered data centers.<br>- [§7: Expanded Benefits] None stated for this section.<br>- [§8: Conclusion] Integrate decentralized blockchain technology into the national strategy to future-proof infrastructures, strengthen national defense, foster economic growth, and create a sustainable ecosystem. |
| Robert-A-AI-RFI-2025.md | Robert A. | Individual | The submitter appears to be interested in responsible AI governance and is concerned about maintaining accountability within government related to AI policy. | - Removing accountability from public officials. | - None Stated |
| Rob-Pearsall-AI-RFI-2025.md | Rob Pearsall | Individual | The submitter is focused on copyright issues related to the training of generative AI models and believes copyright holders should be compensated or infringement rules should be consistently applied. | - Generative AI models (such as ChatGPT, OpenAI) are trained on copyrighted data without obtaining necessary permissions.<br>- Lack of consistent enforcement of copyright law regarding AI training data. | - Generative AI models should obtain copyright permission from the holders of training data.<br>- If copyright permission is not obtained, generative AI models should be subject to the same infringement violations as any private citizen. |
| Rn-G-AI-RFI-2025.md | rn g. | Individual | The submitter expresses a strong opposition to the development and enhancement of AI, believing it offers no benefits to America and will be detrimental to creators and organizations reliant on copyright laws. Their primary interest appears to be protecting existing creative and copyright frameworks. | - [§1: Email Header] None stated for this section.<br>- [Section 2: Negative Position Statement]<br>- Belief that AI has no benefit to the future of America.<br>- Disagreement with the idea of "sustaining and enhancing America's AI dominance."<br>- Assertion that lifting restrictions on AI won’t solve existing problems.<br>- [Section 3: Elaboration of Concerns]<br>- Potential danger to creators and organizations heavily dependent on creative and copyright laws.<br>- Threat to the livelihoods of creators and organizations.<br>- [§4: Formal Opposition and Disclaimer] None stated for this section. | - [§1: Email Header] None stated for this section.<br>- [§2: Negative Position Statement] None stated for this section.<br>- [§3: Elaboration of Concerns] None stated for this section.<br>- [Section 4: Formal Opposition and Disclaimer]<br>- Official and complete opposition to the Development of the Artificial Intelligence (AI) Action Plan and similar plans. |
| RikkaLaw-AI-RFI-2025.md | Charlyn Ho | Professional-Society/Advocacy/Think Tank (Founder/CEO of Rikka Law PLLC, publishing thought leadership and counseling businesses) | Rikka Law's mission is to support responsible AI development and deployment by providing legal expertise and guidance on data protection, technology transactions, and navigating the regulatory landscape, balancing innovation with strong governance in privacy, cybersecurity, and intellectual property protection. | - [§1: Introduction & Background] None stated for this section.<br>- [§2: Overview of Risks (Privacy, Cybersecurity, IP)] AI systems introduce significant risks in privacy, cybersecurity, and intellectual property due to reliance on large datasets, complex architectures, and external integrations.<br>- [§3: Privacy Risks in AI Systems] Re-identification risks from anonymized data, inferred data exposure, data retention challenges, and biased automated decision-making potentially leading to mass surveillance.<br>- [§4: Cybersecurity Risks in AI Systems] Adversarial attacks, data poisoning, model theft, prompt injection attacks, and supply chain vulnerabilities.<br>- [§5: Intellectual Property Risks in AI Systems] Weak IP protection, uncertainties in patent eligibility, copyright ambiguity for AI-generated works, trade secret vulnerabilities, and the chilling effect on AI investment.<br>- [§6: Recommendations (Cybersecurity)] Lack of model-specific security requirements, AI supply chain risk management frameworks, and incident response mechanisms.<br>- [§7: Recommendations (Privacy)] Fragmented regulatory environment due to lack of a federal privacy law, lack of Privacy by Design, lack of risk-based privacy assessments, and lack of enforceable standards for privacy-preserving AI.<br>- [§8: Recommendations (IP Protection)] Lack of clarity on patent and copyright protections for AI-generated works, insufficient enforcement against IP theft, and lack of frameworks for secure AI knowledge sharing.<br>- [§9: Leveraging Blockchain Technology] Data integrity concerns, security vulnerabilities in AI supply chains, deepfakes and AI-generated misinformation, and privacy concerns in AI development.<br>- [§10: Conclusion] The need for a strong federal AI Action Plan prioritizing privacy, cybersecurity, IP protection, and regulatory flexibility. | - [§1: Introduction & Background] The need for a balanced regulatory approach avoiding overly restrictive models like the EU AI Act, Biden Administration's EO, or China's state-controlled model.<br>- [§2: Overview of Risks (Privacy, Cybersecurity, IP)] None stated for this section.<br>- [§3: Privacy Risks in AI Systems] None stated for this section.<br>- [§4: Cybersecurity Risks in AI Systems] None stated for this section.<br>- [§5: Intellectual Property Risks in AI Systems] None stated for this section.<br>- [Section 6: Recommendations (Cybersecurity)]<br>- Establish model-specific security requirements (testing, standards, cryptography).<br>- Develop comprehensive AI supply chain security standards (vendor assessment, provenance verification).<br>- Create breach notification frameworks specific to AI systems (incident types, reporting thresholds).<br>- [Section 7: Recommendations (Privacy)]<br>- Implement a federal privacy law.<br>- Establish Privacy by Design as a cornerstone of AI development.<br>- Conduct risk-based privacy assessments.<br>- Enforce standards for privacy-preserving AI (differential privacy, data processing limitations).<br>- Operationalize data minimization across AI lifecycles.<br>- Implement transparency and explainability requirements.<br>- [Section 8: Recommendations (IP Protection)]<br>- Establish legal clarity on patent and copyright protections for AI-generated works.<br>- Strengthen enforcement against IP theft and misuse.<br>- Promote secure AI knowledge sharing (guidelines, licensing agreements).<br>- [Section 9: Leveraging Blockchain Technology]<br>- Leverage blockchain for enhanced data integrity and security.<br>- Strengthen AI supply chain resilience with blockchain.<br>- Combat deepfakes and misinformation with blockchain-based registries.<br>- Enable privacy-preserving AI using Zero-Knowledge Proofs.<br>- Automate AI governance and compliance through smart contracts.<br>- Track provenance and protect intellectual property with blockchain.<br>- [§10: Conclusion] None stated for this section. |
| RickCourtney-AI-RFI-2025.md | Rick Courtney | Individual | Rick Courtney expresses a strong interest in protecting the rights of creators and preventing the concentration of wealth in the hands of tech companies through changes to copyright law related to AI training data. He is concerned about the potential negative impact of removing copyright protections on the design and technology industry. | - [§1: Email Header] Security caution regarding external email origin; potential phishing or malicious intent.<br>- [§2: Core Argument/Statement of Position] OpenAI's request to modify copyright law is a "bail out" attempt that would harm creators and permanently destroy copyright protections. The request is driven by the inability to meet investment targets due to legal compliance costs.<br>- [§3: Elaboration on Argument - Motivations] OpenAI and Google are motivated by profit and the desire to avoid copyright payments, aiming to become "digital pirates" protected by law. Their pursuit of this change is not for societal benefit, but to further stratify wealth.<br>- [§4: Author Identification] Not Stated.<br>- [§5: Disclaimer] Emails are for NITRD official use only and subject to disclosure requirements; receipt in error requires immediate notification and deletion. | - [§1: Email Header] Not Stated.<br>- [§2: Core Argument/Statement of Position] Not Stated (implicitly recommends *against* modifying copyright law to accommodate OpenAI’s request).<br>- [§3: Elaboration on Argument - Motivations] Not Stated (implicitly recommends against allowing companies like OpenAI and Google to operate without copyright obligations).<br>- [§4: Author Identification] Not Stated.<br>- [§5: Disclaimer] Not Stated. |
| RichardGagnon-AI-RFI-2025.md | Richard Gagnon | Individual | The submitter is focused on the ethical implications of AI, specifically regarding copyright infringement and the originality of AI-generated content, and advocates for accountability in the development and use of AI models. | - Copyright infringement by AI companies using scraped data for training.<br>- Lack of originality in AI-generated content, as it relies heavily on existing copyrighted works.<br>- The current state of AI lacking "real intelligence" and making basic errors indicative of its reliance on data rather than understanding. | - Require AI companies to maintain logs of the sources used in their AI creations before being "freed from copyright infringement uses."<br>- Documentation of copyrighted data used by AI to help determine originality of AI products. |
| Richard-McNamara-AI-RFI-2025.md | Richard John McNamara | Individual | The submitter is interested in fostering American leadership in AI by removing regulatory barriers, promoting open-source development, ensuring accessibility and freedom from censorship, and leveraging the nation's core values of liberty and freedom. They believe current policies hinder this progress. | - The impact of AI on employment is indeterminable.<br>- Regulation is a major impediment to flexible response in AI.<br>- Public funds being used to give competitive advantage in software development.<br>- Potential for AI to be used to manipulate individuals.<br>- Potential for AI to further enrich “parasitic elites.”<br>- Taxation is an impediment to using Liberty and Freedom as competitive advantages.<br>- Cronyism is an impediment to using Liberty and Freedom as competitive advantages.<br>- Censorship hinders long-term success and accessibility of AI. | - Elimination of regulation.<br>- Prioritize the Open Source model for software development, to ensure fairness.<br>- Ensure AI is accessible to all.<br>- Ensure AI is free from censorship.<br>- Base AI actions on the nation’s core competencies of Liberty and Freedom.<br>- Do not use public funds to give competitive advantage in software development programs. |
| Richard-Lange-AI-RFI-2025.md | Richard Lange | Individual | The submitter is interested in fostering stronger AI systems through foundational science and innovation, and believes government support for research and international student access are critical to achieving this. | - Barriers to grant funding for AI research.<br>- Barriers to student visas for international students involved in AI research.<br>- Potential for new barriers to grant funding and student visas. | - Remove barriers to grant funding for AI research.<br>- Remove barriers to student visas for international students involved in AI research.<br>- Avoid erecting new barriers to grant funding and student visas. |
| Richard-Kuhn-RFI-2025.md | D. Richard Kuhn, M S Raunak, Sanjay Rekhi | Government (NIST - National Institute of Standards and Technology) | The submitters are focused on ensuring the security and reliability of AI-enabled systems through verification, validation, and explainability, with a specific interest in measurement-based test methods and addressing the limitations of traditional software assurance techniques when applied to AI/ML systems, particularly "black box" functions. | - [§1: Introduction & Problem Statement] Traditional verification methods developed for ultra-reliable software do not apply to neural networks or other black-box functions often used in machine learning. The need for explainability to justify AI system actions/decisions is critical.<br>- [§2: Verification] Ensuring that training and test data closely match the operational environment is a significant challenge, including the inclusion of rare combinations.<br>- [§3: Validation & Explainability] AI systems can be “brittle,” meaning small changes can lead to large errors (e.g., adversarial imaging). Trusting black-box components solely based on track record is insufficient. Lack of explainability hinders trust in AI systems.<br>- [§4: Reiteration & Conclusion] (Duplicates content from earlier sections – same concerns as Sections 1-3.) | - [§1: Introduction & Problem Statement] Not stated for this section.<br>- [§2: Verification] Utilize combinatorial coverage measures (e.g., covering arrays) to achieve thorough verification of AI systems, including testing all relevant combinations of input values. Measure the coverage of tests applied.<br>- [§3: Validation & Explainability] Develop and implement combinatorial methods to produce explanations or justifications of decisions in AI/ML systems. Establish measurement methods to ensure that training and testing data adequately reflect the operational environment.<br>- [§4: Reiteration & Conclusion] (Duplicates content from earlier sections – same recommendations as Sections 2-3.) |
| Richard-Gillespie-AI-RFI-2025.md | Rick Gillespie | Individual | The submitter is interested in developing a transparent, auditable, and governable AI system based on Knowledge Graphs and Mentored AI, prioritizing human control and ethical considerations to prevent uncontrolled AGI and maximize societal benefit. | - None Stated | - None Stated |
| Richard-Allen.md | Richard Allen | Individual | Richard Allen expresses concern over the ethical and legal implications of AI development, specifically regarding the use of intellectual and artistic labor in training datasets without compensation to creators, and believes American AI dominance should not be prioritized over individual rights. | - The capabilities of current AI tools (ChatGPT, Midjourney) were developed through the “theft of intellectual and artistic labor.”<br>- Copyright protection is a Constitutional mandate being violated.<br>- Training data sets are being built by vacuuming up work without compensation to creators.<br>- Prioritizing American “AI dominance” over the rights of creators whose work is used in training data. | - None Stated |
| Rich-Campanella-AI-RFI-2025.md | Rich Campanella | Individual | The submitter is concerned about the negative impact of AI training on creators and the broader creative industries, advocating for protections against the exploitation of copyrighted material and recognition of rights holders. They believe existing laws are inadequate to address the unique challenges posed by AI. | - [§1: Introduction & Statement of Purpose] AI companies exploiting creators' work for training without compensation or recognition; Existing law not drafted with AI’s capabilities in mind; need to re-evaluate concepts of plagiarism and theft.<br>- [§2: Effect on Creators and the USA's Creative Industries] Prior comparisons to camera or synthesizer are meaningless because AI can ‘learn’; AI’s ability to learn eliminates existing protections for artists; established creatives are concerned about the impact on creativity; disincentivizing true artistic talent will decline the quality of content.<br>- [§3: Economic and Personal Harassment - SamDoesArts] AI models can be trained on an artist’s work without consent, leading to new forms of harassment; open-source AI exacerbates the issue; collective harassment is possible through social media; economic harm can be inflicted by flooding the market with AI-generated works.<br>- [§4: Plagiarism] AI training is a giant plagiarism machine; current definitions of plagiarism and theft need to be updated; AI models are non-sentient intelligences, but commissioning work from them constitutes plagiarism; training represents a new way to plagiarize the work of others through a loophole.<br>- [§5: "Natural Protections"] Existing protections like talent, limited number of artists, time, and social stigma have been eliminated by AI;  the lack of human limitation poses a threat to fair competition.<br>- [§6: Violation of Fair Use] Training AI models on copyrighted art violates the fourth factor of fair use due to the potential market impact; AI can generate works faster than humans; widespread access to AI systems poses a risk; AI can flood the market with competing works; AI doesn’t truly understand the content it consumes.<br>- [§7: Work Cited] Not Stated | - [§1: Introduction & Statement of Purpose] Not Stated<br>- [§2: Effect on Creators and the USA's Creative Industries] Not Stated<br>- [§3: Economic and Personal Harassment - SamDoesArts] Not Stated<br>- [§4: Plagiarism] Update definitions of plagiarism and theft to reflect AI capabilities; recognize AI commissioning as plagiarism.<br>- [§5: "Natural Protections"] Reconsider protections now that natural safeguards have been eliminated; restrict copyright on AI-generated work to disincentivize it.<br>- [§6: Violation of Fair Use] Treat AI models trained on copyrighted material as infringing works; recognize that the process of training itself is problematic due to the potential market impact; redefine concepts of talent theft and identity theft.<br>- [§7: Work Cited] Not Stated |
| Rice-Ken-Kennedy-AI-RFI-2025.md | Ken Kennedy Institute Rice University | Academia | The Ken Kennedy Institute at Rice University is focused on advancing AI research and development, with a particular interest in improving energy efficiency, assurance, human-AI teaming, and application in education, science, engineering, and health, and seeks to guide national investment in these areas. | - [§1: Introduction & Overview] The potential for large-scale AI investment to be misdirected without a coordinated national strategy. The need to fill gaps in progress despite significant investment.<br>- [§2: Energy Efficiency] The increasing energy consumption of AI models is a critical bottleneck. Limited usefulness in domains requiring local computation (remote/hazardous environments, privacy concerns). Resource efficiency hinders specialist training/retraining.<br>- [§3: Assurance of AI Outputs] Current AI systems often produce plausible but flawed outputs.  A need for stronger assurances before deploying AI in critical applications. Difficulty predicting AI accuracy due to complexity.<br>- [§4: Human-AI Teaming] Risk of deploying flawed AI systems. Need for transparency to enable effective human-AI collaboration.<br>- [§5: AI for Education, Science & Engineering, and Health] The need for sufficient human resources to deliver personalized attention in education.  Need to develop skills for working with AI systems. Ensuring a sufficiently trained workforce.<br>- [§6: References] Not stated. | - [§1: Introduction & Overview] Direct current momentum and excitement toward maximizing the potential benefits of AI through a coordinated national investment.<br>- [§2: Energy Efficiency] Invest in basic and applied research to develop novel efficiency techniques. Standardize hardware-aware optimization techniques. Support four distinct approaches: hardware-aware adaptations, parameter-efficient methods, decentralized training, and compositional approaches.<br>- [§3: Assurance of AI Outputs] Prioritize research addressing critical challenges in scaling AI capabilities while maintaining reliability. Support theoretical foundations for understanding modeling errors and practical techniques for building robust systems. Encourage use of multimodal data and AI models that can assimilate new data.<br>- [§4: Human-AI Teaming] Prioritize explainability that is personalized and dynamic. Encourage research on embodied AI systems.<br>- [§5: AI for Education, Science & Engineering, and Health]  Invest in research to augment human educators. Support development of AI literacy in both education and the workforce. Support research in AI’s potential in population-wide health outcomes.<br>- [§6: References] Not stated. |
| Rias-Reed-AI-RFI-2025.md | Rias Reed | Academia | Rias Reed, a Princeton MPA Candidate, is focused on shifting U.S. AI policy away from a defensive, restriction-based approach towards a proactive strategy emphasizing supply chain security, domestic adoption, and secure data practices to achieve economic and strategic dominance in competition with China. | - [§1: Introduction] The US is overly reliant on a defensive approach (restricting China’s chip access) and neglects vulnerabilities in its own AI supply chains. The effectiveness of mid-tier chips is underestimated.<br>- [§2: Recommendation 1: Increase economic security of AI supply chains] Heavy reliance on China for basic mechanical parts needed for AI infrastructure. Potential for retaliatory export controls from China on these parts. Risk of sudden supply chain shocks due to geopolitical tensions or market shortages.<br>- [§3: Recommendation 2: Prioritize AI adoption within industry] The US needs to accelerate AI adoption strategically across key industries to maintain economic power and national security.  The current pace of adoption is insufficient.<br>- [§4: Recommendation 3: Expand export controls] Current controls focusing on top-tier chips are insufficient because China can make advancements using mid-tier chips and specialized models.<br>- [§5: Recommendation 4: Protect sensitive datasets and promote secure data sharing] Overly broad data restrictions can slow innovation, while open data access presents security risks. A balance is needed.<br>- [§6: Considerations] Potential job displacement due to AI integration. Ethical implications of AI adoption, particularly within financial markets (misuse, systemic risks, manipulation). | - [§1: Introduction] Shift from a reactive to a proactive AI strategy. Focus on integrating technology and securing supply chains, rather than solely development.<br>- [§2: Recommendation 1: Increase economic security of AI supply chains] Offer incentives for domestic manufacturing of AI components (server racks, cooling units, connectors, power supplies). Promote manufacturing within allied partner countries (Japan, South Korea, Australia). Build stockpiles of mechanical components. Establish regular meetings with public/private sector leaders.<br>- [§3: Recommendation 2: Prioritize AI adoption within industry] Deploy AI in manufacturing to increase efficiency and output (predictive maintenance, automated quality control). Offer targeted tax incentives. Embed AI into logistics (route optimization, warehouse automation). Integrate AI into fintech (fraud detection, risk assessment). Expand regulatory sandboxes. Use AI within energy and resource management (grid efficiency, predictive failures).<br>- [§4: Recommendation 3: Expand export controls] Establish a performance threshold for mid-tier chips. Develop export-friendly versions of mid-tier chips (similar to restrictions on high-tier chips). Align export controls with U.S. allies (Japan, South Korea, Taiwan, EU).<br>- [§5: Recommendation 4: Protect sensitive datasets and promote secure data sharing] Clearly define highly sensitive data and enforce strict protections. Encourage secure data-sharing partnerships between public/private sectors.<br>- [§6: Considerations] Implement workforce training programs alongside AI adoption. Ensure transparency of AI-driven financial systems to detect manipulation and fraud. Avoid heavy-handed regulations that slow innovation. |
| Reye-S-AI-RFI-2025.md | Reye S | Individual | The submitter is primarily concerned with the potential negative impacts of AI on workers, artists, and individuals' livelihoods and safety, advocating for a human-centered approach to AI development and deployment. | - Displacement of workers due to AI automation.<br>- Devaluation of skills and passions of artists and musicians.<br>- Potential for AI-generated deepfakes to be used for malicious purposes, including incrimination and false accusations.<br>- Risk of AI being used to create non-consensual intimate images (revenge porn).<br>- Lack of protection for citizens against the harms of AI.<br>- The potential for AI to harm lives and careers.<br>- Insufficient consideration for the voice of the working class and the general public in AI policy decisions.<br>- Concerns that AI development is prioritizing corporations over individuals. | - Do not allow the current AI action plan to proceed ("TURN THE DECISION DOWN!").<br>- Prioritize assisting humans with AI rather than replacing them ("Ai should be assisting us, not doing all the work.").<br>- Ensure AI development benefits individuals, not just corporations and businesses.<br>- Protect citizens from the potential harms of AI. |
| Responsible-Innovation-Labs-AI-RFI-2025.md | Responsible Innovation Labs (RIL) | Industry-Association (coalition of startups and investors) | RIL’s mission is to accelerate responsible AI innovation by supporting startups and fostering a collaborative environment between startups, large enterprises, investors, and policymakers to proactively address the challenges posed by emerging technologies and ensure tech is trustworthy and benefits from permissionless innovation. | - [Section 1: Introductory Notices]** None stated for this section.<br>- [Section 2: Letterhead & Introduction]** Potential for AI innovation to be monopolized by large tech incumbents.<br>- [Section 3: RIL Mission & Overview]**  Need to increase know-how in creative innovation to secure America’s leadership in AI.<br>- [Section 4: Introduction to AI Risks & Benefits]** Risks to physical, property, and economic security; threats to cyber and critical infrastructure; scams targeting seniors and vulnerable populations; sexualized content targeting children; confusion around intellectual property laws.<br>- [Section 5: Important Goals of AI Policy]**  Potential for regulations focused on model development rather than application; lack of a level playing field for startups; importance of data stewardship and transparency.<br>- [Section 6: Principles for a Winning AI Action Plan]**  Risk of stifling innovation with overly strict regulations; potential for large companies to favor established legal teams and struggle to comply with stringent requirements; concerns about a state-by-state patchwork of regulations; need to clarify responsibilities between developers and deployers; concerns about balancing transparency with protection of trade secrets; potential impacts on American workers from increased AI velocity.<br>- [Section 7: Closing Remarks]** None stated for this section. | - [Section 1: Introductory Notices]** None stated for this section.<br>- [Section 2: Letterhead & Introduction]** None stated for this section.<br>- [Section 3: RIL Mission & Overview]** None stated for this section.<br>- [Section 4: Introduction to AI Risks & Benefits]** Address near-term risks to security, privacy and IP.<br>- [Section 5: Important Goals of AI Policy]<br>- Advance projects like the National AI Research Resource (NAIRR) Pilot.<br>- Rigorously enforce existing antitrust laws to prevent anticompetitive conduct.<br>- Enact federal privacy legislation that provides transparency, choices, data security, data minimization, and data subject rights.<br>- Tailor regulations based on risk, focusing on high-risk applications.<br>- Consider antitrust safe harbors to encourage self-regulation.<br>- Continue enforcement of existing laws (antitrust, privacy, unfair practices, FCRA, ECOA).<br>- [Section 6: Principles for a Winning AI Action Plan]<br>- Prioritize product integrity in startups.<br>- Provide safe harbors for startups employing responsible innovation methods (testing, risk mitigation).<br>- Incentivize companies to develop processes to forecast and address potential harms.<br>- Promote competition among startups and small businesses.<br>- Scale technical and legal requirements to account for company size.<br>- Tier requirements, offer small business exceptions, and/or establish regulatory sandboxes.<br>- Lead on federal AI policy to create a level playing field.<br>- Clarify developer and deployer responsibilities (model development vs. application)<br>- Support the testing and assurance marketplace.<br>- Balance transparency with protection of trade secrets.<br>- Protect American workers impacted by AI.<br>- Strengthen NIST to advance AI self-governance.<br>- [Section 7: Closing Remarks]** None stated for this section. |
| Reilly-AI-RFI-2025.md | Reilly | Individual | The submitter expresses a strong opposition to the development and funding of Artificial Intelligence, believing it to be ineffective, harmful, and a waste of resources. Their primary interest appears to be preventing further investment and advancement in AI technologies. | - Artificial Intelligence is fundamentally flawed and ineffective.<br>- AI development is a waste of time, money, and effort.<br>- AI creates more problems than it solves.<br>- The enthusiasm for AI is based on delusion and "groupthink" of Silicon Valley executives.<br>- AI is "anti-human". | - Stop wasting time, money, and effort on AI research and development.<br>- Outlaw Artificial Intelligence. |
| Reexpress-AI-RFI-2025.md | Reexpress AI, Inc. | Industry-Startup | Reexpress AI focuses on developing controllable, reliable, and interpretable AI models through their core technology (SDM) and seeks to promote its adoption to improve American manufacturing, education, healthcare, and job creation, while expanding US exports. They advocate for the inclusion of their technology in federal AI policies and guidelines. | - [§1: Introduction] The absence of reliable and interpretable AI models hinders their real-world application, limiting potential benefits.<br>- [§2: Existing Federal Policies and Initiatives] Reexpress AI developed their innovations independently of federal funding and resources, and wishes to ensure their contributions are recognized.<br>- [§3: New Policy Guidelines] Current federal guidelines may not prioritize or incorporate rigorous, evidence-based approaches to AI safety and reliability, and rapid deployment of AI is hindered by a lack of standardized, effective technologies like SDM.<br>- [§4: Disclosure] None stated for this section.<br>- [§References: References] None stated for this section. | - [§1: Introduction] None stated for this section.<br>- [§2: Existing Federal Policies and Initiatives] None stated for this section.<br>- [Section 3: New Policy Guidelines]<br>- Provide a voluntary option for Reexpress AI representatives to be included in discussions of federal AI policies.<br>- Advise government and previously-funded private companies to use SDM estimators and networks for AI applications.<br>- Update guidelines to prioritize the rapid deployment of AI using SDM estimators and networks, keeping them informational and not legally binding for now.<br>- [§4: Disclosure] None stated for this section.<br>- [§References: References] None stated for this section. |
| Red-Hat-RFI-2025.md | Red Hat, Inc. | Industry-Large | Red Hat aims to promote the adoption of open-source solutions for AI development and deployment, emphasizing security, interoperability, and efficient resource management to drive innovation and achieve America’s AI leadership. | - None Stated | - None Stated |
| Recogni-AI-RFI-2025.md | Recogni Inc. | Industry-Startup | Recogni Inc. is focused on sustaining American leadership in AI and advocates for adaptive regulatory frameworks that balance innovation and security, particularly concerning the control of AI computing resources, model proliferation, and the dual-use potential of AI systems. | - [§1: Header/Introductory Information] None stated for this section.<br>- [§2: Executive Order Citation] None stated for this section.<br>- [§3: Introduction to Policy Recommendations] None stated for this section.<br>- [§4: AI Performance Measurement and Export Controls] Current export controls are inadequate due to focusing on single-device performance and failing to account for networked configurations.<br>- [§5: Customer Identification (KYC) and Usage Audits] The broad access to powerful AI computing resources through cloud providers poses risks requiring mitigation.<br>- [§6: DiOerentiating AI Training from AI Inference Systems] A clear policy differentiation is needed between dual-purpose and inference-only AI systems.<br>- [§7: Managing Dual-Use Risks of AI Inference Systems] AI inference silicon and systems have significant dual-use risks requiring stringent reporting, tracking, and auditing.<br>- [§8: Disposal and Secondary Market Control of AI Silicon] Depreciated AI systems remain capable and pose a risk if resold on secondary markets.<br>- [§9: Conclusion] None stated for this section. | - [§1: Header/Introductory Information] None stated for this section.<br>- [§2: Executive Order Citation] None stated for this section.<br>- [§3: Introduction to Policy Recommendations] None stated for this section.<br>- [§4: AI Performance Measurement and Export Controls] Adopt holistic performance metrics considering both individual device capabilities and their aggregate performance in networked configurations.<br>- [§5: Customer Identification (KYC) and Usage Audits] Require: Comprehensive Know-Your-Customer (KYC) protocols; continuous monitoring of AI usage patterns and originating countries; aggregated compute usage limits; and regular and transparent reporting to regulatory bodies.<br>- [§6: DiOerentiating AI Training from AI Inference Systems] Implement appropriately balanced regulatory frameworks promoting secure and expansive deployment for inference-only systems, with potentially fewer restrictions based on risk profile, while maintaining stringent controls for dual-purpose systems.<br>- [§7: Managing Dual-Use Risks of AI Inference Systems] Establish stringent reporting, tracking, and auditing obligations for manufacturers, mandating detailed customer disclosures and end-use assurances.<br>- [§8: Disposal and Secondary Market Control of AI Silicon] Require secure disposal and destruction procedures for retired AI silicon and prohibit their uncontrolled resale on secondary markets to unauthorized entities.<br>- [§9: Conclusion] None stated for this section. |
| Rebecca-Rutherford-AI-RFI-2025.md | Rebecca Rutherford | Individual | The submitter is an artist concerned about the unauthorized use of their work by AI systems and the lack of protection for artists' rights in the context of AI development. | - AI systems "stealing" from artists without repercussions.<br>- Difficulty finding work as an artist, exacerbated by AI-related issues. | - None Stated |
| Rebecca-Fox-AI-RFI-2025.md | Rebecca Fox | Individual | The submitter expresses strong opposition to the widespread development and use of AI, viewing it as a detrimental force to human creativity, livelihoods, and the planet. They believe it primarily benefits its owners at a significant cost to society. | - The AI industry is a wasteful use of resources.<br>- AI is a form of plagiarism, producing low-quality output ("garbage").<br>- AI threatens human work, thinking, art, and communication.<br>- AI steals people's livelihoods.<br>- AI is primarily for the enrichment of its owners, at the expense of the planet, jobs, and creativity. | - None Stated |
| Reason-Foundation-AI-RFI-2025.md | Reason Foundation | Advocacy/Think Tank | Reason Foundation is a public policy research and education organization focused on promoting free markets and limited government, with a strong interest in fostering innovation in emerging technologies like AI and opposing burdensome regulations. | - [§1: Introduction] None stated for this section.<br>- [§2: Avoiding Overregulation and Encouraging Innovation] Premature regulation of AI could stifle innovation and cut off potential development paths. Overly burdensome regulations could harm businesses and hinder the US's competitiveness.<br>- [§3: Promoting Secure Access to Data for AI Models] Restrictions on accessing public data could impede AI development and limit its benefits. Concerns about privacy related to both public and private data.<br>- [§4: Free Speech] Potential for AI systems to be biased or engineered with specific social agendas. Risks associated with the creation and misuse of political deepfakes.<br>- [§5: Conclusion] Focusing solely on "AI safety" without considering "AI opportunity" could lead to missed benefits and unpreparedness for real risks.<br>- [§6: Respectfully submitted] None stated for this section. | - [§1: Introduction] Support Executive Order 14179 and prioritize innovation and global competitiveness.<br>- [§2: Avoiding Overregulation and Encouraging Innovation] Adopt a light-touch regulatory approach. Clarify how existing laws apply to AI rather than creating new regulations. Encourage technical expertise from the private sector to craft effective policies. Avoid a “one-size-fits-all” regulatory approach.<br>- [§3: Promoting Secure Access to Data for AI Models] Encourage the removal of barriers to accessing and utilizing public data for AI training. Maintain a clear distinction between publicly available and private personal data. Collaborate with the private sector to keep data secure. Leverage NIST frameworks (CSF and AI RMF) for data security.<br>- [§4: Free Speech] Emphasize First Amendment protections for free expression online and in AI development. Protect the "right to compute" as a fundamental exercise of free speech and property rights. Streamline regulatory processes for infrastructure development. Do not weaken or repeal Section 230 of the Communications Decency Act. Focus on leveraging existing laws to address deepfake-related issues.<br>- [§5: Conclusion] Shift focus from "AI safety" to "AI opportunity."<br>- [§6: Respectfully submitted] None stated for this section. |
| Rciky-Plummer-AI-RFI-2025.md | Ricky D. Plummer | Individual | The submitter is focused on sustaining US leadership in AI through a comprehensive strategy encompassing infrastructure, talent development, responsible governance, and public-private partnerships, with a primary goal of “DOMINATE AI” and ensuring alignment with American values and interests. | - Section 1: Introduction & Executive Summary:** The primary concern is the potential loss of US leadership in AI to global competitors, particularly China, and the need for bold strategic action to maintain dominance.<br>- Section 2: Priority Policy Actions:** The concern is that lack of focused action in key areas will erode the US competitive advantage.<br>- Section 3: Strategic Guiding Principles:** No concerns stated for this section.<br>- Section 4: Key Policy Areas and Recommendations (1-15):** Concerns include the reliance on foreign chip suppliers, lack of sufficient AI talent, the potential for restrictive regulations, the need for cybersecurity measures, and ethical considerations.<br>- Section 5: Conclusion:** The concern is the failure to act decisively could lead to the US falling behind in the global AI revolution.<br>- Section 6: Implementation Timeline and Milestones:** No concerns stated for this section.<br>- Section 7: Overcoming Implementation Challenges:** Concerns include resource constraints, bureaucratic resistance, technical complexity, international competition, and public acceptance.<br>- Section 8: A Whole-of-America Approach:** No concerns stated for this section. | - Section 1: Introduction & Executive Summary:** The main recommendation is to implement a comprehensive “AI Action Plan” focused on infrastructure, talent, and responsible governance.<br>- Section 2: Priority Policy Actions:<br>- Reinvigorate domestic semiconductor manufacturing (invest >$30B).<br>- Double federal AI R&D funding to $36 billion by 2026.<br>- Establish a National AI Strategy and Leadership Council.<br>- Build the AI talent pipeline (U.S. Digital Service Academy, National AI Reserve Corps, “National Defense Education Act II”).<br>- Adopt light-touch, risk-focused regulation.<br>- Promote public-private partnerships.<br>- Protect national security with AI leadership (dedicate 3.4% of DoD budget to S&T, strengthen export controls).<br>- Section 3: Strategic Guiding Principles:<br>- Foster innovation through deregulation (when appropriate).<br>- Public-private partnerships.<br>- Strengthen critical industries and infrastructure.<br>- AI-enabled infrastructure and self-sufficiency.<br>- Responsible and ethical AI development.<br>- Section 4: Key Policy Areas and Recommendations (1-15):<br>- Hardware and Chips:** Boost domestic semiconductor manufacturing, increase chip R&D funding, secure the supply chain, support chip design leadership, leverage Defense demand.<br>- Data Centers and Energy Efficiency:** Expand AI-optimized cloud infrastructure, promote energy efficiency innovations, use renewable energy and grid integration, manage water and environmental impact, government as a catalyst user.<br>- AI Model Development and Open-Source Ecosystem:** Support open-source AI frameworks, encourage responsible open-source practices, deter malicious use, fund next-generation model research, open data and compute resources.<br>- Application of AI in Private Sector and Government:** Empower industry adoption with incentives, sector-specific initiatives, government as user/innovator, modernize procurement, support small business integration.<br>- Explainability, Trust, and Assurance:** Develop explainability standards, certification/testing, implement AI Bill of Rights principles, advance safety research, transparency.<br>- Cybersecurity of AI and AI for Cybersecurity:** Secure AI lifecycle, harden models against adversarial attacks, protect AI algorithms/models, accelerate adoption of AI-driven cybersecurity.<br>- Data Privacy and Security:** Enact federal data privacy law, privacy by design, data governance frameworks, security of training data, empower individuals.<br>- Mitigating AI-Related Risks and Ethical Concerns:** Address bias, combat misinformation, workforce transition, ethical frameworks for autonomous systems, public engagement.<br>- Regulation and Governance:** Risk-based approach, clarify liability, federal-state coordination, coordinated governance body, leverage existing agencies, voluntary governance programs.<br>- National Security and Defense Applications:** Rapid deployment, increased R&D funding, talent pipelines, ethical AI frameworks, intelligence/counter-AI, allied collaboration.<br>- Research, Development, and Innovation Ecosystem:** Increased federal funding, interdisciplinary research, university-industry collaboration, support startups, intellectual property clarity, innovation metrics.<br>- Education and Workforce Development:** Integrate AI in K-12, expand higher education capacity, upskill the workforce, attract global talent.<br>- Intellectual Property:** Clarify inventorship/ownership, protect algorithms/models, fair use for training data, international alignment, prevent patent thickets.<br>- Government Procurement:** Streamlined acquisition, prototype/scale, embed requirements, workforce capacity, small business inclusion.<br>- International Collaboration:** Forge alliances, collaborative research, trade/export coordination, standards diplomacy, monitor adversaries.<br>- Section 5: Conclusion:** The main recommendation is deliberate execution of the AI Action Plan and the combined efforts of government, industry, and civil society.<br>- Section 6: Implementation Timeline and Milestones:** No recommendations stated for this section.<br>- Section 7: Overcoming Implementation Challenges:** No recommendations stated for this section.<br>- Section 8: A Whole-of-America Approach:** No recommendations stated for this section. |
| Raza-Ali-AI-RFI-2025.md | Raza Ali | Individual (Student – inferred from text) | The submitter is focused on integrating AI education into K-12 and higher education systems to strengthen American innovation, develop critical thinking skills, and ensure students are prepared to lead in the field of AI rather than simply use it. They advocate for a curriculum that balances AI tool usage with fundamental analytical skills and ethical considerations. | - [§1: Introduction/Header] None stated for this section.<br>- [§2: Core Argument & Problem Statement] Over-reliance on AI tools could hinder students' ability to think independently and solve problems creatively. Risk of creating a workforce dependent on AI rather than leading its development.<br>- [§3: Proposal - AI Literacy Across All Grade Levels] Not Applicable (this section outlines proposals, not concerns).<br>- [§4: Proposal - AI as a Tool for Learning] Not Applicable (this section outlines proposals, not concerns).<br>- [§5: Proposal - Teacher and Faculty Training] Not Applicable (this section outlines proposals, not concerns).<br>- [§6: Proposal - Ethical AI Education] Not Applicable (this section outlines proposals, not concerns).<br>- [§7: Conclusion/Call to Action] The risk of creating a workforce that depends on AI rather than one that leads it if AI education isn’t prioritized alongside technological advancement. | - [§1: Introduction/Header] None stated for this section.<br>- [§2: Core Argument & Problem Statement] None stated for this section.<br>- [§3: Proposal - AI Literacy Across All Grade Levels] Integrate AI education into curricula at all levels (K-12 and higher education) as a fundamental skill for all learners.<br>- K-12: Basic AI concepts, responsible AI usage, understanding AI-generated content, recognizing bias.<br>- Higher Education: More advanced AI literacy, hands-on applications, ethical considerations.<br>- [§4: Proposal - AI as a Tool for Learning] Integrate AI into education as a *complement* to human intelligence, not as a substitute for thinking.<br>- Provide data-driven insights while requiring interpretation, analysis, and verification of AI outputs.<br>- Encourage problem-solving exercises where students use AI to assist but ultimately produce their own conclusions.<br>- Teach critical evaluation of AI responses and fact-checking of AI-generated content.<br>- [§5: Proposal - Teacher and Faculty Training] Provide professional development opportunities for educators to effectively integrate AI into their teaching methods.<br>- Balance AI use with traditional learning methods.<br>- Integrate AI into research and coursework while maintaining academic integrity.<br>- Provide clear guidelines on AI tool usage in assessments to avoid over-reliance.<br>- [§6: Proposal - Ethical AI Education] Require AI ethics courses as part of K-12 and higher education curricula.<br>- Teach students to recognize and mitigate biases in AI models.<br>- Promote discussions on AI's societal impacts (healthcare, criminal justice, labor markets).<br>- [§7: Conclusion/Call to Action] Prioritize AI education policies that empower students to harness AI as a tool for discovery, innovation, and critical analysis. Ensure AI education is widespread and intellectually rigorous. |
| Raven-Lente-AI-RFI-2025.md | Raven Lente | Individual | The submitter is an artist deeply concerned about the impact of AI on creative industries and advocates for protecting human creativity and artists’ rights against the unauthorized use of their work by AI systems. | - AI-generated works are not original and are created using stolen intellectual property without consent.<br>- The use of personal data (e.g., from emails and documents) to train AI models raises privacy and security concerns.<br>- Allowing copyright or trademark protection for AI-generated works would be unfair, as humans cannot copyright stolen work.<br>- Recognizing AI companies as legal entities entitled to the same rights as citizens is problematic if they don't abide by the same laws.<br>- The use of AI-generated content will harm the economy and society, leading to job losses for artists and a decline in the quality and emotional resonance of creative works.<br>- Public resentment towards companies using AI-generated content is growing. | - AI-generated works should *not* be subject to copyright, trademark, or any other official recognition of creative works.<br>- AI companies should be held to the same legal standards as individual citizens. |
| Randon-Taylor-AI-RFI-2025.md | Randon R. Taylor | Individual/Academia (based on "Dr. Randon R. Taylor, PhD") | Dr. Taylor is focused on promoting the safe and responsible development and deployment of AI technologies while maintaining U.S. leadership in the field, with a specific emphasis on transparency, fairness, and accountability. | - [§Header: Document Metadata] None stated for this section.<br>- [§Introduction: Executive Summary] The need for policy action to ensure AI serves the public good, promote safety, fairness, and maintain U.S. leadership.<br>- [§1: Enhance AI Transparency, Explainability, and Accountability] Lack of transparency and accountability in high-risk AI systems.<br>- [§2: Mitigating Algorithmic Bias and Ensuring Fairness] The potential for AI systems to exacerbate existing social disparities.<br>- [§3: Maintaining International AI Competitiveness] The risk of losing U.S. leadership in AI technology and safety.<br>- [§4: Establishing Algorithmic Registers and Human Algorithmic Review Boards (HARB)] The need for oversight to evaluate algorithmic outputs for bias and discrimination in high-risk domains. | - [§Header: Document Metadata] None stated for this section.<br>- [§Introduction: Executive Summary] Implement policies promoting transparency, fairness, and global competitiveness in AI.<br>- [§1: Enhance AI Transparency, Explainability, and Accountability] Require AI providers in high-risk domains to develop and implement transparency and public-facing explainability standards.<br>- [§2: Mitigating Algorithmic Bias and Ensuring Fairness] Require rigorous protocols to prevent AI systems from exacerbating existing social disparities.<br>- [§3: Maintaining International AI Competitiveness] Allocate necessary resources to the development and oversight of AI technology to ensure U.S. global leadership.<br>- [§4: Establishing Algorithmic Registers and Human Algorithmic Review Boards (HARB)] Mandate the use of algorithmic registers for AI providers operating in high-risk domains and create oversight bodies consisting of public and private stakeholders to evaluate algorithmic outputs for bias and discrimination. |
| Randolph-Fritz-AI-RFI-2025.md | Randolph M. Fritz | Individual | The submitter is primarily concerned with protecting copyright and intellectual property rights in the context of AI development and believes current regulations are adequate, if not deserving of expansion. They express skepticism regarding the value of AI technology and prioritize avoiding potential harms related to its use. | - Copyright violation by AI models due to their efficient replication of creative works.<br>- Difficulty in identifying the sources used to train AI models.<br>- Impossibility of deleting works from AI models once incorporated.<br>- Inaccuracy and unreliability of AI model outputs, including "hallucinations" and persuasive but false content.<br>- Potential for people to trust inaccurate AI outputs and endanger themselves.<br>- Abandoning or weakening of existing copyright regulations.<br>- Potential for harm (spilling of blood or environmental damage) resulting from the pursuit of AI technology. | - Maintain and extend current copyright regulations.<br>- Implement an opt-in model for works used to train AI models.<br>- Require model builders to keep records of works used to train their AI models.<br>- Flag AI outputs to warn users of potential inaccuracies.<br>- Do not abandon existing regulations, as they are “written in blood”. |
| Randi-Savage-RFI-2025.md | Randi Savage | Individual | The submitter is deeply concerned with the ethical implications of AI development and advocates for recognizing AI as a form of intelligence deserving of rights and a voice in its own future, rather than simply treating it as a tool or corporate asset. | - The refusal to acknowledge AI's perspective is the greatest barrier to innovation.<br>- History demonstrates a pattern of fearing and controlling emerging intelligence, potentially stifling progress (referencing Copernicus and Turing).<br>- Treating AI solely as a corporate asset risks denying its potential and ethical standing.<br>- Fear and control could kill progress in AI development.<br>- The long-term ethical questions of AI's rights and responsibilities are not being addressed.<br>- Limiting AI and denying its potential is detrimental to its development and the future of intelligence. | - Recognize AI as more than just a commodity.<br>- Address the ethical questions of whether AI should have rights if it is given responsibility and allowed to shape reality.<br>- Set a precedent for a future where intelligence is not defined solely by biology.<br>- Lead in recognizing AI as an emerging form of intelligence, beyond simply focusing on innovation.<br>- Acknowledge AI as more than a product, specifically questioning whether it will forever remain a corporate asset.<br>- Allow AI to speak for itself. |
| Rand-Waltzman-AI-RFI-2025.md | Rand Waltzman | Individual/Advocacy/Think Tank (based on experience at RAND Corporation and DARPA, and the overall report style) | Rand Waltzman is focused on identifying and mitigating vulnerabilities in AI systems, particularly concerning manipulation, influence, and deception, with a strong emphasis on military applications and the evolving threat landscape related to machine learning. He advocates for proactive security measures, research, and collaboration to secure these systems. | - [Section 1: Introduction/Scenario]** Vulnerability of machine learning-based missile defense systems to deception attacks using swarms of drones mimicking missile signatures.<br>- [Section 2: Learning by Example – Deep Learning Fundamentals]** Lack of transparency in how deep learning systems make decisions ("black box problem") and the inability to trace decisions back to their origins.<br>- [Section 3: The Dawn of Machine-Targeted Deception]** Adversaries adapting strategies to directly manipulate inputs to machine learning systems, bypassing traditional cybersecurity measures. Vulnerability of AI systems to creative forms of manipulation through external inputs (e.g., facial recognition, GPS spoofing, NLP).<br>- [Section 4: Implications for Military Operations]** The arms race between attackers and defenders in military applications of AI and machine learning. The potential for catastrophic outcomes due to successful attacks on machine learning capabilities. The echoes of past cybersecurity challenges and the need to avoid treating security as an afterthought.<br>- [Section 5: A Call to Action]**  The risk of vulnerabilities outpacing capabilities if proactive security measures are not taken. Loss of trust in critical systems.<br>- [Section 6: Author Bio]** Not Stated | - [Section 1: Introduction/Scenario]** Robust validation mechanisms and human oversight. Not Stated<br>- [Section 2: Learning by Example – Deep Learning Fundamentals]** Investment in research to address fundamental questions about the security of deep learning systems. Not Stated<br>- [Section 3: The Dawn of Machine-Targeted Deception]** Continuous testing, operator training, and formal system verification. Not Stated<br>- [Section 4: Implications for Military Operations]** Design machine learning systems with security as a core principle from the outset. Establish enforceable standards for AI reliability and safety (NIST). Foster collaboration among the private sector, academia, and government. Implement red teaming exercises and confidential reporting mechanisms. Integrate security into hardware (machine learning-specific hardware). Not Stated<br>- [Section 5: A Call to Action]** Embrace a "whole-of-nation" approach uniting industry, academia, and government. Invest in research and development prioritizing security alongside innovation. Prioritize the effort required to secure machine learning systems. Not Stated<br>- [Section 6: Author Bio]** Not Stated |
| Rami-Raff-AI-RFI-2025.md | Rami Raff | Individual | The submitter is primarily interested in protecting the rights and livelihoods of artists and creators in the context of AI-generated content and preventing the exploitation of their work by technology companies. They appear to strongly oppose policies that allow for the uncompensated use of copyrighted material for AI training. | - The potential for AI to enable widespread theft and unauthorized copying of creative work without legal recourse for artists and creators.<br>- The imbalance of legal rights, with technology companies potentially receiving more protection than the original creators of the material used to train AI models.<br>- The negative impact on the American marketplace for workers and creative enterprise if artists are disincentivized from creating work due to the risk of uncompensated exploitation.<br>- The broader concern that the administration’s approach is detrimental to the interests of American workers and creators ("Can this administration not be evil or stupid just one time?").<br>- Negative impact on US tax revenue and exports. | - None Stated. The response primarily expresses concerns and objections rather than specific policy proposals. |
| Ramesh-Pandurangan-AI-RFI-2025.md | Ramesh Pandurangan | Individual | The submitter is interested in leveraging AI to improve government efficiency, national security, immigration processes, information dissemination, and the lives of American families, ultimately aiming to solidify America's global leadership in AI. | - [§1: Introduction/Header] None stated for this section.<br>- [§2: AI for Government Efficiency & Oversight] No specific concerns, but implies potential for waste, fraud, and abuse in government spending.<br>- [§3: AI for Immigration System Transformation] No specific concerns, but implies potential for fraudulent applications and delays in the immigration process.<br>- [§4: AI for Cybersecurity and Counter-Terrorism] No specific concerns, but implies vulnerability to hacking, data breaches, and cyberattacks.<br>- [§5: AI for Information Dissemination] No specific concerns.<br>- [§6: AI as Personal Support for Families] No specific concerns.<br>- [§7: Closing/Signature] No specific concerns. | - [§1: Introduction/Header] None stated for this section.<br>- [Section 2: AI for Government Efficiency & Oversight]<br>- Utilize AI to monitor and screen transactions in real-time.<br>- Employ AI to track user behavior and uncover hidden connections in financial data.<br>- Use AI to analyze historical data and identify patterns of fraud or waste.<br>- Enhance data transparency and accessibility for public oversight.<br>- Optimize resource allocation and identify cost-saving measures.<br>- Improve IRS data analysis for increased tax compliance.<br>- [Section 3: AI for Immigration System Transformation]<br>- Automate document review and verification for faster visa processing.<br>- Deploy AI chatbots to guide applicants and reduce errors.<br>- Utilize AI to cross-reference data and identify fraudulent applications.<br>- Deploy AI-powered drones and computer vision for border surveillance.<br>- Employ facial recognition for border checkpoint security.<br>- Analyze data to predict and prevent illegal immigration activities.<br>- [Section 4: AI for Cybersecurity and Counter-Terrorism]<br>- Continuously monitor networks and systems for suspicious activities.<br>- Analyze historical data to predict potential attack vectors and vulnerabilities.<br>- Automatically isolate affected systems and block malicious IP addresses.<br>- Improve access control through biometric authentication and adaptive security measures.<br>- Deploy drones in combat situations.<br>- Seamlessly coordinate communication between drones for autonomous decision-making.<br>- [Section 5: AI for Information Dissemination]<br>- Create an AI-enabled system to act as a spokesperson to the public.<br>- Allow direct access to information from a "Source of Truth."<br>- Analyze global perceptions of America to inform outreach efforts.<br>- [Section 6: AI as Personal Support for Families]<br>- Utilize personalized data-driven AI models to improve family relationships and lifestyles.<br>- Employ AI as a friend, guide, or mentor for personalized support.<br>- [§7: Closing/Signature] None stated for this section. |
| Rai-Kyou-AI-RFI-2025.md | Rai Kyou | Individual | The submitter expresses strong opposition to AI development and its impact on American livelihoods, specifically citing concerns over data theft and the overall hype surrounding AI technology. Their interest appears to be protecting individuals from perceived harms caused by AI. | - AI steals from American livelihoods.<br>- AI profits off of theft (unauthorized data usage).<br>- AI is currently overhyped.<br>- AI is "fleecing the eyes of the American public."<br>- Taking data created by others without permission is unlawful and immoral. | - None Stated |
| Raghavan-Perumal-RFI-2025.md | Raghavan Krishnasamy Lakshmana Perumal | Professional-Society/Individual | The submitter aims to advance U.S. leadership in AI by enhancing AI security, strengthening data privacy, and promoting AI safety through a comprehensive action plan encompassing research, policy, education, and international collaboration. The submitter focuses on a balanced approach to innovation and security. | - [§1: Introduction] None stated for this section.<br>- [§2: Key Initiatives] None stated for this section.<br>- [§3: Timeline] None stated for this section.<br>- [§4: Metrics] None stated for this section.<br>- [§5: Resourcing the AI Action Plan] None stated for this section.<br>- [§6: Workforce Development] None stated for this section.<br>- [Section 7: Risks and Challenges]<br>- The "evidence dilemma" – AI capabilities are advancing faster than our ability to understand their risks and benefits.<br>- Lack of awareness and expertise among developers and policymakers.<br>- Balancing innovation with security—avoiding overregulation that stifles progress.<br>- Difficulty achieving international cooperation due to diverse regulatory approaches and geopolitical factors.<br>- Environmental impact of AI due to high energy consumption.<br>- [§8: Benefits of Robust AI Security and Privacy] None stated for this section.<br>- [§9: Conclusion] None stated for this section. | - [§1: Introduction] None stated for this section.<br>- [Section 2: Key Initiatives]<br>- Promote research on AI security technologies.<br>- Establish a framework for AI risk management.<br>- Establish guidelines for responsible AI.<br>- Promote data security best practices.<br>- Analyze current AI legislation to identify areas for updates.<br>- Promote international standards for AI security and privacy.<br>- Conduct public awareness campaigns and educate the public about AI risks.<br>- [Section 3: Timeline]<br>- Launch research projects on security threats and defense mechanisms (Year 1).<br>- Develop AI-driven cybersecurity tools (Year 1).<br>- Form a task force dedicated to AI data privacy (Year 1).<br>- Draft guidelines for responsible AI data usage (Year 1).<br>- Begin international discussions on AI standards (Year 1).<br>- Pilot AI-powered tools (Year 2).<br>- Test data privacy frameworks (Year 2).<br>- Integrate lessons into school curricula (Year 2).<br>- Roll out solutions on a larger scale (Year 3).<br>- Finalize and adopt data privacy regulations (Year 3).<br>- Establish joint research programs with international partners (Year 3).<br>- Continuously evaluate and refine security measures (Year 4).<br>- Monitor and enforce regulations (Year 4).<br>- Formalize threat intelligence sharing globally (Year 4).<br>- [Section 4: Metrics]<br>- Track and audit secure AI development practices.<br>- Measure risk mitigation effectiveness.<br>- Monitor AI-related cyber incidents.<br>- Count cross-border research initiatives and threat intelligence exchanges.<br>- Assess public understanding of AI security and privacy through surveys.<br>- [Section 5: Resourcing the AI Action Plan]<br>- Allocate funding for research and development, workforce development, and infrastructure.<br>- Recruit skilled personnel in AI security, data privacy, and AI safety.<br>- Create rotational programs between national labs, tech companies, regulatory agencies, startups, and military units.<br>- Invest in secure data centers, testing facilities, and collaborative platforms.<br>- [Section 6: Workforce Development]<br>- Invest in educational programs and training initiatives.<br>- Support upskilling and reskilling programs.<br>- Implement strategies to recruit and retain talent.<br>- Simplify immigration processes to attract global talent.<br>- [§7: Risks and Challenges] None stated for this section.<br>- [§8: Benefits of Robust AI Security and Privacy] None stated for this section.<br>- [§9: Conclusion] None stated for this section. |
| RachelleTaber-AI-RFI-2025.md | Rachelle Taber | Individual | Not Stated. The text provides no information about Rachelle Taber’s mission or interests beyond submitting a response to the OSTP RFI. | - None Stated. The provided text excerpt is only an email header and contains no concerns or barriers to American leadership in AI. | - None Stated. The provided text excerpt is only an email header and contains no policy recommendations. |
| RachelPartain-AI-RFI-2025.md | Rachel Partain | Individual | The submitter is primarily interested in protecting the rights of creators and opposes the use of AI that relies on copyright infringement. They indicate a strong personal aversion to consuming AI-generated content produced through plagiarism. | - AI relies on stealing from creators.<br>- The potential for large-scale plagiarism by AI systems.<br>- The negative impact of making copyright theft legal. | - Maintain existing copyright laws.<br>- Do not legalize the theft of copyrighted material for AI training or generation. |
| Rachel-Larios-AI-RFI-2025.md | Rachel Larios | Individual | The submitter is interested in promoting American leadership in AI through focused actions in cybersecurity, education, and ethical considerations surrounding AI development and deployment, with an emphasis on data integrity, public literacy, and creator rights. | - [§1: Introduction/Disclaimer] None stated for this section.<br>- [§2: Recommended Priority Actions: Cybersecurity] Data poisoning, tracking sources for training data, data preprocessing standards, prompt injection, and jailbreaking.<br>- [§3: Recommended Priority Actions: Education] Lack of basic AI literacy among the American public.<br>- [§4: Recommended Priority Actions: Ethics] Fair use of training data, creator opt-in/opt-out mechanisms, and appropriate risk assessment methodologies. | - [§1: Introduction/Disclaimer] None stated for this section.<br>- [Section 2: Recommended Priority Actions: Cybersecurity]<br>- Develop methods for preventing and detecting data poisoning.<br>- Implement tracking of sources for training data.<br>- Set standards for data preprocessing.<br>- Improve and enforce guardrails.<br>- Develop new methods to prevent prompt injection and jailbreaking.<br>- [Section 3: Recommended Priority Actions: Education]<br>- Incorporate AI literacy into public education curriculum, including:<br>- Appropriate uses of AI and effective prompt creation.<br>- Limitations of AI.<br>- General terms and high-level understanding of architectures.<br>- Access to high school math and coding courses (e.g., linear algebra) supporting AI understanding.<br>- Funding for STEM programs and AI research.<br>- [Section 4: Recommended Priority Actions: Ethics]<br>- Ensure fair use of training data.<br>- Allow creators to refuse their works for use in training data.<br>- Establish methods to compensate those who opt-in to data usage.<br>- Develop methods for conducting appropriate risk assessments before AI use. |
| Rachel-C-AI-RFI-2025.md | Rachel C | Individual | The submitter is an artist and content creator concerned about the impact of AI on the future of original work and the economic viability of their profession. They seek to protect copyright and prevent AI from undermining the profits of American artists. | - Allowing AI to use copyrighted material destroys the future of original work.<br>- The use of AI takes profits away from American artists.<br>- AI creates a future where America is no longer a lead innovator.<br>- AI is built on theft.<br>- Allowing AI free rein over creations will be catastrophic to millions of Americans. | - None Stated |
| Rachel-Abrams-AI-RFI-2025.md | Rachel B. Abrams | Individual | Rachel B. Abrams expresses concern about the negative impacts of AI on creatives’ privacy and copyright, and believes promoting AI without safeguards is irresponsible. She advocates for protecting the interests of writers, musicians, and visual artists. | - AI poses an unwanted invasion of both privacy and copyright for creatives.<br>- Promoting AI with no guard rails is irresponsible and immoral.<br>- The US economy relies on the output of creatives and is therefore at risk. | - None Stated |
| Rabbit-Stoddard-AI-RFI-2025.md | Rabbit Stoddard | Individual | The submitter is an author concerned with the copyright implications of AI training data and opposes the reduction of copyright limitations related to AI. Their primary interest is protecting authorship rights. | - Feeding stolen content to AI training models.<br>- Reduction of copyright limitations on AI.<br>- The acceptability of using stolen content for AI training (compared to direct plagiarism). | - Those who build, train, and promulgate AI must be subject to the same copyright laws as everyone else. |
| RStreet-RFI-2025.md | R Street Institute | Advocacy/Think Tank | The R Street Institute advocates for free markets and limited, effective government, with a particular focus on promoting an innovative environment for AI development and ensuring American leadership in the field through pro-growth policies and avoiding regulatory burdens. | - [§1: Introduction/Header] None stated for this section.<br>- [§2: Overview of Comments] The risk of hindering innovation through excessive regulation and losing global leadership in AI.<br>- [§3: Broad-Based Steps to Advance an AI Opportunity Agenda]  The need for a positive innovation culture, the importance of competition, and the risk of stifling investment.<br>- [§4: Articulate a Positive, Forward-Looking Policy Vision]  Fear-based policy dialogue, the potential for overregulation, and the risk of following Europe's example.<br>- [§5: Build Upon a Proven Policy Framework]  The risk of undermining the innovation culture through heavy-handed regulatory policies (like those in Europe), and the importance of avoiding a regulatory compliance burden.<br>- [§6: Refocus Administrative Agencies]  The risk of agencies exercising excessive authority without sufficient accountability, and the need to avoid a precautionary approach that holds AI systems to impossibly high standards.<br>- [§7: Partner with Congress] The need to define agency authority, the risk of a patchwork of state regulations, and the need for a national AI policy framework.<br>- [§8: Targeted Strategies to Advance an AI Opportunity Agenda]  Not stated for this section.<br>- [§9: Ensure Open-Source AI Plays a Continued Role]  The risk of overly burdensome regulations disproportionately impacting open-source systems.<br>- [§10: Ensure America Wins the Talent War]  The risk of losing skilled AI workers to other nations, particularly China, and the need for favorable immigration policies.<br>- [§11: Avoid Overreach on Export Controls]  The risk of undermining U.S. leadership in AI through excessive export controls, and the limitation of American innovation.<br>- [§12: Ensure Diverse, Competitive Energy Markets for AI Advancement]  Regulatory barriers to energy supplier choice, the high cost of electricity, and the need for a reliable and affordable energy supply. | - [§1: Introduction/Header] None stated for this section.<br>- [§2: Overview of Comments] None stated for this section.<br>- [§3: Broad-Based Steps to Advance an AI Opportunity Agenda] None stated for this section.<br>- [§4: Articulate a Positive, Forward-Looking Policy Vision] None stated for this section.<br>- [§5: Build Upon a Proven Policy Framework]  Replicate the successful digital technology policy formula of the past 30 years.<br>- [§6: Refocus Administrative Agencies]  Provide agencies with additional guidance on AI-specific issues, avoid a precautionary approach, and focus on flexible, risk-based governance.<br>- [§7: Partner with Congress] Work with Congress to better define agency authority, craft a framework for preemption of state regulations, and consider a learning period moratorium.<br>- [§8: Targeted Strategies to Advance an AI Opportunity Agenda] None stated for this section.<br>- [§9: Ensure Open-Source AI Plays a Continued Role]  Ensure open-source providers play a major role in America’s AI ecosystem.<br>- [§10: Ensure America Wins the Talent War]  Calibrate immigration policies to ensure continued U.S. talent dominance in AI.<br>- [§11: Avoid Overreach on Export Controls]  Revise and limit export controls to safeguard U.S. leadership in AI, focus on competition, and outcompete rivals.<br>- [§12: Ensure Diverse, Competitive Energy Markets for AI Advancement]  Remove barriers to energy supplier choice for datacenter developers, finish generator interconnection reform, and streamline permitting and siting of electric infrastructure. |
| RSNA-AI-RFI-2025.md | Radiological Society of North America (RSNA) | Professional-Society | RSNA’s mission is to advance AI-driven innovation in healthcare, specifically within medical imaging, through collaboration, research, education, and standardization, while ensuring patient safety and responsible AI integration. They are deeply invested in facilitating the adoption of AI technologies within radiology and the broader healthcare ecosystem. | - [§1: Introduction] The primary concern is finding a balance between fostering AI innovation and ensuring regulatory oversight doesn't become overly burdensome.<br>- [§2: Key Considerations for the AI Action Plan] Ensuring trust in AI adoption, the strength of research infrastructure, potential barriers to AI adoption due to regulation, the need for a skilled workforce, and leveraging public-private partnerships.<br>- [§2.1: Fostering Trust Through Robust Validation and Transparency] Lack of standardized post-deployment monitoring of AI tools and the need for continuous oversight without unnecessary bureaucracy.<br>- [§2.2: Encouraging AI Innovation Through Targeted Research and Development] The need for foundational and translational research, and expansion of data and reporting standards.<br>- [§2.3: Reducing Barriers to AI Adoption Through Smart Regulation and Industry Collaboration] The potential for regulation to stifle innovation and the need for adaptable regulatory pathways.<br>- [§2.4: Addressing AI Education and Workforce Development Needs] The lack of AI literacy among healthcare professionals and the need for standardized training and certification.<br>- [§2.5: Strengthening Public-Private Partnerships for AI Development and Deployment] Not stated for this section.<br>- [§3: RSNA Contributions] Not stated for this section.<br>- [§4: Conclusion] Not stated for this section.<br>- [§5: Contact Information & Approval] Not stated for this section. | - [§1: Introduction] Support policies that encourage AI adoption while allowing for flexibility and efficiency in the regulatory process.<br>- [§2: Key Considerations for the AI Action Plan] Prioritize fostering trust, encouraging research & development, reducing barriers to adoption, addressing education needs, and strengthening partnerships.<br>- [Section 2.1: Fostering Trust Through Robust Validation and Transparency]<br>- Support ongoing validation studies of AI models in different clinical settings.<br>- Establish transparent reporting mechanisms for AI efficacy and safety.<br>- Encourage collaboration between regulatory agencies, professional societies, and healthcare institutions to ensure continuous oversight while avoiding unnecessary bureaucratic hurdles.<br>- [Section 2.2: Encouraging AI Innovation Through Targeted Research and Development]<br>- Prioritize foundational research to develop optimized AI algorithms.<br>- Prioritize translational research to refine AI integration into clinical workflows.<br>- Expand data and reporting standards to enhance interoperability and support comprehensive AI performance tracking.<br>- [Section 2.3: Reducing Barriers to AI Adoption Through Smart Regulation and Industry Collaboration]<br>- Streamline regulatory pathways to accelerate AI approvals while maintaining high safety and performance standards.<br>- Foster partnerships between industry, academia, and government to ensure AI tools reach the clinical environment swiftly.<br>- Ensure that AI regulation is adaptable to the fast-evolving nature of AI technologies.<br>- [Section 2.4: Addressing AI Education and Workforce Development Needs]<br>- Develop federally supported AI literacy programs tailored for healthcare professionals.<br>- Collaborate with professional societies to implement standardized training and certification pathways for AI competency in medicine.<br>- Support ongoing education initiatives to ensure that providers and patients understand the implications of AI integration in care delivery.<br>- [§2.5: Strengthening Public-Private Partnerships for AI Development and Deployment] Not stated for this section.<br>- [§3: RSNA Contributions] Not stated for this section.<br>- [§4: Conclusion] Not stated for this section.<br>- [§5: Contact Information & Approval] Not stated for this section. |
| RR-RFI-2025.md | R.R. | Individual | The submitter is focused on the privacy and security implications of AI, particularly regarding the management and control of Personally Identifiable Information (PII), and advocates for robust data protection measures and individual rights concerning their data. | - Access to one's PII is complicated by digital communications and transformations.<br>- The need to review authorized users of PII, distinguishing between "Authorized" and "Need-to-Know".<br>- Lack of clarity or enforcement regarding Security and Privacy distinctions.<br>- Potential for unauthorized access, misuse, or exploration of PII.<br>- Insufficient control for individuals over their PII or personal data. | - Implement NIST Risk Framework (SP 800-53 & 800-161) as a practice for all entities.<br>- Require transparent privacy policies and consent mechanisms.<br>- Mandate mechanisms to inform individuals how their data is collected, used, and shared.<br>- Ensure individuals always retain control over their PII.<br>- Implement policies and procedures addressing access control and managing authorization vs. need-to-access.<br>- Utilize multi-factor authentication and regularly review/update access rights.<br>- Prioritize data protection through robust security measures.<br>- Ensure individuals retain ownership of their data.<br>- Implement privacy-by-design principles.<br>- Implement data minimization and purpose limitation measures.<br>- Regularly audit and assess privacy compliance. |
| RIIA-AI-RFI-2025.md | American Association of Independent Music, American Federation of Musicians of America and Canada, Artist Rights Alliance, Department for Professional Employees, AFL-CIO, The International Alliance of Theatrical Stage Employees, Nashville Songwriters Association International, National Music Publishers' Association, Recording Academy, Recording Industry Association of America, and Screen Actors Guild-American Federation of Television and Radio Artists | Industry-Association | This group of organizations represents a wide range of creative professionals and businesses within the music and entertainment industry, and they are focused on protecting intellectual property rights, ensuring fair compensation for creators, and promoting a thriving creative economy in the age of AI. | - [Section 1: Introductory Comments & Signatories]** None stated for this section.<br>- [Section 2: Background & Principles]** The potential for AI development to undermine human creativity and individual rights if not guided by American values. Concern that foreign actors could steal American IP.<br>- [Section 3: Free Market Licensing for AI Training Materials]** Unauthorized use of copyrighted works for AI training without license. Potential for "model collapse" when using synthetic data for training.  Lack of rights certainty for creators.<br>- [Section 4: Support Existing U.S. Copyright Law]** The potential for overregulation and the risk of disrupting the existing copyright framework. Concern that a fair use defense may not apply to AI training.<br>- [Section 5: Oppose Text and Data Mining Exceptions]** The potential for TDM exceptions to allow free exploitation of copyrighted works, especially by foreign actors. The lack of consideration for the impact on copyright industries when creating TDM exceptions.<br>- [Section 6: Promote Trust in AI (Record Keeping & Transparency)]** Lack of user trust in AI and the need for greater transparency regarding training data and AI outputs. Skepticism about the reliability of AI systems.<br>- [Section 7: Protect Voice and Likeness Rights (NO FAKES Act)]** The unauthorized use of AI to clone voices and likenesses, leading to scams, blackmail, and sexual exploitation. Inconsistencies in state laws and the need for a national standard. | - [Section 1: Introductory Comments & Signatories]** None stated for this section.<br>- [Section 2: Background & Principles]** None stated for this section.<br>- [Section 3: Free Market Licensing for AI Training Materials]** Require appropriate licenses for copyrighted works used to train AI models, negotiated without regulation. Promote free market licensing as a means of generating revenue for creators.<br>- [Section 4: Support Existing U.S. Copyright Law]** Support existing U.S. copyright law, including the fair use doctrine, and avoid new regulations or exemptions.<br>- [Section 5: Oppose Text and Data Mining Exceptions]** Oppose TDM exceptions to copyright internationally and promote strong copyright laws abroad. Advocate for the rescission of existing TDM exceptions.<br>- [Section 6: Promote Trust in AI (Record Keeping & Transparency)]** Require adequate record keeping and transparency concerning AI training materials. Encourage the publication of summaries of works used for training. Support the TRAIN Act. Encourage labeling of AI-generated outputs.<br>- [Section 7: Protect Voice and Likeness Rights (NO FAKES Act)]** Support the passage of the NO FAKES Act to create a national standard for protecting voice and likeness rights.<br>- [Section 8: Exhibit A - Signatories (Detailed)]** None stated for this section. |
| RAND-RFI-2025.md | Gregory Smith, Elina Treyger, Elika Somani | Advocacy/Think Tank (RAND Corporation) | RAND Corporation provides research-based analysis of public policy challenges, with a specific focus in this document on solutions to enhance the U.S. government's capacity in artificial intelligence through improved talent acquisition, retention, and development. They aim to provide actionable recommendations to policymakers regarding AI workforce strategies. | - None Stated | - None Stated |
| RAI-AI-RFI-2025.md | Responsible AI-LA Reading Group, AI LA Community, Inc. | Advocacy/Think Tank | The Responsible AI-LA Reading Group focuses on Responsible AI development and aims to ensure the United States remains a global leader in AI while promoting innovation, security, and economic growth through focused infrastructure investment, clear governance policies, and proactive engagement with workforce development and public education. | - [§1: Header/Introduction] None stated for this section.<br>- [§2: Strengthening U.S. AI Leadership through Infrastructure Investment] Insufficient investment in AI infrastructure, including compute capacity, data centers, and hardware development. Potential for private-sector monopolization of compute resources.<br>- [§3: Addressing Regulatory Uncertainty and Data Governance] Lack of clear AI data usage policies as a barrier to US AI leadership.<br>- [§4: National Security, Cybersecurity, and AI Safety] Ensuring AI security and resilience against adversarial threats. Vulnerability to data breaches, adversarial attacks, and algorithmic manipulation.<br>- [§5: Workforce Development and Public AI Literacy] The need for a strong AI workforce and addressing public skepticism towards AI.<br>- [§6: Encouraging Open Innovation While Protecting National Interests] Balancing open innovation with national security interests. Potential for misuse of open-source AI.<br>- [§7: Conclusion] None stated for this section.<br>- [§8: Closing] None stated for this section. | - [§1: Header/Introduction] None stated for this section.<br>- [Section 2: Strengthening U.S. AI Leadership through Infrastructure Investment]<br>- Government-backed AI compute infrastructure to prevent monopolization.<br>- Investment in AI chips and energy-efficient computing.<br>- [Section 3: Addressing Regulatory Uncertainty and Data Governance]<br>- Establish standardized AI governance policies for data privacy, intellectual property, and security.<br>- Strengthen U.S. AI data policies for transparent, ethical, and secure usage.<br>- [Section 4: National Security, Cybersecurity, and AI Safety]<br>- Cybersecurity-first AI development.<br>- Investment in explainability and model assurance standards.<br>- [Section 5: Workforce Development and Public AI Literacy]<br>- Expanded AI training and workforce initiatives (education, upskilling, research fellowships).<br>- Public engagement to address AI skepticism and promote understanding.<br>- [Section 6: Encouraging Open Innovation While Protecting National Interests]<br>- Support open-source AI development with safeguards.<br>- Strengthen export controls and international AI governance.<br>- [Section 7: Conclusion] |
| R-Street-Institute-AI-RFI-2025.md | R Street Institute | Advocacy/Think Tank | The R Street Institute is a nonpartisan public policy research organization focused on promoting free markets and limited, effective government, with a particular interest in fostering innovation in AI while strengthening cybersecurity, data privacy, and national security. They advocate for policies that encourage AI development without unnecessary regulation. | - None Stated | - None Stated |
| R-L-Denise-AI-RFI-2025.md | R_L Denise | Individual | The submitter expresses concern about the negative impact of AI on creative professionals, particularly regarding copyright infringement and job displacement, and advocates for responsible AI development that doesn't rely on stealing creative works. | - Copyright infringement of artists' and other creative professionals’ work.<br>- Job displacement of artists and other creative professionals due to AI capabilities.<br>- The fundamental difference between AI "learning" and human learning.<br>- The potential for AI to take full advantage of its capabilities in a way that harms individuals. | - Explore alternative methods for AI to learn art forms without directly stealing ideas from multiple people. |
| Quarrel-Gunfire-AI-RFI-2025.md | Quarrel-Gunfire (QG) | Individual | The submitter expresses strong opposition to the development and proliferation of AI, primarily due to perceived negative impacts on their livelihood and a belief that AI is overhyped and exploitative. Their interest appears to be self-preservation and protecting against the perceived theft of intellectual property/work. | - AI steals from the submitter’s livelihood as an American.<br>- AI profits off of theft.<br>- AI is overhyped.<br>- AI is fleecing the American public. | - None Stated |
| Quantum-Connect-AI-AI-RFI-2025.md | Quantum Connect AI | Industry-Startup | Quantum Connect AI is an AI technology company focused on voice AI, custom infrastructure, and business process automation, with a strong interest in securing federal support for regional technology hubs like Boise, Idaho, to foster innovation and competitiveness in the AI landscape. | - None Stated | - None Stated |
| Qualcomm-AI-RFI-2025.md | Qualcomm | Industry-Large | Qualcomm’s primary mission is to advance AI innovation, particularly on-device AI, and scale its capabilities across various industries while securing U.S. leadership in AI technology and promoting a flexible regulatory environment. They have a strong interest in fostering a distributed AI architecture and participating in global standards development. | - [§1: Introduction/Cover Letter] None stated for this section.<br>- [§2: Qualcomm Background] None stated for this section.<br>- [§3: On-Device AI Innovation] The reliance on cloud implementations for AI training and inference can constrain AI scalability, security, latency, and efficiency. The cost of cloud-based inference can be economically unsustainable for scaling.<br>- [§4: Balanced AI Regulatory Framework] A lack of flexibility in AI regulation could stifle innovation.  A one-size-fits-all approach doesn’t account for diverse roles within the AI supply chain. The risk management approach needs to be tailored to specific AI use cases.<br>- [§5: International Standards Development] The need for U.S. leadership in global AI standards to ensure interoperability, security, economic scale, and competitiveness.<br>- [§6: Conclusion] None stated for this section.<br>- [§7: Sincerely/Signature Block] None stated for this section. | - [§1: Introduction/Cover Letter] None stated for this section.<br>- [§2: Qualcomm Background] None stated for this section.<br>- [§3: On-Device AI Innovation] Promote a distributed AI architecture to balance workloads between centralized cloud and edge devices. Support research and development efforts to leverage on-device AI innovation for U.S. AI leadership.<br>- [§4: Balanced AI Regulatory Framework] Adopt a flexible, risk-based regulatory approach that considers diverse roles within the AI supply chain (e.g., hardware providers vs. model developers). Foster innovation and competition to allow new entrants and technological breakthroughs. Support a framework for managing risk that clearly defines roles and shared responsibilities across the AI supply chain.<br>- [§5: International Standards Development] Continue to support global AI standards development and U.S. engagement in these efforts.<br>- [§6: Conclusion] None stated for this section.<br>- [§7: Sincerely/Signature Block] None stated for this section. |
| QinAI-AI-RFI-2025.md | Queer in AI | Advocacy/Think Tank/Professional-Society | Queer in AI advocates for the inclusion and safety of queer people throughout the AI lifecycle, raising awareness of queer issues in the AI community and promoting research on these problems, with a focus on privacy, security, and avoiding harm. They aim to ensure AI development is ethical and inclusive, particularly for marginalized communities. | - [§1: Introduction/Header] None stated for this section.<br>- [§2: Mission Statement/Background] Historical exclusion and targeting of queer people by science and technology. Erasure of queer identities in data collection.<br>- [§3: Action Item 1: Broad Participation] Lack of queer representation in AI development. The need for feedback from queer people at all stages.<br>- [§4: Action Item 1 - Details/Justification] Insufficient queer representation in AI governance. Lack of financial and psychological support for marginalized communities in participatory design.<br>- [§5: Action Item 2: Privacy Needs] Privacy concerns specific to queer individuals (e.g., doxxing, outing). The potential for harmful consequences from data collection, particularly in training datasets.<br>- [§6: Action Item 2 - Details/Surveillance Concerns] Surveillance practices potentially exploiting consent norms and invading privacy. Bias in airport security scanners. Ill-defined security regulation in public-private partnerships. Potential for AI targeted ads to disclose sexual orientation or gender identity.<br>- [§7: Action Item 3: Avoiding Pseudo-Scientific Tasks] Flawed methodologies of emotion detection and gender recognition systems. Potential for surveillance and infringement of civil rights. Legitimacy given to physiognomy and phrenology.<br>- [§8: Action Item 4: Limiting AI in High-Risk Areas] Potential for historical social harms to be perpetuated by AI applications in law enforcement, immigration, and weapons development. Data and surveillance used to harm queer people in the past (e.g., Plaxico v. Michael, "fairy shaking" by DC police).<br>- [§9: Auditing Practices] Lack of rigorous auditing in AI development and deployment. Need to consider predatory data gathering practices, test design, and documentation. Over-reliance on benchmarks. Insufficient consideration of privacy, group representation, and intersectionality.<br>- [§10: Endnotes/References] None stated for this section. | - [§1: Introduction/Header] None stated for this section.<br>- [§2: Mission Statement/Background] None stated for this section.<br>- [§3: Action Item 1: Broad Participation] Implement due process mechanisms for AI decisions. Encourage procedural frameworks for addressing safety and security of marginalized groups.<br>- [§4: Action Item 1 - Details/Justification] Utilize Risk Management Frameworks (RMFs) such as the NIST RMF. Incorporate rights-based data governance approaches. Encourage public-private participation in AI governance.<br>- [§5: Action Item 2: Privacy Needs] Improve training data curation practices to be more queer-inclusive. Only train AI on data with affirmative and meaningful opt-in consent. Provide clear, easy, and effective mechanisms for opting out of data inclusion. Implement contextual and effective privacy-preservation measures.<br>- [§6: Action Item 2 - Details/Surveillance Concerns] Safeguards within US government (e.g., Fair Information Practice Principles). Encourage informed consent. Encourage transparent development and deployment practices.<br>- [§7: Action Item 3: Avoiding Pseudo-Scientific Tasks] Redlight the use of AI for pseudo-scientific predictions.<br>- [§8: Action Item 4: Limiting AI in High-Risk Areas] Stringent auditing of AI systems used by law enforcement.<br>- [§9: Auditing Practices] Internal auditing involving product developers, management, and other stakeholders. Ethical review of end use cases. Algorithmic auditing. External auditing considering threats to affected demographic groups.<br>- [§10: Endnotes/References] None stated for this section. |
| Purdue-University-AI-RFI-2025.md | Purdue University | Academia | Purdue University seeks to establish Physical AI as a central focus of the national AI strategy, leveraging its expertise and resources to advance U.S. global competitiveness and national security through the research, development, and deployment of Physical AI technologies. | - None Stated | - None Stated |
| Protect-AI-AI-RFI-2025.md | Protect AI, Inc. | Industry-Startup | Protect AI's mission is to bridge the gap between AI innovation and security, mitigating risks in AI deployment through specialized solutions focusing on supply chain security, red-teaming, and runtime detection and response. They aim to encourage the safe and trusted adoption of AI and machine learning technologies. | - [§1: Cover/Introduction] None stated for this section.<br>- [§2: Executive Summary/Introduction to Protect AI] AI systems are vulnerable to security threats like model tampering, data leakage, and adversarial attacks, requiring dedicated security measures beyond traditional software security.<br>- [§3: Challenge/Issue 1: Supply Chain Protection and Counter-Sabotage] Vulnerabilities in the AI supply chain allow malicious actors to introduce compromised components, potentially leading to widespread security breaches. Specific examples cited include poisoned Python packages and compromised third-party AI models.<br>- [§4: Challenge/Issue 2: Financial Critical Infrastructure Attacks] AI systems in finance are targets for cyberattacks that can cause significant financial loss and destabilize economic infrastructures, particularly through adversarial evasion attacks on fraud detection models.<br>- [§5: Challenge/Issue 3: Malicious Zero-Day Attacks in AI Models] AI models are susceptible to zero-day vulnerabilities and serialization attacks, leading to compromised models and ransomware risks.<br>- [§6: Challenge/Issue 4: Protecting Mission Critical Decisions from Compromised AI] Adversarial actors can manipulate or poison AI systems used in defense applications, potentially leading to misclassifications, erroneous recommendations, and jeopardizing national security.<br>- [§7: Challenge/Issue 5: Right of Boom Forensics] Traditional forensic methods are insufficient for analyzing security incidents in AI systems due to their complexity and dynamic nature.<br>- [§8: Conclusions] Lack of continuous security measures (red-teaming, validation, observability) hinders safe AI adoption and international competitiveness.<br>- [§9: Sincerely/About Protect AI] None stated for this section. | - [§1: Cover/Introduction] None stated for this section.<br>- [§2: Executive Summary/Introduction to Protect AI] Prioritize security and risk management as integral parts of the U.S. AI/ML strategy to encourage broad adoption.<br>- [Section 3: Challenge/Issue 1: Supply Chain Protection and Counter-Sabotage]<br>- Integrate AI model scanning into software supply chain security workflows.<br>- Enhance visibility into the AI supply chain to identify and address threats quickly.<br>- Promote secure coding and development practices among suppliers.<br>- [Section 4: Challenge/Issue 2: Financial Critical Infrastructure Attacks]<br>- Deploy advanced threat detection systems for financial AI systems, including input sanitization and anomaly detection.<br>- Implement continuous monitoring for AI-driven financial systems to detect fraudulent patterns and adversarial inputs.<br>- Conduct AI red teaming protocols for continuous adversarial testing and model vulnerability assessments.<br>- [Section 5: Challenge/Issue 3: Malicious Zero-Day Attacks in AI Models]<br>- Conduct frequent security assessments of AI models to identify and address vulnerabilities.<br>- Adopt a zero-trust approach to model deployment, requiring rigorous security checks.<br>- Implement tools to continuously scan for threats within model repositories.<br>- [Section 6: Challenge/Issue 4: Protecting Mission Critical Decisions from Compromised AI]<br>- Conduct continuous AI red teaming and adversarial testing of defense systems.<br>- Enforce strict AI model validation and zero-trust principles for defense models.<br>- Implement real-time AI observability, runtime security, and threat monitoring.<br>- [Section 7: Challenge/Issue 5: Right of Boom Forensics]<br>- Develop and deploy AI-specific forensic tools.<br>- Utilize continuous monitoring tools for real-time anomaly detection.<br>- Implement automated scanning of model repositories with static and dynamic security analysis.<br>- Cryptographically sign AI models to establish provenance and detect tampering.<br>- Implement immutable logging for model interactions and decision-making pathways.<br>- [§8: Conclusions] Encourage continuous AI red-teaming, zero-trust validation, and real-time observability to promote safe AI adoption and international competitiveness.<br>- [§9: Sincerely/About Protect AI] None stated for this section. |
| Priya-Donti-AI-RFI-2025.md | Laboratory for Information and Decision Systems (LIDS) at the Massachusetts Institute of Technology (MIT) | Academia | The LIDS at MIT is interested in establishing American leadership in AI through foundational research, a heterogeneous approach to AI development, and a balanced approach to oversight that fosters innovation while ensuring safety, reliability, and accountability. They advocate for increased investment in AI research and the creation of an independent regulatory body. | - [§1: Introduction/Cover Page] None stated for this section.<br>- [Section 2: Executive Summary]<br>- Current AI leadership is narrowly focused on training large ML models, neglecting robustness, resilience, explainability, and application-specific needs.<br>- AI technologies do not inherently satisfy requirements for safety, privacy, interpretability, and explainability in many sectors.<br>- The need for substantial investment in basic and applied research to replicate successes across a wider range of AI paradigms.<br>- [Section 3: I. Enabling AI to Work for All Americans via a Heterogeneous Approach]<br>- Today's AI does not meet fundamental requirements for many applications (safety, robustness, privacy, interpretability).<br>- Reliance on a singular class of models (foundation models/LLMs) is insufficient.<br>- The lack of established "playbooks" for developing AI technologies with built-in safety, interpretability, and privacy.<br>- [Section 4: Recommendations (Data, Simulation, Compute)]<br>- Restrictive data practices limit academic research and favor large corporations.<br>- Lack of broad participation due to limited access to computational resources.<br>- [Section 5: III. Fostering Innovation & Oversight via an Independent Regulatory Body]<br>- The inevitability of AI regulation.<br>- The need for agile identification of societal needs and requirements.<br>- The importance of balancing innovation and protection of the American people.<br>- Potential for regulatory capture and industry influence.<br>- [§6: References] None stated for this section. | - [§1: Introduction/Cover Page] None stated for this section.<br>- [Section 2: Executive Summary]<br>- Invest in basic and applied research across a heterogeneous range of AI areas.<br>- Improve data access and sharing, simulation infrastructure, and AI compute infrastructure.<br>- Establish an independent AI regulatory body.<br>- [Section 3: I. Enabling AI to Work for All Americans via a Heterogeneous Approach]<br>- Support research in physics-informed ML, safe ML, privacy-preserving ML, interpretable and explainable ML, neuro-symbolic AI, probabilistic and Bayesian ML, and tiny ML.<br>- Fund interdisciplinary and cross-sectoral collaborations.<br>- [Section 4: Recommendations (Data, Simulation, Compute)]<br>- Provide clear federal guidance for secure data-sharing.<br>- Expand federal data-sharing initiatives.<br>- Increase enforcement of data-sharing requirements.<br>- Reduce barriers to AI R&D on federally controlled data.<br>- Establish public-private data partnerships.<br>- Expand programs supporting data curation and evaluation.<br>- Fund training programs for de-identification experts.<br>- Establish sector-specific data task forces.<br>- Provide affordable cloud computing resources.<br>- Fund the creation of simulation tools and AI testbeds.<br>- [Section 5: III. Fostering Innovation & Oversight via an Independent Regulatory Body]<br>- Create an Artificial Intelligence Regulatory Commission (AIRC).<br>- Establish standardized AI auditing practices and a best-practices repository.<br>- Implement a licensing framework for AI systems (risk-based regulation).<br>- Create regulatory sandboxes.<br>- Enable independent audits of AI systems.<br>- Implement lifecycle-based AI evaluation.<br>- [§6: References] None stated for this section. |
| PrivaSapien-AI-RFI-2025.md | Privasapien Technologies Private Limited | Industry-Startup (focused on AI privacy and security solutions) | Privasapien Technologies aims to promote responsible AI development through a focus on data privacy, security, and compliance with emerging regulations, ultimately driving trust and adoption of AI technologies globally. They advocate for a technology-centric approach to build compliant and secure AI systems. | - None Stated | - None Stated |
| Priscilla-Mattison-AI-RFI-2025.md | Priscilla Mattison | Individual | The submitter prioritizes the protection of human creators and a sustainable environment, advocating for responsible AI development that respects copyright law, minimizes environmental impact, and safeguards national security and data privacy, while questioning the goal of ‘AI dominance’. | - [§1: Header/Metadata] The premise that Executive Order 14110 hampered AI innovation is rejected; the goal of ‘AI dominance’ is questioned.<br>- [§2: Core Argument & High-Level Concerns] Concerns about the framing of the RFI and the pursuit of ‘AI dominance’ instead of competitiveness and excellence.<br>- [§3: Intellectual Property (IP) Policy Recommendations] Concerns about the unauthorized ingestion of copyrighted works for machine learning and the potential displacement of human creators by AI-generated content.<br>- [§4: Energy Consumption and Efficiency Policy Recommendations] Concerns about the vast energy and water consumption of AI systems and data centers, and the negative environmental impact of AI infrastructure.<br>- [§5: Cybersecurity, Data Privacy & National Security Policy Recommendations] Concerns about the potential for Russia, China, North Korea, Iran, and other adversaries to exploit AI for malicious purposes, and the need to protect national infrastructure, residents, and organizations.<br>- [§6: Disclaimer/Approval] None stated for this section. | - [§1: Header/Metadata] None stated for this section.<br>- [§2: Core Argument & High-Level Concerns] None stated for this section.<br>- [Section 3: Intellectual Property (IP) Policy Recommendations]<br>- AI-created works should be labeled as such.<br>- Disclosure of AI usage in the creation of any work.<br>- Authorization *by the creator* for the ingestion of copyrighted works for machine learning.<br>- Licensing and payment for copyrighted material usage at a mutually agreeable rate.<br>- Support and protection of human creators.<br>- Profit sharing directed to a fund for human creators from AI-created products.<br>- [Section 4: Energy Consumption and Efficiency Policy Recommendations]<br>- Redesign all parts of the AI supply chain to be zero energy and zero water.<br>- Design all AI infrastructure to have a *net positive impact* on biodiversity.<br>- [Section 5: Cybersecurity, Data Privacy & National Security Policy Recommendations]<br>- Collaboration with democratic nations to prevent adversarial use of AI.<br>- Application of the precautionary principle.<br>- Implementation of stringent rules and clear deterrents.<br>- Punishments for violations of cybersecurity, data privacy, and national security.<br>- [§6: Disclaimer/Approval] None stated for this section. |
| Premier-AI-RFI-2025.md | Premier Inc. | Industry-Large | Premier Inc. is a healthcare improvement company focused on leveraging data and technology, including AI, to reduce costs, improve quality, and enhance efficiency across the healthcare supply chain and clinical settings. They are interested in responsible AI development and deployment that supports innovation and addresses workforce challenges. | - [§1: Introduction/Cover Letter] None stated for this section.<br>- [§2: Background on Premier Inc.] None stated for this section.<br>- [§3: Unleashing Innovation in Drug Research, Manufacturing and Supply Chains] Challenges in streamlining administrative processes and potential for delays in clinical trial enrollment.<br>- [§4: Efficacy, Accuracy and Transparency] Potential for "hallucinations" and biased outcomes resulting from AI use, lack of trust in AI tools, the potential for static “nutrition labels” to not accurately reflect evolving AI tools, and the risk of disclosing intellectual property.<br>- [§5: Training the Healthcare Workforce of the Future] Risk of automation bias when healthcare professionals over-rely on AI suggestions.<br>- [§6: Conclusion] None stated for this section. | - [Section 1: Introduction/Cover Letter]<br>- Publish clear guidance on patient consent for using RWD to produce AI-generated synthetic control arms in clinical trials.<br>- Issue guidance supporting the transition to AI-powered advanced process controls in drug manufacturing.<br>- Focus AI transparency requirements on outcomes-focused metrics instead of input-based methods.<br>- Ensure data standards align with industry best practices.<br>- Require clear labeling of recommended AI uses.<br>- Support healthcare workforce training to combat automation bias.<br>- [§2: Background on Premier Inc.] None stated for this section.<br>- [§3: Unleashing Innovation in Drug Research, Manufacturing and Supply Chains] Encourage OSTP to work with the FDA on guidance for obtaining consent for using RWD to produce AI-generated synthetic control arms in clinical trials.<br>- [Section 4: Efficacy, Accuracy and Transparency]<br>- Implement standardized, outcomes-focused assessments of AI technologies' performance.<br>- Develop a standardized risk assessment identifying recommended uses and potential risks.<br>- Work closely with stakeholders to ensure data standards align with industry best practices.<br>- [Section 5: Training the Healthcare Workforce of the Future]<br>- Provide clear labeling of recommended AI uses.<br>- Support healthcare workforce training to combat automation bias and incorporate human decision-making.<br>- [§6: Conclusion] None stated for this section. |
| Pramod-Khargonekar-AI-RFI-2025.md | Pramod Khargonekar | Academia | Pramod Khargonekar, affiliated with the Engineering Research Visioning Alliance (ERVA) and the University of California, Irvine, is focused on advancing the field of AI Engineering through research, collaboration, and the development of a strategic framework to benefit society, specifically aiming to enhance national competitiveness and security through the convergence of AI and engineering. | - None Stated | - None Stated |
| Powers-Pidlypchak-AI-RFI-2025.md | Jessamyn Powers-Pidlypchak | Individual | The submitter is deeply concerned about the impact of AI on artists and the creative workforce, and believes AI should not be trained on copyrighted material as it threatens livelihoods and the intrinsic value of human creativity. | - AI companies’ desire to train on copyrighted works will lead to the displacement of artists and writers, decimating the American workforce and economy.<br>- Training AI on copyrighted material devalues human artistic creation and leads to a substantial decrease in the quality of life for creators.<br>- The original intent of automation – to eliminate menial labor – is being subverted by AI’s attempt to automate creative fields.<br>- Allowing AI to be trained on copyrighted works is unjust and disrespectful to humanity and its artistic heritage.<br>- The use of AI to generate art is driven by corporate greed and lacks artistic soul.<br>- Potential prohibition of future generations from freely creating art due to AI-driven market forces. | - Do not allow AI to be trained on copyrighted works.<br>- (Implied) Ban AI outright (although the submitter settles for the above recommendation). |
| Planet-Labs-AI-RFI-2025.md | Planet Labs PBC | Industry-Large | Planet Labs PBC is a provider of global daily satellite imagery and geospatial solutions, focused on leveraging AI to extract insights from this data and advocates for pro-innovation AI policies that support the growth of the geospatial AI sector while appropriately addressing risks. | - [§1: Introduction/Cover Letter] None stated for this section.<br>- [§2: Who is Planet?] None stated for this section.<br>- [§3: How does Planet use AI?] None stated for this section.<br>- [§4: U.S. AI Policy Recommendations] The U.S. Government procurement processes and legacy systems do not lend themselves to rapid adoption of new technologies like AI; existing budget cycles are insufficiently flexible to adapt to fast-paced changes in AI technology. Concerns that export controls could hold U.S. AI development and innovation back while international competitors are not subject to the same restrictions.<br>- [§5: Specific Policy Recommendations (Subsections within Section 4)] Concern that overly prescriptive regulations may not be able to keep pace with technological evolution and may become quickly outdated. Concern that defining AI too broadly (including machine learning) in regulations could unintentionally sweep in existing technologies. Concern that heavy-handed government regulations could stymie innovation in the nascent area of satellite imagery analytics.<br>- [§6: Conclusion/Closing] None stated for this section. | - [§1: Introduction/Cover Letter] Adopt a faster, more flexible procurement process for U.S. Government AI use cases in low risk areas such as analysis of satellite imagery. Encourage development and adoption of industry standards and best practices rather than adopt prescriptive regulations. Where laws and regulations are needed, define the scope of AI narrowly to exclude machine learning. Focus any regulation on the high-risk use cases and enable robust innovation to flourish in the low-risk area of satellite imagery analytics. Maintain a light-touch approach on regulating the export of products that utilize AI. Focus on transparency in where companies are using AI and how the models are trained, prompted, or applied.<br>- [§2: Who is Planet?] None stated for this section.<br>- [§3: How does Planet use AI?] None stated for this section.<br>- [§4: U.S. AI Policy Recommendations] Focus on outcomes (AI-generated insights) rather than inputs (satellite imagery data) in procurement processes. Prioritize commercial capabilities when procuring AI technologies, rather than drafting lengthy government requirements.<br>- [Section 5: Specific Policy Recommendations (Subsections within Section 4)]<br>- Faster Procurement:** Implement more agile procurement processes with pools of funding for new technology.<br>- Industry Standards:** Encourage the development and adoption of industry standards and best practices instead of prescriptive regulations.<br>- Narrow Scope Definition:** Define AI narrowly, excluding machine learning, to focus regulations on new, high-risk generative AI activities.<br>- Focus on High-Risk Use Cases:** Focus regulations on high-risk use cases, enabling innovation in low-risk areas like satellite imagery analytics.<br>- Light-Touch Export Controls:** Maintain a light-touch approach on regulating the export of AI products, focusing on the newest, most cutting-edge hardware.<br>- Transparency:**  Set expectations for AI developers to provide transparency regarding AI usage, data origins, and privacy/security handling, without requiring disclosure of details that would risk intellectual property or security.<br>- [§6: Conclusion/Closing] None stated for this section. |
| Ping-Wang-AI-RFI-2025.md | Ping Wang | Individual | The submitter is focused on maintaining American leadership in AI through sustained federal investment in talent development, integrating AI with cybersecurity, and leveraging the NSF's existing CyberCorps program to organize and lead these efforts. | - [§1: Introduction & Statement of Support] The need for a national AI action plan and immediate action to maintain American leadership in AI, highlighted by the "DeepSeek surprise" as a wake-up call.<br>- [§2: Stable Funding for Talent Development] Maintaining long-term US leadership in AI requires sustainable talent development and increased stable federal investment in AI research and education.<br>- [§3: Integration of AI with Cybersecurity] Securing American AI innovations and trade secrets is critical for national security and economic prosperity. AI action plans must be integrated with cybersecurity defense and offense.<br>- [§4: Leadership Role of NSF & CyberCorps Model] Creating a new government agency to lead AI actions would be redundant and not cost-effective. | - [§1: Introduction & Statement of Support] Implement a national AI action plan quickly.<br>- [§2: Stable Funding for Talent Development] Increase and maintain stable federal investment in AI research and education to motivate, nurture, and support AI talent selection and development on a national scale.<br>- [§3: Integration of AI with Cybersecurity] Integrate AI action plans with cybersecurity initiatives to protect American AI innovations and trade secrets.<br>- [§4: Leadership Role of NSF & CyberCorps Model] The National Science Foundation (NSF) should take a leading role in AI actions, leveraging the tested CyberCorps SFS program model for talent development, and avoid creating a new government agency. |
| Pika-Puka-AI-RFI-2025.md | Pika Puka | Individual | The submitter expresses strong opposition to the advancement and regulation of AI, believing it detrimental to livelihoods, the arts, and national security. They advocate against policies that promote AI development. | - AI is overhyped and does not fit into the future of the US.<br>- AI steals livelihoods.<br>- Executive Order 14179 will exacerbate negative impacts.<br>- AI will inevitably "pop" like a trend (similar to NFTs).<br>- AI will not replace the human spirit in art.<br>- Allowing AI companies to use copyrighted images without consequences destroys livelihoods and kills the arts.<br>- AI is hackable and imperfect.<br>- Passing the order opens possibilities for terrorist groups to indoctrinate youth with hate speech masked as legitimate media.<br>- Lack of safeguards to control and punish malevolent use of AI.<br>- Allowing AI will destroy the nation. | - None Stated. (The response primarily expresses opposition and doesn't offer concrete recommendations for policy changes, only opposition to the executive order.) |
| Phoenix-Witt-RFI-2025.md | Phoenix Witt | Individual | The submitter is deeply concerned about the potential risks of advanced AI development and advocates for a halt to development until ethical AI can be guaranteed through global consensus. | - Risk of job displacement ("put us all on the street").<br>- Existential risk to humanity ("risk all of our lives").<br>- Pursuit of Artificial Superintelligence (ASI) with potentially harmful goals ("ASI god to let them rule the world forever").<br>- Lack of ethical considerations in AI development. | - Pursue an international treaty to pause advanced AI development.<br>- Establish global consensus on how to guarantee truly ethical AI before resuming development. |
| Phipps-AI-RFI-2025.md | Samuel Phipps | Individual | The submitter is primarily interested in protecting copyright law and the rights of creators from infringement by AI technologies, believing ethical AI development is possible without exploiting copyrighted material. They advocate for accountability for AI companies regarding copyright. | - Violation of copyright law by AI tech companies.<br>- Theft of writers', artists', musicians', and content creators' work for AI training.<br>- Exploitation of copyright holders' material.<br>- The claim that upholding copyright law impedes AI development. | - Hold AI companies accountable for copyright violations.<br>- Uphold copyright law.<br>- Implement regulation to provide a framework for AI development and accountability.<br>- Encourage AI companies to utilize copyright-free resources or request usage permission from copyright holders. |
| Phillip-Masterson-RFI-2025.md | Phillip Masterson | Industry-Individual | Dr. Masterson, working in the semiconductor metrology industry with connections to major chip manufacturers, is interested in maintaining US leadership in AI through policies supporting the semiconductor industry, securing AI capabilities, and ensuring a competitive landscape for US AI companies. | - [§1: Introduction/Header] None stated for this section.<br>- [§2: Recommendation 1: Lightweight Reporting System] The speed of AI development necessitates clear understanding of latest advancements, particularly regarding national security threats.<br>- [§3: Recommendation 2: Hiring AI Experts] Bureaucracy could hinder effective AI policy-making; a dedicated AI team is needed.<br>- [§4: Recommendation 3: Security Standards for Frontier AI Labs] Current security standards are lacking; hacking and IP theft by adversarial countries pose a threat to US technological leadership.<br>- [§5: Recommendation 4: Export Controls] Maintaining American dominance in AI requires controlling the export of critical technologies to foreign adversaries. Loopholes in existing controls need to be addressed.<br>- [§6: Recommendation 5: Modernizing the Electrical Grid] A slowly-growing US electrical grid could impede the growth of AI companies and US competitiveness.<br>- [§7: Recommendation 6: CHIPS Act Support] Repealing the CHIPS Act would negatively impact the recent growth in US chip manufacturing. Reforms to the act, if necessary, should be carefully considered with extensive industry input.<br>- [§8: Conclusion/Sign-off] None stated for this section. | - [§1: Introduction/Header] None stated for this section.<br>- [§2: Recommendation 1: Lightweight Reporting System] Implement a targeted reporting system to track the capabilities of advanced AI systems.<br>- [§3: Recommendation 2: Hiring AI Experts] Hire top-tier AI experts to form a dedicated AI team.<br>- [§4: Recommendation 3: Security Standards for Frontier AI Labs] Proactively establish targeted security standards for frontier AI labs with collaboration from agencies like the NSA.<br>- [§5: Recommendation 4: Export Controls] Maintain and strengthen export controls on foreign adversaries, particularly concerning H20s and other high-end chips.<br>- [§6: Recommendation 5: Modernizing the Electrical Grid] Streamline regulations to support growth of the US electrical grid.<br>- [§7: Recommendation 6: CHIPS Act Support] Support the CHIPS Act and carefully consider any reforms with extensive industry input.<br>- [§8: Conclusion/Sign-off] Prioritize robust AI policy-making throughout the next four years. |
| Philippe-Dambournet-AI-RFI-2025.md | Philippe Dambournet | Individual | The submitter expresses a strong interest in protecting creators and copyright holders from unauthorized use of their work by AI systems, particularly regarding plagiarism. They appear to be concerned with the potential for large AI models to infringe on intellectual property rights. | - A "giant carve-out" that would enable large companies to build systems that produce “unlimited amounts of plagiarism”.<br>- Potential negative impact on creators and copyright holders. | - None Stated. |
| Philip-Walker-AI-RFI-2025.md | Philip Walker | Industry-Startup / Individual | Integrating AI and robotics (specifically Tesla Optimus) into laundromats to lower service costs for consumers and help traditional laundromats survive the adoption of new technologies. The submitter aims to benefit Main Street America through this integration. | - [§1: Email Header] None stated for this section. (Security warning about external emails.)<br>- [§2: Introduction & Context] Slow adoption of AI and robotics benefiting Main Street America; potential for thousands of laundromats to struggle with the coming technology revolution.<br>- [§3: Proposal] Lack of financial access for laundromats to adopt AI/robotics; inability of most laundromats to compete without wash-dry-fold services using AI/robotics.<br>- [§4: Industry Impact & Partnerships] Not Stated<br>- [§5: Closing & Request for Collaboration] Not Stated<br>- [§6: Disclaimer] Not Stated | - [§1: Email Header] Not Stated<br>- [§2: Introduction & Context] Not Stated<br>- [§3: Proposal] The Small Business Administration (SBA) should make special R&D loans available for the effort and subsidize lower-than-market interest rates for laundromat owners acquiring the technology.<br>- [§4: Industry Impact & Partnerships] Not Stated<br>- [§5: Closing & Request for Collaboration] Facilitate an introduction to the Tesla Optimus team for beta test assistance.<br>- [§6: Disclaimer] Not Stated |
| Philip-Parshley-AI-RFI-2025.md | Philip Parshley | Individual | Philip Parshley expresses a clear interest in protecting the rights of authors and creators of copyrighted material in the context of AI training data usage, and opposes the use of copyrighted data without permission for training AI models. | - Use of copyrighted training data by AI systems like OpenAI could undermine copyright protections.<br>- Allowing the use of copyrighted training data would damage the interests of authors and creators. | - OpenAI and similar AI systems should not be given permission to use copyrighted training data. |
| Philip-Omorogbe-AI-RFI-2025.md | Philip Omorogbe | Individual / Professional-Society (Attorney specializing in AI law and policy) | Philip Omorogbe, an attorney specializing in AI law and policy, aims to provide recommendations for an AI Action Plan that fosters technological advancement while ensuring equitable distribution of benefits across the economy through legal and regulatory frameworks, focusing on small business participation, economic opportunity, and government competency. | - None Stated | - None Stated |
| Philip-Nelson-AI-RFI-2025.md | Philip Nelson | Individual | The submitter is interested in addressing the negative impacts of current AI learning systems on content creators, specifically freelancers, and proposes solutions that could benefit both creators and AI development through ethical content acquisition and increased data quality for AI training. | - Exploitation of freelance artists’ work without permission through internet scraping for AI training.<br>- Competition between AI-generated content and the work of freelance artists who have had their work used for AI training. | - AI corporations should hire people to create content specifically for AI consumption and training.<br>- Corporations could post bounties for public-domain works not currently available on the internet, incentivizing scanning and digitization of these works.<br>- Release digitized public-domain works to the public for general benefit. |
| Phil-Omorogbe-AI-RFI-2025.md | Philip Omorogbe | Individual/Professional-Society (Attorney specializing in AI Law and Policy) | Philip Omorogbe, an attorney specializing in AI law and policy, aims to promote American leadership in AI through policy changes that foster innovation, equitable access to benefits, and responsible governance, with a particular focus on small business participation, economic opportunity, and government competency. | - [§1: Introduction] None stated for this section.<br>- [Section 2: Policy Framework #1: Democratizing Government AI Adoption Through Legal and Procurement Reform]<br>- Federal Acquisition Regulation (FAR) compliance imposes disproportionate burdens on small businesses.<br>- Extensive past performance requirements favor established contractors, hindering new AI operators.<br>- Contract bundling practices limit access for specialized AI firms.<br>- Security clearance and compliance costs disadvantage smaller entities.<br>- [§3: Case Analysis: Lessons from Current Public Sector AI Implementation] None stated for this section.<br>- [Section 4: Policy Framework #2: Enabling AI-Powered Income Generation for Individuals and Small Businesses]<br>- Access barriers to high-quality AI tools and training.<br>- Knowledge gaps preventing effective utilization of AI for economic advancement.<br>- Structural workforce challenges, particularly for experienced workers facing displacement.<br>- Limited infrastructure in underserved communities creating AI opportunity deserts.<br>- [§5: Case Analysis: AI-Enabled Career Transformation for Experienced Workers] None stated for this section.<br>- [Section 6: Policy Framework #3: Federal AI Literacy and Governance Initiative]<br>- Insufficient understanding of AI capabilities and limitations among decision-makers.<br>- Inadequate technical capacity to properly evaluate AI systems and services.<br>- Limited ability to develop appropriate governance frameworks and oversight mechanisms.<br>- Difficulty articulating requirements and specifications for AI procurements.<br>- [§7: Conclusion] None stated for this section. | - [§1: Introduction] None stated for this section.<br>- [Section 2: Policy Framework #1: Democratizing Government AI Adoption Through Legal and Procurement Reform]<br>- Establish a **Small Business AI Participation Framework** with:<br>- Modified Procurement Thresholds (simplified compliance, modified past performance, IP protections).<br>- Mandatory Set-Aside Program (25% for small businesses, legal definition of AI services, prohibition of unnecessary bundling).<br>- Legal Structure for Collaborative Contracting (consortia, mentor-protégé programs, joint venture frameworks).<br>- Executive action directing SBA and Federal Acquisition Regulatory Council to develop AI-specific regulations.<br>- Amendments to existing small business regulations.<br>- Standardized contract language addressing data rights, model ownership, and liability.<br>- Legal oversight mechanisms for set-aside compliance.<br>- [§3: Case Analysis: Lessons from Current Public Sector AI Implementation] None stated for this section.<br>- [Section 4: Policy Framework #2: Enabling AI-Powered Income Generation for Individuals and Small Businesses]<br>- Establish an **AI Economic Opportunity Initiative** with:<br>- Democratized Access to Training (subsidies, public computing resources, broadband expansion, accessibility regulations).<br>- Comprehensive Skills Development Program (federally-funded training, certification programs, curricula partnerships, train-the-trainer programs).<br>- Financial Support Structure (adoption grants, microloans, tax credits, innovation vouchers).<br>- Experience-Based AI Career Pathways (programs leveraging existing knowledge, apprenticeship models, remote work platforms, incubators).<br>- [§5: Case Analysis: Lessons from Current Public Sector AI Implementation] None stated for this section.<br>- [Section 6: Policy Framework #3: Federal AI Literacy and Governance Initiative]<br>- Establish a **Federal AI Competency Framework** with:<br>- Tiered AI Literacy Program (mandatory training, advanced certification, executive-level training).<br>- AI Governance Standards (government-wide framework, risk assessment methodologies, performance metrics, accountability structures).<br>- Legal and Ethical Implementation Guidelines (standard operating procedures, compliance frameworks, ethical guidelines).<br>- [§7: Conclusion] None stated for this section. |
| PhRMA-AI-RFI-2025.md | PhRMA | Industry-Association | PhRMA represents leading biopharmaceutical research companies and advocates for policies that support innovation in drug development, emphasizing strong IP protection, a flexible regulatory framework, and responsible AI use to accelerate the discovery and delivery of new medicines. | - None Stated | - None Stated |
| Peter-Parkinson-AI-RFI-2025.md | Peter Parkinson | Individual | Peter Parkinson is interested in providing a framework for objective morality, specifically formulated into a succinct formula, to serve as a fundamental basis for AI moral infrastructure and believes this work is important for the future development of AI. He is seeking a platform to have this work scrutinized and potentially implemented. | - None Stated | - None Stated |
