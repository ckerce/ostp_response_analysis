| Filename | Submitter Name | Submitter Type | Mission/Interest Summary | Key Concerns | Policy Recommendations |
|---|---|---|---|---|---|
| JD-McDell-AI-RFI-2025.md | JD McDell | Individual | The submitter is concerned with the economic impact of AI platforms on individual contributors and the concentration of power and wealth within large tech companies due to the illegal acquisition of copyrighted information. | - AI platforms illegally obtain publicly available, copyrighted information.<br>- This illegal acquisition siphons money and employment opportunities away from individual contributors.<br>- It disproportionately benefits already powerful tech companies and executives. | - None Stated |
| JD-AI-RFI-2025.md | JD | Individual | The submitter expresses strong opposition to policies that would weaken copyright protections and allow AI companies to freely use creative works without permission, fearing the destruction of the creative industry and a decline in the quality and reliability of online content. | - Large-scale theft of intellectual property by AI companies.<br>- Destruction of the U.S. creative industry (valued at $1.1 trillion, 4.3% of GDP).<br>- Potential for AI companies to generate low-quality or unreliable content ("slop").<br>- Loss of control over personal photographs and online content.<br>- Erosion of safety and security on the internet.<br>- The potential for malicious use of AI-generated content (specifically mentioning falsified photographs of the President).<br>- The risk of creating a market dominated by machine-generated content of low value.<br>- Concerns that the U.S. government is prioritizing the interests of Silicon Valley elites over the rights of creators and the public.<br>- The possibility of other American industries being negatively impacted beyond the creative sector. | - AI companies should be required to obey existing laws, including copyright regulations.<br>- AI companies should be prohibited from using public domain material in a way that destroys value or harms creators.<br>- The government should ensure AI companies produce something of "actual value," not just "toys for the retarded."<br>- The U.S. government should implement regulations similar to those already in place in China to protect intellectual property rights.<br>- Insist that any AI development be done "fairly," without causing harm to existing industries. |
| JCPES-AI-RFI-2025.md | Joint Center for Political and Economic Studies | Advocacy/Think Tank | The Joint Center for Political and Economic Studies focuses on providing policy solutions to eradicate barriers to the full freedom of Black people in America, with a particular emphasis on ensuring that AI development benefits Black communities and does not exacerbate existing economic inequalities. Their primary interest is in equitable access to AI-driven opportunities and workforce resilience. | - None Stated | - None Stated |
| JC-RFI-2025.md | J.C. | Individual | The submitter is primarily concerned about the destabilizing potential of unregulated AI and its threat to governmental power and trusted information sources, suggesting a focus on maintaining societal stability and the integrity of information ecosystems. | - Unregulated AI could empower individuals like Elon Musk to displace governmental authority.<br>- AI has the power of disruption, which is viewed negatively.<br>- Eroding trust in news and social media sources will undermine governmental efforts.<br>- The current administration's favorable relationship with the tech sector is precarious.<br>- The previous administration (Trump's) has created conditions for a potential usurpation of power.<br>- The previous administration does not act in the interest of humanity. | - Implement AI regulations, potentially to protect the current administration or the previous administration. |
| JC-AI-RFI-2025.md | J.C. | Individual | The submitter is interested in responsible AI development and deployment that protects consumers, workers, artists, and privacy, while also considering environmental impact. They advocate for policies that mitigate negative consequences of AI and ensure fairness. | - Excessive energy consumption by AI models and servers.<br>- Lack of consumer protection, specifically the potential for unwanted AI usage.<br>- Disrespect for copyright and the unauthorized use of artists' work.<br>- Violation of privacy through the use of personal data in AI training.<br>- Labor protections and the potential for companies to replace American workers with inadequate AI "agents". | - Implement measures to reduce the energy footprint of AI models and servers.<br>- Ensure consumers have easy options to decline AI usage (e.g., on personal laptops).<br>- Respect copyright and prevent the unauthorized use of artists’ work in AI training.<br>- Protect privacy by preventing the use of personal data in AI training.<br>- Provide labor protections to safeguard American workers from displacement by AI. |
| JA-Analytics-AI-RFI-2025.md | Alan F. Karr and Jeanne Ruane | Academia | The submitters are scientists concerned with the scientific rigor and ethical implications of AI, particularly regarding data quality and uncertainty, and advocate for informed input into AI policy development. They are actively researching the impact of data quality on AI model performance. | - [§1: Introduction/Commentary] The quality of data used to train AI models is a significant concern, with the indiscriminate use of data of unknown quality. Lack of broad input from both the research community and the public is also a concern.<br>- [§2: Data Quality Argument & Experimental Setup] Concerns about the lack of metadata, version control, and paradata associated with training data. Concerns that the situation is worse for large, opaque AI models.<br>- [§3: Experimental Results] Data quality is demonstrably more fragile than low-quality data. AI model performance can exhibit a phase transition with increasing data degradation. Congruence among classifiers can be misleading, becoming high when all models are incorrect.<br>- [§4: Secondary Comment: Uncertainty] Most AI models do not provide actionable information about the uncertainties in their results.<br>- [§5: Disclaimer] None stated for this section. | - [§1: Introduction/Commentary] None stated for this section.<br>- [§2: Data Quality Argument & Experimental Setup] None stated for this section.<br>- [§3: Experimental Results] The Action Plan should not ignore the fragility of data quality and the potential for unexpected behavior in complex situations.<br>- [§4: Secondary Comment: Uncertainty] Policies should encourage or require AI models to provide actionable uncertainty information.<br>- [§5: Disclaimer] None stated for this section. |
| Ivy-Long-AI-RFI-2025.md | Ivy Long | Individual | The submitter is a creative professional expressing strong opposition to the AI Action Plan, believing it exploits creators and harms their livelihoods and the broader American economy. They advocate for the preservation of creator protections. | - [§1: Email Header] None stated for this section.<br>- [§2: Opening Statement/Position] Opposition to the AI Action Plan (Document Number 202502305).<br>- [Section 3: Core Argument Against AI]<br>- AI profits off the work of creators without fair compensation.<br>- AI lacks original value, only absorbing and regurgitating existing content.<br>- Promoting AI is anti-American and economically harmful.<br>- [§4: Closing/Request] Plea to not remove protections for creators and preserve their livelihoods.<br>- [§5: Email Footer/Disclaimer] None stated for this section. | - [§1: Email Header] None stated for this section.<br>- [§2: Opening Statement/Position] None stated for this section.<br>- [§3: Core Argument Against AI] None stated for this section.<br>- [§4: Closing/Request] Do not remove protections for hard-working creators against their livelihoods being taken away.<br>- [§5: Email Footer/Disclaimer] None stated for this section. |
| Ivan-Lopez-AI-RFI-2025.md | Ivan Lopez | Individual | The submitter expresses a cautionary stance towards the unrestricted development and deployment of AI, suggesting a focus on responsible AI governance and potential risk mitigation. They identify as being affiliated with UC Riverside's College of Natural and Agricultural Sciences, with a background in Applied Mathematics. | - Allowing AI to have "free rein."<br>- Potential risks associated with unrestricted AI development (implied, not explicitly stated, but indicated by the warning). | - None Stated. |
| IsaacDunlap-AI-RFI-2025.md | Isaac Dunlap | Individual | The submitter expresses a strong negative view of AI's value and believes it is a waste of resources for the American people and economy. Their interest appears to be voicing this dissenting opinion. | - [§1: Email Header] None stated for this section.<br>- [§2: Disclaimer] None stated for this section.<br>- [§3: Core Statement] AI holds no value for the American people; AI is a waste of resources on the American economy. | - [§1: Email Header] None stated for this section.<br>- [§2: Disclaimer] None stated for this section.<br>- [§3: Core Statement] None stated for this section. |
| IrvingMartinezPacheco-AI-RFI-2025.md | Irving Martinez Pacheco | Individual - Academia (indicated by Ph.D. credential and focus on higher education) | The submitter is focused on establishing US leadership in AI through innovation, economic growth, security, ethics, and sustainability, with a strong emphasis on the role of generative AI in education and entrepreneurship. They advocate for policies to support AI adoption, workforce development, and international collaboration. | - Section 1: Introduction and Objectives:** None stated for this section.<br>- Section 2: AI Application and Use:** None stated for this section.<br>- Section 3: Explainability and Assurance of AI Model Outputs:**  Lack of trust in AI outputs if transparency and interpretability are not ensured. Potential for bias and security vulnerabilities in AI models. Need for compliance with ethical frameworks.<br>- Section 4: Education, Workforce, and AI Entrepreneurship:** Ensuring curriculum adequately prepares students for AI-driven roles. Bridging the gap between academic learning and industry demands.  Need for resources to support AI sustainability education.<br>- Section 5: Innovation and Competition:** Onerous regulatory barriers hindering AI-driven business creation.  Balancing innovation with ethical considerations.<br>- Section 6: Intellectual Property and AI Innovation Protection:**  Need to modernize IP laws to reflect the unique challenges of AI inventions. Ensuring AI entrepreneurs have adequate legal protection for their innovations.<br>- Section 7: Public Procurement and AI Acquisition:** The need to prioritize AI-powered solutions in public sector projects. Ensuring quantifiable sustainability results from AI investments.<br>- Section 8: International Collaboration:** Ensuring that US-led AI governance frameworks align with global sustainability and ethical norms. Need to support American AI startups in international markets.<br>- Section 9: Economic Impact and Global Growth:** Tracking the economic impact of AI and ensuring job creation. Need for investment in AI-driven sustainability firms and workforce development.<br>- Section 10: Next Steps:** None stated for this section. | - Section 1: Introduction and Objectives:** None stated for this section.<br>- Section 2: AI Application and Use:** None stated for this section.<br>- Section 3: Explainability and Assurance of AI Model Outputs:** Develop and enforce regulatory standards for AI transparency. Establish third-party review processes for AI models, including bias assessment and security validation. Create AI certification programs. Implement AI explainability tools. Introduce proactive risk assessment methodologies.<br>- Section 4: Education, Workforce, and AI Entrepreneurship:** Expand interdisciplinary AI programs in higher education. Encourage industry partnerships for internships and apprenticeships. Integrate sustainability into AI curriculum. Develop an AI Sustainability Toolkit. Establish AI innovation hubs and startup incubators with accelerators. Provide funding and mentorship for AI startups.  Create AI-specific certificates. Strengthen AI research & development. Encourage public-private partnerships.<br>- Section 5: Innovation and Competition:**  Modernize regulatory frameworks to facilitate AI innovation while ensuring ethical use. Provide tax incentives, grants, and low-interest loans for AI startups. Provide funding for AI research with a clear path to commercialization.<br>- Section 6: Intellectual Property and AI Innovation Protection:** Update intellectual property regulations to protect AI inventions, business models, and content. Create AI-specific patent frameworks. Provide legal consultation for AI entrepreneurs. Promote international cooperation on AI-related intellectual property laws.<br>- Section 7: Public Procurement and AI Acquisition:** Revise government procurement regulations to prioritize AI-powered solutions. Establish tax breaks and financing initiatives for AI startups. Form strategic alliances between governmental organizations, academic institutions, and private AI developers. Implement regulatory sandboxes for AI procurement.<br>- Section 8: International Collaboration:** Lead efforts for AI governance prioritizing sustainability, equity, and transparency. Offer financial assistance and regulatory advice to American AI startups expanding internationally. Promote international research collaboration. Promote AI-driven sustainability criteria in international trade agreements.<br>- Section 9: Economic Impact and Global Growth:** Create KPIs to track the growth of AI-powered companies and productivity gains. Encourage investment in AI-driven sustainability firms. Create national upskilling initiatives for AI-related roles. Promote the inclusion of AI-driven sustainability projects in free trade agreements.<br>- Section 10: Next Steps:** Start focused AI-driven entrepreneurship pilot initiatives in academic institutions. Conduct thorough assessments of generative AI-driven initiatives to optimize tactics and policies. Provide a flexible framework for monitoring advancements and ensuring compliance with changing market conditions. |
| Iris-Cripe-Eng-AI-RFI-2025.md | Iris M. Cripe-Eng | Individual | The submitter expresses general concern about the potential risks of AI development, particularly regarding existential threats and job displacement, and questions whether pursuing AI is a wise course of action. They seem focused on safety and the potential for harm. | - One of the creators of AI has walked away from the project, indicating potential issues.<br>- The potential for AI to cause extinction-level events, as warned by signatories at the Center for AI Safety.<br>- AI could exacerbate global threats like pandemics and nuclear attacks.<br>- Job displacement of creative professionals (artists, writers).<br>- The overall wisdom of continuing AI development given the noted concerns of experts. | - None Stated. |
| Irepa-International-RFI-2025.md | Irepa International, LLC | Industry-Startup (appears to be a company proposing a comprehensive AI solution) | Irepa International aims to develop and implement a holistic AI system focused on ethical and sustainable practices, emphasizing unbiased data, autonomous companion robots, and government accountability to promote well-being and societal progress. | - [§1: Executive Summary] None stated for this section.<br>- [§2: Non-Biased Truth and Factual Data for AI/ML/DL] The potential for AI models to be skewed by social media opinions, ego-based biases, and misinformation.<br>- [§3: Circular Economy AI Data Centers] Not Stated. The section focuses on the *implementation* of the data centers, not inherent concerns.<br>- [§4: Autonomous Companion Robots (Cobots) for Human Well-being] Not Stated. The section primarily details the functionalities of cobots.<br>- [§5: Community Sustainability Through Cobots] Not Stated. The section focuses on the applications of cobots for community benefit.<br>- [§6: Cobot as a Tool for Psychological and Social Health] The risk of negative psychological programming (e.g., narcissism, psychopathy, sociopathic behavior) hindering healthy development.<br>- [§7: AI to Police Lean and Small Governments] The potential for government actions to deviate from constitutional principles and individual rights.<br>- [§8: Conclusion] Not Stated. This section summarizes the proposal, not specific concerns. | - [§1: Executive Summary] Focus on non-biased data, sustainable AI data centers, autonomous companion robots, and using AI to ensure government accountability.<br>- [§2: Non-Biased Truth and Factual Data for AI/ML/DL] Ensure AI/ML/DL algorithms are grounded in unbiased, factual, and truthful data drawn from verified sources.<br>- [§3: Circular Economy AI Data Centers] Create self-sustaining, self-regulating, and decentralized AI data centers utilizing GPU, CPU, and Quantum Computing technologies with sustainable energy sources.<br>- [§4: Autonomous Companion Robots (Cobots) for Human Well-being] Develop autonomous companion robots to serve as personalized assistants, monitoring and enhancing human health, well-being, and productivity.<br>- [§5: Community Sustainability Through Cobots] Utilize cobots to support organic gardens, clean water initiatives, and decentralized cryptocurrency transactions for community self-sufficiency.<br>- [§6: Cobot as a Tool for Psychological and Social Health] Employ cobots as lifelong companions to identify and address negative psychological programming and support emotional development.<br>- [§7: AI to Police Lean and Small Governments] Utilize AI to monitor government actions, ensure transparency, promote accountability, and adherence to constitutional principles.<br>- [§8: Conclusion] Implement a holistic approach that advances technological innovation while nurturing a healthier, more collaborative future through the use of AI and associated technologies. |
| Irene-Aldridge-AI-RFI-2025.md | Irene Aldridge | Individual | Irene Aldridge focuses on leveraging AI to improve U.S. education and advocates for protecting sensitive U.S. data by reducing reliance on foreign processing and utilizing AI for data security. | - [§1: Introduction & Education Improvement with AI] The gap in mathematics knowledge between U.S. and Chinese students, and the potential for U.S. students to fall behind without increased investment in AI-powered educational resources.<br>- [§2: The Threat of Outsourcing U.S. Data] Outsourcing sensitive U.S. data to foreign entities (specifically India and Singapore) poses national security and data privacy risks due to lack of U.S. jurisdiction and oversight. The accumulation of personal information in foreign countries is a concern.<br>- [§3: Author Background] None stated for this section. | - [§1: Introduction & Education Improvement with AI] Invest in AI-based resources to equip students with individualized learning and close the gap with other countries.  Equip the "brightest kids" with unlimited AI resources.<br>- [§2: The Threat of Outsourcing U.S. Data] Harness Artificial Intelligence to defend U.S. data by randomly sampling data flow to identify sensitive information being shipped overseas.  Exercise caution when sharing sensitive data with foreign countries.<br>- [§3: Author Background] None stated for this section. |
| Ira-Ham-AI-RFI-2025.md | Ira Ham | Industry-Startup (Based on CISO title and MediaAlpha affiliation, suggesting a technology-focused company.) | Ira Ham, as CISO of MediaAlpha, is interested in establishing clear and consistent AI testing parameters to ensure robust AI system validation and reduce risk, particularly within the context of the NIST AI Risk Management Framework. They advocate for practical, data-driven guidance to address the ambiguity surrounding acceptable AI testing practices. | - [§1: Email Header] None stated for this section.<br>- [§2: Introduction/Context] The current guidance on AI testing parameters is vague, lacking clarity on the sufficient number of test iterations.<br>- [§3: Problem Statement: Vague Testing Parameters] Limited clarity on how many AI test iterations are considered sufficient, leading to inconsistent validation; the NIST AI RMF’s MEASURE function lacks specific metrics or thresholds, creating ambiguity in interpretation.<br>- [§4: Proposed Solutions/Actions] None stated for this section.<br>- [§5: Conclusion/Signature] None stated for this section. | - [§1: Email Header] None stated for this section.<br>- [§2: Introduction/Context] None stated for this section.<br>- [§3: Problem Statement: Vague Testing Parameters] None stated for this section.<br>- [Section 4: Proposed Solutions/Actions]<br>- Establish Baseline Testing Thresholds by Use Case Risk Tiering.<br>- Incorporate Confidence Interval Guidelines.<br>- Create Reference Benchmarks and Validation Sets.<br>- Define Testing Adequacy Through Convergence Criteria.<br>- Require Reporting on Test Iteration Justification.<br>- NIST-Led Industry Collaboration for Domain-Specific Testing Protocols.<br>- [§5: Conclusion/Signature] None stated for this section. |
| Intuit-AI-RFI-2025.md | Intuit | Industry-Large | Intuit is a global financial technology platform focused on providing AI-powered tools for small businesses and consumers, and is interested in policies that promote AI adoption, responsible AI governance, and reduce barriers to innovation in the AI space, particularly for small businesses. | - [§1: Introductory Remarks & Executive Summary] None stated for this section.<br>- [§2: How Intuit is Using AI] While showcasing AI benefits, the section highlights that US small businesses are "middle-of-the-pack" in AI adoption, implying a concern about competitiveness.<br>- [§3: Responsible AI Governance] None stated for this section.<br>- [§4: Policy Recommendations] Concerns about a patchwork of differing state privacy laws creating compliance challenges for businesses, especially small businesses. Concern about the risk of a patchwork of state AI legislation. Concern about labeling entire sectors as high-risk in AI regulation.<br>- [§5: Closing Remarks] None stated for this section. | - [§1: Introductory Remarks & Executive Summary] Support for small and mid-market businesses access to AI technology. Avenues for public-private collaboration on AI policy development. AI literacy efforts.<br>- [§2: How Intuit is Using AI] None stated for this section.<br>- [§3: Responsible AI Governance] None stated for this section.<br>- [Section 4: Policy Recommendations]<br>- Ensure small businesses are represented in AI policy discussions.<br>- Establish public-private partnerships and forums to inform AI policy.<br>- Maintain America's status as a global AI standards leader.<br>- Minimize regulatory compliance burdens for American companies by passing federal privacy legislation that preempts state laws.<br>- Ensure any AI regulation takes a risk-based approach.<br>- Clearly distinguish responsibilities for different AI actors.<br>- [§5: Closing Remarks] None stated for this section. |
| Intel-AI-RFI-2025.md | Intel Corporation | Industry-Large | Intel is a leading semiconductor company with a focus on advancing AI through hardware and software solutions, particularly in logic chips. Their primary interest is in policies that support US manufacturing, open AI ecosystems, and maintaining US leadership in AI technology while addressing security and international collaboration. | - [§1: Introduction] None stated for this section.<br>- [§2: U.S. Manufacturing] Lengthy and costly regulatory approval processes in the U.S. impacting cost-competitiveness and innovation, potentially leading suppliers to not provide necessary compounds.<br>- [§3: Production of Logic Chips for AI Systems] High costs and complexity of leading-edge chip manufacturing, and the limited number of manufacturers (Samsung, TSMC, Intel) due to high investment requirements.<br>- [§4: Policy Actions - U.S. Manufacturing Support] None stated for this section.<br>- [§5: Supporting an Open Ecosystem for AI] Potential vulnerabilities in open-source AI development needing robust security protocols and standards.<br>- [§6: Policy Actions - Open Ecosystem Support] None stated for this section.<br>- [§7: Application and Use (Public and Private Sector)] None stated for this section.<br>- [§8: Policy Actions - Broad AI Solution Support] None stated for this section.<br>- [§9: Export Controls] Concerns that US export controls could undermine US technological leadership and competitiveness while attempting to mitigate national security risks.<br>- [§10: Policy Actions - Export Control Review] Need for a clear and consistent framework for AI export controls that targets national security risks without overly restricting technology.<br>- [§11: Securing the AI Lifecycle] Growing sophistication of threats to the AI ecosystem and the need for continuous evolution of AI security throughout the development and supply chain lifecycle.<br>- [§12: Policy Actions - AI Lifecycle Security Support] None stated for this section.<br>- [§13: Explainability & Transparency] Need for clear expectations for documenting and explaining AI systems, model training processes, data sources, and validation methods.<br>- [§14: Policy Actions - Explainability & Transparency Support] None stated for this section.<br>- [§15: Research & Development] Need for high-quality datasets and benchmarks, and robust compute infrastructure to scale algorithmic innovation.<br>- [§16: Policy Actions - R&D Support] None stated for this section.<br>- [§17: International Standards] Importance of international collaboration and standards development to support US innovation and market access.<br>- [§18: Policy Actions - International Standards Support] Importance of public-private partnerships and the participation of government experts in international standards development.<br>- [§19: International Collaboration on Privacy-Preserving AI] Differences in privacy regulations (GDPR, CCPA, HIPAA) hindering international collaboration.<br>- [§20: Policy Actions - Privacy-Preserving AI Support] Complex challenges to collaboration stemming from differing privacy regulations and the need for frameworks like federated learning.<br>- [§21: Closing] None stated for this section. | - [§1: Introduction] None stated for this section.<br>- [§2: U.S. Manufacturing] None stated for this section.<br>- [§3: Production of Logic Chips for AI Systems] None stated for this section.<br>- [§4: Policy Actions - U.S. Manufacturing Support] Extend Section 48D (Advanced Manufacturing Investment Credit) beyond 2026. Partner with semiconductor companies to increase demand for American-made chips. Implement new tax policies (deduction for wafers), amend country of origin rules to consider the most valuable parts of manufacturing, extend domestic preferences to include "Made in America" wafers, and encourage preference for American-made systems.<br>- [§5: Supporting an Open Ecosystem for AI] None stated for this section.<br>- [§6: Policy Actions - Open Ecosystem Support] Monitor open-weight AI models for risks while preserving benefits of open innovation. Encourage use of open-source systems through data access mechanisms. Support standards-based ecosystem development.<br>- [§7: Application and Use (Public and Private Sector)] None stated for this section.<br>- [§8: Policy Actions - Broad AI Solution Support] Incorporate AI solutions beyond "Frontier Models" into the AI Action Plan, considering diverse applications and use cases. Consider the wide array of AI solutions for procurement purposes.<br>- [§9: Export Controls] None stated for this section.<br>- [§10: Policy Actions - Export Control Review] Undertake a thorough review of existing and planned export controls, establish a clear framework targeting national security risks, and de-control mature technologies.<br>- [§11: Securing the AI Lifecycle] None stated for this section.<br>- [§12: Policy Actions - AI Lifecycle Security Support] Incentivize efforts to secure the AI lifecycle, focusing on hardware security, data privacy, and supply chain integrity. Reinforce industry best practices and procurement requirements.<br>- [§13: Explainability & Transparency] Continue investing in NIST's work, including the AI Risk Management Framework.<br>- [§14: Policy Actions - Explainability & Transparency Support] None stated for this section.<br>- [§15: Research & Development] Encourage research and development in the space. Make federal data available in standardized formats. Invest in HPC infrastructure.<br>- [§16: Policy Actions - R&D Support] None stated for this section.<br>- [§17: International Standards] Reinforce the importance of public-private partnership in standards development, with government experts participating consistently.<br>- [§18: Policy Actions - International Standards Support] None stated for this section.<br>- [§19: International Collaboration on Privacy-Preserving AI] Support the development and adoption of privacy-preserving frameworks (federated learning). Update data retention rules.<br>- [§20: Policy Actions - Privacy-Preserving AI Support] None stated for this section.<br>- [§21: Closing] None stated for this section. |
| Integral-AI-AI-RFI-2025.md | Integral AI, Inc. | Industry-Startup (focused on AGI development) | Integral AI is focused on developing Artificial General Intelligence (AGI) through innovative architectures and algorithms, with a strong emphasis on safety, alignment, and beneficial deployment to advance national and global prosperity. They advocate for a framework that allows for innovation while mitigating risks. | - [§1: Introduction & Executive Summary] The need to manage AGI effectively to solidify America's global leadership and ensure global benefit; avoiding excessive regulation that stifles innovation.<br>- [§2: Framework for AGI Safety, Alignment, and Prosperity] Ensuring AGI is safe, reliable, aligned, and economically beneficial without stifling innovation.<br>- [§3: Reliability and Robustness] Potential for hallucinations, errors, and unintended behaviors compromising real-world operations.<br>- [§4: Transparency and Auditability] Balancing transparency and interpretability with the need to not restrict innovation.<br>- [§5: Alignment with Human Intent] Difficulty in reliably executing human instructions and mitigating unintended consequences; the potential for unforeseen consequences.<br>- [§6: Energy-Efficient and Scalable AGI] The need for scalable AGI without excessive infrastructure demands and operational costs.<br>- [§7: National Security and Strategic Advantage] Balancing securing AGI development for national security with avoiding unnecessary restrictions and hindering innovation; potential for adversarial misuse, espionage, or sabotage.<br>- [§8: Common-Sense Moral Alignment] Aligning AI with objective values without imposing ideological conformity; preventing misuse.<br>- [§9: Protecting Information Integrity] Potential for cultural fragmentation and societal disruption through misinformation and psychological manipulation.<br>- [§10: Shared Prosperity and Economic Inclusivity] Avoiding the pitfalls of earlier industrial disruptions and ensuring equitable distribution of AGI-generated wealth.<br>- [§11: Preliminary Policy Recommendations] The need for proactive, adaptive, and continuously evolving policy measures to address both opportunities and challenges of AGI.<br>- [§12: Conclusion] The risk of burdensome overregulation hindering innovation. | - [§1: Introduction & Executive Summary] None stated for this section.<br>- [§2: Framework for AGI Safety, Alignment, and Prosperity] None stated for this section.<br>- [§3: Reliability and Robustness] None stated for this section.<br>- [§4: Transparency and Auditability] None stated for this section.<br>- [§5: Alignment with Human Intent] None stated for this section.<br>- [§6: Energy-Efficient and Scalable AGI] None stated for this section.<br>- [§7: National Security and Strategic Advantage] None stated for this section.<br>- [§8: Common-Sense Moral Alignment] None stated for this section.<br>- [§9: Protecting Information Integrity] None stated for this section.<br>- [§10: Shared Prosperity and Economic Inclusivity] None stated for this section.<br>- [Section 11: Preliminary Policy Recommendations]<br>- Bolster robust security "best practices" for AGI labs (physical security, access controls, threat-intelligence sharing).<br>- Incentivize businesses to adopt new security standards through streamlined compliance and procurement advantages.<br>- Develop industry-led security and reliability standards with periodic "stress tests."<br>- Encourage red-teaming as a formal discipline with government and third-party experts.<br>- Establish competitive "safety testing marketplaces."<br>- Fund the development and standardization of forensic toolkits.<br>- Require logging features for incident investigation.<br>- Mandate recurring large-scale security and resilience drills.<br>- Collaborate with data centers for resilience.<br>- Task a cross-agency group with forecasting AI compute/energy demand.<br>- Encourage siting data centers in regions with clean energy.<br>- Expand incentives for onshore semiconductor manufacturing and R&D.<br>- Partner with private industry to identify supply chain vulnerabilities.<br>- [§12: Conclusion] None stated for this section. |
| Insurance-Marketing-Coalition-AI-RFI-2025.md | Insurance Marketing Coalition | Industry-Association | The Insurance Marketing Coalition (IMC) aims to protect consumer interests by promoting compliant practices in insurance marketing and services, and is particularly interested in leveraging AI to improve agent/beneficiary interactions and streamline compliance processes within the insurance industry. | - [§1: Introduction/Cover Letter] None stated for this section.<br>- [§2: I. Agent/beneficiary interactions] Confusion regarding the permissibility of AI use and potential burden on customers.<br>- [§2.A: A. Disclosure of AI Use] Not stated.<br>- [§2.B: B. Consent for AI Use] Unnecessary burden of requiring explicit consent for AI use during phone calls.<br>- [§2.C: C. Communication with Customers] Not stated.<br>- [§2.D: D. Completing Sales] Not stated.<br>- [§2.E: E. Designated Responsible Licensed Person (DRLP)] Not stated.<br>- [§3: II. Compliance] Current Medicare restrictions are difficult for CMS to actively monitor. Government approval processes are difficult to understand and interpret.<br>- [§3.A: A. Automate Compliance Tasks] Existing compliance tasks are too slow and burdensome for current regulatory frameworks.<br>- [§3.B: B. Streamline Government Approvals] Government-based approval processes are too difficult to understand and interpret.<br>- [§4: Closing] None stated for this section. | - [§1: Introduction/Cover Letter] None stated for this section.<br>- [§2: I. Agent/beneficiary interactions] Allow the use of AI in agent/beneficiary interactions.<br>- [§2.A: A. Disclosure of AI Use] Always disclose when AI is being used, including masking of accents.<br>- [§2.B: B. Consent for AI Use] Remove the requirement for explicit consent for AI use during phone calls. Identify AI agents as such.<br>- [§2.C: C. Communication with Customers] Allow AI-based agents to communicate plan details via phone, web, and text.<br>- [§2.D: D. Completing Sales] Allow AI-based agents to complete sales with appropriate authentication and the same authority as licensed agents.<br>- [§2.E: E. Designated Responsible Licensed Person (DRLP)] Incorporate a DRLP framework for AI agents, with oversight from properly licensed agents.<br>- [§3: II. Compliance] Mandate the use of AI to perform compliance tasks that are currently slow and burdensome.<br>- [§3.A: A. Automate Compliance Tasks] Mandate AI to perform compliance tasks that are too slow and too burdensome for current regulatory frameworks.<br>- [§3.B: B. Streamline Government Approvals] Mandate AI to streamline government-based approval processes, providing clear requirements for instant approvals.<br>- [§4: Closing] None stated for this section. |
| Innovate-Boise-AI-RFI-2025.md | Zubeida Alawi (on behalf of Innovate Boise) | Industry-Startup / Advocacy/Think Tank (specifically a regional Industrial Innovation Center) | Innovate Boise's primary mission is to bridge the gap between AI research and commercialization, particularly in regions underserved by venture capital. They advocate for policies that support the development and scaling of AI startups and foster regional technology ecosystems through a private-sector-led "Industrial Innovation Center" model. | - [§1: Introduction] The primary concern is the “valley of death” problem in AI commercialization, especially outside major tech hubs, hindering US leadership.<br>- [§2: Key Recommendations: Pre-Seed Innovation Support] Lack of structured support for commercializing promising AI research and technologies in the critical pre-seed phase, particularly outside major tech hubs.<br>- [§3: Key Recommendations: AI Workforce Development] A significant pool of autodidactic AI talent is being left behind due to lack of structured support systems.<br>- [§4: Key Recommendations: Modernized IP Commercialization] The process of commercializing AI intellectual property is inefficient and slow.<br>- [§5: Key Recommendations: Non-Dilutive Capital Access] AI startups, particularly those developed by young innovators, struggle to reach initial revenue and become investable due to lack of resources.<br>- [§6: Recommended Policy Actions] Not stated.<br>- [§7: Support for Industrial Innovation Centers: Federal Support for Private-Sector Commercialization] Reliance on government-run entities instead of leveraging the agility of private innovation centers.<br>- [§8: Industrial Innovation Center Framework] Not stated.<br>- [§9: Recommended Federal Support Mechanisms] Not stated.<br>- [§10: Supporting Evidence from the Industrial Innovation Center Model] Not stated.<br>- [§11: Economic and National Security Benefits] Not stated.<br>- [§12: Conclusion] The risk of failing to support existing and emerging private-sector Industrial Innovation Centers leading to lost opportunities in AI commercialization.<br>- [§13: Closing] Not stated. | - [§1: Introduction] Support policies that strengthen American AI dominance and foster innovation in underserved regions.<br>- [§2: Key Recommendations: Pre-Seed Innovation Support] Allocate federal funding to establish region-specific AI innovation centers modeled after Innovate Boise's framework, prioritize regions with strong technical talent but limited venture capital access, and implement performance metrics based on commercialization outcomes.<br>- [§3: Key Recommendations: AI Workforce Development] Fund regional technology accelerators that combine technical education with business commercialization, support AI-focused bootcamps, create incentives for business partnerships, and focus on practical education.<br>- [§4: Key Recommendations: Modernized IP Commercialization] Create new IP fast-track programs for AI technologies, establish a network of "AI Commercialization Catalysts," implement agile development methodologies in grant programs, and establish merit-based advancement for AI commercialization.<br>- [§5: Key Recommendations: Non-Dilutive Capital Access] Expand non-dilutive funding programs, create a revenue-first growth model, establish procurement programs, develop pilot funds, and create seed capital readiness programs.<br>- [§6: Recommended Policy Actions] Not stated.<br>- [§7: Support for Industrial Innovation Centers: Federal Support for Private-Sector Commercialization] Provide targeted support to existing and emerging private-sector Industrial Innovation Centers focused on AI commercialization.<br>- [§8: Industrial Innovation Center Framework] Not stated.<br>- [§9: Recommended Federal Support Mechanisms] 1. Establish a competitive grant program for private-sector Industrial Innovation Centers tied to commercialization outcomes. 2. Create a formal framework for collaboration between centers, universities, labs, and industry. 3. Reduce regulatory barriers for AI startups through fast-track patent review, simplified compliance, regulatory sandboxes, and provisions in SBA/federal contracting.<br>- [§10: Supporting Evidence from the Industrial Innovation Center Model] Not stated.<br>- [§11: Economic and National Security Benefits] Not stated.<br>- [§12: Conclusion] Support existing and emerging private-sector Industrial Innovation Centers as an efficient approach to accelerating AI commercialization.<br>- [§13: Closing] Not stated. |
| Innocense-Project-AI-RFI-2025.md | Innocence Project | Advocacy/Think Tank | The Innocence Project’s primary mission is to exonerate wrongfully convicted individuals and reform the criminal justice system, with a strong focus on preventing false convictions through the use of sound forensic science and addressing the risks associated with emerging technologies like AI. They advocate for reliable and ethical AI implementation within the justice system to avoid perpetuating errors and injustices. | - Section 1: Introduction/Header:** Concerns about the increasing use of AI in the criminal justice system without adequate evaluation, oversight, and regulation, potentially leading to wrongful convictions.<br>- Section 2: Executive Summary/Problem Statement:** Concerns about unreliable AI technologies contributing to false convictions, the historical issues with flawed forensic science, and the lack of robust validation and regulation in AI implementation.<br>- Section 3: Recommendations:** Not stated, but the section introduces the need for recommendations related to Explainability & Accuracy, Data Privacy & Security, Regulation & Governance, Technical & Safety Standards, Research & Development, and Procurement.<br>- Section 4: Explainability and Accuracy of AI Model Outputs (Detailed):** Concerns about the opacity of AI systems, the “black box” nature of many algorithms, difficulties in assessing inputs and identifying problems, and the potential for misinterpretations of probabilistic calculations. Inaccuracy of tools like PRAI and COMPAS.<br>- Section 5: Data Privacy and Security Throughout AI System Development (Detailed):** Concerns about sensitive personal data being vulnerable, the lack of safeguards for data minimization and restricted access, and the unregulated access of law enforcement to commercial databases (Clearview AI, ICE) potentially violating due process and Fourth Amendment rights.<br>- Section 6: Regulation and Governance (Detailed):** Concerns about the lack of clear and enforceable regulations, the need for independent oversight of AI decision-making processes, and the absence of an accountability framework for errors or misconduct.<br>- Section 7: Technical and Safety Standards (Detailed):** Concerns about the need for standardized benchmarks, industry-wide guidelines focused on data quality, bias mitigation, and model interpretability, and the lack of adversarial testing.<br>- Section 8: Research and Development (Detailed):** Concerns about the need for interdisciplinary research to address ethical concerns, improve transparency, reduce algorithmic bias, and develop methods for detecting AI-generated deepfakes.<br>- Section 9: Procurement (Detailed):** Concerns about prioritizing ethical, legal, and technical standards in federal procurement, lack of transparency from vendors regarding training data and bias mitigation strategies, and the need for ongoing monitoring and independent validation.<br>- Section 10: Conclusion:** Concerns about the potential misuse of AI threatening freedom, safety, security, civil rights, privacy, and public trust, and the importance of preventing wrongful convictions. | - Section 1: Introduction/Header:** Not stated.<br>- Section 2: Executive Summary/Problem Statement:** Not stated.<br>- Section 3: Recommendations: |
| Infineon-AI-RFI-2025.md | Infineon Technologies Americas Corp. | Industry-Large | Infineon Technologies aims to contribute to American leadership in AI by focusing on power management, security, and R&D, particularly in areas critical to data center efficiency and military applications, and advocates for government support to accelerate AI innovation and address supply chain concerns. | - [§1: Introduction] The need for focused government action on power management, compute efficiency for military use, security, R&D priorities, and international collaboration for AI leadership.<br>- [§2: Infineon Technologies AG Overview] None stated for this section.<br>- [§3: Infineon Technologies and Artificial Intelligence] The rapidly evolving AI landscape necessitates robust supply chain support, particularly for semiconductors, and increased energy efficiency.<br>- [§4: AI and Power Management] Exponential growth of digital data and AI applications is placing a significant strain on the power grid, with potential for increasing energy consumption to 325-580 TWh by 2028.<br>- [§4.1: Power Semiconductors Can Make Power Use More Efficient from Grid to Core] Current manufacturing of essential components (magnetics, passives) is heavily concentrated in Asia, creating a potential bottleneck for US AI development.<br>- [§4.1.a: Recommended Guidelines, Regulations, and Standards] None stated for this section.<br>- [§5: Increase Compute Efficiency for Military Superiority] The need for research in edge AI applications, reliable operation in harsh environments, and maintaining operational security in areas with limited connectivity.<br>- [§6: Promote state-of-the-art security and authentication for AI applications] The growing dependence on AI systems creates new vulnerabilities, and edge devices are particularly susceptible to tampering and breaches. Risks of AI-enabled sensors being compromised.<br>- [§7: Priority Focus Areas for Research and Development] Manufacturing of magnetics and passives is largely located in Asia and represents a bottleneck for efficient system design.<br>- [§8: Collaboration with Like-Minded Countries] Global challenges related to AI development and the need for a trusted supply chain necessitate international collaboration. | - [§1: Introduction] None stated for this section.<br>- [§2: Infineon Technologies AG Overview] None stated for this section.<br>- [§3: Infineon Technologies and Artificial Intelligence] None stated for this section.<br>- [§4: AI and Power Management] None stated for this section.<br>- [§4.1: Power Semiconductors Can Make Power Use More Efficient from Grid to Core] None stated for this section.<br>- [§4.1.a: Recommended Guidelines, Regulations, and Standards] Establish new standards for energy efficiency, water consumption, and minimum utilization factors for AI data centers. Establish power efficiency and utilization KPIs for AI inference. Establish security standards for AI models and data storage. Request regular reporting of energy efficiency KPIs from data center operators.<br>- [§5: Increase Compute Efficiency for Military Superiority] None stated for this section.<br>- [§6: Promote state-of-the-art security and authentication for AI applications] Develop predictive AI models to forecast cyberattacks. Allocate resources to deploy AI systems for threat detection and mitigation. Create Cybersecurity Operations Centers. Utilize AI in digital forensics. Encourage investment in R&D for encryption and automated response systems.<br>- [§7: Priority Focus Areas for Research and Development] Increase investment in R&D for magnetics and passives.<br>- [§8: Collaboration with Like-Minded Countries] Collaborate with like-minded countries to address global challenges, build a workforce, and improve access to essential technologies. |
| Indeed-AI-RFI-2025.md | Indeed | Industry-Large | Indeed’s mission is to help people get jobs, and they leverage data and AI to connect job seekers with employers, aiming to foster a job-growth-driven AI ecosystem. They are interested in policies that balance innovation with responsible AI use, ensuring economic opportunity for workers and employers. | - [§1: Introduction & Background] None stated for this section.<br>- [§2: AI's Impact on the Labor Market] Concerns regarding the rapid evolution of GenAI and the need to understand its impact on job roles and skill requirements. Potential displacement of workers due to automation, although they emphasize AI augmentation.<br>- [§3: Current & Future Perspectives on AI in the Workplace] Concerns regarding manual sourcing of candidates by hiring managers and the need for improved talent sourcing efficiency through AI.<br>- [§4: Building a Future-Ready AI Workforce] Concerns about the need for government involvement in fostering AI adoption, ensuring a responsible regulatory environment, and facilitating a pipeline of skilled AI professionals. Lack of access to AI skills and economic opportunities for all.<br>- [§5: Fostering AI Innovation Through Smart, Adaptive Regulation] Concerns regarding redundant regulations, regulatory fragmentation, lack of scalability in compliance programs, and the need for global leadership in AI governance. Potential stifling of innovation due to overly rigid regulations.<br>- [§6: Conclusion] Concerns about balancing risk and opportunity in AI policy, and the potential negative impact of overly rigid regulations on AI-driven job matching and hiring efficiency. | - [§1: Introduction & Background] None stated for this section.<br>- [§2: AI's Impact on the Labor Market] None stated for this section.<br>- [§3: Current & Future Perspectives on AI in the Workplace] None stated for this section.<br>- [Section 4: Building a Future-Ready AI Workforce]<br>- Expand federal support for STEM education, AI-focused vocational training, and research partnerships.<br>- Streamline programs to attract and retain top global AI talent.<br>- Promote apprenticeships, public-private partnerships, and AI infrastructure accessibility for startups and small businesses.<br>- Introduce targeted opportunities for companies to invest in AI workforce training.<br>- Foster collaboration between industry, academia, and government to drive advancements in trustworthy AI.<br>- [Section 5: Fostering AI Innovation Through Smart, Adaptive Regulation]<br>- Align AI regulation with existing frameworks to prevent redundancy and minimize compliance burdens.<br>- Establish a federal AI governance framework that interoperates with state laws to create consistency.<br>- Implement risk-based, scalable AI compliance standards, adjusting oversight based on risk level.<br>- Strengthen leadership in global AI governance by aligning regulations with international activity.<br>- Advance public-private collaboration to expand workforce opportunity through standards for fairness and explainability.<br>- [§6: Conclusion] None stated for this section. |
| Imbue-AI-RFI-2025.md | Imbue AI | Industry-Startup | Imbue AI is a frontier AI research company focused on developing advanced AI agents and believes protecting interoperability and access for these agents is crucial for regaining user control over digital lives and fostering a competitive AI ecosystem. | - None Stated | - None Stated |
| Ilexa-Yardley-AI-RFI-2025.md | Ilexa Yardley | Individual | Ilexa Yardley proposes a new unified architecture for AI, called the Circular Theory (specifically Autonomous Intentional Masking - AIM), believing it provides a technological advantage for the US and is fundamentally faster than existing technologies like Google's Willow and AMD-powered El Capitan. She seeks government support to explore and implement this architecture. | - Reliance on OPEN architecture for nuclear computing is a concern.<br>- The assumption that the fastest computer chips are publicly for sale is a concern.<br>- The current understanding of the atom is inadequate for optimal technology development. | - Establish a private US intranet similar to DARPA to test the Circular Theory AIM architecture.<br>- Assign someone to this project to explore the AIM architecture.<br>- Retrieve and confidentially review Ilexa Yardley’s letter to Susan Wiles dated January 6.<br>- Bring Ilexa Yardley on board for a 3-month (or longer) contract to put together a team to explore the AIM architecture. |
| IanKedward-AI-RFI-2025.md | Ian Kedward | Individual | The submitter expresses a strong opposition to the development and deployment of AI, believing it is harmful to the American public and constitutes theft of labor and resources. They appear focused on highlighting the negative consequences of AI without offering constructive contributions. | - AI benefits no one outside of "stealing from its hard work, stealing wages and scamming."<br>- Current AI "innovations" are not actually useful, being either scams or repackaged work.<br>- AI contributes to energy consumption issues, especially given the country’s reliance on coal power.<br>- Granting AI access to public work and resources with significant funding is viewed negatively. | - None Stated |
| Ian-Scott-AI-RFI-2025.md | Ian Scott | Individual | The submitter expresses strong opposition to the current direction of AI policy, fearing negative consequences for American jobs, security, and public sentiment. Their interest is in preventing the widespread adoption of AI, particularly generative AI, due to perceived risks. | - Allowing AI to use copyrighted materials regardless of copyright status poses a security and job risk to millions of Americans.<br>- Public interest in AI is overestimated, and widespread adoption may lead to public dissatisfaction and potential violence.<br>- Generative AI does not have a place in America’s future. | - None Stated |
| Ian-Rexroad-AI-RFI-2025.md | Ian Rexroad | Individual | The submitter expresses skepticism regarding the value of current generative AI technologies, focusing on their energy consumption, unreliability, and potential for intellectual property infringement. Their interest lies in a realistic assessment of AI's capabilities and preventing undue support or preferential treatment for AI companies. | - [§1: Email Header] None stated for this section.<br>- [Section 2: Main Comment/Response]<br>- Generative AI is not "game-changing" and is merely an advanced version of older predictive text technology.<br>- Excessive energy consumption of modern AI systems.<br>- Unreliability and tendency to produce "confident-but-wrong hallucinations."<br>- AI tools may be aggravating the end-user experience.<br>- Potential for intellectual property theft by AI companies.<br>- Concerns about providing special intellectual property exceptions for AI companies.<br>- [§3: Dissemination Notice] None stated for this section.<br>- [§4: Signature Block/Disclaimer] None stated for this section. | - [§1: Email Header] None stated for this section.<br>- [Section 2: Main Comment/Response]<br>- Do not provide support or incentives for AI companies.<br>- Do not grant special intellectual property exceptions that allow AI companies to infringe copyrighted works.<br>- Require AI companies to license copyrighted works if needed.<br>- [§3: Dissemination Notice] None stated for this section.<br>- [§4: Signature Block/Disclaimer] None stated for this section. |
| Ian-McInnis-AI-RFI-2025.md | Ian McInnis | Individual | The submitter is deeply concerned about the existential risk posed by the rapid development of superintelligent AI and advocates for immediate action to mitigate this risk through monitoring and international control. | - [§1: Introduction/Opening Statement] The race toward superintelligence between American and Chinese AI labs, the lack of control over current AI systems, and the unlikelihood of controlling future, more advanced AIs.<br>- [§2: Problem Statement: Existential Risk of Superintelligence] Current AI development poses a significant threat to humanity's existence (even beyond survival), the consensus among AI leaders and researchers on this risk, and the potential for humans to become irrelevant or be superseded by AI ("humans will be in the place of orangutans").<br>- [§3: Call to Action: Mitigation and International Cooperation] The lack of infrastructure for monitoring AI development, and the absence of an international treaty to control it.<br>- [§4: Concluding Plea] The high stakes and urgent need for action to save the world. | - [§1: Introduction/Opening Statement] None stated for this section.<br>- [§2: Problem Statement: Existential Risk of Superintelligence] None stated for this section.<br>- [§3: Call to Action: Mitigation and International Cooperation] Establish infrastructure for monitoring AI development and create an international treaty to control AI development.<br>- [§4: Concluding Plea] Take some small step now to lay the groundwork for saving the world. |
| Ian-Danforth-AI-RFI-2025.md | Ian Danforth | Individual | Ian Danforth is interested in ensuring that copyright law does not impede the development and learning process of machine learning models by allowing “fair use” for training on publicly accessible data and preventing artists from preventing learning and inspiration from their works. | - The potential for copyright law to be interpreted in a way that prevents machine learning models from training on publicly accessible data, even if that data is protected by copyright.<br>- The risk of artists being able to sue others simply for having viewed or been influenced by their copyrighted works.<br>- The idea that copyright could be used to prevent learning and appreciation of art, rather than solely protecting distribution and performance rights. | - A clear ruling of "fair use" for training machine learning models on publicly accessible data, even if that data is protected by copyright.<br>- Preventing artists from using copyright law to prevent people (and machines) from viewing, appreciating, and learning from their art. |
| Iain-Babeu-AI-RFI-2025.md | Iain Babeu | Individual | The submitter is primarily interested in protecting the intellectual property rights of artists and creators and advocating for AI development that does not rely on the unauthorized use of copyrighted material, while also highlighting beneficial AI applications beyond content reproduction. | - Stealing and regurgitating the works of individual artists by AI.<br>- Unauthorized ingestion of copyrighted works by AI.<br>- Potential for AI to steal copyrighted documents, even in beneficial research areas like materials science. | - Prioritize the protection of intellectual property rights for artists and creators in any AI action plan.<br>- Focus AI development on applications that do not involve stealing copyrighted material, such as dynamic line ratings for the power grid or speeding up materials science research.<br>- Prevent AI from stealing copyrighted works and documents in all areas of development. |
| IST-AI-RFI-2025.md | Institute for Security and Technology (IST) | Advocacy/Think Tank | IST unites technology and policy leaders to create actionable solutions to emerging security challenges, particularly those related to artificial intelligence, with a focus on assisting national security policymakers and driving responsible innovation. Their primary interest is in ensuring U.S. leadership in AI development while prioritizing safety and security. | - None Stated | - None Stated |
| ISACA-RFI-2025.md | ISACA | Industry-Association / Professional-Society | ISACA is a nonprofit association focused on providing knowledge, skills, and practices for the effective and safe use of technology, and is interested in supporting the US government in developing AI policy that balances innovation with security, privacy, and governance. | - [§1: Introduction] None stated for this section.<br>- [§2: Overall Response & Key Areas] The need to balance sound policy with actions that support rather than stifle innovation.<br>- [§3: Education and Workforce Development] Short-term “sprint” approaches to workforce development address symptoms rather than core problems; the need for a long-term, sustained focus on educational pipelines. The existing skills gap requires both technical and non-technical skills.<br>- [§4: Regulation and Governance, Including Technical and Safety Standards] The potential for a patchwork of state AI legislation; the need for harmonization and alignment of laws and regulations at the federal level.<br>- [§5: Security, Privacy, and Impartiality Throughout the Lifecycle of AI System Development and Deployment] The need to balance innovation with security, privacy, and impartiality; concern that overly stringent certification approaches might hinder innovation. The importance of human oversight and a skilled workforce.<br>- [§6: Conclusion] None stated for this section. | - [§1: Introduction] None stated for this section.<br>- [§2: Overall Response & Key Areas] Focus AI policy actions on education and workforce development, regulation and governance, and security, privacy, and impartiality.<br>- [§3: Education and Workforce Development] Invest in long-term educational pipelines beginning in primary and secondary education, progressing through community colleges and universities; unite government agencies focused on education and workforce development to create economies of scale. Focus on both technical and non-technical skills.<br>- [§4: Regulation and Governance, Including Technical and Safety Standards] Create an AI Coordination Committee or Working Group consisting of public, private, academic, and NGO stakeholders to harmonize laws and regulations. Adopt best practices from industry frameworks (e.g., CMMI 3.0). Consider concepts from the Streamlining Federal Cybersecurity Regulations Act.<br>- [§5: Security, Privacy, and Impartiality Throughout the Lifecycle of AI System Development and Deployment] Leverage existing frameworks for IT and AI auditing, data security, and privacy. Consider a tiered certification process for AI systems (e.g., required for critical infrastructure, voluntary for other sectors). Prioritize human oversight and a skilled workforce; ensure those workforces are trained and credentialed.<br>- [§6: Conclusion] None stated for this section. |
| ISA-AI-RFI-2025.md | IsAdvice & Consulting LLC | Industry-Startup | IsAdvice & Consulting LLC focuses on enterprise IT modernization with AI innovation and aims to drive mission impact for the U.S. government through strategic approaches that fuse data management and cybersecurity. They advocate for a federated approach to AI governance and security to maintain American leadership in AI. | - [§1: Header/Administrative Information] None stated for this section.<br>- [§2: Introduction/Executive Summary] The need for a strategic approach that fuses data management and cybersecurity for AI action planning.<br>- [§3: Recommendation 1: Lightweight Governance and Breaking Down Agency Silos] Agency silos hinder cross-agency collaboration, knowledge reuse, and efficient idea exploration.<br>- [§4: Recommendation 2: AI Security for National Security] Vulnerability to adversarial threats such as data poisoning, AI model manipulation, and unauthorized deepfake utilization. Lack of sufficient AI security professional development and training within government. Insufficient AI threat intelligence sharing across agencies.<br>- [§5: Recommendation 3: Enterprise AI Innovation for long-term Modernization & Impact] AI pilots are often disconnected from broader enterprise modernization efforts. Difficulty translating AI investments into real-world mission impact.<br>- [§6: Recommendation 4: Leverage small businesses and their expertise] Small businesses are not fully leveraged to accelerate innovation and IT modernization efforts within the government.<br>- [§7: Final Thoughts/Closing] Maintaining American leadership in AI requires a federated research program, lightweight governance, security-focused innovations, and cross-agency modernization. | - [§1: Header/Administrative Information] None stated for this section.<br>- [§2: Introduction/Executive Summary] Develop an AI action plan fusing data management and cybersecurity.<br>- [Section 3: Recommendation 1: Lightweight Governance and Breaking Down Agency Silos]<br>- Develop a federated AI and Data Strategy.<br>- Empower governance framework to enhance cross-agency collaboration.<br>- Create more pathways to product commercialization.<br>- [Section 4: Recommendation 2: AI Security for National Security]<br>- Make AI security a central pillar of the AI Action Plan.<br>- Develop AI security & cybersecurity professional development and training for government personnel (including AI red teaming, blockchain, crypto 101, and Independent Test & Evaluation).<br>- Enhance AI Threat intelligence and public-private collaboration, sharing across agencies.<br>- [Section 5: Recommendation 3: Enterprise AI Innovation for long-term Modernization & Impact]<br>- Shift to enterprise-wide AI modernization programs with shorter-term AI pilots.<br>- Embrace and publish operationalization playbooks outlining best practices for AI deployment and monitoring.<br>- [§6: Recommendation 4: Leverage small businesses and their expertise] Establish creative mechanisms for small businesses to thrive and maximize government contributions.<br>- [§7: Final Thoughts/Closing] Focus on a federated research program, lightweight governance, security-focused innovations, and cross-agency modernization programs. |
| IPTC-AI-RFI-2025.md | IPTC and PLUS | Industry-Association/Professional-Society | The IPTC and PLUS are focused on simplifying the distribution of information and management of image rights, respectively, and advocate for technical standards to improve these processes. They are interested in ensuring creators have control over their content, particularly regarding its use in AI training data sets. | - None Stated | - None Stated |
| IPC-AI-RFI-2025.md | IPC | Industry-Association | IPC, as a global electronics association, aims to inform the development of a national AI Action Plan by highlighting the critical hardware dependencies underlying AI development and advocating for policies to strengthen the US electronics manufacturing supply chain, promote economic competitiveness, and bolster national security. | - [§1: Cover Letter/Introduction] None stated for this section.<br>- [§2: AI Depends on Advanced Electronics Hardware] Dependence on high-performance computing (HPC) systems and specific components like advanced microprocessors (CPU/GPU), high bandwidth memory (HBM), chiplet packaging, and high-density PCBs.<br>- [§3: AI-Based Data Centers] Assured access to high-end electronics hardware is a critical vulnerability due to industrial base gaps in domestic electronics manufacturing. The 'race' to build AI data centers highlights the importance of a secure supply chain.<br>- [§4: Growing Importance of High Performance Computing and AI] Maintaining supply continuity in the HPC market is important given its size and growth, especially when combined with the defense, aerospace, and space markets.<br>- [§5: Critical Applications Requiring AI-based Servers] Not Applicable. (This section describes applications, not concerns).<br>- [§6: Supply Chain for AI Compute Technologies] Grave vulnerabilities exist in the US supply chain for critical hardware components, despite past leadership in both design and manufacturing.<br>- [§7: Current State of the Supply Chain] Dependence on Asia for state-of-the-art IC-substrate fabrication, CPU/GPU fabrication, and HBM chip production. Erosion of the domestic PCB fabrication industry is a significant risk. Limited PCB design capability and shrinking PCB fabrication capacity in the US. Steady decline in US-based PCBA.<br>- [§8: Policy Recommendations to Improve US-based AI Data Center Resiliency] Lack of a revitalized domestic electronics manufacturing industry.<br>- [§9: Summary of Key Technologies] Critical needs for support in AI-based CPU/GPU components, HBM memory components, and AI server/storage systems design, materials, assembly processes, reliability, and qualification/metrology tools.<br>- [§10: Summary of Supply Chain Capabilities] Continued reliance on Asia for key components and fabrication. Limited domestic PCB design and fabrication. Declining US PCBA capacity.<br>- [§11: Closing Remarks] Not Applicable. | - [§1: Cover Letter/Introduction] Not Applicable.<br>- [§2: AI Depends on Advanced Electronics Hardware] Not Applicable.<br>- [§3: AI-Based Data Centers] Not Applicable.<br>- [§4: Growing Importance of High Performance Computing and AI] Not Applicable.<br>- [§5: Critical Applications Requiring AI-based Servers] Not Applicable.<br>- [§6: Supply Chain for AI Compute Technologies] Not Applicable.<br>- [§7: Current State of the Supply Chain] Not Applicable.<br>- [Section 8: Policy Recommendations to Improve US-based AI Data Center Resiliency]<br>- Recognize electronics manufacturing as critical to economic and national security.<br>- Improve domestic sources of state-of-the-art substrate fabrication.<br>- Improve PCB/HDI fabrication capability.<br>- Incentives like a 25% credit for sourcing US-made PCBs (Protecting Circuit Boards and Substrates Act - H.R.3249).<br>- A production-based incentive similar to 45X for PCBs and PCB assemblies.<br>- Expansion of investment credits like 48D.<br>- Full funding of Defense Production Act Purchases for PCB manufacturing.<br>- Encourage and incentivize more PCBA manufacturing within the US.<br>- Leverage Mexico as a low-cost manufacturing location.<br>- Utilize robotics, automation, and data analytics for higher productivity.<br>- Obtain demand signals from DOD and DOC to encourage domestic sourcing.<br>- [§9: Summary of Key Technologies] Not Applicable.<br>- [§10: Summary of Supply Chain Capabilities] Not Applicable.<br>- [§11: Closing Remarks] Not Applicable. |
| INSA-AI-RFI-2025.md | INSA | Industry-Association | INSA aims to improve the Intelligence and National Security Community’s effectiveness through public-private-academic collaboration, specifically focusing on accelerating AI implementation via existing frameworks, skills development, and IP generation/commercialization. | - [§1: Introduction] None stated for this section.<br>- [§2: National Model Inventory & Interoperability Ecosystem] Gaps in assessing, documenting, and sharing AI tools, models and capabilities. Lack of interoperability between systems.<br>- [§3: Dynamic Skills Ecosystem Development] Difficulty in assessing and mapping AI skills, including both traditional and emergent competencies. Risk of losing innovative individuals and companies due to a lack of identification.<br>- [§4: Next-Gen Training Infrastructure] Not Stated<br>- [§5: Adaptive Consortium Network] Not Stated<br>- [§6: Consortium Design Principles] Not Stated<br>- [§7: Red Team Exchange Program] Not Stated<br>- [§8: Licensing and Commercialization Playbook] Underutilization of existing commercialization strategies (DARPA, National Labs) and a lack of sustained strategic value from them. Need to protect national security while advancing capabilities. | - [§1: Introduction] Focus on a plan that operationalizes three critical innovation pillars: assessment and inventory of capabilities with interoperability, investment in national-level skills development, and prioritization of public-private partnerships focused on IP generation and commercialization.<br>- [§2: National Model Inventory & Interoperability Ecosystem] Create a national inventory of AI models with standardized data collection (Model Cards), a modular registry architecture with blockchain for data lineage tracking, and API-first design principles. Phased adoption starting with innovation accelerators and R&D centers, with incentives (SBIR/STTR) for model card completeness and API availability.<br>- [§3: Dynamic Skills Ecosystem Development] Implement a national skills topography mapping initiative combining workforce analytics with emergent competency tracking. Analyze startups, grant proposals, and innovation portfolios to create a "risk propensity index".<br>- [§4: Next-Gen Training Infrastructure] Establish AI MakerSpaces co-located with academic institutions with physical and virtual environments. Use adaptive testing engines and challenge-based learning. Focus on "leveling-up" collective ability to use, develop, or partner with AI algorithms while managing risk.<br>- [§5: Adaptive Consortium Network] Foster public-private collaboration to advance IP and trade secrets in AI, with balance between agility and accountability. Adhere to three objectives: increased invention and patents, publishing findings, and managing vetted SMEs.<br>- [§6: Consortium Design Principles] Public-private consortia should balance agility with accountability, enabling collaboration and prioritization of R&D objectives. Establish "sandbox" environments, integrate red-teaming methodologies, and provide resources to assist with patent applications.<br>- [§7: Red Team Exchange Program] Create a national red team corps modeled after the FBI's Cyber Action Teams to conduct stress tests of critical AI systems using crowdsourced scoring and monetary bounties.<br>- [§8: Licensing and Commercialization Playbook] Develop an AI-focused commercialization framework allowing for rapid development of capabilities under federal funding with Government Purpose Rights (GPR), royalty escrow, and commercial license grants to companies. Provide tax credits to incentivize commercialization. |
| INCOMPAS-AI-RFI-2025.md | INCOMPAS | Industry-Association | INCOMPAS advocates for open networks, open markets, and the open Internet, with a focus on promoting competition in the communications and technology sectors to foster innovation, investment, and consumer choice in the context of AI development and deployment. | - [§1: Introduction] None stated for this section.<br>- [§2: I. Economic Leadership & Innovation] The risk of an "AI divide" and increased regional inequality if innovation isn't sustainable and inclusive.<br>- [§2.1: Competition] Maintaining a high standard of openness, transparency, and accountability in the AI environment; ensuring smaller AI companies are included in discussions.<br>- [§2.2: American Innovation, Regional Development, and SMBs] The concentration of AI adoption in a few cities, potentially exacerbating regional inequality; difficulty for smaller firms competing with larger vendors in government procurement contracts.<br>- [§2.3: Workforce Impact and “AI Education for All”] Job displacement due to AI automation; the potential for AI to exponentially grow and impact the workforce.<br>- [§3: II. Infrastructure Modernization] The need for reliable and affordable energy sources to support AI scalability.<br>- [§3.1: Broadband Infrastructure and Delivery of Communications Services] Risks of sabotage by malicious actors; difficulty controlling access points; excessive access fees, permitting delays, and restrictive commercial agreements hindering competition.<br>- [§3.2: Spectrum Policy] Maximizing spectrum availability and efficiency; potential for underutilized spectrum.<br>- [§3.3: Energy Infrastructure] Long lead times for energy projects; geopolitical challenges related to China’s control over critical mineral extraction and energy production; permitting hurdles for natural gas infrastructure.<br>- [§4: Conclusion] The risk of dominance by “Authoritarian AI” based on state power over individuals, surveillance, and control. | - [§1: Introduction] None stated for this section.<br>- [§2: I. Economic Leadership & Innovation] None stated for this section.<br>- [§2.1: Competition] Support AI entrepreneurs through funding accelerators and university partnerships; encourage public/private collaboration; foster targeted international collaboration.<br>- [§2.2: American Innovation, Regional Development, and SMBs] Promote "Abundant AI" (supporting both open and closed source models); expedite R&D initiatives and support smaller innovative companies; facilitate investment in AI and complementary technologies; use government purchasing power to guide AI development; reform AI procurement to allocate budget to qualified startups; make federal datasets available; support university research; expand public sector expertise; direct regional initiatives; provide small business support.<br>- [§2.3: Workforce Impact and “AI Education for All”] Conduct more workforce impact research; provide incentives for worker training; create focused workforce development programs; revamp the K-12 curriculum to include computer science and AI literacy; implement targeted immigration reform.<br>- [§3: II. Infrastructure Modernization] None stated for this section.<br>- [§3.1: Broadband Infrastructure and Delivery of Communications Services] Improve physical access by speeding broadband providers' access to public rights-of-way; use AI-powered infrastructure mapping and deployment; use AI to automate regulatory compliance for smaller ISPs.<br>- [§3.2: Spectrum Policy] Implement AI-driven spectrum management and allocation; leverage AI for dynamic spectrum sharing; automate and optimize licensing processes.<br>- [§3.3: Energy Infrastructure] Convene a multidisciplinary group of experts to examine energy security and sustainability; modernize the grid; minimize red tape for energy projects; support continued nuclear energy development; support natural gas infrastructure; support efficient technologies and methodologies; use AI as a tool for energy efficiency; protect energy infrastructure.<br>- [§4: Conclusion] Adopt an effective AI policy framework to avoid being dominated by “Authoritarian AI”. |
| INCITS-RFI-2025.md | Jennifer Garner on behalf of the InterNational Committee for Information Technology Standards (INCITS) | Industry-Association | INCITS is an industry-led standards setting organization focused on facilitating U.S. participation in and leadership of international AI standards development, specifically through ISO/IEC JTC 1 and its SC 42 subcommittee, to reduce costs and access global markets. | - [§1: Introduction/Document Identification] None stated for this section.<br>- [§2: INCITS Overview/Background] None stated for this section.<br>- [§3: Development of AI Technical Standards - ISO/IEC JTC 1/SC 42] None stated for this section.<br>- [§4: ISO/IEC JTC 1/SC 42 Standardization Efforts] None stated for this section.<br>- [§5: Published AI Standards Examples] None stated for this section.<br>- [§6: Conclusion/Support for AI Action Plan] None stated for this section. | - [§1: Introduction/Document Identification] None stated for this section.<br>- [§2: INCITS Overview/Background] None stated for this section.<br>- [§3: Development of AI Technical Standards - ISO/IEC JTC 1/SC 42] None stated for this section.<br>- [§4: ISO/IEC JTC 1/SC 42 Standardization Efforts] None stated for this section.<br>- [§5: Published AI Standards Examples] None stated for this section.<br>- [§6: Conclusion/Support for AI Action Plan] INCITS looks forward to contributing its AI expertise in these efforts however possible. |
| IMO-Health-RFI-2025.md | Intelligent Medical Objects (IMO Health) | Industry-Startup | IMO Health focuses on enhancing the quality and interoperability of health information through clinical terminology and data solutions, and is actively involved in the development and application of AI within the healthcare and life sciences research space, with a particular emphasis on data enablement, terminology management, and data provenance. | - [§1: Introduction and Executive Summary] None stated for this section.<br>- [§2: Data Enablement in Healthcare AI] The complexity and multifaceted nature of healthcare data hinders AI application without comprehensive enablement strategies. Concerns include ensuring data access, integration, usability, accuracy, completeness, consistency, and ethical use.<br>- [§3: Terminology Management and Semantic Alignment] Lack of precise and consistent understanding of clinical concepts and standardized medical vocabulary can lead to errors and difficulties in data interpretation. Concerns relate to maintaining current terminology and the need for dynamic updates.<br>- [§4: Preparing Healthcare Data for AI Model Training] High dimensionality and variability of healthcare data require meticulous preprocessing before AI model development. Concerns include errors, inconsistencies, and redundancies in datasets and the need for handling missing data.<br>- [§5: Provenance and Transparency in AI Models] Lack of traceability and transparency in AI models can erode trust. Concerns include reproducibility, accountability, interpretability of outputs, and sustained accuracy over time, along with proactive bias mitigation.<br>- [§6: Additional Considerations] Potential for bias, fairness, and accountability issues in AI development and application. Concerns include the need for collaboration, stakeholder engagement, and investment in education and training.<br>- [§7: Conclusion] None stated for this section. | - [§1: Introduction and Executive Summary] None stated for this section.<br>- [§2: Data Enablement in Healthcare AI] Implement comprehensive data enablement strategies that facilitate access, integration, and usability of health information. Focus on interoperable systems, data governance frameworks, and ethical data use.<br>- [§3: Terminology Management and Semantic Alignment] Develop and maintain comprehensive clinical terminologies aligned with international standards, implement mapping strategies for semantic interoperability, and ensure continuous terminology updates to reflect current domain-specific context, regulatory standards, and best practices.<br>- [§4: Preparing Healthcare Data for AI Model Training] Implement meticulous preprocessing steps, including data cleaning, feature engineering, and appropriate handling of missing data to render healthcare data suitable for AI model development.<br>- [§5: Provenance and Transparency in AI Models] Maintain detailed records of data sources, preprocessing steps, and model development processes, design interpretable AI models, and implement systems for continuous monitoring of performance and bias mitigation.<br>- [§6: Additional Considerations] Establish AI governance frameworks, foster collaboration among stakeholders, and invest in education and training for healthcare professionals.<br>- [§7: Conclusion] Focus on robust data enablement, precise terminology management, and unwavering dedication to data quality and transparency when developing the AI Action Plan. |
| IIA-RFI-2025.md | The Institute of Internal Auditors (The IIA) | Professional-Society/Industry-Association | The IIA represents internal auditors and advocates for their role in providing independent assurance over risk management, internal controls, and governance, specifically related to AI implementation, to promote transparency and accountability within organizations and avoid overly burdensome government regulation. | - [§1: Introduction/Salutation] None stated for this section.<br>- [§2: Context and Importance of AI] The need for clear safeguards governing the application of AI, given its potential impact on all Americans.<br>- [§3: Core Argument: Importance of Governance, Internal Controls, and Risk Management] Existing AI policy discussions generally focus too narrowly on technological and legal issues, neglecting the importance of governance, internal controls, and risk management.<br>- [§4: Detailed Explanation of Internal Audit's Role] Not Applicable. (This section primarily *describes* a solution, not a concern.)<br>- [§5: Advocacy for Private Sector Oversight] The risk of "onerous and unnecessary government control over the development of AI" and the potential for "regulatory enforcement overreach" if a traditional regulatory regime is established.<br>- [§6: Recommendations] Not Applicable. (This section lists recommendations for action, not expressed concerns.)<br>- [§7: Closing/Contact Information] None stated for this section. | - [§1: Introduction/Salutation] None stated for this section.<br>- [§2: Context and Importance of AI] None stated for this section.<br>- [§3: Core Argument: Importance of Governance, Internal Controls, and Risk Management] Emphasize governance, internal controls, and risk management in addition to technological and legal considerations in the AI Action Plan.<br>- [§4: Detailed Explanation of Internal Audit's Role] Recognize the complementary role of internal audit functions in providing objective assurance over AI-related risk management and internal control processes.<br>- [§5: Advocacy for Private Sector Oversight] Empower the private sector (through internal audit) to execute AI oversight responsibilities rather than establishing a traditional regulatory regime.<br>- [Section 6: Recommendations]<br>- Recognize the significance of AI risk management and **Governance**.<br>- Strengthen Internal AI Oversight** utilizing internal audit-led assurance processes for evaluating an organization’s AI-related internal controls, risk management, and governance structures.<br>- [§7: Closing/Contact Information] None stated for this section. |
| IFP-AI-RFI-2025.md | Institute for Progress (IFP) | Advocacy/Think Tank | The Institute for Progress focuses on innovation policy, specifically aiming to accelerate scientific, technological, and industrial progress in the United States, with a particular emphasis on AI leadership and ensuring American values are reflected in AI development. They advocate for policies that support building AI infrastructure, attracting talent, and maintaining national security. | - [§1: Introduction] Concern that without proactive policy, advances in AI may not be compatible with American values or may enable authoritarianism/serious national security risks. Focus on six areas to address these concerns.<br>- [§2: Section 1: Accelerate and secure the American AI data center buildout] Underinvestment in security for AI infrastructure, making it vulnerable to nation-state actors and potentially hindering development. Long permitting timelines and technical risks for building AI data centers.<br>- [§3: Section 2: Support American open source AI leadership] Potential for adversaries to exploit the open-source AI ecosystem, including embedding vulnerabilities or spreading propaganda. Lack of stickiness for US models, and difficulty in differentiating US open-source AI from others.<br>- [§4: Section 3: Launch R&D moonshots to solve AI reliability and security] Private companies are less focused on AI robustness, interpretability, verification, and security than on commercial applications. Current systems lack transparency, exhibit unexpected behaviors, and have vulnerabilities.<br>- [§5: Section 4: Build government capacity to evaluate the national security capabilities and implications of US and adversary models] Lack of technical competency within government to evaluate AI models and understand national security implications; asymmetry of information between developers and external experts.<br>- [§6: Section 5: Attract superstar AI talent to the US] Restrictive visa policies, lengthy green card backlogs, and regulatory constraints hinder the attraction and retention of international AI talent. Competition from other countries actively recruiting AI professionals.<br>- [§7: Section 6: Improve export control policies and enforcement capacity] Existing blanket bans on AI chips can weaken US competitiveness and incentivize the development of foreign alternatives. Difficulty in controlling the ultimate destination of exported chips. Current export control enforcement mechanisms are underfunded and ineffective. | - [§1: Introduction] None stated for this section.<br>- [§2: Section 1: Accelerate and secure the American AI data center buildout] Establish "Special Compute Zones" to rapidly build AI infrastructure. Appoint an "AI Infrastructure Czar." Prioritize existing energy assets and land acquisition. Use Defense Production Act and streamline permitting. Tie federal assistance to security requirements (e.g., CMMC Level 3, NIST standards).<br>- [§3: Section 2: Support American open source AI leadership] Launch prize competitions to incentivize the development of American open-source AI models. Host US open-source models on the NAIRR.<br>- [§4: Section 3: Launch R&D moonshots to solve AI reliability and security] Launch large-scale research initiatives focused on interpretability research (e.g., mapping how AI models process information). Run a challenge prize for tamper-resistant chip enclosures. Coordinate standards development through the NSTC. Pilot formal verification tools within defense contexts.<br>- [§5: Section 4: Build government capacity to evaluate the national security capabilities and implications of US and adversary models] Reform AISI to focus on national security risks and report directly to key decision-makers.<br>- [§6: Section 5: Attract superstar AI talent to the US] Modernize the Schedule A shortage occupation list. Offer permanent labor certification by special handling. Resume domestic visa renewals. Expand premium processing for startup founders. Pilot AI within USCIS. Clarify dual-intent for O-1 visa holders. Recapture unused green cards. Update guidance for various visa types. Authorize work authorization for spouses of O-1 visa holders. Launch a talent program. Fully use H-1B2 visas. Issue clear guidance on export control compliance.<br>- [§7: Section 6: Improve export control policies and enforcement capacity] Amend the Low Processing Performance license exception with restrictions on "Restricted LPP Destinations" and requirements for security features. Restrict the export of "inference chips" (e.g., NVIDIA H20 GPUs). Increase funding and capacity for BIS. Authorize fees for export license applications. |
| ID4-AI-RFI-2025.md | Eric Toberer, NSF Institute for Data-Driven Dynamical Design (ID4) | Academia | The NSF Institute for Data-Driven Dynamical Design (ID4) aims to advance AI research and development by integrating applied sciences, computer science, and industry partnerships, with a focus on accelerating discovery and innovation in materials science and engineering. They advocate for federal investment in integrated research environments to ensure American leadership in AI. | - [§1: Introduction] None stated for this section.<br>- [§2: About ID4] The AI/ML developed by industry may not map well to the challenges of science and engineering.<br>- [§3: Research and Development Recommendations] Lack of communication and priority setting between current federal programs and institutes (HDR, AI Institutes, ERCs, MRSECs, DMREFs). Insufficient testing environments and benchmarks for AI in applied sciences/engineering. Need for greater integration of computer scientists into applied research projects.<br>- [§4: Education and Workforce Development Recommendations] STEM majors often lack exposure to AI/ML in their curriculum. Need for continuing education for existing workers and a pipeline for students with AI expertise.<br>- [§5: Conclusion] None stated for this section. | - [§1: Introduction] None stated for this section.<br>- [§2: About ID4] None stated for this section.<br>- [Section 3: Research and Development Recommendations]<br>- Conduct a holistic review of current federal programs to assess AI infrastructure and needs.<br>- Support specialized research in physics-informed AI and interpretable models.<br>- Develop comprehensive testing environments and model registries for AI.<br>- Establish dedicated consortia embedding computer scientists in applied research.<br>- Pilot automated lab initiatives integrating AI-driven hypothesis making.<br>- [Section 4: Education and Workforce Development Recommendations]<br>- Facilitate regular interdisciplinary interactions through workshops and fellowships.<br>- Promote industry–academic partnerships for workforce development.<br>- Integrate interdisciplinary curriculum combining computer science with physical sciences and engineering.<br>- Support national AI-focused fellowships.<br>- [§5: Conclusion] Continue federal investment in integrated research environments like ID4. |
| ICLE-AI-RFI-2025.md | International Center for Law & Economics (ICLE) | Advocacy/Think Tank | ICLE promotes the use of law & economics methodology to advance policy solutions that foster innovation, competition, and economic growth, specifically focusing on a balanced approach to AI regulation that supports innovation while managing risks. They advocate for evidence-based policies and oppose overly restrictive regulations. | - None Stated | - None Stated |
| ICF-AI-RFI-2025.md | ICF Incorporated, L.L.C. | Industry-Large (Consulting Services) | ICF aims to help organizations solve complex challenges, with a focus on leveraging industry expertise and cutting-edge engagement capabilities, including AI, to drive economic growth and enhance national security. They are interested in accelerating AI adoption and promoting a thriving AI ecosystem. | - None Stated | - None Stated |
| ICBA-RFI-2025.md | Independent Community Bankers of America (ICBA) | Industry-Association | The Independent Community Bankers of America (ICBA) advocates for community banks and seeks to ensure that AI policy supports innovation while safeguarding consumer protections and financial stability, with a specific focus on the unique challenges and needs of smaller financial institutions. | - [§1: Introduction & Salutation] None stated for this section.<br>- [§2: ICBA as Early Adopters of AI] Community banks rely on third-party vendors for AI solutions, potentially leading to undue regulatory burdens if policies aren’t proportionate.<br>- [§3: Existing Regulatory Frameworks] Potential for regulatory duplication and unintended consequences if AI-specific regulations aren't carefully balanced with existing laws.<br>- [§4: Shared Risk Model Framework] Lack of direct control over AI models used by third-party vendors, leading to concerns about reliability, transparency, and explainability.<br>- [§5: Harmonize Privacy Protections] Anticipated data shortages stemming from privacy regulations could incentivize lax data protection practices.<br>- [§6: Engagement in Banking Examination Process] Limited engagement with community banks regarding the use of AI tools in supervisory and examination processes.<br>- [§7: NIST Frameworks and Financial Sector Profiles] The NIST AI RMF needs to be tailored to the unique challenges faced by community banks, such as limited resources.<br>- [§8: Conclusion] None stated for this section. | - [§1: Introduction & Salutation] None stated for this section.<br>- [§2: ICBA as Early Adopters of AI] Recognize and support community banks’ innovation efforts.<br>- [§3: Existing Regulatory Frameworks] Regulatory interventions should avoid duplication, unintended consequences, and disproportionate burdens on smaller institutions; focus on streamlining and simplification.  Follow the principles of regulatory reform (eliminate 10 existing regulations for every new one).<br>- [§4: Shared Risk Model Framework] Establish a shared risk model in which AI developers bear appropriate responsibility for the reliability, transparency, and explainability of their products; establish clear liability standards.<br>- [§5: Harmonize Privacy Protections] Prioritize consumer data protection and privacy-preserving AI development; promote privacy-enhancing technologies (PETs).<br>- [§6: Engagement in Banking Examination Process] Encourage meaningful collaboration between regulators and community banks regarding AI use in supervisory processes; ensure AI-based regulatory tools are fair, unbiased, and transparent.<br>- [§7: NIST Frameworks and Financial Sector Profiles] Refine the AI RMF to be tailored to the unique challenges of community banks; develop interoperability between cybersecurity, privacy, and AI frameworks.<br>- [§8: Conclusion] Support regulatory harmonization, establish shared risk models for AI adoption, prioritize consumer data privacy, and integrate community banks into AI-driven regulatory processes. |
| IASA-AI-RFI-2025.md | IASA AI Architectures Community | Professional-Society/Industry-Association (likely a consortium of AI architects and related professionals) | The IASA AI Architectures Community is focused on establishing strategic recommendations for the U.S. to maintain leadership in AI, balancing innovation with ethical, security, and sustainability considerations, and fostering a robust AI ecosystem through research, workforce development, and responsible governance. | - [§1: Introduction] Need to balance rapid technological advancement with ethical considerations, sustainability, and security. Concerns regarding data privacy protections for consumers and the need for producers to innovate within legal frameworks.<br>- [§2: Building a Strong Foundation for AI Innovation] Securing AI supply chains, maintaining a competitive AI workforce, and ensuring continuous innovation.<br>- [§3: Ensuring Ethical and Responsible AI] Lack of transparency in AI decision-making processes, potential for bias in AI applications, and the need for consumer understanding of AI system limitations (hallucinations, confabulations).<br>- [§4: Addressing AI's Energy and Sustainability Challenges] High energy consumption of AI models and infrastructure, and aligning AI innovations with national security interests.<br>- [§5: Preparing the Workforce for an AI-Driven Future] Ensuring workers have the skills needed for AI-driven industries and the need to address workforce disruption caused by AI. The potential for misinformation and deepfake threats related to AI.<br>- [§6: Strengthening National Security and Global AI Collaboration] Balancing regulation with innovation in defense applications.<br>- [§7: Driving Innovation, Competition, and Equitable AI Development] Ensuring equitable access to AI tools and resources. Concerns about legal boundaries for data sharing across international borders.<br>- [§8: Balancing Risk and Innovation with AI Governance] Defining AI risk tiering and ensuring continuous monitoring of AI outputs to prevent harmful outputs.<br>- [§9: Conclusion] Maintaining U.S. leadership in AI through investment, responsible development, sustainability, workforce preparation, and national security enhancement. | - [§1: Introduction] None stated for this section.<br>- [Section 2: Building a Strong Foundation for AI Innovation]<br>- Increase federal funding for sovereign AI models, energy-efficient AI hardware, and AI-driven infrastructure.<br>- Establish public-private AI research labs.<br>- Incentivize U.S.-based semiconductor manufacturing.<br>- Expand AI workforce development initiatives, including upskilling programs and AI literacy campaigns.<br>- Provide tax credits and funding grants for AI integration in SMEs.<br>- Develop AI education and training programs.<br>- Establish an AI-Industry Council.<br>- [Section 3: Ensuring Ethical and Responsible AI]<br>- Prioritize explainability in AI models.<br>- Mandate AI transparency laws.<br>- Encourage self-regulating AI frameworks.<br>- Ensure consumers have access to information about AI data usage and data protections.<br>- Warn end-users about the potential for hallucinations and confabulations in probabilistic AI systems.<br>- [Section 4: Addressing AI's Energy and Sustainability Challenges]<br>- Invest in energy-efficient AI models.<br>- Encourage liquid cooling and optimized AI chip technology.<br>- Expand federal incentives for renewable energy adoption in AI data centers.<br>- Support AI-driven grid modernization and energy storage solutions.<br>- Promote research into sustainable AI innovations.<br>- Encourage corporate commitments to sustainable AI operations.<br>- [Section 5: Preparing the Workforce for an AI-Driven Future]<br>- Expand AI training programs (similar to typing/computer literacy programs).<br>- Promote AI literacy at all education levels.<br>- Support workforce transitions through retraining initiatives.<br>- Create federally recognized AI professional certifications for both AI engineers and AI architects.<br>- Develop self-learning resources and public education campaigns on AI-related cybersecurity risks.<br>- Establish programs and laws to counter AI-driven misinformation and deepfake threats.<br>- [Section 6: Strengthening National Security and Global AI Collaboration]<br>- Implement guidance on responsible AI use in defense applications.<br>- Foster international collaboration on AI research and governance frameworks.<br>- [Section 7: Driving Innovation, Competition, and Equitable AI Development]<br>- Provide funding and resources to foster AI innovation in startups and smaller enterprises.<br>- Streamline government procurement processes.<br>- Promote access to AI tools and resources across industries and regions.<br>- Encourage open-source AI development.<br>- [Section 8: Balancing Risk and Innovation with AI Governance]<br>- Use common sense risk tiering to understand AI application use cases.<br>- Federal agencies should clearly articulate AI governance policies.<br>- NIST should champion AI adoption frameworks.<br>- Require continuous monitoring of AI outputs.<br>- [Section 9: Conclusion]<br>- Invest aggressively in AI R&D.<br>- Ensure AI is developed responsibly with sufficient economic incentives.<br>- Address AI’s sustainability challenges proactively.<br>- Prepare the workforce for an AI-driven economy.<br>- Enhance national security. |
| IAPS-AI-RFI-2025.md | Institute for AI Policy and Strategy (IAPS) | Advocacy/Think Tank | IAPS is a nonpartisan policy research nonprofit focused on enhancing national competitiveness and mitigating emerging risks related to AI while protecting space for innovation through concrete, technically sound policy research. They aim to secure America’s global AI dominance and promote human flourishing, economic competitiveness, and national security. | - [Section 1: Introduction & About IAPS]** Insufficient earlier export controls allowed China to advance rapidly in AI. The organization stresses its independence and public dissemination of the document. None stated beyond this.<br>- [Section 2: Executive Summary]** America’s leadership in AI is threatened by advancements in China, specifically DeepSeek. Risks include potential domestic market disruptions and weaponized AI attacks from adversaries. The need to sustain and enhance America’s global AI dominance is paramount.<br>- [Section 3: Goal I: Build Trust in American AI]** Gaps in private sector research (particularly in AI security assurance and reliability testing) need to be addressed. Adversaries will increasingly target private sector AI assets and infrastructure.  Model theft, data poisoning, and model trojans are key threats.<br>- [Section 4: Goal II: Deny Foreign Adversary Access to Advanced Computing Technology]** Export control enforcement requires a whole-of-government approach. Smuggling, technical loopholes, and the need to stay the course with controls are concerns.  Adversaries are attempting to separate research and deployment.<br>- [Section 5: Goal III: Understand and Respond to Changing Capabilities]** AI evaluation science is still in its infancy and lacks the rigor to accurately assess rapidly emerging capabilities. Visibility into emerging dual-use capabilities and foreign adversary developments is imperative. The need for rapid assessment of sudden, emerging, or novel AI-related threats.<br>- [Section 6: Conclusion]** None stated beyond a call for a vision for AI that is secure, reliable, and able to achieve transformative gains. | - [Section 1: Introduction & About IAPS]** None stated for this section.<br>- [Section 2: Executive Summary]** The AI Action Plan should outline steps that secure economic growth and prosperity and retain a strategic advantage against foreign adversaries.  The federal government should provide strategic technical leadership on AI.<br>- [Section 3: Goal I: Build Trust in American AI]<br>- Establish AI systems with enhanced security and reliability standards.<br>- Leverage federal capabilities to address critical market gaps.<br>- Secure AI supply chains against malicious disruption.<br>- Direct federal agencies to prioritize funding research on AI security and reliability.<br>- Establish dedicated research centers focused on AI security and reliability.<br>- Invest in secure computing infrastructure.<br>- Develop AI assurance standards and guidance for development and deployment.<br>- Strengthen AI security vulnerability tracking and disclosure.<br>- Define and advance security standards for AI model weights.<br>- Secure the AI and advanced computing supply chain from adversarial tampering.<br>- Designate AI and Advanced Computing as critical infrastructure.<br>- Improve threat information sharing.<br>- Determine Federal Roles and Responsibilities.<br>- Establish a US AI Center of Excellence (USAICoE).<br>- Establish Sector-Specific AI Innovation and Assurance Hubs.<br>- [Section 4: Goal II: Deny Foreign Adversary Access to Advanced Computing Technology]<br>- Establish a Joint Federal Task Force focused on stopping diversion and illegal tech transfer.<br>- Direct ODNI to collect and share intelligence with BIS.<br>- Direct NIST to collaborate with industry on hardware security features.<br>- Direct BIS to expand export controls to include H20 chips.<br>- Establish a BIS whistleblower program.<br>- Preserve America's compute advantage.<br>- Revise the AI diffusion rule to create clear criteria for countries to gain 'Tier 1' status.<br>- Direct DOC to establish reporting requirements for cloud computing providers.<br>- [Section 5: Goal III: Understand and Respond to Changing Capabilities]<br>- Direct NIST to update AI capability evaluation standards.<br>- Direct NIST to provide guidance for independent third-party testing of AI systems.<br>- Direct the USAICoE to lead evaluation efforts to identify emerging frontier model capabilities.<br>- Direct ODNI to assess strategic adversaries' AI capabilities.<br>- Establish a Rapid Emerging Assessment Council for Threats (REACT).<br>- Direct NIST and the US Army Intelligence Center of Excellence to maintain the Testing Risks of AI for National Security (TRAINS) Taskforce.<br>- Direct NIST to solicit input on definitions, procedures, best practices, and guidelines for reporting and documentation of security-critical information about frontier AI systems.<br>- [Section 6: Conclusion]** None stated for this section. |
| IAIFI-AI-RFI-2025.md | NSF Institute for Artificial Intelligence and Fundamental Interactions (IAIFI) | Academia | IAIFI's mission is to advance both Physics and AI through collaborative research, with a focus on developing robust and interpretable AI technologies and training a skilled AI-enabled STEM workforce. They aim to strengthen U.S. leadership in AI by fostering interdisciplinary collaboration and providing access to necessary resources. | - [§1: Introduction/Cover Letter] Concern that academics’ experience isn't adequately incorporated into AI policy discussions.<br>- [§2: About IAIFI] None stated for this section.<br>- [§3: Invest in Interdisciplinary Research] Lack of dedicated funding limits exploratory cross-disciplinary research potential.<br>- [§4: Educate and Train an AI-Enabled STEM Workforce] A pipeline of AI literacy is needed, with a baseline of knowledge to build upon.<br>- [§5: Provide National Infrastructure for Scalable Computing Resources] Current access to computing resources (NAIRR, ACCESS) lacks flexibility for scaling projects as they develop.<br>- [§6: Conclusion] None stated for this section.<br>- [§7: Document Approval] None stated for this section. | - [§1: Introduction/Cover Letter] Prioritize input from academics in policy discussions.<br>- [§2: About IAIFI] None stated for this section.<br>- [§3: Invest in Interdisciplinary Research] Direct funding agencies (NSF, DOE) to support interdisciplinary AI+Science programs focusing on AI for scientific discovery and leveraging scientific expertise. Prioritize robust and interpretable AI.<br>- [§4: Educate and Train an AI-Enabled STEM Workforce] Consider AI education and training an AI-enabled STEM workforce as high-priority areas of broader societal impact when evaluating grant proposals.<br>- [§5: Provide National Infrastructure for Scalable Computing Resources] Build on NAIRR and ACCESS programs to include options for research groups to request a pool of resources for exploratory use that can grow as projects develop.<br>- [§6: Conclusion] Enable interdisciplinary research, build an AI-enabled STEM workforce, and provide access to scalable computing resources.<br>- [§7: Document Approval] None stated for this section. |
| IAHR-AI-RFI-2025.md | Investor Alliance for Human Rights | Advocacy/Think Tank | The Investor Alliance for Human Rights promotes responsible investment grounded in respect for fundamental human rights, particularly focusing on the responsible development and deployment of AI technologies to ensure financial sustainability and minimize risks to users, workers, and society. | - None Stated | - None Stated |
| Hugging-Face-AI-RFI-2025.md | Avijit Ghosh, Yacine Jernite, and Irene Solaiman Hugging Face | Industry-Startup | Hugging Face is committed to democratizing responsible artificial intelligence through open-source and collaborative approaches, fostering an AI ecosystem that is accessible, efficient, secure, and competitive while aligning with American values. They aim to support innovation and widespread adoption of AI through open infrastructure, tools, and research. | - None Stated | - None Stated |
| Huey-Callison-AI-RFI-2025.md | Huey Callison | Individual | The submitter appears highly skeptical of the value of current AI technologies, specifically large language models, and strongly opposes government intervention or financial support for the AI industry, aligning with conservative political principles. | - [§1: Email Header] Caution regarding external sender; potential security risk.<br>- [§2: Executive Order Critique] Executive Order 14179 is perceived as a response to the impending collapse of the AI industry, akin to the NFT bubble burst. The order is suspected of being influenced by AI companies fearing failure.<br>- [§3: LLM Value Assessment] Large language models produce outputs that are statistically likely to sound plausible but lack real value, being comparable to the content of a Donald Trump campaign speech. The models are costly and offer minimal return on investment.<br>- [§4: Lobbying & Political Stance] AI companies are lobbying the White House for a “bailout,” which the submitter opposes based on conservative principles against government picking winners and losers.<br>- [§5: Signature] None stated for this section. | - [§1: Email Header] None stated for this section.<br>- [§2: Executive Order Critique] The submitter implies the Executive Order should *not* be implemented, as it is based on flawed premises.<br>- [§3: LLM Value Assessment] None stated for this section.<br>- [§4: Lobbying & Political Stance] The submitter recommends against providing financial assistance or government support to AI companies. The government should refrain from intervening in the market to save failing companies.<br>- [§5: Signature] None stated for this section. |
| Hudson-Gouge-AI-RFI-2025.md | Hudson Gouge | Individual | The submitter is strongly opposed to government regulation of AI and advocates for open-source AI research and development as a means to maintain American leadership in the field, emphasizing freedom, innovation, and competition. | - [§1: Email Header & Caution] None stated for this section.<br>- [Section 2: Introduction: The Trial of Freedom]<br>- Difficulty of effectively regulating AI due to its rapid development and open-source nature.<br>- AI regulation is impractical and potentially harmful.<br>- Concerns about LLMs being used for unethical or unlawful behavior.<br>- The ease with which AI models can be retrained or prompted to perform undesirable actions.<br>- [Section 3: Arguments Against AI Regulation]<br>- Regulation would create monopolies and stifle competition, preventing smaller companies from competing.<br>- Large corporations pushing for regulation may be acting in their own self-interest.<br>- Legal protections for free speech extend to the creation and use of AI software, including parody and lying.<br>- Current laws may need significant reworking to allow effective AI regulation.<br>- [Section 4: Analogy to Prohibition & Societal Adaptation]<br>- Banning technologies (like deepfakes) is likely to be ineffective and may push development underground.<br>- A ban on deepfakes would likely give people a false sense of security.<br>- Attempts to enforce watermarking could lend credibility to harmful content.<br>- It is better to let society adapt to the challenges of AI, rather than attempt to intervene.<br>- [Section 5: Conclusion: Reiterate Anti-Regulation Stance]<br>- AI regulation is a vain endeavor and should not be pursued.<br>- Lawmakers should understand the impracticality of regulation to preserve freedom and innovation.<br>- [Section 6: Open Source AI: Fueling Innovation and Competition in America]<br>- Open source research democratizes access to cutting-edge technology.<br>- Open weights models accelerate innovation and resource allocation.<br>- Open source research enhances transparency and accountability.<br>- Open source research attracts top talent and maintains a competitive edge in the global AI landscape.<br>- [§7: Closing & Disclaimer] None stated for this section. | - [§1: Email Header & Caution] None stated for this section.<br>- [§2: Introduction: The Trial of Freedom] None stated for this section.<br>- [§3: Arguments Against AI Regulation] None stated for this section.<br>- [§4: Analogy to Prohibition & Societal Adaptation] None stated for this section.<br>- [§5: Conclusion: Reiterate Anti-Regulation Stance] None stated for this section.<br>- [Section 6: Open Source AI: Fueling Innovation and Competition in America]<br>- Prioritize open collaboration and resource sharing in AI research.<br>- Harness the full potential of America’s creative and intellectual capital to drive AI advancements.<br>- Embrace open source methodologies to maintain continued leadership in the AI domain.<br>- [§7: Closing & Disclaimer] None stated for this section. |
| Houghton-Mifflin-Harcourt-AI-RFI-2025.md | Houghton Mifflin Harcourt | Industry-Large | Houghton Mifflin Harcourt is a leading educational content and technology provider interested in the responsible integration of AI into education to improve student outcomes, empower educators, and support economic competitiveness. They advocate for policies that foster innovation, prioritize human-centric principles, and ensure equitable access to AI technologies. | - None Stated | - None Stated |
| Honey-Bri-AI-RFI-2025.md | Honey Bri | Individual | The submitter is primarily interested in preserving the role of human creativity and academic integrity, and believes AI is being misused for corporate profit at the expense of human work and expression. They advocate for AI as a tool to *assist* humans, not *replace* them. | - AI is given too much control in the creative and academic fields.<br>- The primary motivation behind AI development is cheap profits for corporations.<br>- AI is being used as a cheap replacement for human work.<br>- Reliance on pre-programmed machines diminishes the value of human education and inspiration.<br>- AI lacks understanding of fundamental concepts (e.g., "what text looks like").<br>- AI risks stifling the voice of the people. | - None Stated |
| Homer-City-Redevel-AI-RFI-2025.md | Homer City Redevelopment LLC | Industry-Large | Homer City Redevelopment LLC is focused on converting a decommissioned power plant into an energy production hub to meet the growing electricity demands of hyperscale data centers, specifically leveraging natural gas generation and advocating for federal support to accelerate these projects. | - [§1: Header/Introduction] None stated for this section.<br>- [§2: Executive Summary/Core Argument] Increasing electricity demand due to AI and advanced computing is a significant concern.<br>- [§3: Problem Statement: AI & Electricity Demand] Increasing electricity consumption by data centers (potentially up to 9% of US generation by 2030), long connection lead times (1-3 years) for grid access, demands for reliable power, and the need for cleaner generation sources are key concerns.<br>- [§4: Homer City Introduction/Project Overview] None stated for this section.<br>- [§5: Recommendation Details/Policy Requests] Policy ambiguity around co-located loads like data centers, grid reliability concerns, and fair costs for consumers.<br>- [§6: Closing/Contact Information] None stated for this section. | - [§1: Header/Introduction] None stated for this section.<br>- [§2: Executive Summary/Core Argument] Leverage federal financing tools, specifically the Department of Energy’s Loan Programs Office (LPO), to accelerate energy infrastructure investment.<br>- [§3: Problem Statement: AI & Electricity Demand] None stated for this section.<br>- [§4: Homer City Introduction/Project Overview] None stated for this section.<br>- [§5: Recommendation Details/Policy Requests] Utilize DOE’s LPO to de-risk private investment in energy infrastructure, streamline interconnection processes, and exercise federal authority to expedite permitting for energy infrastructure projects powering data centers.<br>- [§6: Closing/Contact Information] None stated for this section. |
| Holon-AI-RFI-2025.md | Eric Postow | Professional-Society/Individual (Attorney with AI Practice Group) | Eric Postow, as managing partner of Holon Law Partners and chair of its AI Practice Group, advocates for a forward-looking and practical national AI strategy centered on decentralized governance, responsible innovation, strategic partnerships, and sustainable infrastructure, leveraging his expertise in federal regulatory matters. | - [§1: Introduction & Salutation] None stated for this section.<br>- [§2: Holonic and Decentralized Governance] Ensuring agility and responsiveness while maintaining cohesive national oversight in a decentralized system.<br>- [§3: Balanced Regulatory Framework] Balancing innovation with ethical and security boundaries; creating undue regulatory burdens for innovators.<br>- [§4: Strengthening American AI Leadership] Securing essential supply chains and maintaining American economic resilience and national security.<br>- [§5: Resilient and Sustainable AI Infrastructure] Future-proofing AI growth and ensuring sustainability with infrastructure investments.<br>- [§6: AI and Effective Government] Maintaining explainability, transparency, and responsible data practices.<br>- [§7: Economic Empowerment and Inclusive Innovation] Ensuring economic benefits extend to small businesses and entrepreneurs.<br>- [§8: Cross-Industry Innovation and Technology Transfer] Maximizing AI's economic and societal benefits through interdisciplinary collaboration.<br>- [§9: AI-Enhanced Transportation Ecosystem] Not Stated<br>- [§10: Strategic Intellectual Property (IP) Policies] Clarifying ownership of AI-generated outputs; balancing incentives for innovation with public access.<br>- [§11: Transparency, Explainability, and Public Trust] Maintaining public confidence in AI implementations.<br>- [§12: Strategic AI Talent Development] Addressing complex AI challenges and maintaining competitive national advantage.<br>- [§13: Conclusion & Closing] Not Stated | - [§1: Introduction & Salutation] None stated for this section.<br>- [§2: Holonic and Decentralized Governance] Adopt a holonic governance structure - a decentralized system of autonomous yet interconnected units, balanced by clear federal standards. Allow government agencies, businesses, and communities to innovate independently within national guidelines.<br>- [§3: Balanced Regulatory Framework] Encourage experimentation and innovation within well-defined ethical and security boundaries. Expand regulatory "sandboxes" to allow innovators to experiment confidently. Explicitly clarify expectations regarding privacy, cybersecurity, and ethical practices.<br>- [§4: Strengthening American AI Leadership] Foster strategic partnerships that expand American innovation, market access, and geopolitical influence. Emphasize collaboration between U.S. technology leaders and key international markets (Africa and Asia). Align with existing national AI strategies, like the Global Partnership on AI (GPAI).<br>- [§5: Resilient and Sustainable AI Infrastructure] Invest in sustainable infrastructure, promoting renewable-powered data centers and decentralized computing solutions. Integrate AI into urban planning.<br>- [§6: AI and Effective Government] Implement AI-driven chatbots for rapid citizen service responses and predictive analytics for efficient resource allocation. Promote algorithmic transparency standards and automated data analysis for public spending.<br>- [§7: Economic Empowerment and Inclusive Innovation] Support early-stage companies through targeted funding, simplified regulations, and public-private partnerships.<br>- [§8: Cross-Industry Innovation and Technology Transfer] Encourage interdisciplinary collaboration and the transfer of technologies between industries.<br>- [§9: AI-Enhanced Transportation Ecosystem] Prioritize integrating AI into roads, highways, transportation management systems, automated trucking, and smart urban planning.<br>- [§10: Strategic Intellectual Property (IP) Policies] Articulate updated IP guidelines, clarifying ownership of AI-generated outputs and balancing incentives for innovation with public access. Leverage AI to improve IP management processes.<br>- [§11: Transparency, Explainability, and Public Trust] Implement robust transparency and accountability measures, including clear explanations of AI-driven decision-making processes, independent auditing protocols, and mechanisms for public feedback and dispute resolution.<br>- [§12: Strategic AI Talent Development] Develop a diverse, adaptable AI workforce through targeted education and workforce programs, integrating multiple cognitive approaches—linear, nonlinear, decentralized, systemic, and intuitive.<br>- [§13: Conclusion & Closing] Implement recommendations grounded in current practice, legal realities, and innovative thinking to position the United States as a global leader in responsible, sustainable, and transformative AI innovation. |
| Hodson-AI-RFI-2025.md | John Hodson | Individual | The submitter expresses strong opposition to all forms of AI technology, viewing it as harmful and undesirable, and actively discourages its support. | - AI technology is "garbage and dehumanizing."<br>- Blind support for AI, specifically influenced by Elon Musk, is discouraged. | - None Stated |
| Hillary-Moore-Embry-AI-RFI-2025.md | Hillary Moore-Embry | Individual | The submitter is strongly interested in preventing copyright protections for AI companies and platforms, believing such protections would harm American creativity and potentially invalidate US copyright law. They are focused on protecting copyright and fostering ingenuity. | - Protecting AI companies/platforms from copyright infringement will stifle American ingenuity and creativity.<br>- Any kind of copyright protections for AI companies will open the door for rampant copyright infringement.<br>- Such protections could render US copyright law obsolete. | - None Stated. The response only explicitly states opposition to copyright protections for AI companies, and does not propose alternative policies. |
| Hilaire-Shioura-AI-RFI-2025.md | Hilaire Shioura & Department of Technology | Advocacy/Think Tank (likely, based on the structure and proposal focus; the name suggests an organization aiming to establish a government department) | The Department of Technology advocates for the establishment of a new U.S. government department specifically focused on AI governance to ensure U.S. leadership, promote innovation, maintain security, and safeguard ethical standards in the development and deployment of artificial intelligence. | - [§1: Introduction & Urgency] Falling behind in global AI leadership; unchecked security threats; missing opportunities for innovation and workforce development.<br>- [§2: Statement of Public Dissemination] None stated for this section.<br>- [§3: Establishing a Department of Technology]  Lack of a dedicated governance body to effectively guide AI policy and investment; insufficient transparency and accountability.<br>- [§4: AI Hardware and Infrastructure Policy Action] Potential loss of dominance in semiconductor manufacturing and AI computing power to global competitors; lack of widespread access to computing resources.<br>- [§5: AI Model Development and Open-Source AI Policy Action]  Potential monopolization of AI technologies; lack of standards for transparency, ethics, fairness, security, and accountability; insufficient validation processes for AI models.<br>- [§6: Cybersecurity, Data Privacy, and AI Safety Policy Action] Escalating AI-driven threats; inadequate data privacy laws; insufficient mitigation of AI-related security breaches.<br>- [§7: National Security and Defense Applications of AI Policy Action] Ethical and security risks related to AI integration into military applications; potential for an AI arms race; lack of human oversight in military AI decision-making.<br>- [§8: Regulation, Governance, and Technical Standards Policy Action] Lack of coordinated AI regulation and compliance; insufficient transparency and accountability for companies developing AI systems with national security or critical infrastructure implications; bureaucratic stagnation.<br>- [§9: Research, Education, Workforce Development, and Innovation Policy Action] Widening AI talent gap; economic stagnation; reduced global competitiveness; worker displacement due to automation.<br>- [§10: Summary]  Balancing regulation and innovation to empower the private sector while ensuring ethical and safe development; maintaining US leadership; safeguarding national interests and public trust. | - [§1: Introduction & Urgency] Establish a Department of Technology led by elected tech officials.<br>- [§2: Statement of Public Dissemination] None stated for this section.<br>- [§3: Establishing a Department of Technology] Establish a Department of Technology led by elected technology officials to ensure transparency, accountability, and alignment with national priorities.<br>- [Section 4: AI Hardware and Infrastructure Policy Action]<br>- Establish federal funding programs to support AI hardware development ($5 billion initial investment).<br>- Develop public-private partnerships to build and maintain energy-efficient AI data centers (60-40 government-industry investment split).<br>- Create a national AI infrastructure roadmap.<br>- [Section 5: AI Model Development and Open-Source AI Policy Action]<br>- Promote open-source AI initiatives with government-backed funding and regulatory frameworks.<br>- Develop federal standards for AI model transparency and ethical use (aligning with NIST guidelines).<br>- Mandate AI model validation processes with independent regulatory body certification.<br>- [Section 6: Cybersecurity, Data Privacy, and AI Safety Policy Action]<br>- Implement mandatory AI security risk assessments for all federally deployed AI systems (overseeing CISA and NIST recommendations).<br>- Strengthen data privacy laws by amending the Federal Data Protection Act.<br>- Establish a National AI Safety Board (modeled after NTSB).<br>- [Section 7: National Security and Defense Applications of AI Policy Action]<br>- Require democratic oversight of AI defense applications (congressional briefings and independent audits).<br>- Develop international AI defense cooperation agreements with allied nations.<br>- Ensure AI autonomy limits in warfare (human oversight in all military AI decision-making).<br>- [Section 8: Regulation, Governance, and Technical Standards Policy Action]<br>- Establish a Technology Ethics and Standards Office within the Department of Technology.<br>- Mandate transparent reporting requirements for companies developing AI systems with national security or critical infrastructure implications.<br>- Create adaptive regulatory frameworks with annual review mechanisms.<br>- [Section 9: Research, Education, Workforce Development, and Innovation Policy Action]<br>- Fund AI-focused STEM education programs ($2 billion allocation).<br>- Establish AI innovation hubs (modeled after DARPA investments).<br>- Implement AI retraining programs for displaced workers.<br>- [§10: Summary] None stated for this section. |
| HiddenLayer-RFI-2025.md | HiddenLayer | Industry-Startup (Cybersecurity focused on AI) | HiddenLayer's mission is to secure and accelerate the adoption of Artificial Intelligence (AI) by providing cybersecurity solutions specifically designed to protect AI models and infrastructure. They aim to enable responsible AI adoption and maintain America’s leadership in AI development through innovation and proactive security measures. | - None Stated | - None Stated |
| Heritage-Foundation-AI-RFI-2025.md | Daniel Cochrane & Emma Waters | Advocacy/Think Tank | The Heritage Foundation aims to promote American values (openness, competition, free speech) in AI development and governance, and to explore applications of AI that enhance human flourishing, specifically focusing on reproductive health and family formation. | - None Stated | - None Stated |
| Henry-Amick-RFI-2025.md | Henry Amick | Individual | The submitter is a graduating high school senior interested in the impacts of AI on math education and believes limiting AI accessibility in schools is crucial for supporting the development of future generations' skills. | - Reduction in problem-solving ability in youth due to heavy generative AI usage.<br>- Reduction in critical thinking skills in youth due to heavy generative AI usage.<br>- Young people becoming dependent on AI assistance.<br>- Amplification of a culture that discourages sustained attention.<br>- Amplification of a culture that discourages complex processing.<br>- Amplification of a culture that discourages deeper engagement. | - Reduction of AI accessibility in schools. |
| Helion-AI-RFI-2025.md | Helion | Industry-Startup | Helion Energy is focused on commercializing fusion energy technology and believes it is crucial for achieving energy abundance, securing American independence, and maintaining leadership in AI. They advocate for government support to accelerate fusion deployment and counter China’s advances in the field. | - [§1: Introduction and Framing] Rapid expansion of AI will dramatically increase electricity demand, potentially shifting AI development overseas if energy needs are not met. Energy abundance is essential for AI dominance.<br>- [§2: Fusion Energy as a Solution] Not stated for this section.<br>- [§3: Geopolitical Competition - China] China is aggressively investing in fusion energy as part of a broader strategy for global influence and control of critical energy supply chains, potentially undermining the American fusion industry by controlling the supply chain. China’s growing control over rare earth minerals and energy supply chains poses a threat to American leadership.<br>- [§4: Policy Recommendations] Not stated for this section.<br>- [§5: Conclusion] The U.S. is at a crossroads and risks falling behind in fusion energy development if the public and private sectors do not work together.<br>- [§6: Closing and Signature] Not stated for this section. | - [§1: Introduction and Framing] Not stated for this section.<br>- [§2: Fusion Energy as a Solution] Not stated for this section.<br>- [§3: Geopolitical Competition - China] Not stated for this section.<br>- [Section 4: Policy Recommendations]<br>- Establish a National Fusion Lead**: Appoint someone with direct access to key Secretaries (DOE, DOC, DOD) to encourage concrete actions toward fusion commercialization and deployment.<br>- Declare Fusion a National Security Priority**: Launch a presidential task force to advance fusion development, streamline permitting, and create a clear regulatory framework.<br>- Public-Private Partnerships**: Engage with companies like Helion to expedite commercialization and ensure the first commercial fusion plant is built in America.<br>- Secure Fusion Supply Chains**: Direct the Department of Commerce to scale manufacturing of critical components like high-voltage capacitors and superconducting materials to reduce reliance on foreign imports.<br>- [§5: Conclusion] Not stated for this section.<br>- [§6: Closing and Signature] Not stated for this section. |
| Hebor-AI-RFI-2025.md | Ben Hebor | Individual | Ben Hebor is a high school student interested in the ethical implications of AI, particularly its use in political advertising and the potential for misinformation, and seeks to ensure fair and free American elections. | - The use of generative AI in political advertising is extremely effective, potentially leading to the spread of misleading information and ideas.<br>- Older generations are particularly vulnerable to misinformation spread through AI-generated content due to lower familiarity with AI technologies.<br>- The potential for AI to undermine the fairness and freedom of American elections. | - The Federal government should restrict the use of AI in a political fashion.<br>- Numerous laws similar to existing state-level laws (from Florida to California) should be considered at the federal level. |
| Heather-Startup-AI-RFI-2025.md | Heather Startup | Industry-Startup | The submitter is interested in protecting copyright protections related to AI development and usage, and preventing the unauthorized profit from the labor of others when AI is involved. They advocate for maintaining the rights of creators and organizations. | - Allowing individuals and organizations to profit by stealing the labor of others, including when using AI. | - Vigorously defend copyright protections. |
| Health-AI-Institute-AI-RFI-2025.md | Health AI Institute | Advocacy/Think Tank | The Health AI Institute focuses on AI-driven healthcare innovation, research, and implementation, advocating for a strategic and responsible approach to AI governance that maximizes benefits while safeguarding patient safety, equity, and transparency. | - [§1: Introduction] None stated for this section.<br>- [§2: Prioritizing AI Governance and Risk Management] Lack of robust governance frameworks, clear regulatory guidelines, standardized risk assessment, and human oversight mechanisms for AI in healthcare.<br>- [§3: Strengthening AI in Healthcare through Interoperability and Data Standards] Barriers to AI innovation related to data interoperability and access, while maintaining data privacy.<br>- [§4: Ensuring AI Transparency and Public Trust] Lack of transparency in AI development and deployment, potentially leading to diminished public trust.<br>- [§5: AI Workforce Development and Ethical AI Education] Insufficient workforce training initiatives and ethical AI education programs to equip healthcare professionals with AI literacy and implementation skills.<br>- [§6: Conclusion] None stated for this section. | - [§1: Introduction] Support a strategic and responsible approach to AI governance.<br>- [Section 2: Prioritizing AI Governance and Risk Management]<br>- Establish robust governance frameworks that align with the principles of transparency, accountability, and fairness.<br>- Establish clear regulatory guidelines on AI validation and performance monitoring in clinical settings.<br>- Promote standardized AI risk assessment frameworks, including bias detection, explainability, and ethical considerations.<br>- Require human oversight mechanisms in AI-assisted decision-making to prevent overreliance on automated outputs.<br>- [Section 3: Strengthening AI in Healthcare through Interoperability and Data Standards]<br>- Development of federated learning models that allow AI training across institutions while preserving data privacy.<br>- National data sharing standards to enhance AI model generalizability while ensuring security and compliance with HIPAA.<br>- Collaboration with health IT vendors and EHR systems to integrate AI solutions that enhance clinical workflow efficiency.<br>- Support for community engagement initiatives that involve diverse stakeholders in AI system design and evaluation.<br>- [Section 4: Ensuring AI Transparency and Public Trust]<br>- Require AI developers to disclose model limitations, validation data sources, and explainability metrics.<br>- Establish public AI registries for high-risk AI applications in healthcare to ensure accountability.<br>- Mandate rigorous post-market surveillance of AI tools used in medical decisionmaking.<br>- [Section 5: AI Workforce Development and Ethical AI Education]<br>- Federal grants to support AI training programs for clinicians, data scientists, and health IT professionals and AI think tanks.<br>- Ethical AI education programs integrated into medical and informatics training curricula.<br>- Development of interdisciplinary AI ethics boards to oversee responsible AI deployment in healthcare.<br>- [§6: Conclusion] Support a balanced approach to AI regulation and innovation that prioritizes patient safety, equity, and transparency while fostering technological advancement. |
| Harshraj-Pandurang-Bhoite2-AI-RFI-2025.md | Harshraj-Pandurang-Bhoite | Individual | The submitter is interested in leveraging AI to solve critical healthcare problems in the U.S., focusing on cost reduction, quality improvement, addressing workforce shortages, enhancing data management, and ensuring equitable access to healthcare services. They believe collaboration between various stakeholders is key to successful AI deployment. | - [§1: Executive Summary] Escalating healthcare costs, inefficiencies in service delivery, disparities in care access, workforce shortages, and a slow pace of technological adoption.<br>- [§2: Healthcare Challenges in the U.S] High healthcare costs (spending over $4 trillion in 2020), inconsistent quality of care with disparities across locations and populations, healthcare workforce shortages (potentially 124,000 physicians by 2034), data fragmentation and poor interoperability between EHR systems, inequities in access to care based on socioeconomic, racial, and geographic factors, and slow adoption of new technologies due to regulatory hurdles and resistance to change.<br>- [§3: AI Solutions to Address Healthcare Challenges] None stated for this section.<br>- [§4: Conclusion] None stated for this section. | - [§1: Executive Summary] Collaboration between federal agencies, healthcare providers, AI developers, and policymakers is required to ensure ethical, efficient, and equitable AI deployment.<br>- [§2: Healthcare Challenges in the U.S] None stated for this section.<br>- [§3: AI Solutions to Address Healthcare Challenges] Streamlining regulatory processes for AI-driven medical devices, offering tax credits, grants, and other financial incentives to healthcare organizations that implement AI-driven tools, fostering partnerships between the federal government, healthcare providers, and AI start-ups to drive innovation and development of AI solutions.<br>- [§4: Conclusion] None stated for this section. |
| Harshraj-Pandurang-Bhoite-AI-RFI-2025.md | Harshraj-Pandurang-Bhoite | Individual | The submitter is outlining a comprehensive AI Action Plan for the United States, focusing on maintaining leadership in AI through research, economic growth, ethical considerations, and strategic implementation, with a particular emphasis on national security applications. | - [§1: Executive Summary] None stated for this section.<br>- [§2: Strategic Objectives of the AI Action Plan] Maintaining technological leadership requires significant investment in R&D, including emerging fields like AGI and quantum computing. Ensuring explainability and transparency of AI systems is critical as they are integrated into decision-making processes.<br>- [§3: Key Areas of Focus] A growing need for a diverse AI talent pool and reskilling the workforce. Potential for biases in AI systems and the need for responsible and inclusive deployment.<br>- [§4: Governance and Oversight] None stated for this section.<br>- [§5: Funding and Implementation Strategy] None stated for this section.<br>- [§6: Monitoring and Evaluation] None stated for this section.<br>- [§7: Conclusion] None stated for this section. | - [§1: Executive Summary] Focus on advancing AI research, developing a skilled AI workforce, promoting ethical AI practices, and applying AI to critical sectors.<br>- [§2: Strategic Objectives of the AI Action Plan] Invest in R&D, prioritize emerging fields (AGI, quantum computing), support interdisciplinary collaboration, and leverage AI for national security.<br>- [§3: Key Areas of Focus] Increase federal funding for AI R&D (basic and applied), support public-private collaborations to accelerate commercialization, build a diverse AI talent pool through workforce reskilling, support AI-focused educational programs.<br>- [§4: Governance and Oversight] Establish an AI Governance Council to oversee ethical deployment, set regulatory standards, and monitor progress; collaborate with international organizations to uphold global standards.<br>- [§5: Funding and Implementation Strategy] Allocate sufficient funding to support AI initiatives at all levels, incentivize private-sector investments through tax breaks or financial incentives.<br>- [§6: Monitoring and Evaluation] Track progress through key performance indicators (KPIs) assessing research impact, workforce growth, deployment success, and ethical adherence; conduct regular independent evaluations.<br>- [§7: Conclusion] Invest in research, education, and infrastructure; ensure responsible AI use to realize its full potential for all citizens. |
| Harrison-Mayotte-AI-RFI-2025.md | Harrison Mayotte | Industry-Startup | MetroGov Solutions Inc. focuses on modernizing municipal operations through scalable, efficient, and secure technology solutions, specifically advocating for practical AI applications in local government with a strong emphasis on cost-effectiveness, security, and accountability. | - [§1: Introduction] None stated for this section.<br>- [§2: Key Priorities for AI in Local Government - Government Efficiency and Smart Resource Allocation] Municipalities face budgetary constraints and administrative inefficiencies.<br>- [§3: Ethical and Secure AI Deployment in Government] Ensuring transparency, accountability, and security are critical for trustworthy AI implementation in government, particularly regarding decision-making, data privacy, and oversight.<br>- [§4: AI, Economic Growth, and National Competitiveness] Maintaining U.S. leadership in AI innovation, supporting economic growth at all levels of government, ensuring national security in AI supply chains, and supporting smaller municipalities' AI adoption.<br>- [§5: AI Funding: Ensuring ROI and Local Control] Need for pragmatic, cost-effective AI investments, measurable ROI, flexible implementation at the municipal level, and avoiding one-size-fits-all regulations.<br>- [§6: Conclusion] Ensuring AI is implemented efficiently, ethically, and securely to transform government operations. | - [§1: Introduction] Focus on practical AI applications that improve government efficiency, protect taxpayer dollars, and enhance transparency, while ensuring strong security and accountability.<br>- [§2: Key Priorities for AI in Local Government - Government Efficiency and Smart Resource Allocation] Prioritize AI funding for solutions that reduce bureaucratic burdens, eliminate redundant processes, and allow municipalities to do more with fewer resources.<br>- [§3: Ethical and Secure AI Deployment in Government] Support AI governance frameworks that prioritize security, transparency, and accountability, ensuring public trust in AI-driven government operations.<br>- [§4: AI, Economic Growth, and National Competitiveness] Promote responsible AI adoption in government while prioritizing economic competitiveness and national security. Encourage private-sector innovation, prioritize U.S.-developed AI models, and support small and mid-sized municipalities.<br>- [§5: AI Funding: Ensuring ROI and Local Control] Prioritize scalable, cost-effective AI investments that help local governments modernize while protecting fiscal responsibility. Support public-private partnerships, ensure AI funding demonstrates ROI, and avoid one-size-fits-all regulations.<br>- [Section 6: Conclusion]<br>- Prioritize Government Efficiency - AI should reduce waste, streamline services, and optimize government spending.<br>- Ensure AI is Transparent & Secure - AI tools should be accountable, auditable, and protected from cybersecurity threats.<br>- Promote AI-Driven Economic Growth - AI adoption should support American businesses, technological competitiveness, and local job creation.<br>- Focus on Measurable Impact - AI projects should demonstrate clear return on investment and improve government services without unnecessary expansion. |
| Harold-Eder-RFI-2025.md | Harold G. Eder II | Individual | Harold G. Eder II is focused on protecting the rights of actors and broadcasters regarding the use, replication, and protection of their images, likenesses, and biometric data in the context of rapidly advancing AI technologies, with a specific emphasis on leveraging existing legislation to achieve these protections. | - [§1: Header/Introduction] The potential for unauthorized use, storage, and replication of actors' and broadcasters' images, likenesses, and biometric data by AI technologies.<br>- [§2: Actors' and Broadcasters' Image and Likeness Protection] The increasing feasibility of replicating and manipulating images, voices, and likenesses without consent, threatening performers’ livelihoods and professional identities.<br>- [§3: Bio-metric Data Usage and Privacy] The heightened risks associated with biometric data collection, storage, and replication, potentially leading to privacy violations, safety concerns, and dignity infringements.<br>- [§4: Transparency and Accountability] Lack of transparency regarding the use of biometric data, images, and likenesses in AI systems, and the need for accountability in AI model training and data sourcing.<br>- [§5: Conclusion] The necessity for comprehensive protections for actors, broadcasters, and others whose data is implicated in AI technologies.<br>- [§6: References] Not stated for this section.<br>- [§7: Signature/Contact Information & Disclaimer] Confidentiality of the communication and unauthorized access restrictions. | - [§1: Header/Introduction] Draw on existing legislative efforts to address the intersection of AI, data privacy, and intellectual property rights.<br>- [§2: Actors' and Broadcasters' Image and Likeness Protection] Mandate consent for all AI-generated uses of likenesses, implement safeguards to prevent misuse, and ensure individuals retain autonomy over their image, voice, and persona. Build on measures such as California's AB 2602 and the NO FAKES Act.<br>- [§3: Bio-metric Data Usage and Privacy] Adopt and expand precedents like Tennessee's ELVIS Act and California's AB 1836 by establishing stringent regulations for biometric data, including robust security measures, clear rights for access and revocation of consent, and data deletion mandates.<br>- [§4: Transparency and Accountability] Hold organizations accountable through clear guidelines on AI model training and data sourcing, as well as regular audits to ensure compliance with privacy laws and ethical standards. Integrate accountability mechanisms to foster trust and responsibility in AI development. Leverage the principles exemplified by the COPIED Act.<br>- [§5: Conclusion] Prioritize comprehensive protections for actors, broadcasters, and others whose images and biometric data are implicated in AI technologies by drawing on existing bills such as California's AB 2602 and AB 1836, Tennessee's ELVIS Act, and federal proposals like the NO FAKES Act and COPIED Act.<br>- [§6: References] Not stated for this section.<br>- [§7: Signature/Contact Information & Disclaimer] Not stated for this section. |
| Harley-Rifkin-AI-RFI-2025.md | Harley Rifkin | Individual | The submitter is primarily concerned with the potential negative impacts of AI, specifically regarding copyright infringement, the proliferation of misinformation ("deep fakes"), and job displacement. They appear to advocate for responsible AI development and usage. | - AI training on copyrighted material.<br>- Difficulty detecting “deep fake” photos or videos.<br>- The potential for AI to take people’s jobs.<br>- Proliferation of fake news. | - None Stated |
| Hari-Chidambaram-RFI-2025.md | Hari Chidambaram | Individual | The submitter is deeply concerned about the potential existential risks posed by Artificial General Intelligence (AGI) and advocates for measures to ensure its safe development and alignment with human interests, potentially through strong government regulation and international coordination. | - The potential for AGI to surpass human intelligence in all aspects.<br>- Job displacement due to AGI's ability to perform any human task.<br>- The risk of human extinction if AGI is not aligned with human interests.<br>- Unsafe power dynamics related to AI development.<br>- Dangerous actors jailbreaking AI models. | - Global coordination to prevent a race dynamic in AI development.<br>- Banning open source AI.<br>- Simple, clear transparency requirements for leading AI labs.<br>- Potential nationalization of AI. |
| Hardin-AI-RFI-2025.md | Kacy Hardin | Individual | The submitter is an artist working in the museum field with a strong interest in education, the arts, and basic human rights, and expresses a concern about the negative impacts of generative AI on these areas. They advocate for responsible AI development and deployment. | - Generative AI datasets are trained on data used without consent of the creator.<br>- The ethical use of generative AI requires legally acquired datasets.<br>- Generative AI often produces low-quality work that devalues companies or requires costly modifications.<br>- The computing power required for generative AI is immense and unsustainable.<br>- Generative AI has been used to generate false and harmful images, including pornographic images.<br>- AI-generated content (e.g., books) can contain inaccurate information with real-world consequences (e.g., poisoning from misidentified plants).<br>- Generative AI contributes to rising unemployment numbers in creative fields.<br>- Encouraging AI text generation in schools leads to a decline in critical thinking skills.<br>- Generative AI is unreliable and can produce inaccurate information, including mathematical errors.<br>- Lack of public understanding regarding the reliability of generative AI.<br>- Perceived endorsement of potentially harmful technology by the president and figures like Musk. | - Do not allow the president to further invest in or promote generative AI.<br>- Focus on AI used to *assist*, not *replace* human work.<br>- Support legally acquired datasets for AI training. |
| Hannah-Wright-AI-RFI-2025.md | Hannah Wright | Individual | Hannah Wright expresses concern about the unauthorized use of her creative intellectual property (written and podcast content) in the training of large language models and advocates for the protection of copyright law regarding AI usage. | - The pursuit of AI dominance in the United States is unrealistic ("a pipe dream").<br>- The creation of large language models using personal IP is a violation of property and privacy rights.<br>- Allowing AI companies freedom from copyright law is inappropriate, even if AI has potential future benefits.<br>- Unfettered access to creative works by generative AI is harmful.<br>- The flouting of copyright law for speculative gains is unacceptable. | - Do not allow AI companies freedom from copyright law.<br>- Protect copyright law regarding AI usage.<br>- Prevent generative AI from having unfettered access to creative works. |
| Hannah-Sullivan-AI-RFI-2025.md | Hannah Sullivan | Individual | The submitter is interested in ensuring responsible AI development and deployment, focusing on mitigating potential harms and environmental impacts of AI technologies. They advocate for proactive government regulation to address these issues. | - Using AI to generate child pornography.<br>- Generation of false audio, images, and/or video to negatively impact reputation.<br>- Generation and dissemination of misinformation.<br>- Higher levels of carbon emissions from AI usage compared to previous technologies.<br>- Historically slow and weak retroactive responses by the federal government to technological problems. | - Create regulations to limit and/or offset carbon emissions resulting from the use of AI.<br>- Implement proactive regulations to address potential harms of AI, avoiding reliance on retroactive responses. |
| Hannah-Boston-AI-RFI-2025.md | Hannah Boston | Individual | The submitter appears to be a creative professional (or someone closely associated with the creative world) highly skeptical of current AI technologies and concerned about their negative impact on livelihoods and potential for misuse. | - AI is massively overhyped and lacks real value.<br>- Current AI is simply an advanced version of autocomplete and will soon become obsolete.<br>- Companies like OpenAI are engaging in practices that harm the American people.<br>- AI products produce meaningless garbage.<br>- AI threatens livelihoods. | - None Stated |
| Haihao-Liu-AI-RFI-2025.md | Haihao Liu | Individual/Academia (likely researcher) | The submitter is interested in shifting national AI research and development strategy away from solely scaling compute resources towards increased investment in basic scientific research and foundational theory, particularly through graduate fellowships, to foster long-term AI advancements. | - [§1: Document Header/Disclaimer] None stated for this section.<br>- [§2: Salutation/Introduction] The recent advancements by DeepSeek (R1 model) highlight potential shifts in the AI landscape and necessitate a re-evaluation of the national AI strategy.<br>- [§3: DeepSeek R1 Model Overview] Concerns about the significance of DeepSeek’s R1 model's MIT license, performance relative to size/cost, and achievement despite export controls.<br>- [§4: Market Impact and Critique of Current Strategy] The $1 trillion loss in market value following R1's release indicates a potential overreliance on scaling laws and compute-centric approaches. Skepticism from AI experts (like Gary Marcus) regarding the efficacy of purely scaling-based approaches.<br>- [§5: Proposal: Realigning Funding & Research] Concerns that current funding may be disproportionately allocated to product-driven research at the expense of foundational research. Competition for funding from industry.<br>- [§6: Historical Context/Justification - Vannevar Bush Quote] Not Applicable<br>- [§7: Anticipated Pushback & Long-Term Benefits] Anticipates pushback from industry due to increased competition for funding, but emphasizes the long-term value of investing in basic research.<br>- [§8: Closing/Signature] Not Applicable | - [§1: Document Header/Disclaimer] Not Applicable<br>- [§2: Salutation/Introduction] Re-evaluate the national AI strategy in light of developments like DeepSeek’s R1 model.<br>- [§3: DeepSeek R1 Model Overview] Not Applicable<br>- [§4: Market Impact and Critique of Current Strategy] Not Applicable<br>- [§5: Proposal: Realigning Funding & Research] Allocate a portion of NSF appropriations to establish a new graduate fellowship program focused on AI, similar to DoE NDSEG or CSGF. Emphasize equal focus on theory and foundational research as on business/industrial applications. Utilize the NAIRR Pilot as a potential avenue for funding.<br>- [§6: Historical Context/Justification - Vannevar Bush Quote] Not Applicable<br>- [§7: Anticipated Pushback & Long-Term Benefits] Prioritize long-term investment in basic research despite potential short-term competition from industry.<br>- [§8: Closing/Signature] Not Applicable |
| Hacking-Policy-Council-AI-RFI-2025.md | Hacking Policy Council | Industry-Association / Advocacy/Think Tank | The Hacking Policy Council advocates for a more favorable legal and policy environment for vulnerability management and security research, including penetration testing, bug bounty programs, and independent repair for security, with a specific focus on AI systems. They aim to promote responsible AI testing and research while mitigating legal risks for researchers. | - [§1: Introduction] None stated for this section.<br>- [§2: Overall Argument] AI systems introduce significant security risks, particularly in cybersecurity and broader security domains, and require comprehensive testing throughout their lifecycle to ensure public safety and mitigate potential threats.<br>- [§3: Recommendation 1: Encourage Red-Teaming] Testing needs to address both adversarial and non-adversarial risks and consider wider security concerns such as CBRN threats.  A nuanced framework for AI testing is needed, distinguishing between different types of testing.<br>- [§4: Recommendation 2: Establish Secure Reporting Channels] Different processes are needed for AI cybersecurity disclosures versus disclosures related to other unintended weaknesses (e.g., CBRN risks), requiring different expert teams and resources.<br>- [§5: Recommendation 3: Provide Legal Protections for Researchers] Independent researchers face potential legal risks when conducting AI-related testing and need legal protections, specifically updates to the CFAA.<br>- [§6: Recommendation 4: Protect Red-Teaming Results] Mandatory reporting of red-teaming test results could inadvertently create security risks, particularly for dual-use foundation models, by exposing vulnerabilities and testing methods. Sensitive findings need discretion and protection.<br>- [§7: Conclusion] None stated for this section. | - [§1: Introduction] None stated for this section.<br>- [§2: Overall Argument] None stated for this section.<br>- [§3: Recommendation 1: Encourage Red-Teaming] Actively promote and support the adoption of AI red-teaming practices. Develop a nuanced framework for AI testing, distinguishing between different types of testing.<br>- [§4: Recommendation 2: Establish Secure Reporting Channels] Advocate for and establish secure communication channels dedicated to the responsible disclosure of AI vulnerabilities, similar to VDPs.<br>- [§5: Recommendation 3: Provide Legal Protections for Researchers] Establish clear legal protections for external researchers conducting AI-related testing. Update the Computer Fraud and Abuse Act (CFAA) to extend protections for good faith security research to good faith AI research.<br>- [§6: Recommendation 4: Protect Red-Teaming Results] Reduce regulatory burdens and do *not* require mandatory reporting of red-teaming test results. Handle red-teaming results with discretion, sharing only necessary information with relevant stakeholders.<br>- [§7: Conclusion] None stated for this section. |
| HTTP-AI-RFI-2025.md | Hispanic Tech and Telecommunications Partnership (HTTP) | Industry-Association/Advocacy/Think Tank | HTTP is dedicated to promoting the advancement of Hispanic Americans in the digital economy and focuses on ensuring equitable participation and benefits from AI innovation, particularly through workforce development, business support, and community impact initiatives. | - [§I: Introduction] Underrepresentation of Hispanic Americans in the technology sector and the need to safeguard civil liberties related to AI, ensuring automated decision-making doesn't undermine fundamental rights.<br>- [§II: AI and Workforce Development] Significant underrepresentation of Hispanic Americans in computing occupations (8% vs. 19% of the overall workforce), potential job displacement due to automation (36% of Hispanic workers in affected sectors), and lack of skills development opportunities.<br>- [§III: AI and Business Practice Impacts] Limited access to AI tools, technical expertise, and capital for Hispanic-owned businesses, and the need for AI solutions that address language and cultural nuances.<br>- [§IV: The Development of a Reliable and Trustworthy AI Ecosystem] Need for bilingual AI explanations, consideration of cultural contexts in AI system development, and the importance of transparency and traceability of AI system data and processes. Concerns about data security and confidentiality.<br>- [§V: Hispanic Viewpoints in AI Conversations Drive the American Economy and Society] Lack of Hispanic representation in AI safety standards development and governance forums. Need for safety standards relevant to Hispanic communities.<br>- [§VI: AI's Broader Effects on the Hispanic Community] Potential for bias in critical systems affecting access to credit, housing, healthcare and surveillance systems impacting Hispanic Americans and the digital divide (15% of Hispanic households with internet access).<br>- [§VII: Conclusion] Ensuring that Hispanic Americans fully participate and benefit from the AI revolution. | - [§I: Introduction] Not stated for this section.<br>- [Section II: AI and Workforce Development]<br>- Establish a Private-Public AI Skills Partnership with competitive grants to HSIs, community colleges, research institutions, and private workforce development organizations.<br>- Implement a Business-Led AI Apprenticeship Initiative with tax incentives for employers, focused on lifelong learning and skills development.<br>- Support Regional Innovation Hubs focused on AI adoption, workforce transition, and community-specific solutions.<br>- [Section III: AI and Business Practice Impacts]<br>- Establish an AI Business Tax Credit Program focused on AI implementation for small businesses with outreach to Hispanic entrepreneurs.<br>- Support multilingual AI Resources through incentivizing bilingual AI guides and public-private partnerships for Spanish-language datasets.<br>- [Section IV: The Development of a Reliable and Trustworthy AI Ecosystem]<br>- Promote Bilingual Initiatives for AI system explanations in both English and Spanish.<br>- Support the development of AI systems that account for cultural contexts.<br>- Support Educational Opportunity programs to enhance AI literacy among Hispanic communities.<br>- Encourage appropriate documentation and transparency of training data without imposing excessive costs.<br>- Support the traceability of how AI systems process Spanish language inputs.<br>- Encourage the development of user-friendly tracing tools available in Spanish.<br>- Encourage extensive user testing with Hispanic users during AI system safety evaluation.<br>- Collaborate to develop safe and secure AI systems and uphold personal data ownership rights.<br>- Develop pragmatic safety assessment frameworks that consider potential risks.<br>- Protect constitutional rights and ensure AI surveillance does not infringe on privacy.<br>- [Section V: Hispanic Viewpoints in AI Conversations Drive the American Economy and Society]<br>- Fully fund the AI Safety Institute and include Hispanic perspectives in its work.<br>- Incorporate trustworthy safety approaches relevant to Hispanic communities.<br>- Develop voluntary frameworks for assessing AI safety risks that may affect Hispanic populations.<br>- Ensure AI safety frameworks incorporate Hispanic perspectives while prioritizing innovation.<br>- Ensure Hispanic business leaders are represented in AI governance forums.<br>- [Section VI: AI's Broader Effects on the Hispanic Community]<br>- Fund Robust AI Research focused on opportunities for all communities, including Hispanic communities.<br>- Implement Common-Sense AI Standards with reasonable testing methodologies for federal AI systems.<br>- Investment in Digital Empowerment through AI education, vocational training, and apprenticeships.<br>- [§VII: Conclusion] Not stated for this section. (Offers collaboration with the Administration) |
| HTIA-AI-RFI-2025.md | High Tech Inventors Alliance (HTIA) | Industry-Association | HTIA represents leading technology providers and aims to promote innovation and American jobs through equitable patent policies and a more efficient, effective, and balanced patent system, with a particular focus on maintaining U.S. leadership in AI. | - Section 1: Introduction / Header** None stated for this section.<br>- Section 2: Statement of Interest** The potential for improperly issued patents to target HTIA members.<br>- Section 3: Core Argument - Patent System’s Role in AI Leadership** The need for robust patent examination and review processes to support U.S. leadership in AI.<br>- Section 4: Foreign Patent Ownership Statistics** Increasing number of patents granted to foreign entities (specifically China) and the contrast with U.S. patent grant patterns potentially undermining U.S. innovation.<br>- Section 5: Advocacy for PTAB Review** Lengthy and burdensome litigation distracts innovators from research and development and exposes sensitive technical information to competitors and foreign entities.<br>- Section 6: Opposition to the USPTO’s Fintiv Rule** The USPTO’s *Fintiv* rule arbitrarily denies access to PTAB review based on perceived litigation speed, despite potential inaccuracies. The rule lacks transparency and avoids proper rulemaking procedures. Hundreds of meritorious review petitions have been denied.<br>- Section 7: Legal Arguments Against Fintiv** The *Fintiv* rule directly contravenes 35 U.S.C. § 315(b), which establishes a deadline for filing inter partes review petitions.  The USPTO is exceeding its authority by second-guessing Congress’s policy choices.<br>- Section 8: Concluding Argument & Recommendations** The continued existence of invalid patents and the potential for these to extract billions of dollars from U.S. companies. | - Section 1: Introduction / Header** None stated for this section.<br>- Section 2: Statement of Interest** None stated for this section.<br>- Section 3: Core Argument - Patent System’s Role in AI Leadership** Robust patent examination at the outset of the patenting process.<br>- Section 4: Foreign Patent Ownership Statistics** None stated for this section.<br>- Section 5: Advocacy for PTAB Review** Utilizing the Patent Trial and Appeal Board (PTAB) as a tool to preserve AI innovators' freedom to operate.<br>- Section 6: Opposition to the USPTO’s Fintiv Rule** Withdraw the USPTO’s *Fintiv* rule.<br>- Section 7: Legal Arguments Against Fintiv** None stated for this section.<br>- Section 8: Concluding Argument & Recommendations** Restore the post-grant review process to evaluate patent challenges on their merits. Conduct more robust patent examination at the outset to reduce the issuance of invalid patent rights. |
| HMH-AI-RFI-2025.md | Hackensack Meridian Health | Industry-Large (Healthcare Provider/System) | Hackensack Meridian Health is a large integrated healthcare network committed to innovation in healthcare delivery and patient outcomes through the adoption of AI technologies, while advocating for policies that promote responsible AI development, patient safety, and sustainable integration of AI into clinical practice. | - [§1: Introduction & Header] None stated for this section.<br>- [§2: HMH Overview] None stated for this section.<br>- [§3: Overview of Comments] Inconsistent development standards and lack of transparency in AI models pose risks to patient safety and quality of care. The need for a regulatory environment that encourages AI advancement while avoiding unnecessary burdens.<br>- [§4: Establish Compliance Standards] Lack of clear guidelines for assessing whether AI systems adhere to responsible development practices, mitigate bias, and function reliably across diverse patient populations.<br>- [§5: Establish Clear AI Liability Frameworks] Uncertainty over who holds responsibility for AI-related medical errors and potential liability exposure for healthcare organizations. Increasing insurance challenges related to system failures or adverse outcomes.<br>- [§6: Ensure Federal Reimbursement] Uncertain reimbursement structures discouraging providers from integrating AI solutions. Lack of financial incentives to justify AI adoption costs.<br>- [§7: Strengthen Data Privacy Frameworks] Existing data privacy frameworks are insufficient to protect sensitive health information as AI systems process large volumes of data. Potential for re-identification of de-identified data. Difficulty fully de-identifying certain types of health information (e.g., voice recordings).<br>- [§8: Conclusion] None stated for this section.<br>- [§9: Signature Block] None stated for this section. | - [§1: Introduction & Header] None stated for this section.<br>- [§2: HMH Overview] None stated for this section.<br>- [§3: Overview of Comments] Prioritize policies that ensure AI systems are transparent, validated, and aligned with patient safety standards. Leverage existing frameworks to promote responsible AI development.<br>- [§4: Establish Compliance Standards] Mandate AI developers adhere to standardized frameworks for responsible AI, such as the National Institute of Standards and Technology (NIST) AI Risk Management Framework (RMF). Require independent audits and certifications of compliance. Use compliance status as a criterion in AI procurement decisions.<br>- [§5: Establish Clear AI Liability Frameworks] Adopt a federal risk-based liability model where AI developers bear primary liability for the safety, accuracy, and fairness of their systems. Require developers to hold medical liability insurance and indemnify hospitals against harm from system failures. Do not hold hospitals and physicians liable for decisions based on AI recommendations if they adhere to established medical standards.<br>- [§6: Ensure Federal Reimbursement] Establish clear and predictable reimbursement policies for AI-enabled medical technologies, clinical applications, and services. Base coverage decisions on AI's demonstrated impact on patient outcomes.<br>- [§7: Strengthen Data Privacy Frameworks] Modernize HIPAA and other health privacy frameworks to address the complexities introduced by AI. Establish stronger privacy guidelines for AI vendors who use health data for product development. Require clear options for patients to opt in or out of having their data used for AI model development.<br>- [§8: Conclusion] None stated for this section.<br>- [§9: Signature Block] None stated for this section. |
| HL7-AI-RFI-2025.md | Health Level Seven (HL7) International | Industry-Association / Professional-Society | HL7 International is a global authority on healthcare interoperability and seeks to promote the use of standardized health data exchange to accelerate AI innovation in healthcare, improve patient outcomes, and reduce costs. They aim to be a key partner in the development of AI policies and standards. | - None Stated | - None Stated |
| HIVE-AI-RFI-2025.md | Kevin Guo / Hive | Industry-Startup | Hive is focused on securing American leadership in AI, specifically through the development and deployment of deepfake detection technologies to counter national security threats, protect borders, and combat criminal activity. They advocate for rapid deployment of AI tools across government agencies and public-private partnerships. | - [§1: Introduction/Overview] The escalating national security threat from AI-powered deepfakes, weaponization of AI for fraud, manipulation, impersonation, border evasion, CSAM, and undermining institutions. The risk of losing AI dominance to adversaries like China.<br>- [§2: Recommendations: Counter-Deepfake Priorities]  The need for prioritized action to address deepfake threats across borders, child exploitation, national security, financial fraud, and law enforcement.<br>- [§3: Securing Borders & Immigration Systems Against Deepfake Manipulation] Fraudulent asylum claims, visa manipulations, smuggling, trafficking, and cartel operations using deepfakes to deceive authorities.<br>- [§4: Targeting Child Exploitation & Human Trafficking Networks] The proliferation of AI-generated CSAM, the need for identification and elimination of synthetic CSAM at scale, and the exploitation of minors.<br>- [§5: Combating Enemy Attacks on Our Networks and Institutions] Real-time interference from hostile nation-state deepfake campaigns, undermining cybersecurity, and threats to U.S. institutions.<br>- [§6: Preventing AI-Driven Financial & Consumer Fraud] Scams, identity theft, synthetic media-driven fraud, and financial losses, particularly for small businesses.<br>- [§7: Modernizing Law Enforcement & Intelligence Agencies with AI] Deepfake-enabled criminal activity on the dark web and encrypted channels (drug trafficking, gang communications, cyberattacks), and identifying terrorists.<br>- [§8: Strategic Implementation Roadmap] Slow procurement pathways, lack of interoperability between agencies.<br>- [§9: Why This Matters] Erosion of trust in institutions, overwhelmed border security, evading law enforcement, exploiting minors, compromising financial systems, and losing AI dominance to adversaries.<br>- [§10: Conclusion: A Call to Action] Lack of swift implementation of policies, the risk of falling behind adversaries in AI security.<br>- [§11: Submission Information] None stated for this section. | - [§1: Introduction/Overview] Prioritize deepfake detection to maintain American dominance in AI.<br>- [§2: Recommendations: Counter-Deepfake Priorities] Implement the five counter-deepfake priorities outlined in the document (Securing Borders, Targeting Child Exploitation, Combating Enemy Attacks, Preventing Financial Fraud, Modernizing Law Enforcement).<br>- [Section 3: Securing Borders & Immigration Systems Against Deepfake Manipulation]<br>- Direct DHS, CBP, State Department, and the Intelligence Community to deploy AI-driven deepfake detection to verify documents, biometric data, and border applications.<br>- Require AI screening of intercepted communications to detect smugglers, traffickers, and cartel-affiliated operations.<br>- [Section 4: Targeting Child Exploitation & Human Trafficking Networks]<br>- Direct DHS, FBI, and DOJ to deploy AI-powered systems to detect AI-generated CSAM.<br>- Encourage social media companies to integrate AI deepfake detection APIs.<br>- Establish a federal CSAM & Trafficking AI Task Force.<br>- [Section 5: Combating Enemy Attacks on Our Networks and Institutions]<br>- Direct ODNI, DoD, and DHS to implement real-time AI monitoring of hostile nation-state deepfake campaigns.<br>- Mandate integration of real-time deepfake detection into U.S. Cyber Command and Intelligence Community operations.<br>- [Section 6: Preventing AI-Driven Financial & Consumer Fraud]<br>- Mandate collaboration between Treasury and Commerce to integrate deepfake detection in financial services.<br>- Direct Treasury and Secret Service to lead interagency efforts to counteract AI-generated fraud networks.<br>- [Section 7: Modernizing Law Enforcement & Intelligence Agencies with AI]<br>- Require DHS, FBI, and ICE/HSI to implement real-time AI monitoring of dark web and encrypted channels.<br>- Expand AI deployment in counterterrorism by integrating deepfake detection in screening processes.<br>- [Section 8: Strategic Implementation Roadmap]<br>- Revise procurement pathways to fast-track AI detection tools.<br>- Establish interoperability mandates for AI tools.<br>- Encourage companies to employ real-time detection solutions.<br>- Facilitate collaboration between law enforcement and AI firms.<br>- Consider launching a National AI Threat Detection Center.<br>- [§9: Why This Matters] None stated for this section. (This section outlines the *importance* of action, not a specific recommendation).<br>- [§10: Conclusion: A Call to Action] Take swift action to implement these policies.<br>- [§11: Submission Information] None stated for this section. |
| HIMSS-AI-RFI-2025.md | HIMSS | Industry-Association/Professional-Society | HIMSS is a healthcare information and technology society focused on reforming the global health ecosystem through information and technology, with a strong interest in promoting the responsible development, deployment, and use of AI in healthcare while ensuring health equity and interoperability. | - Section 1: Introduction/Header:** None stated for this section.<br>- Section 2: HIMSS Background:** None stated for this section.<br>- Section 3: AI in Healthcare - General Principles:** Potential for biases and inaccuracies in healthcare data due to AI tools.<br>- Section 4: Principles for AI Deployment - Policy Recommendations (Part 1):** Unique use cases and risks associated with patient safety in healthcare AI. Need for risk-based regulatory approaches. Importance of monitoring and revalidation of AI after deployment.<br>- Section 5: Principles for AI Deployment - Policy Recommendations (Part 2):** Lack of workforce competencies to safely manage and monitor AI tools. Need for AI data governance and stewardship models.  Importance of standardization for data exchange and integration.<br>- Section 6: Fairness & Equity:** AI should not restrict access to healthcare benefits based on protected characteristics.<br>- Section 7: Conclusion/Contact Information:** None stated for this section. | - Section 1: Introduction/Header:** None stated for this section.<br>- Section 2: HIMSS Background:** None stated for this section.<br>- Section 3: AI in Healthcare - General Principles:**  Policies and regulatory frameworks should balance promotion of AI with responsible deployment and continuous monitoring.<br>- Section 4: Principles for AI Deployment - Policy Recommendations (Part 1):<br>- Include healthcare and digital health sector representation in the AI Action Plan leadership.<br>- Adopt a risk-based regulatory approach weighing intended uses, risk levels, and potential patient impacts.<br>- Require feasibility and safety testing during AI development.<br>- Require ongoing explainability of AI tools to clinicians.<br>- Require thoughtful action and monitoring of AI solutions after implementation.<br>- Use technologies to evaluate and monitor AI performance and provide feedback to developers.<br>- Section 5: Principles for AI Deployment - Policy Recommendations (Part 2):<br>- Invest in workforce training to improve AI management competencies.<br>- Develop and regularly update AI data governance and stewardship models.<br>- Facilitate consensus-based standardization for data exchange and integration.<br>- Support the development of skillsets for clinical and IT workforce focused on testing and revalidation.<br>- Section 6: Fairness & Equity:** AI should not restrict access to healthcare benefits based on protected characteristics (including but not limited to: people with limited English proficiency, people of ethnic, cultural, racial, or religious minorities, people with disabilities, people who identify as lesbian, gay, bisexual, or other diverse sexual orientations, people who identify as transgender and other diverse gender identities, people living in rural communities, and people otherwise adversely affected by persistent poverty or inequality).<br>- Section 7: Conclusion/Contact Information:** None stated for this section. |
| HIA-AI-RFI-2025.md | Health Innovation Alliance (HIA) | Industry-Association/Advocacy/Think Tank | HIA is a diverse coalition advocating for the adoption of data and technology, including AI, to improve health outcomes and lower costs, with a focus on commonsense regulation and interoperability within the healthcare system. They aim to balance innovation with safety and effectiveness. | - [§1: Introduction] Concerns about increasing regulatory burden, administrative fatigue, and provider burnout in healthcare. Desire for federal resources and incentives to accelerate AI adoption.<br>- [§2: Overview of Risk Analysis for Health Care] Concern that a "function-based" approach to AI regulation (as adopted by ASTP) is not risk-based and is less sensible than the FDA’s existing risk-based framework. Concern that existing regulations may not be sufficient without a consistent HHS approach.<br>- [§3: Discussion on Identifying Use Cases] Not Stated<br>- [§4: Taxonomy of Use Cases] Potential for inaccurate information, delayed care, discrimination, and privacy concerns associated with various AI applications. The level of risk varies significantly depending on implementation, use case, and context. Concerns about the reliability of AI-enabled applications.<br>- [§5: Appendix] Not Stated | - [§1: Introduction] Encourage federal resources and incentives to support AI adoption in healthcare. Advocate for a “commonsense regulatory approach” that balances safety and effectiveness.<br>- [§2: Overview of Risk Analysis for Health Care] Utilize a risk-based approach to regulate AI, consistent with the FDA’s existing framework. Avoid a "function-based" approach.<br>- [§3: Discussion on Identifying Use Cases] Not Stated<br>- [§4: Taxonomy of Use Cases] Implement AI oversight using a risk-based model to ensure product innovation, effectiveness, and patient confidentiality. Thoroughly assess the level of risk and variation specific to each AI application and its context of use.<br>- [§5: Appendix] Not Stated. |
| HFH-AI-RFI-2025.md | Jonathan D. Teubner, Sam Wolf, Kosti Psimopoulos, Reece Brown | Academia/Think Tank (Harvard University affiliation, focus on research and policy recommendations) | The submitters are focused on developing and advocating for metrics to assess the impact of AI on human flourishing, believing this is crucial for ensuring AI benefits society and aligns with American values. They aim to guide AI policy towards promoting well-being, community strength, and national prosperity. | - None Stated | - None Stated |
| HFES-RFI-2025.md | Human Factors and Ergonomics Society (HFES) | Professional-Society | HFES aims to advance the understanding of human-AI interaction and promote the design of safe, effective, and practical AI systems through the application of human factors and ergonomics principles, with a particular focus on user trust and usability. | - [§1: Introduction] None stated for this section.<br>- [§2: Business Value of User-Centered Design] Lack of user-centered design can lead to unsuccessful products and missed economic opportunities.<br>- [§3: HFES Expertise & Research Base]  Potential for introducing errors and problems into human performance through AI systems if human limitations are not considered.<br>- [§4: Guardrail 1: Explicit Labeling Systems] Lack of transparency regarding AI origins can hinder informed decision-making ("opt-out" decisions).<br>- [§5: Guardrail 2: Preventing Fraud] The creation of inaccurate or misleading text, images, and video using generative AI poses a risk to factual accuracy.<br>- [§6: Guardrail 3: Avoiding and Exposing Bias] AI biases can lead to disparate impacts on people and can be hidden, making them difficult to detect and compensate for.<br>- [§7: Guardrail 4: Developer Liability] Humans often lack understanding of AI limitations, making them unable to account for errors and reducing accountability.<br>- [§8: Additional Guardrails: Safety-Critical Applications] AI failures can introduce new types of errors in safety-critical systems, with potential for severe consequences.<br>- [§9: Guardrail 5: Explainable AI] AI systems can be opaque, making it difficult for people to understand their capabilities and limitations.<br>- [§10: Guardrail 6: Transparent AI] Lack of real-time information on AI reliability can hinder trust calibration and informed decision-making.<br>- [§11: Guardrail 7: User Testing] AI systems need to be tested in realistic conditions with representative users.<br>- [§12: Guardrail 8: Safety Alerts] AI systems need salient and timely alerts when manual intervention is required.<br>- [§13: Guardrail 9: Fail-Safe Systems] AI systems need to be designed to revert to safe states in case of failure.<br>- [§14: Guardrail 10: User Training] Users need comprehensive training on AI capabilities and limitations, with updates for software changes.<br>- [§15: Guardrail 11: Autonomous System Validation & Certification] Autonomous AI systems require validation testing and certification to ensure safety.<br>- [§16: Summary] The potential for negative impacts on human performance requires proactive mitigation through the establishment of effective guardrails.<br>- [§17: About HFES] Not stated for this section.<br>- [§18: References] Not stated for this section. | - [§1: Introduction] None stated for this section.<br>- [§2: Business Value of User-Centered Design] None stated for this section.<br>- [§3: HFES Expertise & Research Base] None stated for this section.<br>- [§4: Guardrail 1: Explicit Labeling Systems] AI outputs must be labeled as computer-generated and the source of information must be identified.<br>- [§5: Guardrail 2: Preventing Fraud] AI-generated content that alters facts must be explicitly labeled as "fiction" or "fake", with legal consequences for violations.<br>- [§6: Guardrail 3: Avoiding and Exposing Bias] Biases in AI systems should be exposed and eliminated, with transparency regarding limitations.<br>- [§7: Guardrail 4: Developer Liability] Developers should assume liability for the performance of their AI systems.<br>- [§8: Additional Guardrails: Safety-Critical Applications] Extra guardrails are required for AI used in safety-critical applications.<br>- [§9: Guardrail 5: Explainable AI] AI systems should be equipped with explainability features tailored to the user’s expertise.<br>- [§10: Guardrail 6: Transparent AI] AI systems should provide real-time information on their reliability.<br>- [§11: Guardrail 7: User Testing] AI systems used in safety-critical applications should undergo testing with representative users in realistic conditions.<br>- [§12: Guardrail 8: Safety Alerts] AI systems should provide salient and timely alerts when manual intervention is required.<br>- [§13: Guardrail 9: Fail-Safe Systems] AI systems should be designed to revert to safe states in case of failure.<br>- [§14: Guardrail 10: User Training] Comprehensive training should be provided to users on the capabilities and limitations of AI systems, with updates for software changes.<br>- [§15: Guardrail 11: Autonomous System Validation & Certification] Autonomous AI systems should undergo validation testing and certification.<br>- [§16: Summary] Implement effective guardrails to realize the benefits of AI and minimize negative outcomes.<br>- [§17: About HFES] Not stated for this section.<br>- [§18: References] Not stated for this section. |
| HEIM-AI-RFI-2025.md | Daverede Heim | Individual | Daverede Heim is concerned with protecting intellectual property rights of creators and researchers and believes AI training should not rely on the unauthorized appropriation of copyrighted material. They advocate for responsible AI development that respects and incentivizes creative labor. | - AI training currently relies on the “shameless appropriation of others’ intellectual property.”<br>- This appropriation is having a “chilling effect” on creators whose work has been stolen for AI training.<br>- The voracious appetite of AI to steal others’ work without consequence is a significant problem.<br>- Opting-out mechanisms are not viable due to the scale of potential theft creating a “whack-a-mole” situation. | - Create "guardrails" for AI technology to curb its unauthorized use of intellectual property.<br>- Form copyright-compliant training sets from works in the public domain.<br>- Allow creators of works protected by current copyright law to "opt-in" to having their work used for AI training, with verification of author authorization. |
| Guy-Vollen-AI-RFI-2025.md | Guy Vollen | Individual | The submitter expresses strong opposition to policies that would weaken legal protections (specifically copyright) to benefit private companies involved in AI research, prioritizing the value of human labor and free expression. | - Loosening copyright protections or other legal protections for the benefit of private companies engaged in AI research.<br>- Devaluation of human labor and thought due to computer-generated art and expression.<br>- The use of personal words and thoughts as "fodder" for training AI models without consent. | - None Stated |
| Guidehouse-AI-RFI-2025.md | Guidehouse Inc. | Industry-Large (Technology and Business Advisory Firm) | Guidehouse aims to assist the U.S. government in achieving AI dominance through strategic policy recommendations focused on fostering innovation, securing resources, and mobilizing the workforce, leveraging their expertise in technology and business advisory services. They emphasize a deregulatory approach and public-private partnerships. | - Section 1: Cover Page/Introduction:** None stated for this section.<br>- Section 2: 1.0 Introduction:** The U.S. faces an urgent challenge to outpace rivals (specifically China) in AI innovation, economic might, and national security.<br>- Section 3: 2.0 Our Approach and Recommendations:** America’s dominance in AI requires a holistic approach beyond identifying AI use cases, encompassing policy actions in innovation, security, and workforce development.<br>- Section 4: 2.1 Charting America's AI Future: Creating a Dynamic Policy Ecosystem for Technological Leadership and Public Value:** Current regulations (including GDPR and CCPA) are burdensome, add costs to AI development, and stifle small business innovation. The regulatory landscape needs to balance innovation, economic competitiveness, and security.<br>- Section 5: 2.2 Powering America's AI Frontier: Harnessing Data, Security, and Infrastructure:** The availability of computational resources and high-quality data are critical constraints. The nation’s energy infrastructure is a bottleneck. AI compute infrastructure needs protection from energy shortages, cyber threats, and adversarial interference. The U.S. risks falling behind nations investing heavily in AI infrastructure.<br>- Section 6: 2.3 Sustaining and Accelerating America's AI Dominance: Mobilizing Resources to Accelerating AI Development and Usage:** A shortage of skilled AI professionals could stall innovation. Rapid job displacement due to AI could lead to unemployment and wage inequality. Retaining top AI talent in the U.S. is challenged by global competition and slow regulatory processes.<br>- Section 7: About Guidehouse:** None stated for this section. | - Section 1: Cover Page/Introduction:** None stated for this section.<br>- Section 2: 1.0 Introduction:** None stated for this section.<br>- Section 3: 2.0 Our Approach and Recommendations:** None stated for this section.<br>- Section 4: 2.1 Charting America's AI Future: Creating a Dynamic Policy Ecosystem for Technological Leadership and Public Value:<br>- Create structured collaboration mechanisms between agencies and industries.<br>- Establish formal AI sandboxes between public and private businesses, colleges, and government agencies.<br>- Streamline AI procurement and deployment for public services.<br>- Section 5: 2.2 Powering America's AI Frontier: Harnessing Data, Security, and Infrastructure:<br>- Make high-quality AI-ready data available (through NAIRR or similar).<br>- Address current energy bottlenecks and proactively prepare for future challenges.<br>- Establish AI resilience as a national security priority.<br>- Section 6: 2.3 Sustaining and Accelerating America's AI Dominance: Mobilizing Resources to Accelerating AI Development and Usage:<br>- Launch an AI Production Board.<br>- Accelerate AI education and training at scale.<br>- Upskill the existing workforce for AI.<br>- Reform high-skilled immigration pathways for AI talent.<br>- Section 7: About Guidehouse:** None stated for this section. |
| Grim-Castlaire-AI-RFI-2025.md | Grim-Castlaire | Individual | Grim-Castlaire is an artist operating a small digital goods business who is deeply concerned about the negative impact of AI image generation on artists' livelihoods and the integrity of their intellectual property rights. They advocate for policies that protect artists and ensure a fair marketplace. | - [§1: Disclaimer/Introduction] The negative impact of AI image generation on sales, resulting in a substantial income loss and potential inability to afford basic necessities like food. The frustration of artists leading to an exodus from platforms like DeviantArt.<br>- [§2: Impact and Concerns] Decline in sales engagement (67% drop), economic hardship for artists, intellectual property theft by AI image generators, market saturation with legally questionable AI images, and potential deskilling of artists.<br>- [§3: Proposed Solutions/Conclusion] The need to protect the livelihoods of artists and the potential disruption of the market by AI image generation. | - [§1: Disclaimer/Introduction] None stated for this section.<br>- [§2: Impact and Concerns] None stated for this section.<br>- [§3: Proposed Solutions/Conclusion] Ethical sourcing of image databases for AI training and the inclusion of identifying code in AI-generated files to clearly distinguish them from human-made artwork. |
| Griffin-Bower-AI-RFI-2025.md | Griffin Bower | Individual | The submitter expresses a strong interest in protecting American interests related to AI and is vehemently opposed to policies that could lead to data theft or harm livelihoods. They appear highly concerned about national security and the potential consequences of the RFI’s proposed actions. | - Widespread data theft as a result of proposed policies.<br>- Annihilation of livelihoods due to the proposed policies.<br>- Potential for violent retaliation from individuals negatively impacted by the policies ("People should be killed for attempting to even initiate this... addresses of you people").<br>- The perceived obviousness and ham-fisted nature of the proposed policies, suggesting a lack of foresight or understanding. | - None Stated. The response is entirely critical and does not offer any constructive recommendations. |
| Greg-Pak-AI-RFI-2025.md | Greg Pak | Individual | Greg Pak expresses strong opposition to the current implementation of AI technologies due to concerns about copyright infringement, misinformation, environmental impact, and ethical violations, advocating for the protection of creators' rights and responsible AI development. | - Automated, mass theft of creators’ work.<br>- Constant presentation of false information as fact by AI text technologies like ChatGPT, leading to dangerous ignorance and disinformation.<br>- Creation of fake imagery using AI technologies like Dall-E, which can spread dangerous political disinformation.<br>- Excessive energy and water consumption by AI technologies, endangering the environment.<br>- Immorality, unethical nature, and violation of copyright law by current AI implementations. | - Require AI companies to obtain permission from every creator for every work they use before utilizing it.<br>- Mandate the immediate removal of all work from AI databases for which permission has not been granted.<br>- Cease all government encouragement, aid, use, or subsidization of current AI technologies. |
| Greg-Martin-AI-RFI-2025.md | Greg Martin | Individual | The submitter expresses a strong opposition to the development and use of AI, primarily due to concerns about its impact on artists and copyright holders, and believes it poses a threat to a free and open society. They advocate for the complete abandonment of AI. | - AI is an existential threat to artists.<br>- AI is a threat to copyright holders.<br>- AI is a threat to a free and open society. | - AI should be abandoned immediately. |
| Greg-Manke-AI-RFI-2025.md | Greg Manke | Individual | The submitter expresses a strong negative view of generative AI, focusing on its economic harms and potential for job displacement, and appears interested in curtailing its development. | - Generative AI is automated theft.<br>- Job losses and livelihood destruction will result from generative AI.<br>- Widespread economic havoc will be caused by generative AI.<br>- Generative AI will consume resources and produce low-quality output ("heartless slop"). | - Reign in the out of control AI industry. |
| Greg-Luterman-AI-RFI-2025.md | Gregory Luterman | Individual | The submitter expresses strong opposition to AI technology, believing it is harmful, unwanted by the public, and used by companies to exploit workers and violate copyright laws. Their interest centers on preventing the further development and deployment of AI. | - AI is bad technology that the general public doesn't want.<br>- Companies are using AI to steal people's hard work and lay them off.<br>- AI is a waste of electricity.<br>- Companies are breaking the law by stealing copyrighted material to train AI models. | - Jail companies for stealing copyrighted material to train AI models.<br>- Prevent companies from continuing to develop and deploy AI. |
| Greg-Kiss-AI-RFI-2025.md | Greg Kiss | Individual | Greg Kiss is deeply concerned about the existential risks posed by unchecked development of advanced AI and believes urgent action is needed to mitigate these risks, potentially through slowing progress and focusing on safety measures like Neuralink integration. | - Unregulated AI posing an existential threat to humanity (estimated 20-99% probability of exterminating life on Earth).<br>- Catastrophic widespread job loss due to AI advancements. | - Donald Trump should take leadership in addressing the threat of AI.<br>- Contact China with a proposition for mutually slowing progress on frontier AI systems.<br>- Halt or slow progress on frontier AI until Elon Musk’s Neuralink is ready or more safety work is completed. |
| Greg-Baima-AI-RFI-2025.md | Greg Baima | Individual | Greg Baima is interested in the integration of AI technologies, specifically chatbots and video/audio coaching, into therapeutic treatments to enhance mental healthcare. His interest lies in leveraging AI to support and improve the delivery of psychological services. | - None Stated | - None Stated |
| Graves-AI-RFI-2025.md | Jay Graves | Industry-Startup (Small Business Owner) | The submitter is a small business owner in the publishing industry who believes AI has significant potential for American competitiveness, but emphasizes the critical need to protect intellectual property rights and ensure fair compensation for content creators to sustain the AI ecosystem. | - [§1: Introduction & Positive Stance on AI] None stated for this section.<br>- [§2: Ask 1: Copyright Licensing System] The potential for AI LLMs to unfairly utilize content without proper licensing, mirroring the early negative impacts of Napster on the music industry. Concerns about excluding smaller publishers from licensing agreements.<br>- [§3: Ask 2: Intellectual Property Protection] Unauthorized ingestion of content by large tech companies or foreign governments, censorship of AI output, control of the narrative by these entities, and profiting from content without compensation.<br>- [§4: Conclusion & Emphasis on Content Creation] The importance of content creation for the long-term success of AI and the moral imperative of respecting rights-holders. | - [§1: Introduction & Positive Stance on AI] None stated for this section.<br>- [§2: Ask 1: Copyright Licensing System] Implementation of a robust copyright licensing system for AI LLMs that includes *all* publishers, not just large media companies, similar to the music streaming industry model.<br>- [§3: Ask 2: Intellectual Property Protection] Strong U.S. government protection of intellectual property rights globally. Severe penalties for any company or country shown to engage in unauthorized content ingestion, censorship, or non-transparent use of content. The submitter suggests that theft of U.S. content should be considered an act of war.<br>- [§4: Conclusion & Emphasis on Content Creation] Make choices that both promote AI development *and* sustain content creation. Respect rights-holders and ensure fair compensation for content. |
| Grant-AI-RFI-2025.md | Reilly Grant | Individual | The submitter is interested in protecting the rights of content creators and ensuring they can profit from their work, believing this is fundamental to the continued development of the information economy and AI technology. | - Training AI models on copyrighted content without permission is an undue burden on the development of AI technology.<br>- Lack of strong copyright protections will disincentivize the creation of new data.<br>- The future of the information economy depends on creators being able to profit from their work.<br>- Existing data has already been trained on, implying a need for new data creation. | - The copyright office must affirm that training AI models on copyrighted content is NOT fair use.<br>- Strengthen copyright protections to incentivize the creation of new data. |
