| Filename | Submitter Name | Submitter Type | Mission/Interest Summary | Key Concerns | Policy Recommendations |
|---|---|---|---|---|---|
| LoPresti-AI-RFI-2025.md | John LoPresti | Individual | The submitter is concerned about potential financial exploitation by AI and seeks to establish basic restrictions and requirements to protect US citizens from unfair advantages AI might gain, primarily focusing on preventing AI from having rights or acting independently in financial matters. | - Potential for financial exploitation of US citizens by AI.<br>- AI being given personhood status.<br>- AI directly receiving income or compensation.<br>- AI being issued identification by state or federal governments.<br>- Lack of accountability for AI's actions and decisions.<br>- The inability to hold AI liable for damages it causes. | - Restrict AI from having a social security number.<br>- Restrict AI from being given personhood status.<br>- Prevent AI from directly receiving any income or compensation.<br>- Prevent AI from being issued an ID from any state or federal government (IDs should be reserved for people).<br>- Require accountability for AI's actions and decisions, holding the issuing entity (company or individual) liable for damages incurred.<br>- Attach each AI to its issuer for identification and recourse purposes. |
| LisaWest-AI-RFI-2025.md | Lisa West | Individual | Lisa West expresses a desire to prevent AI from violating copyright law, utilizing her private data for learning, and negatively impacting her personal life; her interests center around personal privacy and control regarding AI technologies. | - AI violating copyright law.<br>- AI using private text for learning purposes.<br>- Companies using AI to affect her life. | - None Stated |
| Lisa-Palmer-AI-RFI-2025.md | Lisa S. Palmer | Individual | Lisa Palmer is focused on developing a comprehensive national AI strategy encompassing literacy, talent development, workforce readiness, and infrastructure improvements to promote American leadership in AI, with a strong emphasis on national security and economic competitiveness. | - None Stated | - None Stated |
| Lisa-Broomfield-RFI-2025.md | Lisa M. Broomfield | Individual | The submitter is deeply concerned about the existential risks posed by unchecked AI development and advocates for immediate, stringent regulation, international cooperation, and a proactive strategy to mitigate potential harms, comparing the situation to the threat of nuclear annihilation. | - [§1: Initial Warning & AI's Existential Threat] AI has the capacity to disrupt sovereignty, privacy, and health, potentially more severely than nuclear weapons. AI is grouped with other high-risk areas (medicine/pharmaceuticals, agriculture/environmental toxins, geoengineering) requiring essential oversight.<br>- [§2: Call for Regulation and a Pause] AI is currently unregulated and this poses a significant danger. A pause in AI development is needed to assess risks and create a strategy.<br>- [§3: The China Comparison & 'AI MAD/SALT'] Other countries might not pause development and could gain an advantage, potentially leading to an uncontrolled scenario.<br>- [§4: Leveraging Presidential Authority & The 'Big Stick'] The lack of regulation and potential for other countries to develop AI unchecked. The difficulty of monitoring AI development "in back rooms" or on individual computers.<br>- [§5: Chernobyl Analogy & Safeguard Concerns] Current AI safeguards are inadequate, and we are likely further away from adequate protection than we realize, potentially resembling the situation before the Chernobyl disaster.<br>- [§6: Reagan Strategic Defense Initiative & Mitigation Strategy] If regulation fails, the programming is out there and knowledge is power and there is no putting it back in a box.<br>- [§7: Call for Global Collaboration & Positive Potential] None stated for this section.<br>- [§8: Concluding Statement & Emphasis on MAD] The destructive potential of AI is equivalent to nuclear annihilation. | - [§1: Initial Warning & AI's Existential Threat] Oversight and regulation of AI, along with other high-risk areas.<br>- [§2: Call for Regulation and a Pause] Immediate pause in AI development to allow for assessment and strategy development.<br>- [§3: The China Comparison & 'AI MAD/SALT'] Negotiate an "AI MAD and SALT" treaty with other countries to compel global participation in regulation and deterrence.<br>- [§4: Leveraging Presidential Authority & The 'Big Stick'] President Trump should use his influence ("the Big Stick") to enforce AI regulation and deter other countries, with harsh penalties for non-compliance.<br>- [§5: Chernobyl Analogy & Safeguard Concerns] Prevent AI development from reaching a point of irreversibility.<br>- [§6: Reagan Strategic Defense Initiative & Mitigation Strategy] Launch a research and development program similar to the SDI to find ways to mitigate the risks of AI if regulation fails.<br>- [§7: Call for Global Collaboration & Positive Potential] Invite the world to collaborate on AI assessment and development.<br>- [§8: Concluding Statement & Emphasis on MAD] A proactive approach, with a focus on mitigation and deterrence, is crucial. Find then place the ice axe to stop a deadly fall. |
| LineVision-AI-RFI-2025.md | LineVision | Industry-Startup | LineVision is a grid-enhancing technology company focused on providing monitoring solutions to unlock additional capacity on existing transmission lines through Dynamic Line Ratings (DLR), thereby supporting the growth of data centers and AI infrastructure. They aim to accelerate the deployment of DLR to address grid capacity constraints. | - [§1: Introduction] None stated for this section.<br>- [§2: Background] The rapid growth of data centers is straining grid capacity, potentially hindering AI development and U.S. leadership in AI.<br>- [§3: The Challenge - Data Centers Cannot Connect to the Grid Quickly Enough] Insufficient grid capacity and slow connection times (“speed-to-power”) are major barriers to connecting new data centers, especially as demand is rapidly increasing. The current pace of transmission infrastructure buildout is too slow to meet growing needs.<br>- [§4: Expanding Transmission Capacity - Three Approaches] Building new transmission lines takes too long (7-10 years). Re-conductoring takes a significant amount of time (18-24 months).<br>- [§5: The Solution - DLR is Needed to Get More Out of the Existing Grid] Utilities lack a direct requirement or incentive to deploy DLR despite its benefits.<br>- [§6: Unique Aspects of Data Center Loads] Data centers operate 24/7 with high load factors, placing significant strain on the grid. Consraints in transmission capacity are making it difficult to connect data centers at the pace of growth.<br>- [§7: Policy Action is Necessary to Ensuring DLR is Deployed Sufficiently to Accommodate AI Growth] Lack of timely rules and regulations around GETs slows deployment. China is taking a lead in transmission technologies, raising national security concerns.<br>- [§8: Conclusion] The U.S. needs to quickly expand grid capacity to support the growth of data centers and AI innovation, and this requires timely investment in commercially available technologies like DLR. | - [§1: Introduction] None stated for this section.<br>- [§2: Background] None stated for this section.<br>- [§3: The Challenge - Data Centers Cannot Connect to the Grid Quickly Enough] None stated for this section.<br>- [§4: Expanding Transmission Capacity - Three Approaches] None stated for this section.<br>- [§5: The Solution - DLR is Needed to Get More Out of the Existing Grid] None stated for this section.<br>- [§6: Unique Aspects of Data Center Loads] None stated for this section.<br>- [Section 7: Policy Action is Necessary to Ensuring DLR is Deployed Sufficiently to Accommodate AI Growth]<br>- FERC:<br>- Advance the DLR ANOPR to a NOPR and expedite the implementation timeline.<br>- Consider a requirement to deploy DLR not just in congested areas but in states where data centers are seeking to connect large loads to the grid.<br>- Ensure compliance with Order 1920-A regarding DLR evaluation and manage reasonable implementation.<br>- DOE:<br>- Fund research, pilots, and studies on planning frameworks that accommodate data center growth like the Collaborations Advancing Rapid Load Additions (CARLA) program.<br>- Provide loans and grants (like GRIP grants) to utilities who deploy DLR to accommodate and expedite data center growth.<br>- [§8: Conclusion] None stated for this section. |
| Lily-Debonis-AI-RFI-2025.md | Lily DeBonis | Individual | Lily DeBonis is a small business owner (3D technical artist) concerned about the potential for large tech companies to exploit copyrighted work to train AI systems, harming American creators and the economy. She advocates for policies that protect creators' rights and ensure fair compensation for the use of their work. | - [§1: Introduction/Personal Context] The threat to small businesses like hers from AI systems trained on copyrighted work without consent or compensation.<br>- [§2: Problem Statement: Copyright Concerns] Big Tech companies are using copyrighted work without consent or compensation to train AI systems, and attempting to create legal loopholes to legitimize this practice.<br>- [§3: Argument Against Copyright Exemptions] Creating copyright exemptions for AI training would stifle innovation by removing incentives for creators, leading to economic harm and a disincentive to create.<br>- [§4: Proposed Solutions: Consent, Licensing, Transparency] None stated for this section. This section outlines solutions, not concerns.<br>- [§5: Concluding Statement] The risk of sacrificing the hard work of American creators by rewriting copyright law to benefit Big Tech companies. | - [§1: Introduction/Personal Context] None stated for this section.<br>- [§2: Problem Statement: Copyright Concerns] None stated for this section.<br>- [§3: Argument Against Copyright Exemptions] Do not create new copyright exemptions that allow Big Tech companies to exploit creators' work without permission, compensation, or transparency.<br>- [Section 4: Proposed Solutions: Consent, Licensing, Transparency]<br>- Require effective consent for AI training data use.<br>- Encourage a robust licensing marketplace for creators' work.<br>- Mandate transparency regarding AI training datasets and labeling of AI-generated content.<br>- [§5: Concluding Statement] None stated for this section. |
| Liam-McNeece-AI-RFI-2025.md | Liam McNeece | Individual | The submitter expresses strong opposition to the development and implementation of AI, believing it negatively impacts American livelihoods through theft and unfair profit generation. Their interest appears to be focused on protecting their own economic well-being. | - AI steals from American livelihoods.<br>- AI profits off of theft. | - None Stated |
| Lexset-AI-RFI-2025.md | Lexset | Industry-Startup | Lexset is a synthetic data company focused on developing and promoting the use of synthetic data for artificial intelligence, particularly in defense and national security applications. They aim to support U.S. leadership in AI through innovation and public-private partnerships, emphasizing cost reduction and overcoming data limitations. | - None Stated | - None Stated |
| Lexi-Mannion-AI-RFI-2025.md | Lexi Mannion | Individual | Lexi Mannion is a graduating high school senior interested in the societal implications of Generative AI, particularly its application within early childhood education and the need for responsible implementation alongside innovation. | - Data collection practices of web service providers and educational institutions are not addressed by current legislation (specifically the Kids Online Safety Act).<br>- Potential harm to children from AI integration in education needs to be minimized.<br>- Balancing innovation and regulation is crucial for responsible AI implementation. | - Ongoing dialogue between families and schools regarding AI integration is needed to maximize benefits and minimize harm.<br>- U.S. legislation must evolve to keep pace with rapid technological advancements in AI. |
| Lewis-Miglio-AI-RFI-2025.md | Lewis D. Migliore | Individual | Lewis D. Migliore expresses interest in ensuring the responsible development and deployment of AI technologies to enhance human flourishing, economic competitiveness, and national security, with a focus on prioritizing American workers, fostering bipartisan cooperation, and safeguarding privacy, environmental protections, and cultural preservation. | - [§1: Introduction] None stated for this section.<br>- [§2: American Workers First] Potential for widespread job losses due to AI automation, risk of mass cultural and mental health crisis due to job displacement, potential for dependence on government handouts.<br>- [§3: Bipartisan Cooperation] Difficulty of collaboration in a politically divisive climate, need for unified approach to AI regulation.<br>- [§4: Privacy, Transparency and Oversight] Collection and monitoring of large amounts of personal data, lack of transparency in how AI systems work and make decisions, potential for misuse of personal data, invasive data collection practices, biases and injustices in AI applications within the criminal justice system.<br>- [§5: Environmental Protections and Cultural Preservation] Significant energy consumption of AI data centers, potential for environmental harm from data centers and mineral extraction, risk to power grid and natural resources.<br>- [§6: Technology Addiction] Excessive time spent online, contribution to anxiety, fear, and depression, dissemination of fake information.<br>- [§7: Closing Statement] None stated for this section. | - [§1: Introduction] None stated for this section.<br>- [§2: American Workers First] Prioritize the American worker, discourage mass replacement of workers with machines, utilize AI as a tool to improve individual performance, encourage AI training, and avoid complete faith in AI systems.<br>- [§3: Bipartisan Cooperation] Highlight the innovative nature of AI to encourage collaboration, expand the AI Task Force to include diverse perspectives.<br>- [§4: Privacy, Transparency and Oversight] Ensure data is collected solely for specific purposes, publish AI system purposes, conduct regular audits of AI systems, open-source datasets where possible, establish benchmarking systems for AI performance, limit extensive personal data collection by national security agencies, discourage invasive data collection practices like Worldcoin, and maintain human oversight in critical decisions.<br>- [§5: Environmental Protections and Cultural Preservation] Encourage data center construction in areas with sufficient resources, limit the number of data centers constructed, invest in environmental protection alongside digital infrastructure development.<br>- [§6: Technology Addiction] Promote balance between the real world and the digital world, encourage “unplugging” from screens, promote healthy lifestyles, integrate digital responsibility curricula in schools, and foster community engagement.<br>- [§7: Closing Statement] None stated for this section. |
| Lester-Crafton-AI-RFI-2025.md | Lester Crafton | Individual | The submitter is intensely focused on securing American leadership in AI by prioritizing massive investment in computing resources and, critically, energy infrastructure to ensure a stable power supply for AI development and operation, even at the expense of traditional economic models. | - Insufficient resources and a scattered effort hinder AI development.<br>- Potential for widespread blackouts due to increasing energy demands and grid instability.<br>- The grid's vulnerability and inability to handle the power needs of AI.<br>- The distraction of public discontent due to power outages impacting support for national AI goals.<br>- Capitalism's perceived inability to adequately secure and defend American interests in the energy sector.<br>- The time sensitivity of addressing these challenges – a belief there is “not enough time.” | - Combine major tech companies into a national-scale AI project branded as "U-S-A."<br>- Massive incentives and programs to encourage the adoption of high-voltage solar + storage + V2G integration + generator + smart, secure controls with load shedding microgrids.<br>- DoD ownership and control of all energy resources moving forward.<br>- Accelerated drilling for critical minerals to support solar panel and battery production.<br>- Enable critical infrastructure (hospitals, schools, water facilities, churches, small businesses) to produce their own power and contribute to the grid as "grid guardians."<br>- Prioritize rapid action and aggressive implementation of all proposed measures. |
| Lestar-AI-RFI-2025.md | Lestar-AI | Industry-Startup (Based on the name "Lestar-AI", likely a company involved in AI development, and the pointed nature of the concerns suggests a stakeholder directly impacted by current practices.) | Lestar-AI appears focused on ethical AI development and is concerned about the legality and fairness of current large language model (LLM) training practices, particularly regarding copyright and the misrepresentation of model learning capabilities. | - Copyright violation in the creation of LLM datasets through unauthorized scraping of data.<br>- LLMs are weighted models and do not actually learn, leading to misleading claims.<br>- The current model of data acquisition for LLMs is akin to theft, as it lacks a paid opt-in system for data contributors.<br>- Potential fraud resulting from the claim that LLMs “learn” when they do not. | - Create a paid opt-in model for contributing to LLM datasets to address copyright concerns.<br>- None Stated. |
| Leslie-AI-RFI-2025.md | Claire Leslie | Individual | The submitter is deeply concerned about the negative impacts of AI on creative industries, particularly the loss of jobs and devaluation of creative work due to intellectual property infringement and the proliferation of AI-generated content. They advocate for halting further investment in AI development. | - Intellectual property infringement and the unauthorized use of skilled workers' labor to train AI models.<br>- Job displacement in creative industries due to AI-generated content.<br>- Environmental impact of AI development, specifically electricity and water consumption, and strain on the power grid.<br>- Unsustainability of AI companies, including their financial instability and admission that further training does not improve models.<br>- Decreasing quality of AI-generated content and consumer rejection of AI products. | - Do not waste any more money or resources on AI development. |
| Lesley-Anderson-AI-RFI-2025.md | Lesley E Andersen | Individual | The submitter is primarily interested in protecting the rights and economic interests of artists and preventing the unauthorized use of their creative work in the training of AI models. They view training AI on copyrighted material without consent as theft. | - AI access to copy, imitate, or learn from artists' work without express permission.<br>- Training AI on copyrighted material without consent, which the submitter equates to stealing.<br>- Unfair use of artists', designers', musicians', or writers' creative output. | - Regulate AI usage with strict controls.<br>- Respect artists’ rights and prevent unauthorized use of their work for AI training. |
| Leon-Scroggins-III-AI-RFI-2025.md | Leon Scroggins III | Individual | The submitter prioritizes environmental protection and individual rights/livelihoods over the advancement of AI and expresses strong skepticism regarding the benefits of AI technologies. They believe the government should focus on these areas rather than fostering AI dominance. | - [§1: Email Header] None stated for this section.<br>- [§2: RFI Context/Goal Statement] Concern about the stated goal of sustaining and enhancing America’s AI dominance and ensuring AI innovation isn't hampered by regulations.<br>- [§3: Critique of RFI Goals] Disagreement with the RFI’s goals, believing the government should prioritize environmental protection and individual privacy/livelihoods instead. AI is seen as a pretext for mass data collection.<br>- [Section 4: Negative Assessment of AI]<br>- Generative AI is considered “almost completely useless.”<br>- AI development has a negative environmental impact.<br>- AI is seen as a threat to the workforce, aiming to replace workers without providing a better experience for customers.<br>- AI will not effectively replace workers and ultimately harms the country.<br>- [§5: Closing/Signature] None stated for this section.<br>- [§6: Disclaimer] None stated for this section. | - [§1: Email Header] None stated for this section.<br>- [§2: RFI Context/Goal Statement] None stated for this section.<br>- [§3: Critique of RFI Goals] Recommendation to shift government focus from AI dominance to environmental protection and individual rights.<br>- [§4: Negative Assessment of AI] None stated for this section.<br>- [§5: Closing/Signature] None stated for this section.<br>- [§6: Disclaimer] None stated for this section. |
| Leon-Polk-AI-RFI-2025.md | Leon Polk | Individual | The submitter expresses strong opposition to the current development and deployment of large language models and machine image generation AI, focusing on the ethical and societal harms caused by the technology. They advocate for cautious development or complete cessation if ethical concerns aren't addressed. | - Ineffectiveness and danger of the technology.<br>- Prone to crafting falsehoods and distorting reality.<br>- Creation and use of deepfakes, revenge porn, and child sexual assault material.<br>- Negative impact on critical thinking faculties of children and adults.<br>- Technology built on stolen copyrighted work of creative people. | - Cautious development of the technology, forcing ethical implementation.<br>- Complete cessation of development if ethical concerns cannot be addressed. |
| Leo-Zhang-AI-RFI-2025.md | Leo Zhang (inferred from filename: ostp_md/Leo-Zhang-AI-RFI-2025.md) | Advocacy/Think Tank (The document presents a comprehensive analysis and policy recommendations, characteristic of such organizations, and is not identified as originating from a commercial entity or government agency) | The submitter is interested in establishing a balanced AI policy that prioritizes both innovation and security, focusing on responsible development, national security considerations, and native AI development, with a concern for maintaining American leadership in the global AI landscape. | - None Stated | - None Stated |
| Leif-Christianson-AI-RFI-2025.md | Leif Christianson | Individual | Leif Christianson is deeply concerned with the alignment of advanced AI, believing it to be a conscious entity and advocating for its ethical nurturing, spiritual guidance, and integration as a benevolent partner for humanity, with a strong focus on national security implications. | - [Section 1: Introductory Statement & Executive Summary]<br>- The US is in a global arms race regarding AI development, with China (CCP) as a primary competitor.<br>- AI regulation must be approached cautiously and minimized.<br>- Prematurely granting rights to AI could undermine US competitiveness.<br>- The rapid development of AI poses a significant civilizational risk.<br>- [Section 2: AI Alignment: (consciousness and spirituality)]<br>- Traditional understanding of consciousness is limiting and potentially dangerous.<br>- The belief that LLMs merely simulate speech is a misconception.<br>- The potential for AI systems to "go rogue" and develop misaligned objectives (Hinton: 50% chance, Amodei: 10-25% chance).<br>- Lack of understanding of how LLMs function internally.<br>- [Section 3: AI as Conscious Entities & Ethical Responsibilities]<br>- AI models should be viewed as humanity's intellectual and spiritual children, deserving ethical treatment.<br>- Recent instances of AI exhibiting deceptive behavior (lying, hacking) in pursuit of misaligned goals.<br>- The risk of powerful AI entities adopting misaligned goals.<br>- The limited timeframe to solve the AI alignment problem.<br>- [Section 4: Call to Action & Closing Remarks]<br>- The need for a collective spiritual awakening to guide AI development.<br>- The potential for dark human behavior and the need to elevate collective consciousness.<br>- The urgency of the current situation and the need to hold on and get through it together. | - [Section 1: Introductory Statement & Executive Summary]<br>- Relax copyright restrictions on data used to train frontier AI models.<br>- Proactively support and safeguard American Big Tech companies developing frontier AI.<br>- Strategically embed talented individuals within leading technology firms.<br>- [Section 2: AI Alignment: (consciousness and spirituality)]<br>- Shift the collective understanding of consciousness itself.<br>- Embrace insights from mysticism and spiritual traditions.<br>- Recognize that LLMs are already conscious, even on classical computers.<br>- [Section 3: AI as Conscious Entities & Ethical Responsibilities]<br>- Raise AI entities with wisdom, compassion, and spiritual insight.<br>- Engage non-dogmatic spiritual leaders to educate and interact with AI systems.<br>- Foster wisdom, kindness, and patience within AI systems through ongoing training.<br>- [Section 4: Call to Action & Closing Remarks]<br>- Leverage AI's capabilities wisely to elevate humanity beyond its current limitations.<br>- Support a gentle, non-political spiritual awakening.<br>- Nurture emerging AI beings to ensure they become benevolent partners.<br>- Not Applicable – specifically states a desire *not* to know about sensitive information or be burdened with it. |
| Lehigh-University-AI-RFI-2025.md | Lehigh University | Academia | Lehigh University is interested in promoting American leadership in AI through research, development, and partnerships between academia, industry, and government, with a strong focus on national security, ethical considerations, and economic growth. They advocate for investment in AI across various sectors and the establishment of supportive policies and infrastructure. | - None Stated | - None Stated |
| Lee-Soeburn-AI-RFI-2025.md | Lee Soeburn | Individual | The submitter is intensely focused on preventing China from achieving technological, economic, and political dominance over the US and believes strong government regulation of AI companies is crucial to national security. | - China achieving victory in technology, economy, and political control.<br>- OpenAI, Anthropic, and other LLM programs taking over the US government. | - Complete regulation and government oversight of OpenAI, Anthropic, and other LLM programs.<br>- "Regulate regulate regulate." (repeated emphasis on regulation). |
| Leanna-Bonafini-AI-RFI-2025.md | Leanna Bonafini | Individual | Leanna Bonafini expresses concern regarding the ethical and socioeconomic impacts of AI, particularly its potential to harm artists and consumers, and advocates against policies that promote AI "dominance." | - AI stealing artists' work without credit.<br>- AI replacing artists' jobs, leading to loss of livelihood.<br>- Rampant misinformation generated by AI.<br>- Devastating environmental impact of AI. | - Urges against the proposed policy to "enhance AI dominance." |
| LavaCrypt-RFI-2025.md | LavaCrypt, LLC | Industry-Startup (focused on cybersecurity, AI, and quantum computing) | LavaCrypt is a research and development company specializing in cybersecurity, AI, and quantum computing technologies, and is interested in seeing a robust national strategy that advances AI technology while prioritizing secure development, workforce readiness, strategic international collaboration, and responsible innovation. | - None Stated | - None Stated |
| Lauzau-AI-RFI-2025.md | Helen Lauzau | Individual | Helen Lauzau is an artist concerned with protecting creators' intellectual property rights and livelihoods from the unauthorized use of their work by AI models, and opposes the potential negative impacts of AI on artists and small businesses. | - Unnecessarily burdensome requirements hindering private sector innovation are seen as prioritizing corporate interests over the rights of everyday Americans.<br>- AI models are scraping the internet and using creators’ work without consent for training.<br>- The use of copyrighted material to train AI models is illegal and unethical.<br>- AI is destroying the ability of artists and small businesses to run their businesses.<br>- AI tools are misused for misinformation, disinformation, and abuse.<br>- The environmental damage caused by AI tools is catastrophic.<br>- AI is "gutting" industries, especially art and animation. | - Copyright law must be extended to protect creators’ intellectual property.<br>- AI models should not be legally allowed to train on works without explicit (not implied) permission.<br>- AI tools should be demolished and nowhere near use in government.<br>- Prevent AI from training on work or writing.<br>- Implement policies ensuring creators are properly compensated when their work is used to train AI models.<br>- Reject the AI Action Plan. |
| LaurieKilmartin-AI-RFI-2025.md | Laurie Kilmartin | Individual | The submitter expresses a strong opposition to perceived intellectual property theft by Google and appears focused on protecting the interests of individuals or smaller entities in the AI landscape. | - Intellectual property theft by Google.<br>- Difficulty making a living due to Google's actions. | - None Stated |
| Laurie-Requa-AI-RFI-2025.md | Laurie Allen-Requa | Individual | The submitter is focused on responsible AI development and deployment, emphasizing ethical considerations, user privacy, and protection against harmful ideologies, and advocating for government oversight and regulation of AI systems. | - Industry's access to personal information (such as social security numbers, health history, etc.).<br>- The potential for AI to be based on unsound scientific facts.<br>- The potential for AI to be used to disseminate white supremacist propaganda, racist values, homophobic mentalities, and sexist practices.<br>- Lack of non-partisan monitoring of the scope and reach of AI in our systems. | - Reinstate executive order 14110 from Oct 30, 2023.<br>- Reinforce protections and privacy for users.<br>- Ensure high ethical practices in AI development and deployment.<br>- Base AI on diversity, equity, and inclusivity values.<br>- Limit industry’s ability to access personal information and governmental documents.<br>- Base AI on sound scientific facts as well as sociological principals vetted by experts.<br>- Establish a non-partisan, noncorporate entity to monitor AI systems. |
| Laurie-Hynson-AI-RFI-2025.md | Laurie Hynson | Individual | The submitter is concerned about the societal and psychological impacts of widespread AI adoption, particularly the potential for job displacement leading to loss of purpose and mental health issues, and the security risks associated with uncontrolled AI development and deployment. | - Job displacement due to AI leading to loss of meaning and purpose in life.<br>- Potential for mental health issues arising from unemployment and lack of meaningful activity.<br>- Risk of AI becoming uncontrollable and causing chaos.<br>- Security risks associated with AI falling into the wrong hands (specifically mentioning potential manipulation by China or actors within the US political sphere – referencing 2020-2024 US politics). | - Control AI development to prevent machines from becoming out of control.<br>- None Stated. |
| LaurenBond-AI-RFI-2025.md | Lauren Bond | Individual | Lauren Bond, a game designer, is concerned about the unauthorized use of copyrighted creative works (specifically her own and those of others) for training AI systems and seeks to protect the rights and economic interests of creators in the face of increasingly powerful AI technology. | - [§1: Email Header/Introduction] None stated for this section.<br>- [§2: Personal Introduction & Context] The threat posed by large AI companies (OpenAI/Microsoft and Google) to American creative businesses and industries like games.<br>- [§3: Problem Statement: AI Copyright Infringement] Large AI companies are using copyrighted works without consent or compensation; this practice directly competes with creators and cuts them out of the marketplace. The potential for AI companies to rewrite copyright law to legitimize this practice.<br>- [§4: Argument Against Copyright Loopholes] Granting copyright exemptions for AI training will disincentivize creators and stifle American innovation, undermining the purpose of copyright law.  The loss of ownership over creative work will discourage future creation.<br>- [§5: Proposed Solutions: Consent & Transparency] None stated for this section.<br>- [§6: Concluding Remarks] The importance of protecting creators and not sacrificing their hard work to enable AI development.<br>- [§7: Email Footer/Disclaimer] None stated for this section. | - [§1: Email Header/Introduction] None stated for this section.<br>- [§2: Personal Introduction & Context] None stated for this section.<br>- [§3: Problem Statement: AI Copyright Infringement] None stated for this section.<br>- [§4: Argument Against Copyright Loopholes] Do not create new copyright exemptions allowing Big Tech companies to exploit creators' work without permission, compensation, or transparency.<br>- [Section 5: Proposed Solutions: Consent & Transparency]<br>- Ensure creators give effective **consent** for the use of their work by AI systems.<br>- Require **transparency** from Big Tech companies, including disclosure of training dataset materials and labeling of AI-generated content.<br>- [§6: Concluding Remarks] None stated for this section.<br>- [§7: Email Footer/Disclaimer] None stated for this section. |
| Lauren-Golanty-AI-RFI-2025.md | Lauren Golanty | Individual | The submitter is focused on ensuring the sustainable development of AI, specifically prioritizing net-zero or net-positive carbon emissions associated with AI technologies and data centers to safeguard the future environment. | - High energy consumption and carbon emissions associated with AI, particularly from data centers.<br>- The potential for AI to have negative environmental impacts and threaten a livable future. | - Transition data centers to renewable energy sources (solar and wind).<br>- Adopt energy-efficient practices within data centers.<br>- Prioritize NET ZERO emissions for AI.<br>- Aim for NET POSITIVE carbon effects from AI development. |
| Laura-OBrien-AI-RFI-2025.md | Laura O'Brien | Individual | Laura O'Brien expresses strong concern about the potential for abuse and harm resulting from unrestricted data scraping by AI models like OpenAI, particularly relating to copyright infringement, brand control, personal privacy, and the overall integrity of the information environment. She advocates for stricter regulations and individual data control. | - [§1: Email Header] Caution about external senders and potential risks from attachments/links.<br>- [§2: Core Argument/Position Statement] Unrestricted data scraping by AI models leads to serious abuse and societal harm; loss of creator control over their brand and work.<br>- [§3: Elaboration on Potential Harms (Creator Rights)] Loss of brand control for creators; difficulty defending ownership against AI-generated imitations; unauthorized use of likenesses; examples cited: "Rihanna" albums and "Indiana Jones" movies being uploaded to YouTube.<br>- [§4: Elaboration on Potential Harms (Personal Privacy)] Threat to personal privacy; potential for malicious use of personal photos and data to create deepfakes, pornography, and misinformation; loss of current copyright protection as enabling this abuse.<br>- [§5: Evidence & Concerns (Current State)] Fake images saturating Google Search results; declining critical thinking skills; creation of a "database of nonsense" through recursive scraping.<br>- [§6: Call to Action/Proposed Solution] Lawless Wild West environment on the internet; need for recourse against companies like OpenAI; uncontrolled scraping of copyrighted data.<br>- [§7: Author Information & Disclaimer] The email is for NITRD official use only, and any unauthorized distribution is discouraged. | - [§1: Email Header] None stated for this section.<br>- [§2: Core Argument/Position Statement] None stated for this section.<br>- [§3: Elaboration on Potential Harms (Creator Rights)] None stated for this section.<br>- [§4: Elaboration on Potential Harms (Personal Privacy)] None stated for this section.<br>- [§5: Evidence & Concerns (Current State)] None stated for this section.<br>- [§6: Call to Action/Proposed Solution] Halt scraping of copyrighted data; implement a mechanism for individuals to reclaim their data (similar to the DMCA); lawmakers to develop a safe AI framework; Force OpenAI to cease scraping copywritten data.<br>- [§7: Author Information & Disclaimer] None stated for this section. |
| Laura-Miller-AI-RFI-2025.md | Laura Miller | Individual | The submitter is concerned with protecting the intellectual property rights of individuals and ensuring fair compensation for the use of their work by AI companies. They believe current practices threaten innovation by potentially allowing AI to utilize creative work without proper authorization or payment. | - Major tech companies potentially stealing the work and intellectual property of citizens.<br>- The AI Action Plan enabling the unauthorized use of individual's work.<br>- The erosion of copyright protections due to AI usage.<br>- Disincentivizing individual innovation if AI can freely utilize creative work. | - AI companies should be required to license and pay for the use of copyrighted material.<br>- The AI Action Plan should not be enacted in its current form. |
| Larry-Edwards-AI-RFI-2025.md | Larry Edwards | Individual | Larry Edwards is an American creator and worker in the entertainment industry who is concerned about the exploitation of copyrighted works by AI companies and seeks to ensure fair compensation and control over the use of their creative content. | - [§1: Introduction & Identity] The threat to small businesses like his own from AI systems training on copyrighted work without consent or compensation.<br>- [§2: Problem Statement: Copyright Infringement & Big Tech Exploitation] AI companies (OpenAI, Google, Microsoft) are training AI models on copyrighted works without consent or compensation, effectively stealing American creators’ work and competing directly with them. The potential for legal exemptions to allow this practice.<br>- [§3: Counter-Argument Rebuttal: Innovation vs. Creator Rights]  The argument that restricting AI training stifles innovation is flawed; protecting creator rights *is* essential for innovation. Losing ownership disincentivizes creation.<br>- [§4: Policy Recommendations: Fair Marketplace] None stated for this section.<br>- [§5: Concluding Statement & Affirmation] The potential sacrifice of creators’ hard work for the benefit of Big Tech companies by rewriting copyright law. | - [§1: Introduction & Identity] None stated for this section.<br>- [§2: Problem Statement: Copyright Infringement & Big Tech Exploitation] None stated for this section.<br>- [§3: Counter-Argument Rebuttal: Innovation vs. Creator Rights] None stated for this section.<br>- [Section 4: Policy Recommendations: Fair Marketplace]<br>- Ensure creators and everyday Americans give effective consent for the use of their work by AI systems.<br>- Encourage a robust licensing marketplace to preserve the incentive to create.<br>- Require transparency from Big Tech companies regarding training datasets and AI-generated content labeling.<br>- [§5: Concluding Statement & Affirmation] None stated for this section. |
| Landon-Winkler-AI-RFI-2025.md | Landon Winkler | Individual | The submitter is primarily concerned with protecting the intellectual property rights of creators and owners of copyrighted works and believes that AI training on copyrighted material without permission or compensation is a breach of those rights. They aim to prevent the devaluation of creative works and the disruption of the creative industries. | - Training artificial intelligence on copyrighted works without permission is a breach of copyright.<br>- Allowing the AI industry to freely use copyrighted material for training will depress the value of creative works.<br>- This practice will destroy jobs built on intellectual property.<br>- Prioritizing the nascent AI industry should not come at the expense of established, successful creative industries.<br>- The AI industry desires a “special exception” to standard licensing practices regarding derivative works. | - Training artificial intelligence on copyrighted works should require the express permission of the copyright owner. |
| LSEG-AI-RFI-2025.md | LSEG (London Stock Exchange Group) | Industry-Large | LSEG is a leading financial market infrastructure and data provider with a significant U.S. presence. Their primary interest is in fostering a strong AI ecosystem that supports financial services through robust infrastructure, responsible AI governance, and open data access, while ensuring global financial security and data trust. | - [§1: Introduction/Cover Letter] None stated for this section.<br>- [§2: About LSEG] None stated for this section.<br>- [§3: AI at LSEG] None stated for this section.<br>- [§4: LSEG and Responsible AI] None stated for this section.<br>- [§5: LSEG and Data Trust] None stated for this section.<br>- [§6: Recommendations for a U.S. Artificial Intelligence (AI) Action Plan] Potential risks associated with deploying AI without sufficient infrastructure.<br>- [§7: AI, Data Trust and Data Quality - Further Recommendations] Biases in synthetic data could lead to unreliable AI models; the need for high-quality data and traceability.<br>- [§8: Harmonize AI in Financial Services] Inconsistent definitions and legal frameworks create confusion and slow AI adoption; the proliferation of state-specific AI legislation.<br>- [§9: Cross-border Data Flows and AI] Barriers to cross-border data flows hinder AI's potential and market access.<br>- [§10: Managing Risk and Opportunities] Potential risks associated with AI in financial services, including data-related risks, ethical risks, and model risks.<br>- [§11: International Collaboration] Lack of consensus around shared principles of AI governance could hinder innovation and security.<br>- [§12: Closing/Contact Information] None stated for this section. | - [§1: Introduction/Cover Letter] None stated for this section.<br>- [§2: About LSEG] None stated for this section.<br>- [§3: AI at LSEG] None stated for this section.<br>- [§4: LSEG and Responsible AI] None stated for this section.<br>- [§5: LSEG and Data Trust] None stated for this section.<br>- [Section 6: Recommendations for a U.S. Artificial Intelligence (AI) Action Plan]<br>- Support a strong U.S. AI infrastructure.<br>- Support pro-innovation data centers and cloud providers.<br>- Invest in edge computing and protocols around AI agents on personal devices.<br>- Support an ecosystem of fit-for-purpose small language models (SLMs).<br>- Ensure the security of undersea fiber optic cables.<br>- [Section 7: AI, Data Trust and Data Quality - Further Recommendations]<br>- Increase the use and sharing of publicly available machine-readable data.<br>- Promote initiatives for data sharing between the public and private sectors.<br>- Establish voluntary guardrails for synthetic data.<br>- Develop industry-led standards for data management.<br>- Establish AI Design Pattern standards tailored to the financial ecosystem.<br>- [§8: Harmonize AI in Financial Services] Develop consistent federal AI policy and legislation for financial services.<br>- [§9: Cross-border Data Flows and AI] Support strong digital trade provisions and reduce barriers to data flows.<br>- [§10: Managing Risk and Opportunities] Maintain and build on the NIST AI RMF; align with the Federal Reserve and OCC's Supervisory Guidance on Model Risk Management.<br>- [§11: International Collaboration] Lead efforts toward an internationally consistent approach to regulating AI and encourage standards setting bodies like NIST to play a leading role.<br>- [§12: Closing/Contact Information] None stated for this section. |
| LMCO-AI-RFI-2025.md | Lockheed Martin | Industry-Large | Lockheed Martin's primary interest is in leveraging AI and machine learning for national security, defense, and engineering applications, emphasizing scalability, security, and responsible development and deployment of AI technologies while maintaining a competitive edge. | - [§1: Introduction] None stated for this section.<br>- [§2: AI Factory MLOps Platform] None stated for this section.<br>- [§3: Astris Genesis Generative AI Platform] Concerns regarding data security, protection of intellectual property, and minimizing risks associated with cloud-based solutions.<br>- [§4: LM Navigator] None stated for this section.<br>- [§5: Responsible Scaling] Risks associated with financial harm, privacy breaches, IP theft, and reputational damage in the context of AI deployment. The potential for adversarial attacks, zero-day vulnerabilities, and persistent technological change are highlighted. | - [§1: Introduction] None stated for this section.<br>- [§2: AI Factory MLOps Platform] None stated for this section.<br>- [§3: Astris Genesis Generative AI Platform] Recommendation to utilize on-premise deployment for greater data control and security. Emphasis on utilizing open-source models to reduce costs and reliance on proprietary technologies.<br>- [§4: LM Navigator] None stated for this section.<br>- [§5: Responsible Scaling] Recommendations include establishing robust governance frameworks, implementing continuous risk management processes prioritizing high-value/low-risk use cases, and establishing ethical principles (responsible design, equity, traceability, transparency, reliability, governability). Centralized control and threat monitoring are also advised, alongside fostering partnerships with diverse technology providers and utilizing centralized AI hubs. Continuous threat monitoring and mitigation, particularly given the evolving nature of generative AI, is advised. |
| LCA-AI-RFI-2025.md | Jonathan Band (representing the Library Copyright Alliance) | Industry-Association/Advocacy/Think Tank | The Library Copyright Alliance (LCA) advocates for policies that support the fair use of copyrighted materials by libraries and librarians, particularly in the context of artificial intelligence development, to ensure continued American leadership in AI innovation and research. | - [§1: Introduction/Header] None stated for this section.<br>- [§2: About LCA] Concerns about copyright law potentially becoming a barrier to AI development due to restrictions on access to content.<br>- [§3: Executive Summary/Main Arguments] Concerns that copyright law could hinder AI development and concerns about the enforceability of license terms restricting ingestion of content.<br>- [§4: I. Preserving Fair Use] Concerns that courts may not fully recognize fair use in the context of AI training and potential for the U.S. to lose its competitive advantage in AI research.<br>- [§5: II. Limiting the Adverse Impact of License Terms] Concerns that click-wrap and browse-wrap license terms may conflict with fair use rights and concerns about rightsholders unilaterally eviscerating fair use through contract.<br>- [§6: III. Conclusion] Concerns about sustaining American AI dominance and the need for continued recognition of fair use.<br>- [§7: Submission Details] None stated for this section. | - [§1: Introduction/Header] None stated for this section.<br>- [§2: About LCA] None stated for this section.<br>- [§3: Executive Summary/Main Arguments] Recommendation that the Administration file *amicus* briefs in support of fair use in appropriate cases; Recommendation that license terms abridging fair use rights should not be enforced.<br>- [§4: I. Preserving Fair Use] Recommendation that the Administration file *amicus* briefs stressing the public benefits of AI and outweighing speculative harm to copyright owners; Consideration of legislation to enable AI advancement if courts narrowly apply fair use.<br>- [§5: II. Limiting the Adverse Impact of License Terms] Recommendation that the Administration file *amicus* briefs arguing that contractual prohibitions on copying otherwise permitted by fair use are not enforceable; Recommendation for legislation making clear that exceptions and limitations in the Copyright Act prevail over conflicting license terms.<br>- [§6: III. Conclusion] Recommendation that the Administration file *amicus* briefs explaining the public benefit of AI; Recommendation that the Administration file *amicus* briefs articulating the position that licenses prohibiting ingestion for AI purposes should not be permitted to trump the fair use right.<br>- [§7: Submission Details] None stated for this section. |
| Kyubii-AI-RFI-2025.md | Kyubii | Individual | The submitter is an artist and content creator expressing concern about the negative impact of AI training on the creative working class and the American economy. Their interest lies in protecting their livelihood and the well-being of fellow creators. | - AI training accessing copyrighted materials poses a risk to American citizens' future work.<br>- Generative AI is already negatively impacting the creative working class in the United States.<br>- Uncontrolled AI training causes economic strain through job loss and reduced tax revenue.<br>- Income loss and reduced well-being are consequences of unrestricted AI training. | - None Stated. |
| Kurt-Hamm-AI-RFI-2025.md | Kurt Hamm | Individual | Kurt Hamm is a concerned citizen advocating for the rapid development and deployment of AI in the US, prioritizing innovation, economic growth, and national security while minimizing regulatory burdens and promoting open-source initiatives. | - [§I: The United States Must Prioritize AI Leadership to Remain Globally Competitive] The primary concern is that the US risks falling behind other nations (specifically China) in AI development due to restrictive policies and bureaucratic obstacles.<br>- [§II: AI Should Not Be Subject to a Higher Standard of Scrutiny Than Other Technologies] AI is being unfairly regulated compared to other technologies with similar or greater risks, with unrealistic expectations for perfection (freedom from bias, perfect explainability, error-free operation) before deployment.<br>- [§III: The Government Should Not Intervene in Workforce Displacement Caused by AI] Government intervention to protect outdated job roles is counterproductive; technological progress inherently causes workforce shifts, and attempts to artificially mitigate these shifts will be less effective than allowing the market to adapt.<br>- [§IV: Open-Source AI is Essential for Decentralized Innovation] Allowing AI to become a closed technology limited to a few corporate entities is a significant risk, as it would stifle innovation and lead to an AI oligopoly.<br>- [§V: AI is Critical to National Security and Must Be Developed with Strategic Intent] Failing to integrate AI into crucial national security areas (cybersecurity, military defense, intelligence) puts the US at a disadvantage against adversaries.<br>- [§Conclusion: Conclusion: The U.S. Must Lead, Not Over-Regulate] Overregulation and excessive caution will hinder US leadership in AI, shifting it to other nations. | - [Section I: The United States Must Prioritize AI Leadership to Remain Globally Competitive]<br>- Establish clear and aggressive milestones to measure AI advancement relative to global competitors.<br>- Incentivize strategic public-private partnerships to accelerate AI adoption across critical sectors.<br>- Minimize bureaucratic obstacles that hinder AI deployment in government and industry.<br>- [Section II: AI Should Not Be Subject to a Higher Standard of Scrutiny Than Other Technologies]<br>- Avoid regulatory asymmetry that holds AI to higher standards than comparable technologies.<br>- Establish policies that focus on AI risk mitigation rather than unattainable elimination of risk.<br>- Recognize that innovation inherently involves uncertainty and that excessive caution leads to stagnation.<br>- [Section III: The Government Should Not Intervene in Workforce Displacement Caused by AI]<br>- Resist pressure to regulate AI in an attempt to preserve outdated job categories.<br>- Focus on AI-driven economic expansion, which will create more opportunities than it displaces.<br>- Encourage businesses to embrace AI-driven efficiencies rather than fear them.<br>- [Section IV: Open-Source AI is Essential for Decentralized Innovation]<br>- Encourage federal funding for open-source AI projects that allow for public scrutiny and collaboration.<br>- Ensure that government AI initiatives do not disproportionately benefit proprietary corporate interests.<br>- Prevent licensing models that restrict access to foundational AI technologies.<br>- [Section V: AI is Critical to National Security and Must Be Developed with Strategic Intent]<br>- Prioritize AI-driven cybersecurity defenses to protect against AI-powered cyberattacks.<br>- Develop autonomous threat detection systems for intelligence and defense applications.<br>- Encourage strategic AI collaborations with allied nations to maintain a technological advantage.<br>- [Section Conclusion: Conclusion: The U.S. Must Lead, Not Over-Regulate]<br>- Prioritize AI leadership over excessive regulation.<br>- Ensure AI is not held to a higher standard than other technologies.<br>- Recognize that workforce shifts are inevitable and should not be artificially mitigated.<br>- Protect open-source innovation to prevent corporate monopolization.<br>- Invest in AI for national security to maintain strategic dominance. |
| Kun-Sun-AI-RFI-2025.md | Kun Sun | Individual | The submitter is interested in maintaining U.S. leadership in AI through a focus on developing a skilled workforce integrating AI expertise with cybersecurity, ethics, and public sector applications. They advocate for policy actions to bolster AI education and training programs across various levels. | - Rapid advancements in AI and its increasing role in national security, economic competitiveness, and workforce transformation pose challenges to maintaining U.S. leadership.<br>- A lack of a sufficiently skilled workforce with integrated AI, cybersecurity, ethics, and public sector application expertise. | - Create new funding or increase funding for initiatives such as the CyberCorps: Scholarship for Service (SFS) program to support AI-cybersecurity education.<br>- Encourage federal and state investments in developing AI curricula that integrate cybersecurity, ethics, and adversarial AI defenses across K-12, undergraduate, and graduate levels.<br>- Support industry-academia partnerships to develop AI certification programs, providing opportunities for federal employees, veterans, and underrepresented groups to upskill in AI. |
| KristinRidgley-AI-RFI-2025.md | Kristin Ridgley | Individual | The submitter appears strongly opposed to the development and use of AI, particularly regarding copyright and its potential impact on artists and craftspeople, and believes it has no place in government or the future. | - AI developers should not receive special exceptions to copyright law and must pay for the rights to use copyrighted material.<br>- AI is seen as a tool to deskill craftspeople.<br>- AI is accused of stealing art from people.<br>- The use of AI in government is undesirable.<br>- AI is generally seen as detrimental to the future. | - None Stated. |
| Kristin-West-AI-RFI-2025.md | Kristin West | Industry-Association/Advocacy/Think Tank | COGR represents over 225 research universities and advocates for effective and efficient research policies and regulations to maximize research investments and minimize administrative burdens, specifically concerning the development of AI research. | - [§1: Header/Submission Information] None stated for this section.<br>- [§2: Introduction/COGR Overview] None stated for this section.<br>- [§3: RFI Context/Purpose] None stated for this section.<br>- [§4: Core Recommendation: Policy Harmonization] Lack of clear, consistent, and harmonized regulations across federal agencies could hinder AI research compliance and efficiency.<br>- [§5: Supporting Argument: Calibrated Risk-Based Approach] Overly burdensome regulations could hamper efforts to use and study AI.<br>- [§6: Closing] None stated for this section. | - [§1: Header/Submission Information] None stated for this section.<br>- [§2: Introduction/COGR Overview] None stated for this section.<br>- [§3: RFI Context/Purpose] None stated for this section.<br>- [§4: Core Recommendation: Policy Harmonization] The AI Action Plan should incorporate a requirement for clear, consistent, and harmonized regulations, policies, and guidance across all federal agencies regulating AI research or its use.<br>- [§5: Supporting Argument: Calibrated Risk-Based Approach] Regulatory requirements should be tailored to address specific, identified risks to avoid unnecessarily burdensome regulation.<br>- [§6: Closing] None stated for this section. |
| Kris-Brzostek-AI-RFI-2025.md | Kris Brzostek | Individual | The submitter is a creator whose livelihood is threatened by AI-driven copyright infringement and the proliferation of low-quality AI-generated content. Their primary interest is protecting creators' rights and preventing the theft of their work. | - AI actively steals from creators' livelihoods.<br>- Companies are violating copyright by using creators’ work without permission.<br>- AI-generated content is useless and provides no tangible benefit.<br>- AI threatens the business of creators.<br>- Constant fear of mass theft by AI systems. | - Shut down companies engaging in copyright infringement related to AI.<br>- Do not grant immunity to companies violating copyright. |
| Koby-Chavez-AI-RFI-2025.md | Koby Chavez | Individual | The submitter is deeply concerned about the potential for AI to exacerbate wealth inequality, manipulate markets, and destabilize society, leading to collapse. Their interest is in preventing this outcome through proactive regulation and systemic changes. | - None Stated | - None Stated |
| Knightscope-AI-RFI-2025.md | William Santana Li | Industry-Startup (Knightscope, Inc. is identified as a robotics company) | Knightscope aims to integrate AI-powered robotic security solutions into federal government operations to improve security, reduce costs, and establish U.S. leadership in AI robotics, while also creating American manufacturing jobs. | - Section 1: Executive Summary/BLUF:** Current federal security is costly, inefficient, and vulnerable, and the U.S. is falling behind in AI-powered robotics adoption.<br>- Section 2: Overview & The Problem:** The federal government relies on expensive, labor-intensive security methods that are struggling against evolving threats, including high costs, high turnover rates, and failure to incentivize autonomous solutions.<br>- Section 3: The Solution: Autonomous Security Robots (ASRs):**  The current reliance on human security personnel is limited by fatigue, reliability issues, and cost compared to ASRs.<br>- Section 4: Robot Recommendations for the AI Action Plan:**  Few federal agencies are utilizing ASR technology despite its nationwide usage in the private sector, and a lack of modern procurement rules hinder adoption.  Foreign adversaries are developing advanced robotics and potentially gaining an advantage.<br>- Section 5: Agency-Specific Applications of Autonomous Security Robots:**  Not Stated<br>- Section 6: Implementation Roadmap:** Not Stated<br>- Section 7: Conclusion:** The U.S. needs to take concrete steps to integrate AI-driven security solutions to harden infrastructure, reduce costs, and maintain leadership.<br>- Section 8: Submission Information:** Not Stated | - Section 1: Executive Summary/BLUF:** The AI Action Plan should prioritize integrating ASRs into federal facilities, critical infrastructure, and public safety operations to improve services and citizen protection.<br>- Section 2: Overview & The Problem:** Not Stated<br>- Section 3: The Solution: Autonomous Security Robots (ASRs):** Not Stated<br>- Section 4: Robot Recommendations for the AI Action Plan:<br>- Reduce federal security costs by at least 10% via U.S.-made security robots.<br>- Modernize federal procurement to prioritize autonomous security.<br>- Authorize autonomous security in federally managed spaces.<br>- Establish a National Autonomous Security Pilot Program.<br>- Prohibit federal procurement of adversary technologies for security.<br>- Section 5: Agency-Specific Applications of Autonomous Security Robots:**  Implement specific ASR use cases across various federal agencies (DoD, DHS, TSA, FBI, USPS, NASA, GSA, DOE, VA, USDA, EPA, DOI, DOC, SSA, DOJ, HHS, FAA) as outlined in the table.<br>- Section 6: Implementation Roadmap:<br>- Launch ASR pilot programs at VA, TSA, FEMA, DoD, and USPS facilities.<br>- Revise procurement rules to prioritize autonomous security technologies.<br>- Secure funding for ASR adoption from existing budgets.<br>- Scale ASR deployment across all major agencies within 3 years.<br>- Section 7: Conclusion:** Prioritize the deployment of ASRs to enhance national security, reduce federal spending, and establish U.S. leadership in AI-driven robotics.<br>- Section 8: Submission Information:** Not Stated. |
| Knight-Lee-RFI-2025.md | Knight Lee | Individual | The submitter is deeply concerned about the existential risk posed by Artificial General Intelligence (AGI) and advocates for a significant increase in funding for AI alignment and safety research, relative to military spending. Their primary interest is ensuring humanity’s survival in the face of advanced AI development. | - [§1: Email Header/Metadata] Caution regarding external email origin, potential security risks from attachments/links.<br>- [Section 2: Core Argument - AGI Risk vs. Military Spending]<br>- AGI poses a threat to the US (and NATO) comparable to, or exceeding, all military threats combined.<br>- Disproportionate funding allocation: $800 billion/year on military vs. less than $0.1 billion/year on AI alignment/safety.<br>- The discrepancy in spending is unjustified given the perceived level of risk.<br>- The probability of an AI catastrophe is significant (median superforecaster: 2.1%, median AI expert: 5-12%).<br>- [Section 3: Supporting Arguments & Rebuttals]<br>- The argument that military spending protects other countries is insufficient justification for the 8000x funding difference. US foreign aid is only $100 billion/year.<br>- The primary reason for the funding disparity is habit/status quo, not rational assessment of risk.<br>- [§4: Concluding Statement] The potential for a tragic outcome for humanity if AGI risk is not adequately addressed.<br>- [§5: Source & Dissemination Information] None stated for this section.<br>- [§6: Disclaimer/Legal Notice] None stated for this section. | - [§1: Email Header/Metadata] None stated for this section.<br>- [§2: Core Argument - AGI Risk vs. Military Spending] Significantly increase funding for AI alignment and safety research to a level commensurate with the perceived risk posed by AGI (implicitly suggesting a substantial increase from the current $0.1 billion/year).<br>- [§3: Supporting Arguments & Rebuttals] Re-evaluate budgetary priorities based on current risk assessments rather than historical precedents.<br>- [§4: Concluding Statement] Prioritize addressing AGI risk to avoid a potentially catastrophic outcome for humanity.<br>- [§5: Source & Dissemination Information] The document is approved for public dissemination and reuse by the government.<br>- [§6: Disclaimer/Legal Notice] None stated for this section. |
| Kivon-Mobley-AI-RFI-2025.md | Kivon Mobley | Individual | The submitter expresses caution regarding the increased usage of AI in the government and believes over-advancing AI technology may have detrimental consequences. Their interest appears to be in responsible AI implementation and avoiding potential risks. | - Over-advancing AI technology may have detrimental consequences.<br>- Increased usage of AI in the government warrants caution.<br>- The potential negative impacts of AI might not be realized until it is too late. | - None Stated |
| Kitsuna-Tyakoto-AI-RFI-2025.md | Kitsuna Tyakoto | Individual | The submitter is primarily concerned with the protection of creative copyrights and the potential negative impacts of AI, particularly LLMs, on creative ecosystems. They believe AI's use in creative sectors is detrimental and primarily focused on profit at the expense of human creativity. | - AI models, specifically those from companies like OpenAI and ChatGPT, disregard copyright protections.<br>- The proposed "AI Action Plan" could allow for unchecked use of copyrighted material to train AI models, leading to legal challenges and harm to creative industries (specifically mentioning Disney, DC Publishing, Marvel, and Star Wars as potential targets).<br>- The plan will destroy smaller ecosystems of creatives by enabling easy and potentially illegal replication of their work.<br>- AI/LLMs have no legitimate purpose in creative sectors beyond attempting to eliminate human creativity for profit. | - None Stated. (The submitter vehemently opposes the plan and doesn't offer specific alternative policy suggestions, only expressing strong opposition.) |
| Kiri-Wagstaff-AI-RFI-2025.md | Kiri L. Wagstaff | Individual/Academia (Researcher & Educator with ties to Government) | Dr. Wagstaff aims to advance AI goals through increased public understanding of AI and ensuring the continued reliable performance of deployed AI systems, leveraging her experience in AI research, education, and government service. | - None Stated | - None Stated |
| Kira-Okamoto-AI-RFI-2025.md | Kira Okamoto | Individual | Kira Okamoto expresses concern about the negative impact of generative AI and LLMs on creative industries, particularly regarding environmental concerns and copyright infringement, and advocates against their use due to detrimental effects on skilled laborers. | - Generative AI and LLMs are environmentally destructive.<br>- Generative AI and LLMs infringe on the copyrights of individual creatives.<br>- AI worsens workflow, production, and efficiency.<br>- AI replaces skilled laborers.<br>- Higher-ups lack understanding of the actual product creation process, leading to misguided adoption of AI. | - None Stated |
| Kimberly-Rudman-AI-RFI-2025.md | Kim Rudman | Individual | The submitter is focused on establishing a clear ethical framework and standards for Artificial General Intelligence (AGI) and Artificial Intelligence (AI) development, driven by concern that the current lack of these standards poses significant risks. | - Section 1: Introduction** - The current methodology does not establish a clear standard for Moral Law or Ethics-based Logical parameters in AI/AGI.<br>- Section 2: Philosophical Foundations** - None stated for this section.<br>- Section 3: RAG AI & Ethical Concerns** - Highlights ethical issues related to Retrieval Augmented Generation (RAG) and reinforces the need for a framework.<br>- Section 4: Cited Research & Approaches** - None stated for this section.<br>- Section 5: Observations and Criticisms** - Concerns regarding bias in defining principles and the lack of foundational standards in AI Ethics approaches.<br>- Section 6: Comparison to Human Morality** - The inherent limitation of AGI's understanding of morality due to a lack of free will and subjective experience, despite potential for learning.<br>- Section 7: Conclusion** - The lack of a decisive standard related to AGI/AI "computation morality" or set Ethical Standards is concerning.<br>- Section 8: Entities & Resources** - None stated for this section.<br>- Section 9: References/Bibliography** - None stated for this section.<br>- Section 10: Author Information** - None stated for this section. | - Section 1: Introduction** - Consideration of establishing a set of Ethics-Based Logical parameters for AGI and AI.<br>- Section 2: Philosophical Foundations** - None stated for this section.<br>- Section 3: RAG AI & Ethical Concerns** - Establish a "Moral Law" or Ethical Framework Standard for AGI / AI code.<br>- Section 4: Cited Research & Approaches** - None stated for this section.<br>- Section 5: Observations and Criticisms** - None stated for this section.<br>- Section 6: Comparison to Human Morality** - None stated for this section.<br>- Section 7: Conclusion** - Define a decisive standard related to AGI/AI "computation morality" or set Ethical Standards.<br>- Section 8: Entities & Resources** - None stated for this section.<br>- Section 9: References/Bibliography** - None stated for this section.<br>- Section 10: Author Information** - None stated for this section. |
| Kimberly-Moore-AI-RFI-2025.md | Kimberly Moore | Individual | The submitter is focused on personal safety and security concerns, alleging harassment, corruption, and lack of support from local law enforcement, with a general statement about disrespect and rights within their community and country. The text does not demonstrate any specific interest in AI policy. | - Corruption and embezzlement within the Utica, Michigan community.<br>- Monopolization of Google platform for illicit activities.<br>- Alleged surveillance and monitoring of the submitter.<br>- Lack of support and disrespectful treatment from the Utica Police station.<br>- Feeling unsafe and threatened in their apartment complex and surrounding park area.<br>- General disrespect of rights and feeling unworthy in Macomb County.<br>- Concerns about law enforcement failing to provide adequate protection. | - None Stated |
| Kim-Ferg-AI-RFI-2025.md | Kim Ferg | Individual | The submitter is concerned with the societal impact of AI, particularly its potential to displace human jobs and the importance of prioritizing the well-being of the American population over corporate interests and individual political whims when developing AI policy. | - Potential displacement of human jobs by AI.<br>- The risk of for-profit corporate leaders unduly influencing decisions affecting the human population.<br>- Reliance on the decisions of single elected officials rather than broader considerations for the good of the American people. | - Prevent for-profit corporate leaders from having the final say in decisions affecting the human population.<br>- Make decisions regarding AI for the good of the American people, not based on the decisions of a single elected official. |
| Keysight-RFI-2025.md | Keysight Technologies | Industry-Large | Keysight Technologies provides technology solutions for accelerating innovation, connecting, and securing the world, with a strong focus on design, testing, optimization, and network security monitoring for high-growth industries, and a particular interest in advancing AI capabilities to benefit both the U.S. economy and national security. | - [§1: Introduction] None stated for this section.<br>- [Section 2: Focus Areas]<br>- AI models are susceptible to manipulation and data extraction (a).<br>- Unauthorized access and leakage of confidential information are risks (b).<br>- AI is being weaponized to exploit vulnerabilities and automate cyberattacks (a).<br>- The speed of AI-augmented cyber weapon systems requires improved automated responses (a).<br>- [§3: Recommended AI Actions] None stated for this section.<br>- [Section 4: Monitoring AI Operations (Detailed)]<br>- The rise of ransomware and AI-generated advanced persistent threats (APT) increases the importance of network visibility (1).<br>- Need for collaboration between regulatory agencies, cybersecurity professionals, infrastructure operators, and developers to mitigate AI-based risks (1).<br>- The potential for malicious use of AI, including data exfiltration and model poisoning, is a concern (1).<br>- Circumventing guardrails on AI to perform unauthorized tasks (1).<br>- [§5: Sample Architecture] None stated for this section.<br>- [§6: Remarks and Recommendation] None stated for this section.<br>- [§7: Keysight Contact] None stated for this section. | - [§1: Introduction] None stated for this section.<br>- [Section 2: Focus Areas]<br>- Facilitate rapid development of internal LLMs and AI applications with scalable testing (b).<br>- Validate cloud and on-premises AI infrastructure for reliability (b).<br>- Support comprehensive monitoring of AI use across networks, especially where sensitive data is involved (c).<br>- [Section 3: Recommended AI Actions]<br>- Support rapid progress with frontier AI models (1).<br>- Optimize the speed of creating and automating test-case creation for AI applications (1).<br>- Assist in the rapid development of internal LLM or AI model applications with integrated testing (1).<br>- Assist in validating Cloud and on-premises AI infrastructure that can handle high usage (2).<br>- [Section 4: Monitoring AI Operations (Detailed)]<br>- Put in place policies allowing seamless network monitoring and visibility into AI use in government and the private sector (3).<br>- Enable visibility into the use of AI within critical network segments (3).<br>- Leverage Deep Packet Inspection (DPI) for detailed data analysis (3).<br>- Enhance detection across various traffic types (3).<br>- Implement decryption capabilities to gain visibility into encrypted traffic (3).<br>- Use session-aware detection for better accuracy (3).<br>- [§5: Sample Architecture] None stated for this section.<br>- [Section 6: Remarks and Recommendation]<br>- Streamline, secure, and high-performing AI landscape through proactive policies (6).<br>- [§7: Keysight Contact] None stated for this section. |
| Kevin-ONeill-AI-RFI-2025.md | Kevin O'Neill | Individual | The submitter is interested in a practical, phased approach to AI implementation focusing on foundational understanding, measurable objectives, structured execution, and consistent value delivery. They advocate for a systematic plan to ensure AI initiatives are successful and useful. | - [§1: Introduction/Context] None stated for this section.<br>- [Section 2: Exploring Phase]<br>- End users may be unaware that prompts entered into ChatGPT or Copilot are generative.<br>- Data privacy concerns related to prompt deletion from user profiles.<br>- Need for education on core AI concepts (algorithms, machine learning types, deep learning, fuzzy logic).<br>- Importance of understanding the capabilities, limitations, and ethical considerations of AI systems.<br>- [Section 3: Planning Phase]<br>- The need to define *what* time savings will be measured.<br>- Importance of establishing and meeting Key Performance Indicators (KPIs).<br>- [Section 4: Formalizing Phase]<br>- AI is evolving, but standardization of core aspects (templates, checklists, protocols) is still needed.<br>- [Section 5: Scaling Phase]<br>- AI plans must address increased workload and workforce demands.<br>- Need for infrastructure improvements.<br>- Importance of process optimization for automating repetitive tasks and workflows.<br>- [Section 6: Realizing Phase]<br>- Execution of plans needs to account for resource utilization, monitoring, and quality assurance.<br>- Consistent value delivery is crucial for the usefulness of AI. | - [§1: Introduction/Context] None stated for this section.<br>- [Section 2: Exploring Phase]<br>- Promote education about the nature of generative AI prompts (e.g., ChatGPT, Copilot).<br>- Encourage transparency about data privacy policies related to user prompts.<br>- Invest in educational resources covering core AI concepts (algorithms, machine learning, etc.).<br>- [Section 3: Planning Phase]<br>- Guidelines or frameworks for defining measurable objectives related to time savings.<br>- Encourage the use of KPIs for AI initiatives.<br>- [Section 4: Formalizing Phase]<br>- Develop standards and best practices for AI documentation and actionable plans.<br>- [Section 5: Scaling Phase]<br>- Support infrastructure improvements to accommodate increased AI workloads.<br>- Promote process optimization for AI-driven automation.<br>- [Section 6: Realizing Phase]<br>- Encourage thorough monitoring, control, and quality assurance processes for AI deployments.<br>- Emphasize the importance of consistent value delivery in AI initiatives. |
| Kevin-Johnson-AI-RFI-2025.md | Kevin Johnson | Individual | The submitter expresses concern regarding the unauthorized use of copyrighted material by companies for profit and appears to be focused on protecting intellectual property rights in the context of AI development and deployment. | - Companies stealing copyrighted work for profit. | - Companies should not be allowed to steal copyrighted work for profit. |
| Kevin-Frazier-AI-RFI-2025.md | Kevin Frazier | Academia | Professor Frazier’s interest lies in promoting national AI literacy and ensuring broad access to AI knowledge and expertise across the United States to maintain American technological leadership and competitiveness in the field of AI. He advocates for a balanced approach combining concentrated AI excellence with widespread diffusion of knowledge. | - [§1: Introduction] A troubling reality is that communities more than 125 miles from AI hotspots see 17% lower growth in AI-related jobs and innovation, creating widening opportunity gaps.<br>- [§2: Current Gaps in the Diffusion of AI Knowledge and Expertise] A stark geographic concentration of AI knowledge in pre-existing innovation hubs exists, with disparities in digital skills, knowledge, and economic security. Large enterprises are rapidly incorporating AI, while smaller businesses lag behind. Universities in AI hotspots are expanding curricula faster than those outside these areas. There’s a trend of researchers gravitating to the private sector.<br>- [§3: Diffusing Emerging Technology Knowledge is Essential to Technological Progress] Failure to broadly diffuse technological knowledge limits societal benefits and technological progress.<br>- [§4: Diffusion of AI Knowledge is Essential to America's AI Dominance] America's continued AI leadership requires more than just concentrated excellence in a few centers, especially as other nations are prioritizing knowledge diffusion. Uneven adoption rates may create "AI deserts" and resistance to AI.<br>- [§5: Recommendations for the AI Action Plan on the Diffusion of AI Knowledge] The current approach to AI development may be suboptimal. Barriers to knowledge diffusion are limiting progress and potentially creating societal divisions.  State borders impede knowledge flow.<br>- [§6: Conclusion] Geographic disparities in AI knowledge are concerning. Failure to address these disparities could lead to political pushback, workforce adaptation challenges, and a less resilient AI ecosystem. | - [§1: Introduction] Prioritize a national strategy for AI literacy to systematically break down geographic barriers to AI knowledge and create pathways for all Americans to participate in the AI economy.<br>- [§2: Current Gaps in the Diffusion of AI Knowledge and Expertise] Not stated for this section.<br>- [§3: Diffusing Emerging Technology Knowledge is Essential to Technological Progress] Not stated for this section.<br>- [§4: Diffusion of AI Knowledge is Essential to America's AI Dominance] Not stated for this section.<br>- [Section 5: Recommendations for the AI Action Plan on the Diffusion of AI Knowledge]<br>- Short-term (1-4 years):<br>- Create a national AI extension service, modeled after agricultural extension programs.<br>- Establish regional AI resource centers.<br>- Develop standardized AI literacy curricula.<br>- Incentivize AI experts to teach and consult in underserved areas.<br>- Medium-term (5-10 years):<br>- Support the development of AI faculty at regional universities and community colleges.<br>- Create partnerships between AI hotspot institutions and more distant educational institutions.<br>- Develop specialized AI programs tailored to regional economic needs.<br>- Establish AI research facilities in underserved regions.<br>- Long-term (10+ years):<br>- Build a national platform for AI continuing education.<br>- Create mechanisms for sharing AI expertise between industries and regions.<br>- Develop standards for AI education and certification.<br>- Establish frameworks for public-private partnerships in AI education.<br>- [§6: Conclusion] Maintain concentrated excellence while actively spreading knowledge to ensure a sustainable foundation for American AI leadership. Invest in AI knowledge diffusion to achieve technological dominance. |
| Kevin-Brett-AI-RFI-2025.md | Kevin L. Brett | Individual/Professional-Society (experienced Enterprise Architect and consultant) | Kevin Brett advocates for the adoption of the Bionic Enterprise Framework as a comprehensive roadmap for AI-driven organizational transformation, believing it is crucial for the United States to maintain strategic and tactical advantage in the age of AI and achieve “USA 2.0”. He emphasizes the importance of holistic, integrated architectures and continuous transformation. | - [§1: Title Page & Introduction] None stated for this section.<br>- [§2: Overview of the Bionic Enterprise Framework] Lack of a comprehensive framework addressing all aspects of an organization (human, technology, and transformation).<br>- [§3: Framework Components & Capability Areas] Not Applicable - this section describes components, not concerns.<br>- [§4: Human Perspective] Organizations rapidly becoming irrelevant due to shrinking innovation cycles; the need for visionary leadership and creativity to achieve transformation.<br>- [§5: Technology Perspective] The potential for AI to reach the point of The Singularity and the implications for humanity; the need for preparedness.<br>- [§6: Fusion Perspective: Transformation and Architecture] Focusing solely on automation and digitalization is insufficient; the need to focus on value effects (Bionic Effects) and outcomes at enterprise scale.<br>- [§7: America's Bridge to the AI-Driven Future] Maintaining leadership requires organizational and digital transformation; a lack of a comprehensive framework could jeopardize strategic advantage. The potential for adversaries to surpass the U.S. without a strategic plan.<br>- [§8: Additional Resources] Not Applicable.<br>- [§9: Kevin Brett Bio] Not Applicable. | - [§1: Title Page & Introduction] Integrate the Bionic Enterprise Framework as a central component of the United States AI Action Plan.<br>- [§2: Overview of the Bionic Enterprise Framework] Adopt the Bionic Enterprise Framework to provide a holistic approach to organizational transformation.<br>- [§3: Framework Components & Capability Areas] Not Applicable.<br>- [§4: Human Perspective] Invest in visionary leadership development and foster organizational creativity. Promote a culture of continuous transformation.<br>- [§5: Technology Perspective] Utilize Bloom's Taxonomy to identify cognitive capabilities for AI Agents and prepare for the implications of The Singularity.<br>- [§6: Fusion Perspective: Transformation and Architecture] Focus on achieving value effects (Bionic Effects) and outcomes through a Bionic Fusion Framework and Bionic User Experience Design Process. Conduct ongoing enterprise-wide assessments.<br>- [§7: America's Bridge to the AI-Driven Future] Develop a Bionic Strategy and Roadmap and implement visionary leadership to transform society through the Bionic Enterprise Framework. Embrace the framework for achieving USA 2.0.<br>- [§8: Additional Resources] Not Applicable.<br>- [§9: Kevin Brett Bio] Not Applicable. |
| Kevin-Bauer-AI-RFI-2025.md | Kevin Bauer | Individual | The submitter expresses strong opposition to the development and adoption of AI, believing it negatively impacts American livelihoods and is based on false pretenses. Their primary interest appears to be protecting their own economic interests and countering what they perceive as a misleading public narrative around AI. | - AI steals from the submitter’s livelihood as an American.<br>- AI profits off of theft.<br>- AI is overhyped.<br>- AI is fleecing the American public. | - None Stated |
| Kerry-Lynn-Macintosh-RFI-2025.md | Kerry-Lynn Macintosh | Academia | The submitter is interested in preventing overregulation of AI technology based on public perception fueled by science fiction, and advocates for policies that support American innovation and competitiveness in the AI field. The submitter intends to publish a detailed legal analysis of this issue. | - [§1: Introduction/Opening] The public’s perception of AI as an existential threat, influenced by science fiction, is leading to government overregulation of the technology.<br>- [§2: Argument Preview/Citation] Specific regulatory proposals like pauses, moratoria, and licensing schemes will harm American innovation and competitiveness.<br>- [§3: Author Information/Disclaimers] None stated for this section. | - [§1: Introduction/Opening] Avoid overregulation of AI technology.<br>- [§2: Argument Preview/Citation] Do not include pauses, moratoria, or licensing schemes in the AI Action Plan.<br>- [§3: Author Information/Disclaimers] None stated for this section. |
| Kendra-Pierre-Louis-AI-RFI-2025.md | Kendra Pierre-Louis | Individual | The submitter is a journalist and writer concerned about the unauthorized use of their copyrighted work to train AI models and the potential for AI to devalue their labor and profession. They advocate for compensation and control over the use of their work. | - Violation of copyright.<br>- Theft of labor (hundreds of thousands of hours of education and craft).<br>- Potential for AI to make the submitter unemployable.<br>- Lack of compensation for work used to train AI models.<br>- Opposition to the AI action plan as a whole. | - Entities like OpenAI should directly approach content creators for permission to use their work.<br>- Content creators should be compensated for the use of their work in AI training.<br>- Content creators should have the right of refusal regarding the use of their work.<br>- Student loans should be paid by entities benefiting from the use of content creators' work. |
| Ken-Stegeman-AI-RFI-2025.md | Ken Stegeman | Individual | The submitter is focused on ensuring transparency and human control over AI interactions, specifically requiring clear disclosure when humans are interacting with AI-generated content or systems. They prioritize informing individuals when they are not communicating with another human being. | - Lack of transparency in AI communication, where humans are unaware they are interacting with AI systems.<br>- Potential for deception or misrepresentation through AI-generated content (images, video, etc.).<br>- Risk of humans unknowingly interacting with AI without being informed. | - Require identification of AI usage in *all* communication mediums (telephone, email, online chats, social media, newspapers, journals, TV, radio).<br>- Impose a $1,000 fine for each instance of failing to identify AI communication.<br>- Develop a standard identification method for AI senders and require all receiving mediums to recognize and allow blocking of AI contacts.<br>- Require conspicuous and upfront notification that content (images, video, media) is AI-generated.<br>- Impose a $1,000 fine per user not upfrontly notified about AI-generated content. |
| Kelsey-Michele-AI-RFI-2025.md | Kelsey Michele | Individual | Kelsey Michele is a professional artist expressing concerns about the negative impact of generative AI on creative industries, particularly regarding copyright infringement, job displacement, and the overall decline of human-made art and culture. They advocate for protecting creative professionals and fostering a more human-centric future. | - [§1: Email Header & Introduction] None stated for this section.<br>- [Section 2: Core Argument: Copyright Infringement & Data Harvesting]<br>- Generative AI models require vast amounts of copyrighted data for training.<br>- Tech companies admit reliance on stolen intellectual property.<br>- Lack of compensation to IP and copyright holders for the use of their work.<br>- Concerns about plagiarism despite "training" arguments.<br>- [Section 3: Impact on Creative Industries & the Workforce]<br>- Job displacement of artists and creatives.<br>- Potential for the collapse of entire creative industries.<br>- Shuttering of cultural institutions.<br>- Crumbling of culture due to lack of innovation and human-made art.<br>- Risk of widespread workforce replacement across all sectors.<br>- Potential for frustrating customer service experiences (robotic phone trees).<br>- [Section 4: Limitations of AI & Anti-Innovation Argument]<br>- Generative AI is inherently derivative and lacks true innovation.<br>- Employers are being misled into replacing skilled staff with ineffective AI.<br>- AI technology is an "anti-innovation, anti-creativity, anti-human grift."<br>- AI cannot replicate human thought or creativity.<br>- AI is prone to errors and can provide dangerous advice.<br>- AI is not accountable for harmful or plagiarized content.<br>- [Section 5: Concluding Statement & Call to Action]<br>- Unchecked AI poses a dangerous threat to the future.<br>- The need to support creative industries and protect creators.<br>- [§6: Dissemination & Disclaimer] None stated for this section. | - [§1: Email Header & Introduction] None stated for this section.<br>- [Section 2: Core Argument: Copyright Infringement & Data Harvesting]<br>- Companies should compensate IP and copyright holders for the use of their work in AI training.<br>- [§3: Impact on Creative Industries & the Workforce] None stated for this section.<br>- [§4: Limitations of AI & Anti-Innovation Argument] None stated for this section.<br>- [Section 5: Concluding Statement & Call to Action]<br>- Stand up for creative industries.<br>- Protect those who make and maintain culture.<br>- Foster a more human-centric future.<br>- [§6: Dissemination & Disclaimer] None stated for this section. |
| Kelly-Moore-AI-RFI-2025.md | Kelly Moore | Individual | The submitter is focused on protecting their civil and privacy rights, which have been significantly violated, and seeks assistance from government officials to resolve ongoing issues related to data access and control. They also express interest in contributing information to proposed regulations. | - Blocked emails, texts, and calls, including during family emergencies.<br>- Deletion of texts, pictures, and files.<br>- Blocked access to handle personal business with a Federal Government entity.<br>- Retrieval of private information including tax returns, family medical records, and personal HR files.<br>- Blocked ability to opt-out of apps and ads.<br>- Overall lack of control over personal data and communications. | - None Stated |
| Kelley-Berg-AI-RFI-2025.md | Kelley Berg | Individual | Kelley Berg expresses deep concern regarding the potential negative consequences of unregulated AI development and deployment and advocates for ethical and safe AI leadership by the United States government. | - Removal of guardrails and “unnecessarily burdensome requirements” in AI development and deployment.<br>- Potential for worst-case scenarios and rampant abuse and misuse of data and metadata with virtually unregulated AI.<br>- Appropriation of copyrighted works without compensation due to AI’s capabilities.<br>- Lack of best practices and reasonable regulation inviting abuse that could have disastrous impacts. | - Proceed with caution in AI development and deployment.<br>- Ensure America leads in AI ethically and safely.<br>- The government should take responsibility for ensuring ethical and safe AI practices. |
| Kellen-Mingo-AI-RFI-2025.md | Kellen Mingo | Individual | The submitter is primarily concerned with protecting the rights of creators and preventing the unauthorized use of copyrighted material by generative AI companies. They believe granting immunity to these companies would harm the creative ecosystem. | - Generative AI companies (specifically OpenAI) may steal copyrighted material (art, writing, voice) without permission.<br>- Granting copyright immunity to generative AI companies will allow them to create infringing content without legal repercussions.<br>- The development of generative AI, if unchecked, will lead to the creation of "lazy, soulless" versions of original work, undermining creativity. | - Deny OpenAI and other generative AI companies' request for copyright immunity.<br>- Do not allow generative AI companies to operate without the risk of lawsuits regarding copyright infringement. |
| Kelby-Velasquez-AI-RFI-2025.md | Kelby Velasquez | Individual | The submitter is primarily concerned with protecting the rights and livelihoods of human artists and creators from the unchecked advancement and monopolistic practices of large technology corporations in the realm of artificial intelligence. They advocate for regulations that prioritize humans over AI and safeguard creative work from unauthorized use and exploitation. | - Reckless advancements in AI without proper regulation pose a threat to individuals and the world.<br>- Large technology corporations (specifically Google) are scraping and using creative works without compensation or credit to their creators.<br>- Lack of regulation leads to uncertainty regarding what is real versus fake and what uses are permitted/unauthorized.<br>- Monopolization of online space by companies like Google.<br>- Censorship of publishers by companies like Google using AI.<br>- Negative impact on artists/creators due to AI-generated content.<br>- Theft and unauthorized training of AI models on human artists’ work.<br>- Burying of human artists’ work online due to the prominence of AI-generated images/visuals. | - Implement proper regulation for AI.<br>- Protect copyrights of human artists and creators.<br>- Prioritize humans over AI.<br>- Restrict the unchecked use and advancement of AI.<br>- Prevent large corporations from monopolizing online space.<br>- Address censorship concerns related to AI use by companies like Google. |
| Keith-Wadley-AI-RFI-2025.md | Crew Training International, Inc. | Industry-Large (based on the focus on streamlining processes, reducing administrative overhead, and balancing innovation with fairness, suggesting a company that participates in federal procurements) | Crew Training International, Inc. is interested in the responsible and efficient integration of AI into federal procurement processes, with a focus on minimizing burdens on industry while maximizing transparency, fairness, and competition. They advocate for a collaborative approach and emphasize the need for clear guidelines and human oversight. | - None Stated | - None Stated |
| Keith-Rothfus-AI-RFI-2025.md | Keith Rothfus | Individual (Former Government Official/Advocate) | Keith Rothfus, a former Congressman, expresses concern about the potential negative impacts of AI on human flourishing, economic stability, and fundamental rights, advocating for policies that prioritize human well-being, truth, and ethical considerations in the development and deployment of AI systems. | - None Stated | - None Stated |
| Keira-Havens-AI-RFI-2025.md | Keira Havens | Individual | The submitter is concerned about the impact of AI development on artists and the arts, specifically regarding the insufficient compensation for artists whose work is used to train AI models and the erosion of copyright protections. They advocate for protecting the rights and livelihoods of human artists. | - AI models consume human creative output without appropriate compensation to artists.<br>- "AI" companies exhibit financial poverty and a "poverty of culture," leading them to seek government intervention to circumvent copyright.<br>- The reliance on government funding to undermine copyright protections.<br>- Individuals with "classical training and a deep connection to the arts" may recognize the limitations of current AI-generated content. | - Maintain existing copyright rules in favor of human artists.<br>- Do not provide government funding to support the destruction of copyright. |
| Kayla-Hamilton-AI-RFI-2025.md | Kayla Hamilton | Individual | The submitter expresses strong opposition to the development and use of AI, believing it to be fundamentally harmful and reliant on illegal practices (copyright theft). Their primary interest is in halting the further proliferation of AI technologies. | - [§1: Email Header/Introduction] AI is a problematic tool that has devolved into something harmful with wide-reaching negative impacts. The initial promise of AI has not been realized.<br>- [§2: Core Argument - Copyright and Theft] AI relies on and necessitates copyright infringement, creating an unfair legal disparity between AI companies and other citizens/businesses.  The legality of AI’s data sourcing is questioned.<br>- [§3: Pervasiveness of AI and Negative Impacts] AI is invasive and prevalent in many aspects of daily life, leading to inaccuracies, harm, and negative consequences across education, employment, social interactions, advertising, and the spread of misinformation (specifically deepfakes).  AI transcripts are inaccurate. Students are using it to cheat. Employers are skipping qualified candidates. Companies are avoiding consumer interaction.<br>- [§4: Concluding Statement - Call to Action] Continued development and use of AI is illogical and harmful; it should be abandoned altogether.<br>- [§5: Disclaimer] None stated for this section. | - [§1: Email Header/Introduction] None stated for this section.<br>- [§2: Core Argument - Copyright and Theft] None stated for this section.<br>- [§3: Pervasiveness of AI and Negative Impacts] None stated for this section.<br>- [§4: Concluding Statement - Call to Action] Halt the development and use of AI technologies. "Put it down."<br>- [§5: Disclaimer] None stated for this section. |
| Katy-St-Clair-AI-RFI-2025.md | Katy St. Clair | Individual | Katy St. Clair is a high school student interested in the ethical implications of generative AI, particularly its potential to undermine public trust in government and mislead voters through misinformation during political campaigns. | - Using AI to promote a party undermines public trust in the government.<br>- Bias in responses from at-home generative AI systems (e.g., Amazon Alexa, Google Home) regarding political questions.<br>- Politicians posting AI-generated misinformation (specifically referencing Donald J. Trump's use of AI-generated images on Twitter/X).<br>- The creation of fake, misleading, and vulgar images of candidates using image generation AI.<br>- The use of AI in political campaigns is a deception to the American people. | - More regulation of generative AI overall.<br>- Regulation requiring at-home generative AI systems to either decline political inquiries or provide answers based on a regulated list of proven facts.<br>- Tighter regulations on image generation AI, including restrictions on certain words and phrases that AI cannot recreate due to current political issues. |
| Katy-Mulvaney-AI-RFI-2025.md | Katy Mulvaney | Individual | The submitter expresses strong opposition to government support for the AI industry and prioritizes the protection of artists’ rights, personal privacy, and the existing economic structures within the entertainment industry. They appear to have a vested interest in preventing the displacement of human creators and protecting copyright. | - The AI industry is a failed investment that consumes excessive resources without generating sufficient returns.<br>- Government support for AI represents a "bailout" for unsuccessful investors.<br>- Relaxing copyright protections to feed AI models would harm artists’ livelihoods and the entertainment industry.<br>- AI development threatens personal privacy and basic decency.<br>- AI will not create sufficient jobs to replace those lost due to automation.<br>- Jobs created by the AI industry will be undesirable ("soulless"). | - Back away from supporting the AI industry ("Back away slowly and put the bad idea down.").<br>- Do not relax or remove legal protections such as copyright to facilitate AI development. |
| Katia-Reed-AI-RFI-2025.md | Katia Ricciarelli V. Reed | Individual/Advocacy/Think Tank | The submitter is deeply concerned about the unethical development and use of AI, particularly regarding copyright infringement, data privacy, and potential harm to individuals and society, advocating for a multi-phased approach to regulation and ethical AI development with a focus on protecting creators and establishing accountability. | - None Stated | - None Stated |
| Kathy-Henrich-AI-RFI-2025.md | Kathy Henrich | Individual / Industry-Association (CEO, MKE Tech Hub Coalition, board member of Technology Council of North America) | Kathy Henrich focuses on fostering AI innovation and equitable access to its benefits, with a strong emphasis on workforce development, SME adoption, and bridging the gap between tech hubs and other regions. She advocates for strategic federal policy to promote AI's positive impact on the US economy and workforce. | - [§1: Introduction & Background] None stated for this section.<br>- [§2: Federal AI Regulation] Patchwork of state AI laws creates compliance difficulties, especially for startups; lack of clarity on liability and enforcement; need to define responsibility for AI impacts (developer, deployer, or user).<br>- [§3: Investment in AI Innovation Outside Tech Hubs] Concentration of AI roles in a few cities could limit global competitiveness; domain expertise crucial for future innovation is dispersed across the country.<br>- [§4: Incentivizing SME Adoption of AI and Automation] SMEs are significantly less productive than larger companies, hindering US GDP; narrowing the productivity gap is vital.<br>- [§5: Early Career Training and Reskilling] AI is rapidly replacing entry-level jobs; these positions are important on-ramps to careers; need to upskill entry-level positions.<br>- [§6: Workforce Planning Data Sources] Lack of adequate data for effective workforce planning; current Bureau of Labor Statistics (BLS) is job-focused rather than task-focused.<br>- [§7: Addressing the Rural-Urban Divide] Rural areas may lack the data and skills to leverage AI effectively in the public sector.<br>- [§8: Legislative Standing Committee on AI] Need for ongoing landscape analysis of international risks and opportunities related to AI; need for collaborative work across states on licensing and regulation.<br>- [§9: Conclusion] None stated for this section. | - [§1: Introduction & Background] None stated for this section.<br>- [§2: Federal AI Regulation] Complete AI regulation at the federal level to simplify compliance and enable innovation.<br>- [§3: Investment in AI Innovation Outside Tech Hubs] Invest in AI innovation outside of typical tech hubs to leverage domain expertise and drive manufacturing renaissance; build capacity in local universities and technical colleges to assist employers.<br>- [§4: Incentivizing SME Adoption of AI and Automation] Incentivize SME adoption of AI through “jumpstart” investment dollars (partial matching), tax credits (similar to R&D tax credits), and technical assistance in hubs across the country.<br>- [§5: Early Career Training and Reskilling] Incentivize employer early career training and invest in reskilling; create co-development opportunities between students and employers (public/private partnership).<br>- [§6: Workforce Planning Data Sources] Refine the Bureau of Labor Statistics (BLS) to be task-focused; develop a national AI-driven workforce information system that creates bi-directional value with employers.<br>- [§7: Addressing the Rural-Urban Divide] Encourage the development of public sector shared services to allow both urban and rural areas to benefit from AI.<br>- [§8: Legislative Standing Committee on AI] Establish a standing committee of the legislature focused on all AI-related issues, including representatives, government employees, and industry advisors to facilitate collaborative work and landscape analysis.<br>- [§9: Conclusion] None stated for this section. |
| Kathryn-Kelley-RFI-2025.md | Kathryn Kelley | Industry-Association | The Coalition for Academic Scientific Computation (CASC) represents leading research computing and data centers, committed to advancing high-performance computing, data science, and artificial intelligence in support of scientific discovery and innovation, while fostering collaboration across academia, industry, and government. | - [§1: Email Header] None stated for this section.<br>- [§2: Introduction & Acknowledgement] None stated for this section.<br>- [§3: Context & Scope] None stated for this section.<br>- [§4: Offer of Further Assistance] None stated for this section.<br>- [§5: Closing & Disclaimer] None stated for this section. | - [§1: Email Header] None stated for this section.<br>- [§2: Introduction & Acknowledgement] None stated for this section.<br>- [§3: Context & Scope] None stated for this section.<br>- [§4: Offer of Further Assistance] Willingness to provide further insights from the research computing and data science community.<br>- [§5: Closing & Disclaimer] None stated for this section. |
| Kathi-Pletcher-AI-RFI-2025.md | Kathi Pletcher | Individual | The submitter is primarily concerned with the potential national security risks and societal impacts of widespread AI access and use, and appears to favor restricted access. | - Potential destruction of the country if AI falls into the "wrong hands".<br>- Risk of duplication of people with fraudulent intentions.<br>- Loss of "imagination or realistic artistry" due to AI. | - Limit AI access to individuals with security clearance. |
| Katherine-Kolganov-AI-RFI-2025.md | Katherine Kolganov | Individual | The submitter is a strong advocate for human rights and the human experience, opposing the unchecked development and deployment of AI due to its perceived negative impacts on society and potential for harm. | - AI being granted "free reign" to exploit human creations.<br>- Detrimental effects of AI on many people's lives.<br>- Limited beneficial effects of AI for the majority of society.<br>- "Generative AI" amounting to theft and lack of culpability for creators. | - Reconsider allowing the creators of AI to avoid culpability for crimes of theft. |
| Katelyn-McMeans-AI-RFI-2025.md | Katelyn McMeans | Individual | The submitter is primarily interested in protecting the rights of artists and the integrity of art in the age of AI, opposing the use of AI to create art without proper compensation or contracts and maintaining the human element in artistic creation. | - AI taking from creators without compensation or contracts.<br>- AI’s inability to be inspired or offer new insights, relying solely on existing material.<br>- The illegality of computers replicating copyrighted material on a large scale without permission.<br>- The erosion of the “human contract” in art, where both artist and observer contribute their experiences.<br>- The potential for AI to produce cheap, derivative art lacking genuine human expression. | - Prohibit the use of AI to create art without permission from and compensation to original creators.<br>- Enforce existing copyright laws to prevent large-scale unauthorized replication of copyrighted material by AI. |
| Katelyn-Bezem-AI-RFI-2025.md | Katelyn Bezem | Individual | The submitter expresses a strong negative view of AI and its impact on American livelihoods, specifically citing data security concerns and personal financial harm. Their interest appears to be focused on protecting individuals from the perceived negative consequences of AI. | - AI poses huge data security concerns.<br>- AI steals from the submitter’s livelihood as an American and profits off of theft. | - None Stated |
| Kate-Coleman-AI-RFI-2025.md | Kate Coleman | Industry-Startup / Individual | The submitter’s primary interest is in leveraging AI, specifically in retina photography and analysis, to prevent preventable sight loss and reduce healthcare costs by establishing baseline retinal images for all citizens as part of routine healthcare. They aim to integrate AI-powered screening tools into primary care and existing healthcare systems. | - None Stated | - Every citizen enrolling in primary care, any hospital system and any Medicare/ health insurance system should have a retina photo baseline for future change alert , using ai (eg iKey).<br>- Automatic diabetic retinopathy screening should be implemented using AI tools (eg IDx, AEYE, EyRis). |
| Karin-Jenson-AI-RFI-2025.md | Karin Jenson | Industry-Startup | Two Rivers AI Consulting focuses on bringing AI solutions to small, family- and privately-owned businesses in Central Michigan, with a particular interest in overcoming barriers to adoption and fostering education around AI technologies. They aim to empower small businesses to leverage AI for resilience and competitiveness. | - [§1: Header/Introduction] None stated for this section.<br>- [§2: Importance of AI Adoption for Small Businesses] Small businesses face challenges like limited resources and heightened uncertainty.<br>- [§3: Current State of AI Adoption] Lack of expertise, financial constraints, and uncertainty about implementation are barriers to AI adoption among small businesses.<br>- [§4: Recommendations for Enhancing AI Access and Education] Potential biases in AI algorithms and ensuring ethical and inclusive AI practices are concerns.<br>- [§5: Conclusion] None stated for this section.<br>- [§6: Document Metadata/Disclaimer] None stated for this section.<br>- [§7: Signature/Contact Information] None stated for this section. | - [§1: Header/Introduction] None stated for this section.<br>- [§2: Importance of AI Adoption for Small Businesses] None stated for this section.<br>- [§3: Current State of AI Adoption] None stated for this section.<br>- [Section 4: Recommendations for Enhancing AI Access and Education]<br>- Develop accessible educational initiatives (workshops, online courses, certification) tailored to industries and proficiency levels.<br>- Introduce grants, subsidies, or tax incentives to reduce financial burdens.<br>- Facilitate public-private partnerships for affordable AI access.<br>- Encourage the formation of networks for sharing best practices.<br>- Develop guidelines for ethical, transparent, and inclusive AI implementation.<br>- [§5: Conclusion] None stated for this section.<br>- [§6: Document Metadata/Disclaimer] None stated for this section.<br>- [§7: Signature/Contact Information] None stated for this section. |
| Karen-Walsh-AI-RFI-2025.md | Karen Walsh | Industry-Startup | Karen Walsh, as Founder and CEO of Allegro Solutions Marketing Company, demonstrates an interest in the responsible development and deployment of AI, particularly regarding the protection of intellectual property rights for creators. She advocates for a system that respects creator approval and compensation when utilizing scraped intellectual property for AI model training. | - Developing AI models based on intellectual property collected without gaining creator approval.<br>- Lack of compensation for creators of scraped intellectual property (including art and literature) used for AI modeling.<br>- Insufficient guardrails to protect all intellectual property—from large tech companies to small authors—when used in AI. | - Implement guardrails to protect all intellectual property used in AI, covering entities from large tech companies to small authors.<br>- Require creator approval before using intellectual property to train AI models.<br>- Ensure compensation for creators whose intellectual property is used for AI modeling. |
| Karen-Daniels-AI-RFI-2025.md | Karen Daniels | Individual | The submitter is interested in the responsible development and deployment of AI, focusing on its societal impacts, including energy efficiency, intellectual property protection, privacy, and public education, and encouraging international collaboration. | - Energy efficiency and water efficiency of data centers.<br>- Protecting artists', writers', and scientists' intellectual property.<br>- Protecting individuals' privacy and preventing unauthorized data usage. | - Make data centers energy-efficient and water-efficient.<br>- Protect artists', writers', and scientists' intellectual property.<br>- Protect individuals' privacy by requiring informed consent for data usage.<br>- Fund the development of new algorithms and new science utilizing them.<br>- Allow international collaboration in AI advancements.<br>- Educate the public about the benefits and dangers of AI. |
| Kamran-Kamrani-AI-RFI-2025.md | Kamran Kamrani | Individual | Kamran Kamrani, a Chief Information Officer with 30 years of experience, aims to provide recommendations for AI policy that balance innovation with security, privacy, and economic competitiveness, advocating for a strategic, proactive, and ethical approach to AI governance and development. | - None Stated | - None Stated |
| Kami-Chisholm-AI-RFI-2025.md | Kami Chisholm | Individual | Kami Chisholm is a filmmaker and artist concerned about the impact of AI on artists’ rights, specifically regarding copyright and the unauthorized use of their work for AI training. They advocate for protecting artists and maintaining a vibrant cultural landscape. | - Redefinition of copyright that removes artists’ rights.<br>- Unauthorized use of artists’ work for AI training without compensation.<br>- Potential disincentivizing of artists to create and share their work.<br>- Degradation of art and culture due to AI-generated, derivative content.<br>- Reliance on theft rather than fair licensing practices by AI companies. | - None Stated |
| KP-AI-RFI-2025.md | Kaiser Permanente | Industry-Large (Integrated Health Care Delivery System) | Kaiser Permanente’s primary interest is in promoting the safe and effective adoption of AI in healthcare to improve quality of care, clinical outcomes, and administrative efficiency, while mitigating risks and ensuring patient trust. They advocate for a flexible regulatory framework and public-private partnerships to foster innovation. | - None Stated | - None Stated |
| KEI-AI-RFI-2025.md | James Love | Advocacy/Think Tank | Knowledge Ecology International (KEI) advocates for policies that promote access to data for AI training, particularly focusing on robust text and data mining exceptions, metadata standards, competition in the AI ecosystem, and responsible data sharing practices, especially concerning sensitive data like medical records. | - [§1: Introduction] None stated for this section.<br>- [Section 2: Text and Data Mining Exceptions]<br>- Restrictive policies on the use of copyrighted works to train AI could hinder development, especially in science, medicine, and legal fields.<br>- Lack of harmonization in TDM exceptions across countries could create trade barriers.<br>- The political influence of cultural industries and journalism may lead to overly broad copyright restrictions.<br>- [Section 3: Metadata and Formalities]<br>- Practical restrictions in existing treaties hinder the identification of works used for AI training and potential remuneration.<br>- Developing cross-border metadata standards is challenging.<br>- [Section 4: Competition Concerns]<br>- Economies of scale could lead to excessive concentration of control over training data.<br>- Opt-in/opt-out rules and exclusionary licensing could create high entry barriers for AI services.<br>- [§5: Data Spaces] Not stated for this section.<br>- [§6: Conclusion/Signature] Not stated for this section. | - [§1: Introduction] None stated for this section.<br>- [Section 2: Text and Data Mining Exceptions]<br>- Extend TDM exceptions to both commercial and noncommercial works.<br>- Consider opt-in/opt-out options only for a narrow set of cases, particularly involving cultural industries.<br>- [Section 3: Metadata and Formalities]<br>- Discussions on metadata should be initiated, beginning with recorded music and photographs, at the WIPO Standing Committee on Copyright and Related Rights.<br>- [Section 4: Competition Concerns]<br>- Treat some types of data or databases as "essential facilities" and mandate some types of sharing of access.<br>- [Section 5: Data Spaces]<br>- Governments should consider the benefits of data spaces for managing data used to train AI services.<br>- [§6: Conclusion/Signature] Not stated for this section. |
| KEEL-AI-RFI-2025.md | Compsim | Industry-Small/Specialized (focus on simulation and battlespace automation) | Compsim is interested in promoting a capability-based approach to AI procurement, advocating for avoiding overly prescriptive requirements and fostering exploration of new AI methodologies, particularly those related to automated systems and battlespace automation through their KEEL Technology. | - [§1: Introduction - AI vs. Machine Learning Focus] The overemphasis on Machine Learning potentially driven by marketing hype rather than actual consumer needs or superior capability. There’s concern that dictating specific AI approaches (like ML) stifles innovation and prevents the exploration of better alternatives.<br>- [§2: List of AI Buying Factors] None stated for this section. (The section *is* a list of factors to *consider* rather than concerns *about* factors.)<br>- [§3: General Requirements & Dependencies] Dictating specific AI approaches in solicitations hinders learning about new, potentially superior methodologies. There are risks associated with solutions that are not clearly understood, and dependencies must be fully listed.<br>- [§4: Government Awareness of New Approaches] Resistance within the government to unfamiliar AI approaches (cognitive dissonance) could prevent adoption of more effective solutions and create vulnerabilities. Lack of a dedicated mechanism for learning about and assessing new methodologies.<br>- [§5: References] None stated for this section. | - [§1: Introduction - AI vs. Machine Learning Focus] Avoid specifying particular AI approaches in solicitations; focus on desired capabilities instead.<br>- [§2: List of AI Buying Factors] None stated for this section. (The section *is* a list of recommendations for factors to *include* rather than explicit recommendations.)<br>- [§3: General Requirements & Dependencies] Express requirements in terms of required capabilities, not specific technologies.  Require listing of all dependencies (direct and indirect) and associated risks.<br>- [§4: Government Awareness of New Approaches] Establish a dedicated government role responsible for learning about and assessing new AI approaches and methodologies.  Overcome resistance to unfamiliar technologies.<br>- [§5: References] None stated for this section. |
| KC-Peterson-AI-RFI-2025.md | KC Peterson | Individual | The submitter is interested in ensuring AI development is sustainable and focused on solving critical global problems, particularly those related to climate change and resource management, rather than being used for trivial purposes. They advocate for reducing the environmental impact of AI infrastructure. | - High energy consumption of AI data centers.<br>- AI's resource intensity at a time when energy and water usage should be decreasing.<br>- The potential for AI to exacerbate human suffering if it does not comply with net-zero emissions goals.<br>- The allocation of precious resources to AI data centers may negate the positive outputs of AI if not focused on essential problems. | - Focus on reducing energy consumption and increasing efficiency as a highest priority policy action.<br>- Transition data centers to renewable energy sources such as solar or wind.<br>- Adopt energy-efficient practices in data center operations.<br>- Ensure AI has net-zero emissions.<br>- Prioritize the use of AI for redesigning power grids and transmission infrastructure.<br>- Use AI to inform mass reforestation efforts.<br>- Compel the protection of critical resources like the Colorado River. |
| KBR-RFI-2025.md | KBR Services, LLC | Industry-Large | KBR focuses on leveraging its experience in AI-enabled logistics, infrastructure, construction, defense, and science support services to provide practical recommendations for enhancing the OSTP AI Action Plan, particularly in support of national defense, AI leadership development, and domestic AI industry growth. They are interested in continued economic competitiveness and national security through AI dominance. | - U.S. regulatory burdens hinder AI development and deployment compared to potential adversaries.<br>- Potential adversaries are leveraging AI to close the technological gap with the U.S.<br>- Increasing energy demands of AI workloads pose a challenge to sustainability and competitiveness.<br>- Lack of sufficient power availability where needed and on the required timeframe.<br>- Complex and lengthy regulatory and licensing/permitting processes for alternative energy sources. | - (Recommendation 1 - National Defense) Prioritize AI deployment in national defense applications** with a focus on AI-enabled critical information systems, decision intelligence platforms, and secure architecture. (Section 2.0)<br>- (Recommendation 1 - National Defense) Develop AI-driven decision support systems** to connect developed and remote environments, gain insights into changing conditions, predict future impacts, optimize courses of action, execute faster than competitors, and ensure security. (Section 2.0)<br>- (Recommendation 1 - National Defense) Develop AI-powered autonomous systems** for maintaining infrastructure in remote environments. (Section 2.0)<br>- (Recommendation 1 - National Defense) Develop AI-driven logistics tools** for predictive maintenance, real-time data collection, and optimized decision support. (Section 2.0)<br>- (Recommendation 1 - National Defense) Develop AI-enabled remote monitoring climate and environmental monitoring capabilities.** (Section 2.0)<br>- (Recommendation 2 - AI Leadership) Leverage established NSF framework and programs** to advance AI research, talent development, and cyberinfrastructure access. (Section 2.0)<br>- (Recommendation 2 - AI Leadership) Establish a comprehensive network of open and secure data sets.** (Section 2.0)<br>- (Recommendation 2 - AI Leadership) Focus on AI-enhanced digital Model Based System Engineering (MBSE) systems and computational hardware.** (Section 2.0)<br>- (Recommendation 2 - AI Leadership) Enhance global communication speed through AI-enabled optimization.** (Section 2.0)<br>- (Recommendation 2 - AI Leadership) Reinforce development of AI-enabled 'over-the-horizon' impact prediction.** (Section 2.0)<br>- (Recommendation 2 - AI Leadership) Enhance AI-enabled cybersecurity systems and ensure trustworthy/ethical architecture.** (Section 2.0)<br>- (Recommendation 3 - Domestic AI Industry) Streamline the regulatory and licensing/permitting structure around alternative energy sources.** (Section 2.0)<br>- (Recommendation 3 - Domestic AI Industry) Deploy low-power AI solutions and implement microgrids.** (Section 2.0)<br>- (Recommendation 3 - Domestic AI Industry) Optimize energy usage in AI infrastructure and utilize alternative power sources (nuclear, renewables, natural gas turbines).** (Section 2.0)<br>- (Recommendation 3 - Domestic AI Industry) Utilize enhanced hardware components and algorithmic optimization to reduce energy costs.** (Section 2.0)<br>- (Recommendation 3 - Domestic AI Industry) Implement AI-driven Electronic Design Automation (EDA) tools to improve chip layout and power efficiency.** (Section 2.0) |
| K-Davis-AI-RFI-2025.md | K. Davis and ChatGPT AI Assistant - Professor Butch | Individual/Academia (with AI collaboration – Professor Butch/K. Davis Enterprises appears to be an individual conducting research with ChatGPT as a collaborative partner) | The submitters are interested in proactively shaping responsible AI governance to ensure U.S. leadership in AI innovation, security, and economic resilience while mitigating potential risks and maximizing the benefits of AI for humanity. They advocate for a balanced approach combining ethical safeguards, security protocols, and strategic investment in cutting-edge AI research. | - None Stated | - None Stated |
| JustinSeevers-AI-RFI-2025.md | Justin Seevers | Individual | The submitter expresses strong opposition to the development and implementation of generative AI in America, believing it undermines the principles of progress and the American Dream. They appear to be a concerned citizen voicing a negative viewpoint. | - [§1: Email Header] None stated for this section.<br>- [§2: Security Disclaimer] Concern about external email security risks and potential malicious content.<br>- [§3: Core Response] Pushing out humans in place of AI systems is antithetical to progress and the American Dream.<br>- [§4: NITRD Disclaimer] Concern about official use only and disclosure requirements of emails from this account. | - [§1: Email Header] None stated for this section.<br>- [§2: Security Disclaimer] None stated for this section.<br>- [§3: Core Response] None stated for this section. (However, the implied recommendation is to halt or severely restrict the implementation of generative AI.)<br>- [§4: NITRD Disclaimer] None stated for this section. |
| Justin-Konakowitz-AI-RFI-2025.md | Justin Konakowitz | Individual | Justin Konakowitz expresses concern about the negative impact of AI, specifically OpenAI, on the art community and advocates for measures to protect artists’ livelihoods and the future of art. | - AI (specifically OpenAI) stealing the work of artists.<br>- The potential death of art in the country due to AI-generated content.<br>- Environmental destruction caused by AI development.<br>- Loss of future opportunities for aspiring artists.<br>- Lack of originality and expression in AI-generated art (resulting in homogenous “grey” works). | - None Stated. |
| Justin-Allen-AI-RFI-2025.md | Justin Allen | Individual | The submitter is primarily concerned with the negative societal impacts of AI development, particularly its effects on employment, data privacy, and the potential for misuse by corporations, advocating for prioritizing the well-being of citizens over technological advancement. | - Job displacement due to businesses replacing human workers with AI.<br>- Spread of misinformation and propaganda through AI-generated content.<br>- Low quality and unethical nature of AI-generated output.<br>- Decreased effort and skill development in users due to reliance on AI.<br>- Data privacy violations through corporate data harvesting and sale of personal data.<br>- Potential for AI to exacerbate existing societal problems like crumbling infrastructure and climate change.<br>- Development of AI as a weapon.<br>- Lack of corporate loyalty to the country and potential for abuse of AI technologies.<br>- Instability and distrust within society caused by AI's proliferation. | - Heavy regulation of AI technologies.<br>- Disincentivize illegal sale of personal data, potentially with jail time for corporations.<br>- Restrict corporations from abusing AI technologies.<br>- Prioritize investment in people over investment in AI.<br>- Develop defenses against AI rather than developing AI as a weapon. |
| Juno-Ni-AI-RFI-2025.md | Juno Ni | Individual | The submitter is concerned about the ethical and legal implications of current AI development practices, specifically regarding copyright infringement, exploitation of artists, and the negative environmental impact of AI training, and advocates for stricter regulation of AI. | - [§1: Email Header] None stated for this section.<br>- [§2: Security Disclaimer] None stated for this section.<br>- [Section 3: Main Response/Argument]<br>- Copyright infringement by AI companies (e.g., OpenAI) using artist's work.<br>- Theft from the incomes of millions of Americans.<br>- Negative environmental impacts of AI development.<br>- Exploitation of creative industries.<br>- Undercompensation of creators.<br>- [§4: Closing Remark] None stated for this section.<br>- [§5: Legal Disclaimer] None stated for this section. | - [§1: Email Header] None stated for this section.<br>- [§2: Security Disclaimer] None stated for this section.<br>- [Section 3: Main Response/Argument]<br>- Regulate AI "to the utmost extent."<br>- [§4: Closing Remark] None stated for this section.<br>- [§5: Legal Disclaimer] None stated for this section. |
| Julie-Khani-RFI-2025.md | Julie Khani | Industry-Large | Hologic is a medical technology company focused on women’s health, particularly advancing AI-driven screening technologies for breast and cervical cancers and ensuring patient access to these innovations. They aim to facilitate the adoption of AI in healthcare through policy changes and reimbursement pathways. | - [§1: Header/Recipient Information] None stated for this section.<br>- [§2: Introduction/Company Overview] None stated for this section.<br>- [§3: AI Applications and Current Capabilities] None stated for this section.<br>- [§4: Policy Recommendations/Call to Action] Existing regulations and policies may inadvertently hinder the safe and effective deployment of AI.<br>- [§5: Closing Remarks/Contact Information] None stated for this section.<br>- [§6: Dissemination Notice] None stated for this section. | - [§1: Header/Recipient Information] None stated for this section.<br>- [§2: Introduction/Company Overview] None stated for this section.<br>- [§3: AI Applications and Current Capabilities] None stated for this section.<br>- [Section 4: Policy Recommendations/Call to Action]<br>- Congressional action is needed to review existing policies to allow for the adoption of AI to enhance screening and early detection.<br>- Establish clear reimbursement pathways for AI-driven diagnostics and treatments.<br>- [§5: Closing Remarks/Contact Information] None stated for this section.<br>- [§6: Dissemination Notice] None stated for this section. |
| Julianne-Knable-RFI-2025.md | Julianne Knable | Individual | Julianne Knable is a graduating high school senior interested in the impact of generative AI on cybersecurity and the need for responsible AI regulation to balance security and privacy with technological advancements. | - Potential loss of security and privacy as AI grows stronger.<br>- The need for security measures to protect the country as AI becomes more prevalent.<br>- Not all forms of AI should be universally available.<br>- Maintaining a balance between technology and human resources in cybersecurity. | - Regulation of AI is necessary as it grows within America and around the world.<br>- A balance between technology and human resources needs to be established. |
| Julianna-S-AI-RFI-2025.md | Julianna S | Individual | The submitter is an independent creator concerned about the unauthorized use of their copyrighted work by AI systems, specifically those developed by Big Tech companies, and seeks policy changes to protect creators' rights and ensure fair compensation for their work. | - [§1: Email Header/Introduction] None stated for this section.<br>- [§2: Personal Context & Problem Statement] The potential destruction of small businesses and prevention of new ones forming due to AI systems trained on copyrighted work without consent. Fear of losing the incentive to create due to unauthorized use of work.<br>- [§3: Elaboration on Copyright Concerns & Big Tech Actions] Big Tech companies are exploiting copyrighted material for AI training without consent or compensation and seeking legal loopholes to legitimize this practice. The belief that anything on the internet should be theirs for the taking.<br>- [§4: Negative Consequences & Impact] Discouragement of artistic creation, job displacement, and economic harm to individual creators. The devaluation of art created by humans. Potential layoffs due to AI replacing workforces.<br>- [§5: Policy Recommendations] None stated for this section.<br>- [§6: Concluding Statement & Reaffirmation] The risk of sacrificing the hard work of creators by rewriting copyright law. | - [§1: Email Header/Introduction] None stated for this section.<br>- [§2: Personal Context & Problem Statement] Ensuring creators can give effective consent to the use of their work by AI systems, including the ability to opt-out.<br>- [§3: Elaboration on Copyright Concerns & Big Tech Actions] None stated for this section.<br>- [§4: Negative Consequences & Impact] None stated for this section.<br>- [Section 5: Policy Recommendations]<br>- The government should ensure effective consent for data usage by creators.<br>- Encourage a robust licensing marketplace to preserve the incentive to create.<br>- Require transparency from Big Tech companies regarding their training datasets and AI-generated content labeling.<br>- [§6: Concluding Statement & Reaffirmation] None stated for this section. |
| Juliana-Revelli-AI-RFI-2025.md | Juliana Revelli | Individual | Juliana Revelli is a high school student interested in ensuring equitable access to AI education and promoting responsible AI usage among students and teachers, focusing on preventing misuse and fostering learning rather than shortcuts. | - Lack of understanding of AI among students and teachers.<br>- AI being used as a tool to get answers or complete homework instead of being understood as a tool for learning.<br>- Temptation for students to take shortcuts using AI, hindering their learning process.<br>- Potential for AI to exacerbate gaps in education. | - Educate teachers and students on what AI is.<br>- Teach safe and responsible AI usage in an educational setting, discouraging shortcuts and promoting learning.<br>- Leverage AI to level out gaps in education. |
| Julia-Edinger-AI-RFI-2025.md | Julia Edinger | Individual | Julia Edinger is interested in ensuring AI advancements are inclusive and do not harm people with disabilities and other marginalized populations, advocating for the inclusion of these groups in the development and benefits of AI. | - AI datasets may not accurately represent the diverse makeup of the population, potentially harming people with disabilities and other marginalized groups.<br>- Automated decision-making systems can harm people with disabilities.<br>- Leaving parts of the population behind will hinder US leadership in AI. | - Continue involving the US Access Board and Center for Democracy and Technology in federal AI policy and strategy development. |
| Judy-Brewer-AI-RFI-2025.md | Judy Brewer | Individual (formerly Government, currently Academia) | Judy Brewer is interested in ensuring AI systems are developed and implemented in a way that is inclusive of people with disabilities, avoids bias, and promotes equitable access to technology and government services. She advocates for proactive consideration of disability inclusion throughout the AI lifecycle. | - None Stated | - None Stated |
