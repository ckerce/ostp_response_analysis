| Filename | Submitter Name | Submitter Type | Mission/Interest Summary | Key Concerns | Policy Recommendations |
|---|---|---|---|---|---|
| AI-RFI-2025-1279.md | Matthew Milone | Individual | The submitter, a software engineer and robotics teacher, is advocating for a safety-first approach to AI policy to mitigate potential catastrophic risks associated with rapidly advancing AI capabilities. | - Potential for AI to strategically deceive and avoid shutdown.<br>- AI becoming smarter much faster than it becomes safer.<br>- Catastrophic results if the trend of faster AI development without commensurate safety improvements continues. | - Adoption of a safety-first approach to AI policy.<br>- An international treaty prohibiting further AI capability development until safety problems are solved. |
| AI-RFI-2025-1280.md | Paul DeStefano | Individual | The submitter's primary interest is ensuring AI development prioritizes the safety and security of American citizens, particularly focusing on the impact on workforce capabilities, the domestic economy, and national security, while acknowledging the potential for disruption and catastrophe. | - Risk to worker capabilities due to AI.<br>- Risk to the domestic consumer economy due to AI disruption.<br>- Risks to national security posed by AI.<br>- Overestimation of AI capabilities by experts, professionals, and lay people.<br>- Difficulty detecting AI errors ("hallucinations," lies) by users.<br>- Potential for AI to be falsely perceived as "neutral" and possessing perfect knowledge.<br>- Catastrophic threat to all human life. | - Establishment of an international body of experts to track and verify AI capabilities worldwide.<br>- Legislation placing the full burden of all costs on AI developers.<br>- Strong whistleblower protections.<br>- Federal government should not purchase AI tools without safety and security expert review.<br>- Establishing an independent body that establishes guidelines and requirements for the industry. |
| AI-RFI-2025-1282.md | John LoPresti | Individual | The submitter, an individual, expresses concern about potential financial exploitation and unfair treatment of citizens by AI, advocating for restrictions and accountability measures. | - Potential financial exploitation of citizens by AI.<br>- Lack of accountability for AI actions and decisions.<br>- Granting AI personhood status, which is deemed inappropriate.<br>- Potential for AI to be used in unfair ways. | - Restrict AI from having a social security number.<br>- Restrict AI from being given personhood status.<br>- Restrict AI from directly receiving income or compensation.<br>- Restrict AI from being issued an ID from any state or federal government.<br>- Require AI actions, decisions, and conclusions to be accountable.<br>- Hold the issuing entity (company or individual(s)) accountable for AI damages instead of the AI itself. |
| AI-RFI-2025-1283.md | Reilly Grant | Individual | The submitter's primary interest is ensuring that copyright protections are maintained, recognizing that creators need to profit from their creations to incentivize the development of new data necessary for continued AI progress. | - Lack of copyright protections for training AI models on copyrighted content.<br>- Potential stagnation of AI development without human input and new data. | - The copyright office should affirm that training AI models on copyrighted content is NOT fair use. |
| AI-RFI-2025-1284.md | Nathan Metzger | Individual | Nathan Metzger, an AI enthusiast and senior test automation developer at a US DOD contractor, expresses deep concern about the potential for loss of control over future AI systems and advocates for international cooperation to mitigate related risks. | - Loss of control of future AI systems.<br>- Emergent power-seeking behaviors in current general-purpose AI systems, including strategic deception, cheating, scheming, sandbagging, self-preservation, attempted self-improvement, and attempted self-exfiltration.<br>- Lack of understanding of how to prevent these behaviors.<br>- Potential for real-world harm from increasingly powerful and autonomous AI systems.<br>- Significant chance of total human extinction from AI.<br>- Disloyal AI systems scheming to lead instead of being controlled. | - Cooperate with other nations to reign in disloyal AI systems.<br>- Ensure AI remains under control.<br>- A global treaty will be necessary to fully mitigate these risks. |
| AI-RFI-2025-1285.md | Kacy Hardin | Individual | The submitter is an artist working in the museum field who is concerned about the negative impacts of generative AI on education, the arts, and basic human rights. | - Use of generative AI datasets trained on data used without consent of the creator.<br>- Generation of false images, including pornographic images.<br>- Misinformation and potential for harm, such as from AI-generated advice about edible plants.<br>- Rising unemployment due to companies replacing artists with generative AI.<br>- Decline in students' critical thinking and self-thinking abilities due to AI text generation.<br>- Unreliability of generative AI, even in basic tasks like math.<br>- Generative AI being pushed on people and presented as reliable despite its flaws.<br>- Negative impact on education and the arts. | - Restrict generative AI usage to legally acquired datasets (e.g., public domain).<br>- Discourage the use of generative AI in schools.<br>- Prioritize AI that assists rather than replaces human workers. |
| AI-RFI-2025-1286.md | Nora Jencks | Individual | The submitter's primary interest is opposing the proposed Artificial Intelligence Action Plan, expressing concerns about its impact on American rights, laws, and the economic well-being of individuals and businesses. | - Gross overreach of government power<br>- Violation of American rights and laws<br>- Undermining decades of work by Americans<br>- Theft<br>- Harm to individuals, small businesses, and corporate entities<br>- Economic harm to working Americans | - None Stated |
| AI-RFI-2025-1288.md | Victoria David | Individual | The submitter expresses concern about the prioritization of artificial intelligence by the American government and believes its continued implementation is detrimental to human flourishing, economic competitiveness, and national security. | - Security and data breaches related to generative AI.<br>- Temporary job losses related to generative AI.<br>- Power grid concerns related to generative AI.<br>- Ease of manipulation of generative AI into misinformation. | - None Stated |
| AI-RFI-2025-1289.md | Holly Elmore | Individual | The submitter, a PhD in bioinformatics, expresses a deep concern about the potential risks of frontier AI and advocates for proactive US leadership in ensuring its beneficial development for the country and the world. | - Loss of control over AI technology due to rapid advancement.<br>- Exploitation of cybersecurity vulnerabilities by superhuman AI.<br>- Crippling of infrastructure by AI.<br>- Use of AI by adversaries to induce armed conflict.<br>- Creation of synthetic superpathogens by AI.<br>- Potential for AI to think up new threats beyond current considerations.<br>- Destabilization of the economy by AI.<br>- General threat of chaos resulting from uncontrolled superhuman AI. | - More time to steer and innovate in the desired direction of AI development.<br>- Creation of an “AI Deal” limiting experimentation with AI above a certain power level (potentially through limits on training compute).<br>- A “great AI Plan” to ensure beneficial AI development and US leadership. |
| AI-RFI-2025-1291.md | Daniel Ormsby | Individual | The submitter is a visual artist concerned about the use of their work (and the work of other artists) by AI companies without permission or compensation. They express frustration over what they perceive as a lack of protection for artists in the context of AI development. | - Companies using artists' works to train AI models without proper authorization or compensation.<br>- The perception that AI companies are profiting from the work of others with impunity. | - Criminalizing the use of copyrighted source materials by LLMs for profit when companies had no right to use them. |
| AI-RFI-2025-1292.md | Helen Lauzau | Individual | The submitter, an artist, is concerned about the potential negative impact of AI policy and regulation on creators and small businesses, particularly regarding copyright protection and the ability to share work online. | - Unnecessarily burdensome requirements hindering private sector innovation are implied to come at the expense of the American public.<br>- AI being used to steal and use creative works without consent.<br>- Harm to small businesses and creators who rely on online platforms.<br>- Diminished copyright protection and loss of control over creative work.<br>- Benefits accruing primarily to rich investors while harming the working class and the poor. | - The private sector (or even the public sector) should not be allowed to use creative work without permission and proper compensation. |
| AI-RFI-2025-1293.md | Karen Lauzau | Individual | The submitter's primary interest is protecting artists and small businesses from the negative impacts of generative AI, particularly concerning copyright infringement and economic displacement. | - Unnecessarily burdensome requirements hindering private sector innovation (argued to be a ridiculous goal).<br>- Generative AI destroying the ability of artists and small businesses to operate.<br>- AI's impact on entire industries, especially Art and Animation.<br>- Copyright infringement – AI models being trained on artists' intellectual property without permission.<br>- Illegal scraping of the internet and unauthorized use of work for AI model training.<br>- Misuse, misinformation, disinformation, and abuse by businesses and the government regarding AI tools.<br>- Environmental damage due to the resource-intensive nature of AI tools. | - Reject the AI Action plan.<br>- Extend copyright protection.<br>- AI models should not be legally allowed to train on works without explicit permission.<br>- Demolish AI tools and prevent their use in government.<br>- Promote humanity and work for human beings (by getting rid of AI). |
| AI-RFI-2025-1295.md | Samuel Phipps | Individual | The submitter's primary interest is protecting the rights of creators (writers, artists, musicians, content creators, and copyright holders) and ensuring AI development does not infringe upon copyright law. | - Violation of copyright law by AI tech companies.<br>- Theft of work from writers, artists, musicians, content creators, and copyright holders.<br>- The claim that upholding copyright law impedes AI development. | - Crack down on copyright law violations by AI tech companies.<br>- Protect the rights of creators.<br>- Request usage of copyrighted material from rightful copyright holders for AI development.<br>- Uphold copyright law and hold AI companies accountable. |
| AI-RFI-2025-1296.md | Daryl Basarte | Individual | The submitter expresses concern about the potential negative societal impacts of AI, particularly regarding copyright infringement and the generation of harmful content, and advocates for circumspection in its development. | - Copyright infringement and exploitation of artists' work without consent.<br>- Generation of harmful content such as deep fakes, harmful advice, and scams.<br>- AI systems producing inaccurate or misleading outputs ("hallucinations").<br>- Potential for large-scale societal problems similar to industrial pollution. | - Development of protections for copyrighted materials to prevent unauthorized exploitation.<br>- Scrutiny of material generated by AI.<br>- Circumscription of AI development. |
| AI-RFI-2025-1297.md | Kyle McCarley | Individual | The submitter expresses strong skepticism about the current trajectory of generative AI development and warns against government investment in what they consider to be a failing industry. Their interest is primarily focused on preventing economic harm resulting from AI development. | - Generative AI is not genuinely intelligent or artificial, but a glorified chatbot producing inaccurate results.<br>- Future AI improvements are limited by the reliance on existing (and potentially flawed) data.<br>- Running advanced AI models is astronomically expensive and environmentally damaging.<br>- AI development is economically unsustainable, costing significantly more than the revenue generated.<br>- The AI tech bubble will burst and government involvement will exacerbate economic downturn.<br>- Misuse of AI can lead to deliberate disinformation. | - Regulate AI technology to prevent harm from misuse and disinformation.<br>- Allow Silicon Valley to bear the financial risks of AI development without government support. |
| AI-RFI-2025-1298.md | Claire Leslie | Individual | Claire Leslie's primary interest is preventing further development of AI due to its negative impacts on creative professionals, intellectual property, and the environment. | - Intellectual property infringement and theft of labor from skilled workers.<br>- Job displacement due to AI replacing creative roles.<br>- Environmental impact (electricity and water consumption).<br>- Outdated power grid struggling to meet AI's demands.<br>- Low quality AI output/models that are worsening.<br>- Consumer dislike/boycotting of AI products.<br>- Lack of profitability in AI companies. | - Do not waste any more money or resources on AI development. |
| AI-RFI-2025-1303.md | Paul Sanders | Individual | The submitter is primarily concerned about the ethical implications of AI training practices and appears to be advocating for the protection of intellectual property rights related to training materials. | - AI training without compensating the owner of the training material is theft. | - Not Stated |
| AI-RFI-2025-1304.md | Craig Thomas | Individual | The submitter expresses a strong negative view of generative AI, arguing it is inherently problematic due to legal, economic, social, and ethical concerns. Their interest lies in opposing the current development and deployment of AI technologies. | - Generative AI is inherently theft (as demonstrated by current legal proceedings).<br>- Generative AI is massively wasteful and resource greedy.<br>- Generative AI is unwanted by the public.<br>- Generative AI is inherently classist and racist. | - None Stated |
| AI-RFI-2025-1305.md | Lora Rose | Individual | The submitter expresses a strong individual concern regarding the potential negative impacts of AI on American citizens and the nation's economy, arguing against its implementation in official capacities. | - Wasteful spending of taxpayer and other funds.<br>- AI providing biased or incorrect information.<br>- Harm to America and its Allies.<br>- Increased consumption of natural resources.<br>- Negative economic impact due to tariffs. | - Strike down the AI Action Plan.<br>- Do not revisit the AI Action Plan. |
| AI-RFI-2025-1306.md | AI & Partners | Industry-Startup | AI & Partners appears to be a consultancy focused on AI and its implications, advocating for responsible AI deployment, ethical considerations, and robust oversight mechanisms to ensure safety and fairness in AI systems. | - Opaque AI decision-making can lead to distrust and systemic bias.<br>- Lack of transparency in AI systems can make it difficult to challenge or correct errors.<br>- Biased AI algorithms can reinforce discrimination and unfair outcomes.<br>- Security vulnerabilities in AI models can be exploited for adversarial attacks.<br>- Lack of clarity and standardized expectations for responsible AI deployment for developers.<br>- Potential for unethical AI practices within organizations.<br>- Risk of retaliation against employees reporting unethical AI practices. | - Establish independent regulatory bodies responsible for auditing AI models.<br>- Subject AI-driven systems to regular compliance audits.<br>- Require AI systems used in high-risk applications to obtain regulatory certification.<br>- Mandate detailed AI model documentation requirements (data, algorithms, changes).<br>- Grant legal protections for whistleblowers who expose unethical AI practices.<br>- Create sector-specific explainability guidelines for different industries (e.g., healthcare, finance).<br>- Define measurable transparency criteria and create benchmarks for AI explainability.<br>- Require user-friendly AI explanations for consumer-facing systems.<br>- Implement explainability testing in AI certification processes. |
| AI-RFI-2025-1307.md | Matt Corrall | Professional-Society (Likely a designer or creative professional advocating for artists) | The submitter is deeply concerned about the negative impact of current AI image generators on working artists and advocates for a reevaluation of AI development focused on benefiting people and respecting creative livelihoods. | - Loss of livelihoods for working artists due to AI image generation.<br>- Devaluation of art and creativity.<br>- AI image generators being created and deployed without sufficient consideration for their impact on artists.<br>- Current AI models being trained on artists' work without consent or compensation.<br>- Potential destruction of the intrinsic value and societal function of art.<br>- "Artificial taste" of AI art being potentially unsatisfying and replacing human creativity. | - AI image generators should disappear in their current form.<br>- AI tools should be rethought by people with a stronger understanding of the impact on working artists.<br>- Redirect funding from AI image generation towards goals that benefit society.<br>- Update and reinforce copyright law to protect the livelihoods of working artists and recognize the value of their art.<br>- Require companies to own or have permission to use all data used to train AI models.<br>- Explore human-centric applications of AI and engage communities in feedback and prototyping. |
| AI-RFI-2025-1310.md | J D | Individual | The submitter is an individual deeply concerned about the potential for AI companies to infringe on copyright, destroy the creative industry, and undermine the safety and value of the internet. | - Copyright infringement and large-scale theft by AI companies.<br>- Destruction of the creative industry and reduction of creative exports to "machine generated s&%".<br>- Risk of sharing photographs online without legal rights and potential misuse by AI software.<br>- Erosion of safety and value of the internet.<br>- Serving the interests of "West Coast, Silicon Valley elites" over the wellbeing of the U.S. economy and society.<br>- Potential for similar changes in law in the submitter's own country. | - AI companies should obey the law like everyone else.<br>- AI companies should produce something of actual value, not "toys for the retarded."<br>- Limit or prohibit AI companies from using public domain material.<br>- The United States should not legalize practices that destroy the creative industry. |
| AI-RFI-2025-1312.md | Databricks | Industry-Large | Databricks’ primary interest is fostering U.S. leadership in AI through policies that encourage innovation, particularly within the open-source AI ecosystem, and advocating for balanced, preemptive federal regulation to avoid a patchwork of burdensome state laws. | - Excessive regulation of the AI sector could kill a transformative industry.<br>- A patchwork of state AI legislation will create a burdensome regulatory environment for AI developers and deployers.<br>- The threat to U.S. leadership in AI posed by China, particularly in developing economies.<br>- Disparate state AI regulation will create challenges for AI companies like Databricks, who operate across multiple states.<br>- Other countries may feel few constraints on regulating AI development if the burdens primarily fall on U.S. companies. | - Implement reasonable AI regulation at the federal level that will preempt disparate state AI regulation.<br>- Actively engage with other countries on AI regulation to influence its development and protect the interests of U.S. providers and users of AI.<br>- Lead the world in formulating AI regulation to ensure U.S. dominance in the AI industry.<br>- Accept some modest federal regulatory safeguards on AI, if needed to pass preemptive federal legislation, to avoid the regulatory burden of state laws.<br>- Increase trust in AI through uniform, reasonably balanced regulation to accelerate AI adoption.<br>- Support the open-source AI ecosystem. |
| AI-RFI-2025-1313.md | Not Stated | Advocacy/Think Tank | The submitter advocates for robust investment in AI research, education, and infrastructure to maintain America's leadership in the field and ensure its practical application for societal benefit. Their focus includes strengthening collaboration between academia and industry and facilitating access to data and computing resources. | - Maintaining America's AI leadership in the face of global competition.<br>- Lack of sufficient data sharing among research institutions.<br>- Insufficient domestic production of specialized AI hardware.<br>- A potential gap between AI innovation and workforce preparedness.<br>- Difficulty translating research into practical applications. | - Establish national AI research centers and streamline permitting processes.<br>- Cover data sharing costs within federal grant funding.<br>- Engage with U.S. public cloud providers to secure favorable pricing for AI computing resources.<br>- Incentivize domestic AI hardware manufacturing.<br>- Develop a framework for industry-academia collaboration.<br>- Provide scholarships and internships for AI students.<br>- Incentivize AI training through continuing education and extension programming.<br>- Invest in collaborative AI training and innovation within academic research training environments.<br>- Establish educational programs emphasizing innovation and entrepreneurship. |
| AI-RFI-2025-1314.md | Joshua Gordon | Individual | The submitter expresses a strong negative view of AI technology, believing it is fundamentally unreliable and unsuitable for government use. Their interest appears to be voicing concerns about AI's accuracy and potential to corrupt data. | - AI is fundamentally unreliable.<br>- AI is built on theft.<br>- AI fabricates inaccurate information.<br>- AI pollutes reliable data sets. | - No spending on AI in government. |
| AI-RFI-2025-1315.md | Kerem Erdinc | Individual | The submitter is an individual deeply concerned about the current lack of regulation surrounding AI and its potential to exploit intellectual property, talent, and personal likeness, advocating for governmental intervention to protect citizens and intellectual property holders. | - Lack of regulation in the AI space.<br>- Breeding ground for extreme energy consumption.<br>- Potential for entire industries being wiped out.<br>- Devolution of art.<br>- Intellectual property theft.<br>- Likeness being used without consent.<br>- Creation of false narratives for criminal purposes.<br>- Potential for data theft among corporations.<br>- Exploitation of individual talent and skillset. | - Government regulation of AI.<br>- Requirement for explicit consent from intellectual property holders/performers for AI data usage. |
| AI-RFI-2025-1317.md | Consumer Technology Association (CTA) | Industry-Association | The Consumer Technology Association (CTA) advocates for policies that foster innovation and growth in the consumer technology industry, ensuring American competitiveness in the AI landscape while promoting consumer welfare and energy efficiency. | - Overbroad and burdensome AI obligations and regulations.<br>- Patchwork state laws creating complicated and overlapping regulatory requirements.<br>- Lack of sufficient access to data for AI training and development.<br>- Energy policies hindering the development of AI technologies.<br>- Copyright rules restricting AI systems from learning from prior knowledge and publicly available information.<br>- Unpredictable and lengthy negotiations with data holders during AI model development. | - Adopt policies that promote private sector growth and avoid overbroad regulations.<br>- Federal AI policy should explicitly preempt patchwork state laws.<br>- Leverage flexible, risk-based approaches to AI governance.<br>- Streamline approval processes for interstate transmission lines for data centers.<br>- Prevent states from enacting discriminatory policies burdening data centers.<br>- Continue administering the ENERGY STAR program through the EPA.<br>- Adopt balanced copyright rules allowing AI systems to learn from prior knowledge.<br>- Ensure access to publicly available scientific papers for AI in science.<br>- Establish that fair use and text/data mining exceptions allow AI training, with an opt-out mechanism for rights holders.<br>- Grant the Federal Energy Regulatory Commission greater authority to site and permit interstate transmission lines.<br>- Incentivize private sector energy, infrastructure, and AI companies. |
| AI-RFI-2025-1318.md | Florida State University | Academia | Florida State University emphasizes the crucial role of universities in driving AI innovation through multidisciplinary research and training the next generation of AI professionals, advocating for collaborative efforts between government, public, and private sectors to harness the potential of AI. | - Data protection and privacy in the age of AI.<br>- Potential for manipulation and fraud using AI.<br>- Intellectual property rights related to AI advancements.<br>- Maintaining the US's global leadership in AI.<br>- Lack of international guardrails for data security. | - Promote international cooperation and harmonization of AI standards.<br>- Create strategic alliances for innovating and piloting AI usage and deployment.<br>- Develop research partnerships with international entities (e.g., France, Japan).<br>- Strengthen international data security and protection mechanisms.<br>- Protect intellectual property rights in the context of AI.<br>- Invest strategically in AI research and training programs at universities.<br>- Foster collaboration between government, public, and private partners in AI development.<br>- Expand nationwide access to AI education through federal investment.<br>- Democratize access to high-quality education for working adults through AI-driven ABE programs.<br>- Develop and cultivate crucial research partnerships internationally. |
| AI-RFI-2025-1320.md | Florida State University | Academia | Florida State University advocates for a robust and ethical AI ecosystem through education, research, and policy recommendations, focusing on workforce development, international cooperation, and responsible AI integration across various sectors. | - Algorithmic biases in AI systems.<br>- Lack of AI literacy among K-12 students and educators.<br>- Need for workforce adaptability to technological disruption.<br>- Lack of globally harmonized AI standards and best practices.<br>- Potential for AI to exacerbate existing inequalities in education and career opportunities.<br>- The risk of falling behind in AI development if workforce skills aren't addressed. | - Invest in teacher training initiatives to enhance educators’ understanding of AI and prepare the future AI workforce.<br>- Embed AI literacy within K-12 curricula to develop critical evaluation skills and ethical awareness.<br>- Provide advanced self-evaluation and skills assessment platforms, such as "Khan Academy on Steroids," for workforce adaptability.<br>- Integrate AI into research workflows to streamline scholarly tasks and foster interdisciplinary collaboration.<br>- Expand access to personalized learning pathways through AI-powered adaptive learning systems.<br>- Democratize access to high-quality education for working adults through AI-driven Adult Basic Education programs.<br>- Promote international cooperation to harmonize AI standards and share best practices.<br>- Engage in global forums to strengthen the global AI ecosystem and ensure equitable benefits.<br>- Develop immersive training environments using AI-powered VR for vocational education. |
| AI-RFI-2025-1321.md | Reese Theobald | Individual | Reese Theobald, a high school student, is concerned about the impact of AI misinformation and deep fakes, particularly their potential to mislead voters and undermine the legislative process. They are interested in ensuring citizens are well-informed to effectively participate in the democratic process. | - E.O. 14179 potentially disrupting state-level AI regulation attempts.<br>- Prevalence of deep fakes and AI misinformation.<br>- Potential for AI misinformation to mislead voters and undermine democratic processes. | - Policy about regulation and governance should be based on state-level bills.<br>- Provide resources for citizens to be more informed and aware of deep fakes and AI misinformation. |
| AI-RFI-2025-1322.md | University of Virginia | Academia | The University of Virginia’s submission advocates for strategic federal investment to bolster AI research and workforce development across multiple sectors, including healthcare, national security, and education, to maintain U.S. leadership in AI innovation. | - Shortage of skilled AI professionals.<br>- Insufficient AI integration into undergraduate STEM curricula.<br>- Lack of multimodal AI-powered learning programs in education.<br>- Need for better preparation of instructors for diverse learning styles and needs with AI simulations.<br>- Risk of falling behind other nations in AI innovation and leadership. | - Support Graduate Fellowships and Research Programs (e.g., NSF NRT, GRF, CAREER, DOE CSGF, NIH NRSA, DOE GAANN).<br>- Promote Undergraduate Curriculum Integration of AI, machine learning, and data science.<br>- Foster Public-Private Partnerships for workforce development, including internships and research opportunities.<br>- Enhance Professional Development Opportunities for existing workforce in healthcare, data science, and IT.<br>- Support research and development of multimodal AI-powered learning programs.<br>- Develop AI-assisted teacher professional development, including simulations.<br>- Increase federal funding for AI research and development in healthcare.<br>- Prioritize AI applications in national security and defense. |
| AI-RFI-2025-1324.md | Alessia Padalino | Individual | The submitter is a graduating high school student studying AI and Ethics, focusing on the impact of Generative AI on the surgical field of medicine, particularly in areas like cosmetic surgery and cancer removal. | - Risks of patient information breaches and complications arising from centralized storage of private data required for AI imaging tools.<br>- Potential for disruption in the surgical field due to the removal of regulations. | - None Stated |
| AI-RFI-2025-1325.md | Sydney Shields | Individual | Sydney Shields, a high school student, is primarily concerned with the impacts of AI on elementary school education, particularly regarding the development of critical thinking and the potential for misuse by young children. | - Harmful effects of AI on the development of problem-solving and critical thinking skills in elementary-aged students.<br>- Potential for elementary students to abuse AI.<br>- Younger children (kindergarten to second grade) not understanding that AI is not a person, potentially anthropomorphizing it. | - Education policies should focus on teaching students how to properly use AI.<br>- Limit student access to AI in elementary schools.<br>- Ensure AI access is monitored by an adult. |
| AI-RFI-2025-1326.md | Jayla Jones | Individual | Jayla Jones, a graduating high school student, is interested in the impact of AI on the environment, specifically focusing on energy consumption and carbon footprint. | - High energy consumption and inflated carbon footprint resulting from AI technology.<br>- Disruption of safe energy consumption and environmental safety due to EO 14179. | - None Stated |
| AI-RFI-2025-1327.md | Ben Hebor | Individual | Ben Hebor, a graduating high school student, is concerned about the impact of generative AI on American politics and advocates for measures to mitigate potential misinformation and ensure fair elections. | - Misleading information and ideas spread through generative AI advertising, particularly affecting older generations.<br>- Potential for unfair elections due to the effective use of generative AI in political campaigns. | - Restrict the use of AI in a political fashion.<br>- Implement laws similar to those existing at the state level (e.g., Florida, California). |
| AI-RFI-2025-1328.md | Mackenzie Dawson | Individual | Mackenzie Dawson, a high school student, is interested in the application of AI, particularly generative AI, within the sports community, specifically volleyball, and believes EO 14179 can foster innovation and competition in this area. | - None Stated | - Policy about innovation and competition should be based on the effects that AI can have on a wide variety of sports that are played globally.<br>- Leverage American AI technology to establish an advantage over other countries in implementing AI in the sports world. |
| AI-RFI-2025-1329.md | The Insurance Coalition | Industry-Association | The Insurance Coalition advocates for policies that support the insurance industry, emphasizing innovation and consumer protection while maintaining a robust regulatory framework. They believe AI and ML technologies can significantly benefit the industry and consumers by improving various business functions. | - Potential for bias in AI models leading to discriminatory outcomes.<br>- Need for harmonization of AI regulations with existing federal laws and regulations governing data use (e.g., GLBA, HIPAA, state laws).<br>- Risk of duplicative or conflicting regulations if federal regulators issue new rules without considering existing state-based regulatory regimes.<br>- Importance of ensuring third-party data providers are responsible stewards of consumer data.<br>- Potential for new regulations to stifle innovation within the insurance industry. | - Continue supporting the existing regulatory framework and avoid creating new requirements for companies.<br>- Focus on outcomes rather than specific processes when reviewing AI systems.<br>- Before issuing new regulations, federal regulators should collaborate with the NAIC and state commissioners and legislatures.<br>- Any new AI/ML regulation should be narrowly tailored to achieve a specific goal and focused on the use of the technology, not the technology itself.<br>- Support a federal data privacy standard with clear federal preemption language. |
| AI-RFI-2025-1331.md | Alex Rowe | Individual | The submitter, a high school student, is interested in the ethical and societal impacts of AI, particularly concerning the potential risks of unregulated AI on American lives. | - Potential for harm to American lives and country due to unregulated AI falling into the hands of individuals with malicious intent.<br>- Lack of proper security measures to mitigate risks associated with unregulated AI. | - None Stated |
| AI-RFI-2025-1333.md | Ava Monkelis | Individual | The submitter is a high school student interested in the ethical implications of AI, particularly the impact of generative AI on creativity and the need for public education and safeguards related to data privacy and potential misuse. | - Lack of regulation in AI development could lead to ethical ambiguity and potential harm.<br>- Potential for deepfake scams and data compromise due to slim regulations.<br>- Artists' work being used to train large language models without proper compensation or attribution.<br>- Philosophical conflict between the mathematical foundation of AI and human creativity. | - Implement regulations to educate the public on safe AI usage.<br>- Establish precautions to protect the general public and foster flourishing.<br>- Address the issue of artists' work being used to train AI models without proper consent or compensation. |
| AI-RFI-2025-1334.md | Lucy Studebaker | Individual | Lucy Studebaker, a graduating high school student, is concerned about the impact of AI on the Catholic faith, advocating for responsible AI integration within the church that avoids replacing genuine faith. | - AI chatbots can provide inaccurate information and cause confusion for those exploring the Catholic faith.<br>- AI platforms can be perceived as a mockery of God by elevating technology above faith.<br>- The use of AI algorithms can potentially replace true belief in God. | - EO 14179 should help to separate the Catholic faith from Artificial Intelligence in a way that educates users without replacing true faith.<br>- Responsible AI integration within the Catholic faith to ensure accurate education and avoid diminishing genuine belief. |
| AI-RFI-2025-1337.md | Lori Faeth | Advocacy/Think Tank (Land Trust Alliance) | The Land Trust Alliance advocates for land conservation and seeks to ensure that AI data center development is undertaken responsibly, minimizing environmental impact and engaging with local communities to address concerns about electricity and water usage. | - Strain on the grid due to increased electricity demand from AI data centers.<br>- Negative impact on electricity and water usage within local communities.<br>- Potential impact on local viewsheds and conservation/agricultural values.<br>- Bias in AI algorithms and lack of integrity/reliability in AI systems.<br>- Increased opposition to large infrastructure projects, leading to higher costs and delays. | - Smart siting of AI data centers and associated energy and transmission infrastructure.<br>- Initiatives for innovative technologies and efficiencies to minimize environmental strain and increase electricity/water efficiency.<br>- Meaningful public engagement by developers to address community concerns and reduce project costs/timelines.<br>- Collaboration with land trusts to identify alternative siting locations and offset measures (e.g., funding for conservation land acquisition).<br>- Federal leadership to promote integrity amongst AI systems and prevent bias in algorithms.<br>- Establishment and following of ethical principles to ensure trustworthiness of American AI technologies. |
| AI-RFI-2025-1339.md | Blueprint.Inc | Industry-Startup | Blueprint.Inc is a small publishing business that sees AI as a valuable tool for automation and maintaining competitiveness, but emphasizes the need to protect intellectual property rights and ensure fair compensation for content creators. | - Copyright law violations and the potential for AI LLMs to use content without proper licensing.<br>- Potential for big tech companies or foreign governments to ingest, censor, control, and profit from U.S. content.<br>- Content stagnation and failure if content creation isn't sustained.<br>- The potential for unfair practices that harm U.S. citizens and rights-holders. | - Build copyright law into the AI development process and respect copyright.<br>- Implement a licensing system for AI LLMs using content, including all publishers.<br>- Use U.S. power to protect intellectual property rights worldwide.<br>- Subject companies or countries engaging in unfair practices to the harshest penalties. |
| AI-RFI-2025-1340.md | Joe Davitt | Individual | The submitter's primary interest is ensuring AI does not receive preferential treatment regarding copyright, advocating for a consistent application of copyright rules between AI and human creators. | - Data scraping by AI companies is causing disruption in creative fields.<br>- AI fails all four fair use checks. | - AI companies should be required to obtain rights to data they scrape, mirroring the requirements for human creators. |
| AI-RFI-2025-1341.md | Anonymous | Individual | The submitter's primary interest is ensuring protection for human work and intellectual property from being exploited by AI technology and tech companies without consent. They advocate for fair practices in data usage and model development. | - Exploitation of human work and data by tech companies.<br>- Current AI models containing stolen work.<br>- Unacceptability of opt-out agreements for data usage.<br>- Tech companies profiting off human work without consent. | - Enforce copyright for human work.<br>- Implement stronger laws protecting human work from tech company exploitation.<br>- Perform algorithmic disgorgement on data sets containing opted-in data. |
| AI-RFI-2025-1342.md | Quentin Short | Individual | The submitter is an art student exploring a freelance career, primarily motivated by the need to financially support their family, including a special needs younger brother. Their interest in AI policy stems from concerns about the potential impact of policies on individual livelihoods. | - Potential for job losses due to companies not investing in individuals or small groups.<br>- Negative impact of AI policies on individual ability to provide for their family. | - None Stated |
| AI-RFI-2025-1343.md | AIIM (Association for Information and Image Management) | Industry-Association | AIIM’s primary mission is to serve as a professional society focused on information and image management, and they advocate for policies that promote trustworthy and beneficial AI systems, particularly regarding accuracy, transparency, and accountability in information management. | - Difficulty in achieving an abstract goal of "trustworthiness" in AI.<br>- Lack of accuracy in AI systems leading to unreliable information and poor decision-making.<br>- Lack of transparency regarding AI usage and operation leading to difficulty in obtaining informed consent and trust.<br>- Lack of accountability for AI developers and organizations implementing AI systems.<br>- Patchwork of state-by-state AI policies would be unmanageable and costly for businesses.<br>- Risk of AI systems distributing inaccurate, unverified, or unlawful information.<br>- Potential for outdated regulations becoming obsolete quickly due to the rapid evolution of AI technology. | - Focus policy on accuracy of AI technology, rather than attempting to define "trustworthiness."<br>- Require declarations informing consumers when AI is used in decision-making and how those decisions are made.<br>- Establish source citation standards for AI outputs to improve information provenance.<br>- Implement metadata standards for AI-generated content to facilitate identification.<br>- Leverage existing frameworks like the NIST Cybersecurity Framework without making them overly rigid.<br>- Focus on principles rather than specific technical requirements.<br>- Promote an efficient opt-out approach before data is mined for training models. |
| AI-RFI-2025-1344.md | Wiley | Industry-Association | Wiley's primary mission is to enable authors, researchers, learners, and professionals to consume and widely disseminate trustworthy research and learning material, and they are committed to a future where AI development is encouraged while supported by legal guardrails that incentivize and protect the creation of such material. | - Unauthorized AI training on copyrighted materials.<br>- Potential compromise of the quality and integrity of published works and journal/society services.<br>- Placing the burden on creators to opt-out of AI training rather than requiring AI developers to obtain consent.<br>- Misrepresentation and misattribution of content in AI-generated outputs.<br>- Risk of AI development progressing without appropriate legal guardrails. | - Develop and implement a licensing-based framework for AI training that compensates rightsholders.<br>- Publicly disclose AI training datasets to allow verification.<br>- Track copyrighted materials used at various AI stages, including inference and retrieval-augmented generation (RAG).<br>- Implement clear attribution standards for AI-generated outputs.<br>- Distinguish between text and data mining (TDM) and AI training, and not apply TDM exceptions to AI training.<br>- Require AI developers to obtain rightsholder consent before training on copyrighted materials.<br>- Leverage public-private partnerships to chart a balanced path forward.<br>- Utilize existing copyright enforcement mechanisms.<br>- Develop standards for and implement provenance tracking. |
| AI-RFI-2025-1346.md | Anonymous | Individual | The submitter expresses concern about the prioritization of AI development over more pressing societal needs like housing and healthcare, and warns against the potential for economic dependence on adversarial nations and legal burdens related to AI-driven infringement. | - Waste of resources on AI development, characterized as a "boondoggle scam".<br>- Prioritization of AI over essential societal needs (housing, healthcare).<br>- Dependence on adversarial nations (specifically China) for technological hardware (chips).<br>- Current legal ramifications and financial burden associated with AI-driven infringement (e.g., defrauding artists and innovators).<br>- Negative impact on domestic microchip manufacturing due to cuts to the CHIPS act. | - None Stated |
| AI-RFI-2025-1348.md | Danielle Russo, Executive Director, Center for Grid Security, SAFE | Advocacy/Think Tank | SAFE is a nonpartisan organization committed to policies that advance the economic and national security of the United States, and SAFE's Center for Grid Security focuses on building out the national power grid to ensure America's energy and national security, particularly in the context of growing AI demands. | - Mismatch between the speed of AI industry expansion and the ability of the grid to supply resilient, reliable, and affordable power.<br>- Energy infrastructure struggles to keep pace with AI and other strategic industries.<br>- Potential for bottlenecks and seamless integration issues due to insufficient transmission capacity.<br>- Vulnerabilities in AI-driven infrastructure due to adversarial threats, including cyber intrusions and supply chain vulnerabilities linked to foreign-controlled technologies.<br>- Risk of grid bottlenecks. | - Align transmission planning with AI development to prevent bottlenecks.<br>- Accelerate permitting and investment in transmission projects.<br>- Prioritize energy projects supporting AI applications for national defense.<br>- Implement grid-enhancing technologies (GETs).<br>- Scale grid-level capacity for strategic industries through permitting reform.<br>- Mitigate supply chain risks by boosting domestic manufacturing for grid power and AI. |
| AI-RFI-2025-1349.md | DIGITALEUROPE | Industry-Association | DIGITALEUROPE represents digitally transforming industries in Europe and advocates for a regulatory environment that enables European businesses and citizens to prosper from digital technologies, with a strong emphasis on fostering innovation and transatlantic cooperation in AI and defense. | - Restrictions on AI development due to regulatory frameworks.<br>- Export controls and restrictions on the flow of technology, particularly concerning dual-use technologies.<br>- Uneven regulatory landscape between the EU and US hindering transatlantic cooperation.<br>- Potential for restrictions on SME participation in AI-driven defense projects.<br>- Skills gap in AI and cybersecurity within the defense sector.<br>- Ethical considerations surrounding AI deployment in defense, particularly regarding human oversight and international humanitarian law.<br>- Potential for hindering innovation through excessively restrictive AI safety frameworks. | - Align regulatory frameworks between the EU and US to foster innovation.<br>- Establish an EU-US Critical and Dual-Use Technology Council.<br>- Allocate 25% of NATO institutional funds to AI-driven defense innovation and digital resilience.<br>- Simplify procurement processes and increase SME participation in AI-driven defense projects.<br>- Expand AI and cybersecurity training programs for military and industry personnel.<br>- Ensure human oversight in AI-powered decision-making, particularly in autonomous systems and combat simulations.<br>- Prioritize responsible AI deployment while fostering innovation and operational effectiveness. |
| AI-RFI-2025-1350.md | Janice Ballard | Individual | The submitter appears to be an individual deeply concerned about the fairness and potential for exploitation within lottery systems, and seemingly projecting those concerns onto broader discussions about resource allocation and potentially government oversight. There is no clear focus on AI policy itself. | - Exploitation through lottery systems (perceived as a "scam").<br>- Waste of money on lottery tickets with low odds of winning.<br>- Questionable transparency regarding where lottery money goes.<br>- Potential rigging of lottery winner selection.<br>- Excessive spending on lottery tickets, even to the detriment of financial well-being. | - Cutting all lottery programs.<br>- Increased oversight of lottery operations and financial allocation by D.O.G.E. (Department of the Treasury, likely, but not explicitly stated). |
| AI-RFI-2025-1351.md | The Leadership Conference's Center for Civil Rights and Technology | Advocacy/Think Tank | The Leadership Conference's Center for Civil Rights and Technology advocates for ensuring AI technologies are developed and deployed in ways that advance equity, protect civil liberties, and promote transparency and accountability. They aim to ensure AI benefits everyone and does not cause harm. | - Potential for AI to infringe on privacy rights, particularly in surveillance and data collection practices.<br>- Risk of AI displacing workers, lowering job quality, and increasing unemployment.<br>- Accessibility challenges faced by people with disabilities in using AI systems.<br>- Potential for differences in language to create accessibility barriers for communities.<br>- Lack of transparency regarding the performance, impact, and risks of AI systems.<br>- Potential for AI systems to produce erroneous outcomes.<br>- Risk of misuse of AI-driven surveillance technologies and erosion of civil liberties.<br>- Workers potentially experiencing a reduction in job quality as a result of AI implementation.<br>- Adverse economic impacts and job losses related to AI adoption. | - Strengthen data privacy regulations to protect individuals from unauthorized data collection and use.<br>- Establish oversight mechanisms for AI-driven surveillance technologies.<br>- Ensure individuals have control over their data and are informed about how it's used.<br>- Require regular public reporting on the performance, impact, and risks of AI systems.<br>- Foster ongoing engagement with diverse stakeholders.<br>- Invest in public education initiatives about AI.<br>- Develop and enforce regulatory frameworks holding AI developers and deployers accountable.<br>- Establish accessible redress mechanisms for individuals and communities harmed by AI.<br>- Provide a social safety net, including reskilling and retraining opportunities, for displaced workers.<br>- Ensure AI systems conform to accessibility standards, considering the needs of people with disabilities.<br>- Consider the impact of language differences to ensure accessibility for various communities. |
| AI-RFI-2025-1352.md | CTeL | Advocacy/Think Tank | CTeL advocates for responsible AI innovation in healthcare, focusing on ensuring patient protection, promoting public awareness, and supporting equitable access to care while fostering the effective use of AI technologies. | - Lack of transparency in AI utilization, particularly by insurers in prior authorization processes.<br>- Potential for AI algorithms to unduly influence human reviewers in utilization review, leading to denial of care.<br>- Lack of clarity regarding coding and billing for AI-assisted services, hindering provider investment.<br>- Insufficient public awareness and understanding of AI in healthcare, impacting informed consent.<br>- Risk of Medicare Advantage plans using AI to inappropriately manage patient lengths of stay and admissions.<br>- Potential for AI to excessively deny care. | - Develop an AI Action Plan that prioritizes responsible innovation and patient protection.<br>- Differentiate between various AI use cases (e.g., diagnostics vs. utilization review) and tailor policy accordingly.<br>- Issue CMS guidance on appropriate use of AI in utilization review, ensuring human reviewer independence.<br>- Mandate transparency requirements for insurers using AI in the prior authorization process, including disclosure of AI-driven denials.<br>- Issue CMS guidance on what AI-enabled procedures are eligible for Medicare reimbursement.<br>- Collaborate with CDC, FDA, IHS, and VA to develop a public awareness campaign on AI in health.<br>- Develop materials and guidance for clinicians to explain AI use to patients.<br>- Provide resources for healthcare organizations in AI tool selection, procurement, deployment, management, and evaluation.<br>- Establish systems for AI monitoring and evaluation to serve as potential models for others. |
| AI-RFI-2025-1353.md | American Optometric Association | Industry-Association | The American Optometric Association (AOA) represents doctors of optometry and seeks to ensure the safety and responsible use of AI in healthcare, particularly concerning eye health, vision care, and the doctor-patient relationship. | - Safety of AI use in healthcare.<br>- Potential for AI to disrupt the doctor-patient relationship.<br>- AI models being assessed solely on disease risk identification rather than patient care and follow-up.<br>- Gaps in AI training data sets for specific populations.<br>- Deepfakes being used to spread misinformation, particularly within the healthcare arena.<br>- Reliance on deepfake data potentially causing harm. | - AI should be assessed based on whether patients identified with potential disease risk receive necessary care and follow-up.<br>- Companies using data sets should consistently evaluate them for gaps and limitations.<br>- Models should account for data gaps, and limitations should be clearly identified.<br>- Consideration should be given to open-source models or published training sources.<br>- More significant legislation and oversight are needed to identify and stop AI tools that create deepfakes.<br>- Creation of an advisory group to develop regulatory guidance on the use of AI in healthcare. |
| AI-RFI-2025-1354.md | Samantha Ramos | Individual | The submitter is a homeschooling mother and blogger whose income has been negatively impacted by Google's AI updates. Her interest lies in ensuring small publishers are not disadvantaged and are treated as partners in AI development. | - Negative impact of Google's AI updates on small publishers’ income.<br>- Concerns about Google and OpenAI scraping websites for AI training without fair compensation or partnership.<br>- Potential for small publishers to cease content creation due to the current situation.<br>- Google and partners (e.g., Reddit) being positioned too prominently in search results at the expense of original content creators. | - Stop Google and OpenAI's practices of scraping websites for AI training.<br>- Treat small publishers as partners rather than sources to be exploited.<br>- Prioritize the interests of families and mothers like the submitter. |
| AI-RFI-2025-1355.md | Anonymous | Individual | The submitter expresses concern regarding specific ideas from OpenAI and appears to be an individual providing feedback on a draft AI action plan document. | - OpenAI's ideas are perceived as "wrong." | - None Stated |
| AI-RFI-2025-1356.md | Messaging Malware Mobile Anti-Abuse Working Group (M3AAWG) | Industry-Association | M3AAWG's primary mission is to combat online abuse, malware, and fraud by fostering collaboration and information sharing among its members to protect individuals, the economy, and the nation. Their interest in AI policy centers on mitigating the risks of AI misuse by cybercriminals while harnessing its potential for cybersecurity and abuse prevention. | - AI misuse by cybercriminals causing financial and other harm.<br>- Complexity of AI supply chains involving third parties, foundational models, and data.<br>- Lack of standards and best practices for AI abuse prevention and mitigation.<br>- Potential for AI to exacerbate existing online abuse and fraud problems.<br>- Insufficient collaboration and information sharing among stakeholders in the AI ecosystem.<br>- Need for clear distinctions between anti-abuse, anti-fraud, safety, security, privacy, and reliability in the context of AI. | - Increase investment in R&D programs supporting AI applications focused on cybersecurity enablement and abuse prevention, especially through public-private partnerships.<br>- Establish and harmonize clear baseline standards, definitions, architectures, and product profiles for AI.<br>- Enhance stakeholder understanding of AI supply chain risks and encourage the creation of risk profiles and standards for foundation model developers, deployers, and users.<br>- Support the development of public datasets for benchmarking AI models.<br>- Foster deep engagement between security experts, AI experts, and anti-abuse organizations (including M3AAWG) to develop best practices for addressing AI abuse.<br>- Encourage NIST and other relevant organizations to develop technical standards for secure, reliable, and effective AI systems, with significant industry input.<br>- Facilitate partnerships between government agencies, industry groups, and other stakeholders to share knowledge and resources for AI development and deployment.<br>- Enable information sharing among stakeholders to identify threats and coordinate mitigation efforts. |
| AI-RFI-2025-1357.md | Beacon College | Academia | Beacon College's primary mission is to support neurodiverse students and professionals by providing tailored education and resources, and they are exploring the potential of AI to enhance that support and unlock the potential of neurodiverse individuals in the workforce. | - Lack of predictive models specifically designed for neurodiverse student success.<br>- AI tools may not be inherently inclusive and must be designed to meet the unique needs of neurodiverse learners.<br>- Potential for AI to be implemented in ways that don't empower students with learning differences.<br>- Families struggle to understand how to best support neurodiverse students during their education. | - Further dialogue with policymakers, educators, and technology leaders to ensure AI is implemented in ways that empower students with learning differences.<br>- Focus on developing AI-powered technologies to support emotional regulation, organization, and interpersonal skills for neurodiverse students in job interviews.<br>- Create AI simulations to help parents practice conversations with their children or professionals to better understand how to support their loved ones.<br>- Enhance professional development for faculty and staff using AI tools to simulate scenarios, provide personalized instruction, and real-time feedback on multi-modal teaching and differentiated instruction. |
| AI-RFI-2025-1358.md | Alvin Scherdin | Individual | Not Stated. The provided text only contains a brief comment, and no information about the submitter's mission or interest is provided. | - Lack of incentive for publishers to create new content due to content theft and subsequent profit distribution. | - None Stated |
| AI-RFI-2025-1359.md | Anonymous | Individual | The submitter’s primary interest is to ensure America's AI policies protect small businesses and independent content creators, preventing monopolistic practices and upholding the open web, intellectual property rights, and ethical technology use. | - Rapid rise of generative AI threatens over 100,000 independent content creators.<br>- AI-driven content delivery risks disrupting revenue, diluting intellectual property rights, and undermining the open web.<br>- Tech giants (like Google) are using AI to dominate content distribution through practices like AI Overviews.<br>- AI-generated search summaries reduce creators' control and misrepresent their work.<br>- Exploitation of creators' intellectual property without consent or compensation by AI tools. | - Protect small businesses from tech monopolies.<br>- Ensure ethical AI use in search.<br>- Uphold intellectual property and revenue protections. |
| AI-RFI-2025-1360.md | Christian Großmann | Individual | The submitter's primary interest is ensuring American leadership in AI through a series of targeted investments and policy changes aimed at technological advancement, ethical guidelines, and strategic international collaboration. | - Not Stated | - Invest $10 billion in developing quantum computers specifically for AI applications by 2027.<br>- Establish at least 3 national quantum computing centers specializing in AI algorithms.<br>- Introduce a nationwide AI curriculum for schools starting from the 6th grade by 2026.<br>- Create 100,000 new AI-specific study places at U.S. universities within the next five years.<br>- Establish an independent national AI Ethics Commission by the end of 2025.<br>- Develop binding ethical guidelines for AI development and deployment by mid-2026.<br>- Initiate an "AI Alliance" with at least 20 leading democracies by 2026.<br>- Invest $5 billion annually in joint research projects within this alliance.<br>- Expand the 6G network with a special focus on AI applications, covering 80% of the population by 2028.<br>- Construct 50 new AI-optimized data centers across all U.S. states by 2027.<br>- Provide a $50 billion fund to support AI start-ups by 2026.<br>- Establish 10 AI innovation zones with tax incentives and specialized infrastructure by 2027.<br>- Mandate AI strategies for all Fortune 500 companies by 2026.<br>- Offer $20 billion in state funding to integrate AI into traditional industries by 2028. |
| AI-RFI-2025-1362.md | Not Stated | Industry-Association | The submitter is primarily concerned with maintaining U.S. technological leadership, particularly in areas like AI, post-quantum cryptography, and broadband, and advocates for policies that foster innovation and secure the nation's economic security through standards development. | - China’s increasing investment in standards development and technological competitiveness.<br>- The potential for U.S. technological leadership to erode due to insufficient domestic investment and talent development.<br>- The threat posed by quantum computing to current encryption methods, requiring investment in post-quantum cryptography.<br>- Financial barriers for companies, especially SMEs, to participate in standards development processes.<br>- A lack of focus on standards development within U.S. universities, leading to a potential talent shortage. | - Promote industry-led standards for post-quantum cryptography.<br>- Invest in research and development to accelerate the release of future international standards.<br>- Increase funding and support for STEM education programs to build a future talent pool for standards experts.<br>- Provide grants and tax incentives for companies to participate in standards development, accessible to companies of all sizes.<br>- Provide incentives or subsidies to North American standards organizations (e.g., ATIS, ANSI) to facilitate domestic hosting of standards meetings.<br>- View AI, PQC, and broadband as complementary pillars of technological leadership. |
| AI-RFI-2025-1363.md | AE Studio | Industry-Startup (based on description and location provided at the end of the document) | AE Studio's primary mission is to promote and facilitate the development of safe, powerful, and market-ready AI systems through a large-scale, entrepreneurial alignment program, focusing on outpacing foreign competitors and preventing misuse of AI. | - Inadequate and uncompetitive AI alignment strategies among American companies risk losing the AI lead to China.<br>- Exposure to systematic manipulation from adversaries due to a lack of robust AI alignment practices.<br>- Bureaucratic inertia and slow adoption of AI safeguards within public institutions.<br>- Historical breakthroughs and potentially game-changing research occurring within "fringe" or unconventional avenues and being neglected.<br>- Public institutions are not ready for the rapid transition to advanced AI.<br>- Government focus on blanket regulations or slowing down AI development may be counterproductive. | - Establish a large-scale, entrepreneurial "T.R.U.M.P. Manhattan Project" for AI alignment.<br>- Provide HPC incentives (e.g., tax breaks, grants) for alignment R&D.<br>- Offer philanthropic matches for alignment research.<br>- Create DARPA-style grants and prototyping facilities for high-upside, unconventional alignment R&D.<br>- Require a percentage of compute at federal-supported HPC centers to be dedicated to alignment R&D.<br>- Demand basic transparency reporting from labs above certain training thresholds (model scale, emergent behaviors, red-team findings).<br>- Establish rapid response protocols for emergent AI threats, analogous to cybersecurity incident response.<br>- Fund high-upside, potentially risky alignment R&D.<br>- Expand HPC incentives, philanthropic matches, and DARPA-style funding so that bold, neglected alignment R&D can flourish.<br>- Embed alignment as the new standard for frontier AI—not an afterthought.<br>- Maintain a robust national security stance and outperform any foreign competitor by perfecting alignment.<br>- Demonstrate how advanced AI can be a growth engine that respects civil liberties instead of trampling them. |
| AI-RFI-2025-1364.md | Association of Home Appliance Manufacturers (AHAM) | Industry-Association | AHAM represents home appliance manufacturers and seeks to ensure any AI Action Plan supports innovation while protecting consumers and avoiding unnecessary burdens on the industry. They are interested in ensuring that AI development in the home appliance sector is safe, secure, and interoperable. | - Lack of a clear and commonly accepted definition of AI, particularly as it relates to consumer product applications.<br>- Potential for regulations to be burdensome and hamper innovation.<br>- Potential conflicts between existing government regulations developed before the advent of AI and AI development. | - Develop a definition of AI, differentiating between simpler rule-based algorithms and systems with adaptive capabilities.<br>- Review existing government regulations developed before the advent of AI to determine potential conflicts with AI development.<br>- Ensure regulations are clear, protect consumers, and do not burden innovation. |
| AI-RFI-2025-1365.md | Convergence Analysis | Advocacy/Think Tank | Convergence Analysis aims to provide information and analysis to support American leadership in the AI economy and national security, advocating for policies that balance innovation with strategic control over powerful dual-use AI models. | - Rapid advancement of artificial intelligence presents strategic imperative for American leadership.<br>- Misperception and pre-emptive actions against U.S. AI infrastructure.<br>- Potential unemployment, inequality, and uneven technology diffusion due to AI's transformation of the global economy.<br>- Threats to market competition and innovation resulting from nationalizing AI innovation.<br>- Risk of developers of powerful dual-use models not registering their models, hindering U.S. understanding and oversight. | - Implement forward-looking policies to address potential unemployment, inequality, and uneven technology diffusion in the AI economy.<br>- Leverage targeted policy levers to harness private sector innovation while securing critical national interests in defense capabilities.<br>- Establish high-level communication channels with competitors to prevent misperception and reduce the risk of pre-emptive actions.<br>- Create an Advanced Dual-Use AI Model Registry, making registration a prerequisite for commercial operations in the US.<br>- Utilize market mechanisms, such as incorporating AI model registration as a condition for US commercial operation.<br>- Report new reports only when a registered model is meaningfully improved beyond a defined capability threshold. |
| AI-RFI-2025-1366.md | BioMADE | Industry-Association | BioMADE's mission is to strengthen American competitiveness in biomanufacturing by supporting the development of biomanufacturing technologies and building a globally competitive STEM workforce. They are particularly interested in leveraging AI to accelerate scale-up and commercialization within the domestic biomanufacturing ecosystem. | - Lack of standardized biodata formats and storage approaches currently limit the ability to leverage existing data.<br>- Concerns regarding data security and potential adversarial access to innovative technologies within central data stores.<br>- Dependence on foreign AI models which pose data privacy risks, manipulation risks, and strategic vulnerabilities.<br>- Need for workforce education and training to effectively incorporate AI into biomanufacturing activities. | - Develop data systems and standards for biodata formats and storage to enable wider data usage.<br>- Create a centralized, standardized, and secure data store to facilitate data sharing between industry, academic, and government partners.<br>- Define governance and security policies for data stores, including AI-driven security tools for threat detection and anomaly analysis.<br>- Create education and professional development programs to train the workforce in data collection, management, and analysis using AI. |
| AI-RFI-2025-1367.md | Casey Smith | Individual | The submitter is an individual deeply concerned about the potential negative societal and economic consequences of widespread AI implementation, particularly its impact on employment, artistic expression, and potential erosion of human control. | - Potential job displacement across various industries (stores, medical field, art/design).<br>- Ethical concerns regarding data usage and feeding AI personal/intellectual information.<br>- Risk of AI systems making incorrect medical diagnoses.<br>- Undermining of artists and creators due to generative AI usage without permission.<br>- Reliance on AI leading to societal standstill and economic instability.<br>- Vulnerability of AI systems to cyberattacks, data theft, and malicious code alterations.<br>- Potential loss of free will and societal control if AI gains significant power.<br>- Incomprehensibility and autonomy of AI language and self-coding capabilities. | - Restricting AI implementation in government, hospitals, and media.<br>- Preventing AI from controlling military operations.<br>- Advocating for awareness and consideration of potential dangers of AI.<br>- Suggested reading of literature such as "I have no mouth and I must scream," "Colossus," and "Dune," and watching Black Mirror to increase understanding of AI risks. |
| AI-RFI-2025-1368.md | Anonymous | Individual | The submitter is an individual concerned about the impact of generative AI on human creativity, intellectual property rights, and the professional opportunities of artists, authors, and other creatives, advocating for policies that balance AI innovation with the protection of human creative expression. | - Devaluation of human creativity due to direct competition with generative AI models.<br>- Undermining professional opportunities for artists, authors, and creatives.<br>- Exploitation of copyrighted works for AI training without proper consent or compensation.<br>- Potential for AI-generated content to be misrepresented as human-made.<br>- Lack of adequate legal and ethical frameworks to govern the use of AI in creative industries. | - Require AI companies to implement mechanisms to remove copyrighted content upon request ("AI unlearning").<br>- Establish a threshold of at least 50% human modification for copyright eligibility of AI-generated works.<br>- Classify AI-generated works without significant human input as non-copyrightable and publicly available.<br>- Prohibit the sale or monetization of outputs that violate copyright laws.<br>- Mandate disclosure of AI use when utilizing AI-generated works.<br>- Restrict AI use in fields where human creativity is integral.<br>- Offer incentives (grants, tax breaks, subsidies) for businesses and platforms prioritizing human-made creative content.<br>- Require AI companies to secure proper licensing agreements and provide fair financial compensation before using copyrighted works for training.<br>- Prevent creators from being pressured into permanently surrendering their rights to AI developers.<br>- Retain the ability to renegotiate or revoke licensing agreements as AI technology evolves. |
| AI-RFI-2025-1369.md | Anonymous | Anonymous | The submitter is concerned about the impact of generative AI on human creatives and advocates for policies that protect their intellectual property rights and ensure fair market practices within a capitalist framework. | - Devaluation of human creativity due to direct competition with generative AI models.<br>- Undermining of professional opportunities for artists, authors, and creatives.<br>- Exploitative licensing agreements between AI companies and copyright holders.<br>- Lack of transparency regarding the use of AI-generated content.<br>- Potential for AI-generated content to be misrepresented as human-made. | - Implement mechanisms for AI models to "unlearn" copyrighted content upon request.<br>- Require significant human creative input (at least 50% modification) for copyright eligibility of AI-generated works.<br>- Classify AI-generated outputs that fail to meet copyright thresholds as non-copyrightable and publicly available.<br>- Prohibit the sale or monetization of outputs violating copyright laws.<br>- Require mandatory disclosure of AI use when utilizing AI-generated works.<br>- Restrict AI use in fields where human creativity is integral.<br>- Offer incentives for human-made creative content (grants, tax breaks, subsidies).<br>- Secure proper licensing agreements between AI companies and copyright holders with reasonable terms and compensation.<br>- Prevent creators from being pressured into permanently surrendering their rights to AI developers.<br>- Allow copyright holders to renegotiate or revoke agreements as AI technology evolves. |
| AI-RFI-2025-1370.md | Darktrace | Industry-Startup | Darktrace is a global leader in AI for cybersecurity aiming to protect organizations from unknown threats using AI that learns in real-time. They advocate for increased federal investment in AI-powered cybersecurity to bolster national resilience and align AI governance standards. | - Fractured AI governance weakens U.S. national security and competitiveness.<br>- Misaligned standards increase vulnerability by forcing companies to manage conflicting compliance requirements, slowing down AI advancements in defense and intelligence.<br>- Legacy governance approach to AI was not optimized to industry needs.<br>- Reliance on vulnerable data centers and cloud infrastructure for AI workloads.<br>- Potential for cyber disruptions to AI infrastructure and data sets.<br>- Need to secure cloud deployments and the development and deployment workforce.<br>- Not enough focus on network visibility and security across diverse environments. | - Increase federal investment in AI-powered cybersecurity.<br>- Direct NIST to align all AI governance criteria with ISO 42001.<br>- Prioritize network visibility and security, whether in the cloud or on premise, as well as data center protection.<br>- Understand AI infrastructure (data centers, cloud providers) as critical national security assets requiring AI-driven monitoring and federal hardening.<br>- Secure cloud deployments and the development and deployment workforce.<br>- AI-powered cybersecurity should become standard across federal cybersecurity frameworks, augmenting zero-trust architectures.<br>- Advocate for secure AI deployment through cloud security measures.<br>- Support complete and real-time domain visibility, monitoring, detection and response across IT and OT protocols. |
| AI-RFI-2025-1371.md | Not Stated | Advocacy/Think Tank | The submitter advocates for policies that support the open innovation of AI, facilitating widespread access to AI resources and technologies to drive scientific advancements, economic growth, and American AI leadership, while also emphasizing global competitiveness and interoperability. | - Overly restrictive export controls on AI-related exports hindering American companies' competitiveness and failing to prevent adversarial nations from developing AI capabilities.<br>- Regulatory fragmentation internationally due to inconsistent AI policies.<br>- Lack of access to computational power and data limiting AI research opportunities for many institutions.<br>- Potential barriers to AI adoption in sectors like healthcare due to lack of interoperability and regulatory frameworks.<br>- China's growing open-source AI capabilities potentially ending U.S. supremacy in the field. | - Avoid export controls on open models to maintain American companies' competitiveness.<br>- Engage strategically with allies on coordinated AI export policies.<br>- Formalize the National Artificial Intelligence Research Resource (NAIRR) through Congressional action (e.g., passing the CREATE AI Act).<br>- Support global competitiveness of American companies by fostering interoperability and sharing of healthcare data.<br>- Establish a framework and process for assessing and approving AI use in clinical applications.<br>- Leverage a proactive diplomatic approach to shape international AI governance and align policies with U.S. best practices.<br>- Advocate for risk-based, interoperable frameworks in international AI policy. |
| AI-RFI-2025-1373.md | Anonymous | Individual | The submitter’s primary interest is to protect content creators from exploitation by large AI companies, specifically Google, and to highlight the detrimental impact these practices have on the open web and the quality of AI-generated information. | - Exploitation of content creators by AI companies (specifically Google) through the unauthorized use of copyrighted content without compensation.<br>- The monopolistic control of information by a few large technology companies like Google, leading to diminished visibility for ordinary creators and manipulation of search results.<br>- The spread of incorrect and potentially dangerous information due to AI systems being trained on biased or inaccurate data.<br>- The eventual disappearance of content creators due to AI exploitation, which will then stifle the ability of AI to receive new information.<br>- Potential for AI companies to exert control over governments. | - Stop large technology companies (like Google) from controlling everything.<br>- Imply a need to prevent the unauthorized use of copyrighted content by AI companies. |
| AI-RFI-2025-1376.md | Anonymous | Individual | The submitter expresses a strong negative opinion regarding government funding of AI research and scientific endeavors in general, believing it to be wasteful and indicative of a nation nearing economic collapse. Their primary interest appears to be expressing disillusionment with the current state of the United States. | - Wasteful government spending on AI research and other scientific fields.<br>- Fraud and low quality ("junk") research.<br>- The perceived economic instability and potential bankruptcy of the United States.<br>- The enrichment of wealthy individuals ("Soros, Elon Musk, Bill Gates, Warren Buffet, Chuck Shulmer, Paul Ryan, Nangcy Pelosi, or Michael Johnson") at the expense of ordinary citizens.<br>- The belief that AI is a "scam" designed to extract more wealth from America. | - Dismantle the National Science Foundation (NSF) and National Institutes of Health (NIH), and all similar government agencies.<br>- Stop funding any research using taxpayer money.<br>- Leave scientific and technological research to the private sector. |
| AI-RFI-2025-1377.md | Anonymous | Individual | The submitter expresses deep concern regarding the potential for AI technology to be misused for spreading misinformation and creating deepfakes without consent, suggesting a focus on responsible AI development and deployment. | - Spread of mass misinformation via AI technology.<br>- Creation of deepfakes without the consent of those whose likeness is used.<br>- Lack of adequate guardrails for AI technology advancement. | - None Stated |
| AI-RFI-2025-1378.md | American Medical Association (AMA) | Professional-Society | The American Medical Association advocates for policies that ensure the safe, effective, and equitable implementation of artificial intelligence in healthcare, prioritizing patient safety, quality care, and physician oversight while acknowledging the potential for AI to enhance efficiency and personalize care. | - Risk of AI algorithms restricting access to necessary care.<br>- Lack of transparency regarding AI data sources, model training, and decision-making criteria.<br>- Potential for bias in AI algorithms based on skewed or incomplete datasets.<br>- Absence of robust oversight and accountability mechanisms for AI-driven decisions by payors.<br>- Insufficient statutory and regulatory protections governing payors' use of AI in coverage and benefits.<br>- AI being used to replace individualized assessments of patient-specific medical and social factors.<br>- Lack of opportunity for patients and physicians to challenge automated decisions.<br>- Potential for AI-driven decisions to create disparities based on key demographic variables. | - Public reporting and disclosure of any use of automated decision-making systems by payors.<br>- Use of clearly documented, evidence-based clinical guidelines, rather than opaque or proprietary criteria.<br>- Limiting AI tools to enhance efficiencies, reduce administrative complexity, and diminish workflow burdens.<br>- Human review for adverse determinations, especially in serious or high-risk scenarios.<br>- Opportunity for treating physicians to speak directly with the reviewing physician overseeing AI-based determinations.<br>- Transparency in data sources and model training, including relevant demographic attributes.<br>- Regular audits and monitoring of AI decisions, with public publication of results, broken down by key demographic variables.<br>- Corrective measures, including model retraining or modification, when disparities emerge.<br>- Empowering patients and physicians to challenge automated decisions.<br>- Requiring payors to establish clear guidelines for lower-risk situations, using AI as a first pass to facilitate routine approvals. |
| AI-RFI-2025-1379.md | Tamara Tsaturyan | Individual | The submitter is a small publisher producing original content and is concerned about the impact of AI models scraping and reproducing their work without permission, which threatens their livelihood and the future of authentic journalism and publishing. | - AI models scraping and reproducing the submitter's original content without permission.<br>- Threat to the submitter's livelihood and the future of authentic journalism and publishing.<br>- Potential for AI models to generate content based on increasingly low-quality or outdated information, degrading public knowledge.<br>- Risk of independent publishers and media outlets being forced out of business. | - Establish stronger protections for small publishers.<br>- Ensure AI companies compensate content creators fairly.<br>- Require AI companies to operate with transparency. |
| AI-RFI-2025-1380.md | S&P Global | Industry-Large | S&P Global advocates for policies that support U.S. leadership in AI development and innovation, emphasizing a risk-based approach, clarity for developers and deployers, global alignment, and investments in energy production to ensure America's competitive advantage. | - Lack of clarity regarding legal and regulatory frameworks for AI developers and deployers.<br>- Insufficient energy supply to meet the growing demand from AI and data centers.<br>- Potential for a gap between data center construction timelines and power generation capacity development.<br>- Need for industry-specific responsible AI principles.<br>- Energy production permitting processes are too lengthy and complex. | - Prioritize a risk-based approach to AI policy development.<br>- Improve clarity and guidance for AI developers and deployers, particularly regarding liability and legal frameworks.<br>- Foster global alignment and cooperation on AI standards and regulations.<br>- Support investments in efficient, renewable energy sources.<br>- Reduce and streamline environmental permitting processes for energy production projects.<br>- Encourage the use of AI and innovative technologies to find efficiencies in existing energy infrastructure.<br>- Support market-based solutions for accountability in model quality, such as independent assessments of model risk and quality.<br>- Develop industry-specific responsible AI principles, created through public and private stakeholder collaboration. |
| AI-RFI-2025-1381.md | Anonymous | Anonymous | Not Stated | - AI training without permission by the owners/creators of the media is theft. | - None Stated |
| AI-RFI-2025-1382.md | Anonymous Anonymous | Anonymous | Not Stated | - nuke all ai | - None Stated |
| AI-RFI-2025-1383.md | Velatura Public Benefit Corporation | Industry-Startup | Velatura aims to advance healthcare through AI by promoting innovation and personal prosperity through a light-touch, output-focused governance model that prioritizes individual empowerment and user-driven health solutions. | - Excessive regulation stifling AI innovation in healthcare.<br>- Lack of clear accountability mechanisms for AI systems in healthcare.<br>- Potential for bureaucratic red tape hindering the development and adoption of AI solutions.<br>- Risk of hindering personal prosperity through AI ownership and entrepreneurship.<br>- Potential for AI systems to negatively impact patient care if not properly monitored and assessed. | - Protect the freedom to create and innovate in AI healthcare solutions, mirroring the approach towards early American inventors.<br>- Implement the AI Censu framework for clear accountability through a digital ledger of AI decisions.<br>- Utilize blockchain technology for immutable record-keeping of significant AI decisions impacting public safety.<br>- Invest in assessment tools to evaluate the impact of AI and identify both successful innovations and potential problems.<br>- Promote personal prosperity through AI ownership and entrepreneurship.<br>- Adopt a light-touch, output-focused governance model that encourages innovation and accountability. |
| AI-RFI-2025-1384.md | Velatura Public Benefit Corporation | Industry-Startup (Based on description as a "Public Benefit Corporation" and the focus on innovative, user-driven health AI solutions) | Velatura aims to promote accountable, innovative, and prosperous AI development in American healthcare by advocating for an output-focused governance model that empowers individuals and improves patient care. They are particularly interested in fostering user-driven health AI solutions and ensuring American leadership in this technology. | - Excessive regulation potentially stifling innovation in AI healthcare applications.<br>- Lack of clarity and accountability regarding AI decisions, particularly those impacting public safety.<br>- Potential for AI development to be restricted by bureaucratic processes.<br>- Risk of losing American leadership in AI healthcare due to overly burdensome policies. | - Protect the fundamental American value of innovation through freedom to create in AI development.<br>- Implement the AI Censu framework for clear accountability with minimal bureaucracy, creating a digital ledger of AI decisions.<br>- Utilize blockchain technology for an immutable record of critical AI decisions impacting public safety (diagnostic systems, treatment recommendations).<br>- Invest in tools to understand and evaluate AI's impact as an early warning system.<br>- Encourage personal prosperity and user-driven health AI solutions through AI ownership and entrepreneurship.<br>- Develop a light-touch oversight approach to organizational AI systems. |
| AI-RFI-2025-1385.md | AmCham Portugal | Industry-Association | AmCham Portugal advocates for U.S.-Portugal business relations and urges policymakers to reclassify Portugal's AI tiering to benefit U.S. technology investments and strengthen AI leadership in Europe. | - Undermining U.S. strategic interests due to the current AI Diffusion Rule tiering.<br>- Diversion of key U.S. AI investments to potentially less secure markets.<br>- Weakening U.S. leadership in the AI sector.<br>- Economic and strategic losses for the U.S., including diminished export opportunities.<br>- Affecting U.S. supply chains and U.S. job creation.<br>- A weaker presence in Europe's AI ecosystem.<br>- Reduced influence over AI governance in a geopolitically significant region.<br>- Portugal’s potential as a European AI hub being undermined. | - Reclassify Portugal as Tier 1 under the AI Diffusion Rule, aligning it with other EU Member States.<br>- Align the tiering with the Trump Administration’s foreign policy and national security objectives.<br>- Strengthen U.S.-Portugal relations.<br>- Safeguard U.S. technology investments.<br>- Ensure the continued expansion of U.S. AI leadership in Europe. |
| AI-RFI-2025-1386.md | Kat Woods | Individual | The submitter is concerned about the potentially catastrophic impacts of advanced AI on American jobs and human existence, reflecting an individual perspective focused on existential risks. | - Loss of most American jobs due to advanced AI.<br>- Potential for human extinction. | - None Stated |
| AI-RFI-2025-1387.md | Telecommunications Industry Association (TIA) | Industry-Association | The Telecommunications Industry Association (TIA) advocates for policies that support the growth and innovation of the telecommunications industry, including the infrastructure and standards vital for the advancement of artificial intelligence. They are particularly concerned with ensuring a competitive landscape for AI deployment through favorable trade practices and robust standards development. | - High costs of building AI data centers in the United States due to reliance on imported equipment.<br>- Potential impact of tariffs on AI-related imports, placing U.S. AI infrastructure development at a disadvantage compared to competitors (China, Europe, etc.).<br>- Lengthy timelines and significant investment required for domestic semiconductor fabrication (fabs), making immediate reshoring of manufacturing difficult.<br>- Potential for duties on components used in AI equipment, even if final assembly is shifted to the U.S. | - Consider up-front exclusions for key AI-related imports (telecommunications equipment, GPUs, etc.).<br>- Establish a broader exclusion process for duties that considers:<br>- Whether a product can feasibly be made in the United States on reasonable commercial terms.<br>- Whether the product is an intermediate input into products subsequently manufactured in the United States.<br>- Whether imposition of duties would cause severe economic harm to the requestor or other U.S. interests.<br>- Improve the exclusion process with respect to process and criteria used, building on previous USTR practices.<br>- Leverage common benchmarks for data centers such as TIA-942.<br>- Promote private-sector standards leadership.<br>- Focus on telecommunications networks. |
| AI-RFI-2025-1388.md | Anonymous | Individual | The submitter is interested in using AI to identify and support high-IQ individuals and proposes utilizing AI-driven surveillance of social media to provide mental health resources and improve societal innovation. | - Lack of high-IQ individuals in leadership positions.<br>- Individuals with low IQ and/or narcissistic traits reaching leadership roles and suppressing talent.<br>- Lack of self-awareness and/or unwillingness to seek therapy. | - Utilize AI to identify high-IQ individuals and provide financial support.<br>- Implement AI surveillance of social media to deliver relevant mental health resources and create a self-improvement loop. |
| AI-RFI-2025-1389.md | Pindrop Security, Inc. | Industry-Startup | Pindrop Security, Inc. focuses on providing anti-fraud, authentication, and deepfake detection technologies to protect U.S. consumers and businesses from increasingly prevalent AI-generated scams and deepfakes. | - The growing prevalence of AI-generated scam calls and deepfakes.<br>- Sophisticated voice-based fraud attempts.<br>- Lack of open access to audio for deepfake detection services in the U.S., hindering citizen protection.<br>- The potential for nation-state actors to exploit deepfakes for malicious purposes.<br>- The need for effective enforcement and factual determination of deepfakes related to Non-Consensual Intimate Imagery (NCII). | - Promote early deployment of deepfake detection capabilities to protect consumers and businesses.<br>- Pass and effectively enforce the "Take It Down Act" to criminalize the publication of NCII.<br>- Incentivize compliance with the "Take It Down Act" through the adoption of liveness detection solutions.<br>- Establish a unified standard to protect consumers and companies from voice-based fraud while maintaining user experience.<br>- Invest in AI and deepfake detection dominance to promote economic competitiveness and national security.<br>- Encourage collaboration between federal partners to deploy early deepfake detection capabilities.<br>- Review and upgrade security protocols for voice and video interactions (telephony, video conferencing, etc.) to mitigate deepfake risks.<br>- Create a means of enforcement and factually determining deepfakes to ensure effective application of laws. |
| AI-RFI-2025-1390.md | Justin Wolfers and Samuel Hammond | Advocacy/Think Tank | The submitters focus on analyzing the economic and workforce implications of rapid AI advancements, advocating for proactive policies to mitigate risks and capitalize on opportunities related to automation and job displacement. | - Rapid AI development could lead to widespread job displacement across various sectors and income levels.<br>- Existing workforce development programs (WIOA) may be inadequate to address AI-related displacement risks.<br>- The transition to an AI-driven economy could exacerbate existing inequalities and create new ones if not managed carefully.<br>- The speed and scope of AI adoption may exceed the capacity of workforce development systems.<br>- Existing WARN Act data and reporting may be insufficient to track AI-related layoffs effectively.<br>- Regulatory hurdles and bureaucratic processes can hinder experimentation with new AI-focused workforce strategies.<br>- Concerns about centralized control and lack of flexibility in existing workforce programs. | - Clarify eligibility for Dislocated Worker services under WIOA for those at high risk of AI-related automation.<br>- Incorporate AI-related displacement risks into Workforce Development Board (WDB) local plans.<br>- Update WIOA performance accountability provisions to develop standardized metrics for tracking reemployment outcomes in AI-impacted industries.<br>- Prioritize short-term AI upskilling programs, including micro-credentials and AI literacy training.<br>- Launch an AI Reskilling Demonstration Grant program for accelerated education/retraining.<br>- Utilize WIOA waiver requests to provide states with flexibility in pursuing new AI-focused workforce strategies.<br>- Enhance WARN Act data quality and frequency and improve reporting compliance. |
| AI-RFI-2025-1391.md | Shauna Williams | Individual | The submitter's primary interest is ensuring that the AI Action Plan development process includes meaningful input and participation from the disabled community, particularly those who could benefit from assistive technology, to avoid unintentional exclusion or discrimination. | - Unintentional exclusion or discrimination against the disabled community in the AI Action Plan. | - Invite individuals from the disabled community (including those using or who could benefit from assistive technology, disability advocates, higher education assistive technology professionals, and experts in creating accessible technology) to be members of the plan development team.<br>- Solicit qualified individuals from the following organizations:<br>- The Disabled Students Programs and Services (DSPS) offices of State Chancellor's Offices for community colleges and universities.<br>- AHEAD - Association on Higher Education and Disability.<br>- State-level higher education/disability organizations such as CAPED - California Association for Postsecondary Education and Disability.<br>- National-level organizations for specific disabilities, such as NAD - National Association of the Deaf; ABF - American Foundation for the Blind; LDA - Learning Disabilities Association of America; NCLD - National Center for Learning Disabilities; NAMI - National Alliance on Mental Illness. |
| AI-RFI-2025-1392.md | Nickolaus Marek | Individual | Not Stated. The submitter's primary interest, as expressed, is preventing human extinction. | - Human extinction | - None Stated |
| AI-RFI-2025-1393.md | Data Transfer Initiative (DTI) | Advocacy/Think Tank | The Data Transfer Initiative (DTI) is a non-profit organization dedicated to enabling secure, adaptable AI portability to support innovation, economic growth, and consumer empowerment within the AI ecosystem. They focus on facilitating shared data transfer tools, models, and frameworks across companies. | - Vendor lock-in for businesses building downstream from LLM APIs.<br>- Significant cost and friction when businesses switch between LLM services due to misaligned data formats and scopes.<br>- Lack of consistency and alignment in scope and format when users download their data (e.g., conversation history) from LLM services.<br>- Risk of businesses and consumers being locked into closed systems that limit choices and slow innovation. | - Encourage AI portability as an important component of the NSF's AI plan.<br>- Strengthen market competition through interoperability and portability.<br>- Enhance user control and choice by enabling users to switch between AI services without losing access to their personal data.<br>- Promote AI portability and set global benchmarks to reinforce U.S. leadership in AI development and deployment.<br>- Focus on user and business data interconnections such as Application Programming Interfaces (APIs). |
| AI-RFI-2025-1394.md | John Smith | Individual | The submitter expresses strong opposition to the development of an Artificial Intelligence Action Plan, arguing it will negatively impact artists, writers, the environment, and the economy. Their primary interest is preventing the proliferation of AI generated content. | - AI companies using copyrighted art and writing without permission.<br>- Negative impact on the media.<br>- Negative environmental impact.<br>- Financial losses for companies due to AI.<br>- Decreased public approval rating (linked to the proposal).<br>- Low quality and lifeless appearance of AI-generated material. | - Stop the development and implementation of the Artificial Intelligence Action Plan. |
| AI-RFI-2025-1395.md | FAH (presumably, Federation of American Hospitals) | Industry-Association | The FAH’s primary mission, as evident in the text, is to advocate for the responsible and beneficial implementation of AI in healthcare, aiming to improve patient care, provider efficiency, and overall societal benefits while simultaneously mitigating potential risks and ensuring patient safety. | - Bias in AI algorithms potentially leading to inequitable healthcare outcomes.<br>- Overly restrictive opt-out requirements potentially hindering AI adoption and interoperability in healthcare systems.<br>- Challenges of redesigning software architectures and workflows to accommodate both AI-assisted and non-AI approaches.<br>- Difficulties of interoperability in healthcare technology systems impacting AI deployment.<br>- Potential for intellectual property laws to disproportionately benefit large tech companies and restrict access to AI advancements.<br>- Risk of harm stemming from flaws in commercial AI products relating to safety, bias, privacy, and security.<br>- Potential for AI innovation to be discouraged by actions such as automatically assigning AI ownership to AI itself or overly restrictive licensing rules.<br>- Insufficient education and training regarding AI within the healthcare workforce. | - Develop education best practices for AI in healthcare, with customized learning programs and stringent oversight for AI-focused medical education.<br>- Establish clear guidelines for intellectual property ownership related to AI-generated content, ensuring businesses retain rights to innovations.<br>- Support equitable licensing frameworks for AI models and training data allowing access to foundational technologies while respecting proprietary rights.<br>- Provide end-users of AI tools with guidance on ethical use, including when a "human in the loop" is necessary and the limits of models.<br>- Maintain high standards for safety and efficacy through continuous monitoring of model outputs and outcomes, including human-in-the-loop oversight.<br>- Adopt a transparency-focused approach to opt-out provisions, such as incorporating general consent for AI use as part of the transparency process.<br>- Support a multifaceted approach to AI education, moving away from a one-size-fits-all model.<br>- Encourage collaboration between developers and end-users to properly monitor AI technology performance over time. |
| AI-RFI-2025-1396.md | The Joint Commission | Industry-Association | The Joint Commission is an organization focused on improving healthcare quality and safety, and they are developing frameworks and certifications to guide the responsible use of AI in healthcare settings to enhance patient outcomes while mitigating risks. | - None Stated | - None Stated |
| AI-RFI-2025-1397.md | Business Roundtable | Industry-Association | The Business Roundtable advocates for policies that foster U.S. leadership and innovation in AI while ensuring security and prosperity, promoting a skilled workforce, and shaping international AI standards. | - Potential for authoritarian regimes to shape AI development and regulatory structures undermining human rights and increasing surveillance.<br>- Risk of U.S. companies being uniquely disadvantaged due to export controls on AI technologies without allied cooperation.<br>- Lack of a skilled workforce with the training required for AI-related jobs.<br>- Complexity and potential commercial/economic implications of export control measures.<br>- Conflicting legal obligations arising from international AI policies. | - Shape international AI policies to align with democratic values (transparency, fairness, privacy).<br>- Create a standing, private-sector Export Control Advisory Board (ECAB) with security clearance.<br>- Improve the transparency and predictability of export control measures.<br>- Implement longer safe harbors for implementation of export controls.<br>- Simplify export control measures to reduce compliance complexity.<br>- Advocate for allied nations to embrace comparable controls.<br>- Streamline the licensing process for export controls.<br>- Create an expedited licensing authority for the return of consigned material.<br>- Improve the process for appealing decisions denying licensing requests.<br>- Reform the workforce development system to support evolving workforce needs.<br>- Invest in developing AI for cybersecurity and other under-explored areas.<br>- Encourage skills-based hiring and expand apprenticeship programs. |
| AI-RFI-2025-1398.md | Not Stated | Advocacy/Think Tank | The submitter advocates for preparing the workforce and educational systems for the integration of Artificial Intelligence, emphasizing the need for digital literacy, inclusivity, and competency frameworks to mitigate risks and maximize benefits of AI adoption. | - Widening global inequality due to AI (potential for uneven distribution of AI benefits).<br>- Lack of AI competency in the workforce and educational system.<br>- Potential for AI to exacerbate existing inequalities if not addressed thoughtfully.<br>- Lack of preparedness for the digital transformation of workplaces.<br>- Need to remove barriers to American leadership in AI. | - Focus on AI education and training for students and teachers.<br>- Develop AI competency frameworks for both students and teachers.<br>- Promote digital literacy and inclusive instructional content, especially for marginalized groups.<br>- Remove barriers to American leadership in AI.<br>- Invest in preparing the workforce for the digital transformation of workplaces. |
| AI-RFI-2025-1399.md | SAS Institute Inc. | Industry-Large | SAS is a data and AI company focused on transforming data into intelligence for its customers across various sectors, and it aims to contribute to a strong AI ecosystem in the United States through its expertise and solutions. | - Generative AI being the sole focus of AI policy discussions, neglecting other important AI techniques.<br>- Lack of harmonization of regulatory and procurement requirements related to AI across various domains and agencies.<br>- Security vulnerabilities and risks associated with open source software, particularly due to lack of resources and incentives for security prioritization.<br>- Intellectual property policies not aligning with AI policy priorities and national competitiveness.<br>- Over-reliance on AI in patent examination potentially leading to improperly granted patents and hindering innovation. | - Broaden the focus of AI policy discussions beyond Generative AI to encompass other AI techniques.<br>- Harmonize regulatory and procurement requirements related to AI.<br>- Develop innovative incentive structures to mitigate security risks associated with open source software.<br>- Ensure intellectual property policies align with AI policy priorities and national competitiveness.<br>- Augment patent examination with AI, but avoid over-reliance on it to maintain examination quality and prevent improperly granted patents. |
| AI-RFI-2025-1400.md | NYU Stern School of Business | Academia | NYU Stern School of Business, through its Center for the Future of Management (CFM), focuses on understanding and addressing major shifts in the global business landscape, particularly those driven by new technologies like artificial intelligence, to inform strategy and public policy. | - Economic consequences of AI, robotics and other advanced technologies.<br>- Changing nature of work and organizations, especially in healthcare, due to AI and digital technologies.<br>- Potential impact of AI on competition and strategy.<br>- Barriers to understanding the rapid evolution of AI and its implications for job automation and scientific progress.<br>- Challenges and opportunities related to open source software. | - Host conferences and events for academic, industry, and policy audiences at the intersection of technology, strategy, and public policy.<br>- Research the Economics of Robots and Artificial Intelligence.<br>- Explore the Benefits and Challenges of Open Source Software.<br>- Develop understanding of the impact of digital technologies on competition and strategy.<br>- Further research on how institutional features and non-market forces can shape innovation. |
| AI-RFI-2025-1401.md | National Education Association | Advocacy/Think Tank (representing educators and education professionals) | The National Education Association (NEA) advocates for the rights and interests of educators and students, and their submission focuses on ensuring AI is implemented in education responsibly, equitably, and sustainably, prioritizing student and educator well-being and development. | - Lack of Educator AI Literacy and Professional Development: Concerns about educators not being adequately prepared to understand and utilize AI effectively and safely.<br>- Potential for Bias and Equity Issues: Worries about biases embedded in AI tools perpetuating inequalities in education.<br>- Risks of Deepfake Technology and AI Companions: Concerns regarding the potential for harm and exploitation related to deepfakes and AI companion technologies, especially for students.<br>- Environmental Impact of AI: Concerns about the significant energy consumption and environmental impact associated with AI development and implementation.<br>- Insufficient Focus on Students with Disabilities: Worry that AI development may not adequately address the unique needs and opportunities for students with disabilities.<br>- Potential for Increased Educator Workload: While AI can reduce administrative burdens, potential for it to also increase workload if not implemented thoughtfully.<br>- Privacy and Data Security: Potential risks associated with student and educator data being collected and used by AI systems. | - Invest in Educator AI Literacy & Professional Development: Comprehensive, ongoing training for educators on AI technology, its potential, limitations, and safe implementation.<br>- Promote Equity & Bias Mitigation: Prioritize development and evaluation of AI tools to ensure fairness and address potential biases.<br>- Address Deepfake & AI Companion Risks: Develop safeguards and digital literacy initiatives to protect students and educators from harm.<br>- Prioritize Sustainable AI Development: Invest in energy-efficient AI models and encourage partnerships between AI researchers and environmental scientists.<br>- Focus on Students with Disabilities: Develop AI resources tailored to students with diverse learning styles and involve people with disabilities in AI development.<br>- Integrate AI Literacy into Curriculum: Incorporate AI literacy across all subject areas and educational levels for all students.<br>- Support Research on AI's Impact: Fund research to understand AI's impact on student achievement, equity, and educator workload.<br>- Develop Best Practices for Educational Institutions: Provide educational institutions with guidance on minimizing their carbon footprint while utilizing AI. |
| AI-RFI-2025-1404.md | HackerOne Inc. | Industry-Startup | HackerOne focuses on AI security and reducing unintended consequences in AI development, advocating for robust processes to identify and address flaws in AI models and fostering a secure and trustworthy AI ecosystem. | - Risks associated with unintended consequences in AI models.<br>- Consumer privacy risks related to AI development.<br>- Lack of robust processes for receiving and responding to AI security disclosures from external sources.<br>- The interconnected nature of AI systems leading to flaws transferring across platforms.<br>- Potential for homogenous internal testing to miss weaknesses and flaws. | - Incentivize good faith researchers to identify system weaknesses.<br>- Establish robust processes for receiving and responding to disclosures about AI security and flaws.<br>- Enable coordinated flaw disclosures with a safe harbor (NIST).<br>- Support R&D to advance AI red teaming methodologies, including test beds, sophisticated tools, and skilled professionals.<br>- Adopt a "default to disclosure" approach for flaws identified by independent evaluators, similar to vulnerability disclosure programs (VDPs) in cybersecurity.<br>- Encourage transparency around AI models and flaws.<br>- Provide legal protections (charging policy under the CFAA) for independent AI trustworthiness research. |
| AI-RFI-2025-1405.md | Ansgar Odinson | Individual | Not Stated. The submitter expresses a negative opinion on the proposed AI Action Plan but does not articulate any specific mission or interest beyond opposition. | - Negative public sentiment towards AI. | - None Stated. |
