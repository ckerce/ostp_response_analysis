| Filename | Submitter Name | Submitter Type | Mission/Interest Summary | Key Concerns | Policy Recommendations |
|---|---|---|---|---|---|
| 1Day-Sooner-RFI-2025.md | 1Day Sooner | Advocacy/Think Tank | 1Day Sooner is a philanthropically funded non-profit that leads campaigns in science, policy, and ethics to advance medical innovation to combat harmful diseases. They are interested in ensuring AI is utilized effectively within the Department of Health and Human Services (HHS) to improve healthcare outcomes and innovation. | - Lack of specialized AI expertise within the federal workforce, creating adoption delays.<br>- Review delays and limited interactions with the FDA cited by the pharmaceutical industry.<br>- Potential gaps in AI procurement practices within the FDA. | - Establish an AI Corps within HHS to accelerate the integration of AI across its agencies.<br>- Strengthen the FDA's Regulatory Capacity through AI.<br>- Prioritize Data Readiness for AI Integration within the FDA.<br>- Conduct an FDA Reviewer Benchmark Test to evaluate AI-assisted reviews.<br>- Publish a report on AI procurement guidelines for the FDA.<br>- Foster AI Adoption through Targeted Reviewer Engagement at the FDA. |
| 3C-AI-RFI-2025.md | Connected Commerce Council (3C) | Industry-Association | The Connected Commerce Council (3C) is dedicated to ensuring small businesses have the digital tools, including AI-powered tools, they need to thrive in the current economy and maintain U.S. leadership in AI innovation and adoption. | - Overly burdensome regulations disproportionately impacting small businesses and hindering innovation.<br>- Patchwork of state laws on AI privacy creating complexity, costs, and legal risks for small businesses.<br>- AI compliance being too complex, costly, and legally risky for small businesses.<br>- Regulations that restrict AI development and innovation.<br>- Making all users of AI models liable for potential misuse or flaws, making AI use prohibitively legally risky for small businesses.<br>- Potential for a lack of a federal standard that supersedes overly restrictive European AI privacy laws. | - Promoting AI literacy and training to help small businesses effectively adopt and utilize AI technologies.<br>- Avoiding overly burdensome regulations that disproportionately impact small businesses.<br>- Establishing a federal AI privacy framework to avoid a patchwork of state laws.<br>- Focusing regulations on sensitive contexts such as healthcare, finance, and law enforcement rather than broadly restricting AI development.<br>- Focusing on AI outputs (how AI-generated content is used) rather than restricting AI inputs.<br>- Developing a comprehensive federal AI privacy framework that supersedes state laws.<br>- A balanced approach to data and copyright regulations, particularly encouraging a fair use-based approach to copyright questions and text- and data-mining exemptions.<br>- A federal standard that provides a smart alternative to overly restrictive European AI privacy laws. |
| A-King-RFI-2025.md | A. King | Individual | The submitter, a student of AI Policy and Management, is primarily interested in ensuring responsible AI development and deployment that prioritizes consumer protection, transparency, and ethical governance rather than solely pursuing rapid advancement through deregulation. | - Risks to consumers, such as discrimination, misinformation, fraud, and privacy violations.<br>- Revocation of the Biden-Harris AI Executive Order 14110 and the removal of critical consumer protections.<br>- Lack of clear liability and accountability structures for AI developers and deployers.<br>- Embedding of structural discrimination and reinforcement of societal inequalities due to biased training data.<br>- Privacy risks associated with AI's ability to process and analyze massive datasets.<br>- Ethical concerns related to AI's expansion into surveillance, deepfake technology, and autonomous decision-making.<br>- Potential for biased decision-making in critical areas such as hiring, lending, criminal justice, and access to government services.<br>- Risk of unintended consequences due to hasty deregulation. | - Establish clear liability and accountability structures for AI developers and deployers.<br>- Require mandatory risk assessments for high-impact AI applications.<br>- Mandate diverse and representative training datasets.<br>- Encourage third-party AI audits.<br>- Implement stronger data privacy protections.<br>- Require ethical AI impact assessments before deploying AI in public sector or critical infrastructure.<br>- Establish a government advisory board on AI ethics.<br>- Create a federal AI oversight task force with the authority to adapt regulations in real time.<br>- Promote public-private collaboration.<br>- Align AI policy with international best practices. |
| AAAI-AI-RFI-2025.md | Association for the Advancement of Artificial Intelligence (AAAI) | Professional-Society | The AAAI, as a leading professional society in AI, seeks to promote responsible innovation and advancement in the field, emphasizing the foundational role of federally funded research in driving breakthroughs and advocating for policies that support continued progress. | - Lack of recognition for the crucial role of basic, federally funded research in creating breakthroughs that underpin current AI advancements (e.g., Deep Learning, Autonomous Driving, Personal Assistants, Reinforcement Learning).<br>- Potential for overlooking the importance of long-term, foundational research in favor of immediate, commercially driven applications. | - Increase and prioritize funding for basic AI research through grants and block grants to academic institutions.<br>- Acknowledge and highlight the impact of DARPA and other government programs in fostering AI innovation.<br>- Invest in programs and competitions, like the DARPA Grand Challenge, to accelerate innovation and maturation of AI techniques.<br>- Support research into areas like Reinforcement Learning and Deep Learning, even when immediate applications are unclear.<br>- Prioritize long-term research investments over short-term, commercially-focused initiatives. |
| AABA-RFI-2025.md | Association for Advancement of Business AI (AABA) | Industry-Association | The Association for Advancement of Business AI (AABA) is dedicated to advancing AI-driven innovation, policy, and economic competitiveness in the United States, focusing on cost-effective, vendor-agnostic AI reference models that prioritize American industry and national security interests. | - Excessive regulation slowing down AI progress and weakening U.S. leadership.<br>- Vendor lock-in due to lack of open and scalable AI frameworks.<br>- Adversaries gaining an advantage in AI development and deployment.<br>- Lack of alignment between AI policy and practical business adoption.<br>- Potential for AI to be used in ways that threaten national security. | - Prioritize strategic advantage, resilience, and adaptive governance in AI development.<br>- Develop open, scalable AI frameworks to reduce vendor lock-in.<br>- Implement a tiered regulatory approach differentiating between low-risk and high-risk AI applications.<br>- Utilize regulatory sandboxes and iterative policy reviews to foster rapid innovation.<br>- Treat ethical considerations as strategic instruments, aligning them with U.S. interests.<br>- Foster real-time industry engagement in AI governance.<br>- Develop cost-effective, vendor-agnostic AI reference models.<br>- Apply advanced decision models to evaluate AI regulation impact.<br>- Align AI adoption with multi-domain operational frameworks. |
| AAN-AI-RFI-2025.md | American Academy of Nursing | Professional-Society | The American Academy of Nursing aims to create solutions and inspire change to propel transformation towards a healthier future for all people, with a particular interest in the implications of AI on the nursing workforce, patient care, and the broader health care system. | - Exacerbation of access to care disparities.<br>- Patient safety risks.<br>- Privacy breaches.<br>- Impact on the health care workforce and burden on clinicians.<br>- Potential for AI to replace nurses' roles and threaten the quality of care.<br>- Data limitations (inaccuracy, inconsistency, lack of standardization) eroding trust and harming patients.<br>- Potential for abuse or misuse of AI systems. | - Invest in research and postmarket surveillance to monitor the impact of deployed AI.<br>- Further investments in research being conducted at the National Institutes of Health to support the use of AI in health care.<br>- Continued federal support for work on data and health information technology standards.<br>- Use of comprehensive data sources, inter-professional clinical data, and patient reported outcomes. |
| AANA-RFI-2025.md | American Association of Nurse Anesthesiology (AANA) | Professional-Society | The AANA represents Certified Registered Nurse Anesthetists (CRNAs) and student registered nurse anesthetists, and their primary interest is ensuring patient safety and enhancing the expertise of CRNAs in the context of AI adoption within anesthesia and perioperative care. | - Patient safety risks related to AI implementation, including system failures, algorithmic biases, and over-reliance on automation.<br>- Potential replacement of CRNAs' extensive knowledge, expertise, critical thinking, clinical judgment, and direct patient interaction.<br>- Lack of transparency and explainability in AI decision-making processes.<br>- Ethical and bias considerations related to AI models trained on potentially unrepresentative datasets. | - AI should enhance CRNAs' ability to deliver safe, high-quality care rather than replace their expertise.<br>- Establish robust patient safety standards for AI systems used in anesthesia and perioperative care, including rigorous validation, testing, and continuous monitoring.<br>- Ensure AI tools function under the direct supervision of CRNAs and other healthcare professionals.<br>- Promote transparency and explainability in AI decision-making processes.<br>- Train AI models on diverse, representative datasets to minimize bias and support equitable care.<br>- Subject the development and deployment of AI in anesthesia care to appropriate regulatory safeguards.<br>- Utilize AI to enhance operational decision-making, optimizing OR case scheduling, staffing, and supply management.<br>- Include the voices of CRNAs alongside other healthcare providers in the design, testing, and implementation of AI technologies. |
| AAP-AI-RFI-2025.md | American Academy of Pediatrics (AAP) | Professional-Society | The American Academy of Pediatrics' primary mission, as evidenced in the text, is to ensure the safety, well-being, and optimal health of all children, and they are deeply concerned about the potential impacts of AI on pediatric care, child welfare, and the developmental well-being of young people. | - Bias and discrimination in AI algorithms used for child welfare assessments (specifically citing ABA Journal article).<br>- Potential for AI to exacerbate disparities in social services and foster care.<br>- Lack of consideration for the developmental stage of young people when developing and deploying AI tools.<br>- Risk of harmful outcomes from widespread commercialization and misuse of AI technology by young people.<br>- Algorithms easily fooled by unrecognizable images (citing Nguyen et al. paper).<br>- Linguistic properties of AI-generated text beyond basic syntactic/grammatical measures not being adequately addressed.<br>- Adaptation of commercial systems leading to circumvention of security measures like barcoding and digital watermarking.<br>- Unintended consequences of AI tools and lack of accountability for harm caused.<br>- Inadequate performance metrics beyond those developed by the computer science community (e.g., focusing solely on leaderboards). | - Pediatric-specific AI standards and safety benchmarks should be developed collaboratively with the AAP and other experts.<br>- A pediatric risk assessment framework should be incorporated into AI regulation.<br>- Address concerns related to AI-assisted child welfare decision-making.<br>- Collect and review unintended consequences and establish accountability for harm.<br>- Collaboration between federal agencies and the AAP to develop these standards.<br>- Data definitions of performance and goals should be clearly defined and monitored.<br>- Standard pre-procurement questions regarding AI incorporation should be established for vendor evaluation.<br>- Development of a tool/assessment process for vendors, defining AI as a starting point.<br>- Utilize generative AI appropriately, rather than explicitly altering the technology.<br>- Enhance the use of barcoding or digital watermarking technology (while acknowledging potential circumvention). |
| AAU-AI-RFI-2025.md | Not Stated | Academia/Professional-Society (Likely a consortium or group representing research universities, given the focus on university research, energy costs, and talent attraction; potentially a professional society focused on AI in science) | The submitter’s primary mission is to advocate for federal policies that promote AI-enabled scientific discovery and maintain U.S. leadership in AI and related fields, emphasizing the vital role of research universities in driving innovation and addressing workforce needs. | - High energy costs affecting research universities.<br>- Energy-intensive computation potentially hindering AI-driven discovery.<br>- Fierce worldwide competition for scientific talent.<br>- Potential for missed opportunities if federal policy fails to align with the possibilities of AI-enabled science.<br>- Need for data on the AI workforce to understand the landscape and address skill gaps. | - Increase federal funding for AI research, particularly at universities.<br>- Reduce energy costs and improve grid reliability.<br>- Invest in novel energy-efficient techniques for AI and computation.<br>- Attract and retain top AI talent from around the world, streamlining visa processes.<br>- Collect data on the AI workforce through federal statistical agencies to identify skill gaps.<br>- Develop an action plan for AI and allocate resources within the Department of State and the Department of Homeland Security for talent acquisition.<br>- Prioritize policies that facilitate collaboration between universities, industry, and government agencies. |
| ABA-AI-RFI-2025.md | American Bankers Association (ABA) | Industry-Association | The American Bankers Association (ABA) advocates for the financial services industry and is interested in fostering responsible innovation in AI while maintaining trust and accountability, particularly within the banking sector. | - Risks associated with the use of AI, including potential biases, lack of transparency, and challenges in overseeing third-party AI providers.<br>- Field examiners unduly focusing on granular technical details (like computer code) instead of broader risk areas (inputs, outputs, outcomes) hindering innovation.<br>- Overly prescriptive safeguards or prohibitions on AI use that could impede valuable use cases and limit banks' ability to test and adapt new tools.<br>- The economics of Large Language Model (LLM) development driving adoption of third-party offerings, creating challenges for oversight and potential interoperability issues.<br>- Community banks disproportionately affected by improper supervisory practices.<br>- Lack of interoperability across sectors and jurisdictions due to varying approaches to AI governance. | - Congress should enact legislation to address AI policy.<br>- Development of voluntary strategies and standardized disclosure templates (model cards) for validation exercises without sharing confidential commercial information.<br>- Industry certifications to demonstrate compliance with fairness, transparency, and explainability standards.<br>- Public/private partnerships to address challenges posed by advanced technologies.<br>- Development of an explainability approach that transcends traditional methodologies, leveraging data governance, weighted decision-making, assurance/testing, and continuous risk monitoring, mapping to the NIST AI Risk Management Framework and/or creating sector-specific profiles.<br>- Updated guidance for banks when using third-party AI, clearly delineating responsibilities and ensuring flexibility for testing and adaptation.<br>- Field examiners should implement agency policy, not create their own, and focus on broader risk areas instead of granular technical details.<br>- Congress to ensure banks have appropriate flexibility to test and adapt new AI tools.<br>- Congress should pursue interoperability across sectors and jurisdictions. |
| ACC-AI-RFI-2025.md | American Chemistry Council | Industry-Association | The American Chemistry Council (ACC) focuses on advocating for the responsible and innovative use of chemistry, and their submission highlights concerns regarding AI regulation, particularly its impact on the chemical industry's research, development, and regulatory compliance processes. They emphasize the need for human oversight and risk governance structures to ensure AI is safe, secure, and beneficial. | - None Stated | - None Stated |
| ACE-AI-RFI-2025.md | Heidi AI (Adaptive Computing) | Industry-Startup (with ties to larger Industry - Adaptive Computing) | Heidi AI's mission is to provide every student with access to their own personal supercomputer, ensuring all students have the tools to succeed in STEM fields and reach their full potential by making HPC & AI accessible and affordable for educational institutions. | - Lack of access to high-performance computing (HPC) resources and AI infrastructure for educational institutions.<br>- Difficulty integrating computational tools into curricula.<br>- Cost of building or maintaining HPC and AI infrastructure.<br>- Lack of access to preloaded datasets and student-friendly learning environments. | - Not Stated |
| ACHP-AI-RFI-2025.md | Alliance of Community Health Plans (ACHP) | Industry-Association | ACHP is a national organization focused on promoting a payer-provider aligned model in healthcare, and they seek AI policies that prioritize patient outcomes, privacy, safety, and technology accessibility while recognizing the unique needs of the healthcare sector. | - Privacy of personal health information.<br>- Patient safety.<br>- Data quality (incomplete, inaccurate, or poor-quality data).<br>- Risk of AI use cases within the healthcare system.<br>- Disparities between those who can develop, access and implement AI and those who cannot.<br>- Data falling outside of HIPAA protections.<br>- Lack of a common language/understanding of AI terminology within health care.<br>- Fragmented policy landscape and siloed regulations between states and federal agencies. | - Develop an AI Action Plan that prioritizes patient outcomes and experience while promoting privacy, safety, and technology accessibility.<br>- Include clear guidelines for how existing security and privacy requirements apply to data being used by AI.<br>- Ensure data sets are clean and representative to facilitate effectively tailored care.<br>- Determine a common language for AI in health care to eliminate ambiguity.<br>- Maintain a coordinated effort with stakeholders to establish seamless national policies and guardrails.<br>- Refine existing policies and frameworks based on industry input.<br>- Support the positions outlined in the CTA Health AI Collaborative: Policy Considerations for a New Congress and Administration. |
| ACLA-AI-RFI-2025.md | American Clinical Laboratory Association (ACLA) | Industry-Association | ACLA represents leading clinical laboratories and advocates for policies that expand access to clinical laboratory services, improve patient outcomes, and advance personalized care, emphasizing the importance of AI tools to streamline processes and improve diagnostic accuracy while ensuring patient safety and appropriate reimbursement. | - Unnecessarily burdensome regulatory requirements that hamper innovation.<br>- Impact of AI and automation negatively impacting patient coverage and laboratory reimbursement, particularly through third-party coding edits leading to claim denials.<br>- Patchwork of inconsistent and burdensome state laws that are infeasible for clinical laboratories.<br>- Potential for AI to be used to deny or impede patient access to medically necessary services automatically.<br>- Lack of stable and predictable reimbursement for AI-enhanced laboratory services. | - Regulatory clarity and transparency regarding AI oversight.<br>- Flexibility in AI policies to keep pace with technological advancements.<br>- Risk-based approach to AI regulation, balancing risks and benefits, and leveraging existing frameworks.<br>- Transparency in AI systems to enable users to understand validity, reliability, and trustworthiness.<br>- Federal preemption to prevent a patchwork of inconsistent state laws.<br>- Safeguarding patient data and privacy while permitting the use of deidentified data for AI innovation.<br>- Stable and predictable reimbursement for AI-enhanced laboratory services, including PAMA reform.<br>- Human evaluation to ensure patients are not being denied care that is medically necessary. |
| ACLI-2-RFI-2025.md | Not Stated | Industry-Association | The submitter appears to represent an industry association (likely in the financial services sector, specifically insurance) focused on promoting innovation while ensuring responsible AI implementation within a heavily regulated environment. Their primary interest lies in advocating for industry-by-industry regulatory approaches aligned with existing laws and emphasizing the appropriateness of state-level insurance regulations. | - Difficulty in harmonizing AI governance across different jurisdictions (inside and outside the United States).<br>- Potential stifling of AI innovation by broad-brush regulations.<br>- Challenges for multinational companies managing AI risk across different jurisdictions.<br>- Divergent levels of consumer protection and access to AI-powered services due to differing regulations.<br>- Applicability of existing state insurance regulations, particularly concerning unfair discrimination and rate standards, to AI technologies.<br>- Need for tailored AI governance practices and third-party due diligence for each jurisdiction. | - Allow for industry-by-industry innovation in accordance with the industry's specific laws and regulations.<br>- Support existing state insurance regulations, particularly the NAIC Model \#880, Model \#900, and the NAIC AI Model Bulletin.<br>- Avoid broad-brush AI regulation that could stifle innovation.<br>- Continue fostering a state-level "laboratories" approach for greater efficiencies.<br>- Utilize existing risk management frameworks like the NIST AI Risk Management Framework, EU AI ACT, and ISO/IEC standards. |
| ACLI-RFI-2025.md | American Council of Life Insurers (ACLI) | Industry-Association | The ACLI advocates on behalf of its member companies, which are life insurance companies, and promotes consumers' financial and retirement security. Their interest in AI policy lies in ensuring the continued development and responsible use of AI in the life insurance industry while supporting a strong regulatory framework. | - None Stated | - Any AI Action Plan developed by the federal government should defer to the National Association of Insurance Commissioners (NAIC) and state insurance departments regarding matters related to life insurers and their products.<br>- Support broader adoption of the NAIC AI Model Bulletin to ensure consistent requirements for insurers nationwide. |
| ACM-AI-RFI-2025.md | ACM (Association for Computing Machinery) | Professional-Society | ACM advocates for the advancement of computing as a science and profession, and this document focuses on providing recommendations to the US Administration regarding the AI Action Plan, particularly concerning AI innovation, export controls, and national security implications. | - Fragmented international regulations regarding AI.<br>- The potential for adversaries, including non-state actors, to leverage AI for sophisticated cyberattacks and cyber warfare.<br>- The tension between AI export controls and the global growth of US tech companies.<br>- Gaps created by export controls not restricting access to open-source AI models, which can be leveraged by countries subject to restrictions.<br>- The space race-like competition between the US and China in AI development.<br>- Potential for misuse of AI in autonomous and semi-autonomous weapons systems.<br>- Concerns regarding copyright claims related to AI models (specifically mentioning DeepSeek and ChatGPT). | - Review national security issues related to AI carefully, leveraging expertise in AI, export control, and innovation.<br>- Engage in diplomatic efforts and inclusive public-private partnerships in multilateral fora (G7, OECD, UN) to guide AI development towards transparency, fairness, and security.<br>- Engage industry experts in diplomatic efforts to ensure policies remain grounded in technical realities.<br>- Review existing AI export control measures to address potential gaps related to open-source AI models.<br>- Encourage harmonization of AI policies in a manner that is beneficial to the US. |
| ACR-AI-RFI-2025.md | American College of Radiology | Professional-Society | The American College of Radiology (ACR) is a professional association focused on advancing safe, effective, and clinically useful radiology AI innovations to improve patient care and believes the AI Action Plan should incorporate healthcare-specific priorities. | - Lack of robust post-deployment monitoring mechanisms for AI-enabled software medical devices.<br>- Lack of transparency in AI devices, particularly regarding safety and effectiveness considerations.<br>- Potential for unsafe or ineffective use of AI by unqualified end-users.<br>- Current physician payment systems not adequately recognizing the value of AI innovations.<br>- Lack of standardized implementation and monitoring of AI within healthcare facilities. | - Continue FDA regulation of AI-enabled software medical devices, with potential for enhanced or modified oversight.<br>- Require AI device compatibility with balanced, risk-appropriate, post-deployment monitoring mechanisms.<br>- Consider "AI nutrition labels" to improve device transparency.<br>- Require more specificity about the qualifications of intended end-users of AI devices.<br>- Provide new, physician-informed payment for high clinical value AI.<br>- Ensure healthcare AI is appropriately, safely, and effectively implemented and used by providers via accreditation programs. |
| ACS-AI-RFI-2025.md | American Chemical Society (ACS) | Professional-Society | The American Chemical Society recognizes the potential of AI for innovation and improvement in the chemical sciences while emphasizing the importance of responsible development and deployment of AI systems to avoid harm and protect intellectual property. | - Potential for AI systems to cause harm to human life, health, or the environment.<br>- Risk of AI systems infringing on intellectual property rights.<br>- Reinforcement of societal inequality through AI use.<br>- Disproportionate harm to certain individuals or groups caused by AI systems.<br>- AI giving an advantage to large companies due to expense and dependence on large datasets and computing power.<br>- Increased energy usage of AI infrastructure and its impact on grid resiliency and sustainability.<br>- Lack of accessibility to infrastructure required for effective AI development for smaller universities and companies.<br>- Limited access to non-proprietary content and data needed for AI model and algorithm development. | - Prioritize privacy and security in data handling for AI applications, including opt-in/opt-out options and responsible handling of sensitive information.<br>- Ensure transparency and disclosure regarding the data and sources used to train AI systems.<br>- Hold AI actors accountable for system functionality, output, intellectual property rights, and individual privacy/dignity.<br>- Promote AI literacy for productive and responsible engagement.<br>- Utilize AI to support educational goals while fostering learning skills, ensuring privacy, and allowing for human intervention.<br>- Design AI systems to promote fairness and avoid disproportionate harm.<br>- Engage multiple stakeholders in AI development and regulation.<br>- Ensure AI technologies are not harmful to the environment or human life.<br>- Regularly review and update AI guidance to ensure compliance and relevance.<br>- Support efforts to develop publicly accessible databases of high-quality, non-proprietary content and data.<br>- Improve grid resiliency and flexibility alongside energy efficiency and sustainability to support AI infrastructure. |
| ADI-AI-RFI-2025.md | Alliance for Digital Innovation (ADI) | Industry-Association | The Alliance for Digital Innovation is an industry association advocating for the removal of institutional and bureaucratic barriers to the operation of a modern digital government, with a focus on promoting the adoption of innovative commercial technologies, including AI, by the Federal Government. | - Unnecessary constraints on low-risk, enterprise-level AI uses.<br>- Routine enterprise functions being classified as high-risk AI applications.<br>- Difficulty for smaller, innovative companies to contribute AI solutions due to procurement challenges.<br>- Lack of security built into AI technology adopted and utilized across government networks.<br>- Insufficient collaboration between government and industry in AI development and adoption.<br>- Shortage of a skilled workforce equipped with AI competencies.<br>- Issues with the quality and accessibility of government data for AI model training. | - Implement a risk-based approach to AI governance, concentrating regulatory efforts on high-risk applications.<br>- Exempt routine enterprise functions (cybersecurity, network management, etc.) from high-risk classifications.<br>- Increase micro-purchase and simplified acquisition thresholds for AI solutions.<br>- Encourage engagement with emerging tech providers through streamlined procurement.<br>- Support AI-driven cyber defense mechanisms and prioritize investment in defense against next-generation cyber-attacks.<br>- Adopt security-forward postures and impose appropriate requirements on developers of high-risk AI systems.<br>- Work with industry to develop and implement secure practices for AI technology, leveraging existing compliance mechanisms.<br>- Establish public-private partnerships to co-develop AI solutions.<br>- Facilitate knowledge exchange through forums and workshops.<br>- Develop curricula and certification programs for AI competencies.<br>- Provide reskilling and upskilling initiatives for existing employees.<br>- Review and improve government data management practices, including migrating paper-based data to digital formats.<br>- Congress should consider updating/amending the Federal Data Strategy and Evidence Acts to include AI considerations around data management.<br>- Prioritize leveraging existing government data to train government AI models. |
| AFB-AI-RFI-2025.md | American Foundation for the Blind | Advocacy/Think Tank | The American Foundation for the Blind (AFB) advocates for the inclusion, accessibility, and equitable opportunities for individuals who are blind or have low vision in all aspects of society, including education, employment, and access to technology like AI. | - Inaccessible curricular materials hindering participation in science lessons for blind students.<br>- Sighted children receiving computer skills training before blind children.<br>- Potential for AI to exacerbate existing inequalities if accessibility is not prioritized.<br>- Accuracy and reliability of AI-powered tools, especially when used to provide information or make decisions affecting blind individuals (e.g., healthcare, employment).<br>- Risk of algorithmic bias leading to discriminatory outcomes for blind or low-vision individuals.<br>- Lack of AI literacy and upskilling opportunities for people who are blind or have low vision, potentially creating a disadvantage in the workforce.<br>- Use of algorithmic decision-making in child welfare cases without appropriate oversight or consideration for disability.<br>- Potential for AI systems to reinforce harmful stereotypes or provide inaccurate information. | - Promote accessibility in AI design and development.<br>- Ensure accessible curricular materials for science education.<br>- Provide computer and assistive technology skills training for blind children earlier.<br>- Develop AI literacy and upskilling courses accessible to people who are blind or have low vision.<br>- Enforce the Individuals with Disabilities Education Act, the Americans with Disabilities Act, and Section 504 of the Rehabilitation Act.<br>- Adopt a whole-of-government approach to accessibility, data representation, and workforce development.<br>- Promote responsible use of algorithmic decision-making, especially in sensitive areas like child welfare.<br>- Prioritize data representation and ensure AI is designed to avoid bias and promote equitable outcomes for people with disabilities. |
| AFP-AI-RFI-2025.md | Americans for Prosperity | Advocacy/Think Tank | Americans for Prosperity advocates for policies that promote economic prosperity and individual liberty, believing that abundant and affordable energy and streamlined regulations are crucial for innovation in AI and other emerging technologies. | - Regulatory barriers hindering energy innovation and deployment.<br>- A "precautionary principle" mindset in regulation that excessively focuses on worst-case scenarios and discounts potential benefits.<br>- Permitting barriers blocking scaling of cutting-edge energy solutions.<br>- Potential constraints on energy supply to meet AI’s increasing power demands.<br>- The US having seen only a single new reactor licensed to completion in nearly half a century. | - Expand energy supply to get abundant and affordable energy to Americans and leading AI companies.<br>- Clear regulatory “red tape” bogging down energy innovators and implementers.<br>- Support and implement the PIONEER Act, which creates a broader Office of Federal Regulatory Relief within the Office of Information and Regulatory Affairs.<br>- Advocate for a balance that empowers innovation while respecting the purpose and intent of regulations protecting consumer health, safety, and financial well-being. |
| AFRICA4DEV-AI-RFI-2025.md | Africa Tech for Development Initiative - Africa4dev | Advocacy/Think Tank | Africa4Dev is committed to championing responsible AI policy, ethical governance, and equitable technological advancements, particularly focusing on ensuring AI benefits all communities and promotes sustainable development. | - Algorithmic bias and lack of fairness in AI systems.<br>- Lack of transparency and explainability in AI decision-making (need for XAI).<br>- Potential impact of AI on labor markets.<br>- AI’s impact on democracy and the spread of misinformation.<br>- Need for diverse data representation to avoid perpetuating biases.<br>- Risk of AI systems not being consistent with human rights principles.<br>- Inefficiencies in the federal hiring process for tech experts. | - Increase overall AI R&D spending significantly.<br>- Support AI for Social Good Initiatives, especially for startups and non-profits.<br>- Require AI researchers to collaborate with experts in human rights, philosophy, and regulatory policy.<br>- Establish AI Ethics and Governance Research Centers in Universities.<br>- Address inefficiencies in the federal hiring process through fellowship programs and enabling tech experts to float between agencies.<br>- Foster international cooperation to advance AI research and development as an open democratic society.<br>- Require data diversity to avoid perpetuating biases.<br>- Develop and implement a comprehensive AI Action Plan that prioritizes inclusivity, transparency, and accountability.<br>- Focus on explainable AI (XAI) to improve decision-making transparency. |
| AHCapitalManagement-AI-RFI-2025.md | AH Capital Management, LLC | Industry-Startup (Focus on investment and AI policy advocacy, specifically referencing and supporting a startup, "Little Tech.") | AH Capital Management, LLC advocates for policies that promote American AI innovation and competitiveness, particularly by fostering a thriving ecosystem for startups like "Little Tech," and regulating harms rather than models. | - Lack of policies to promote American AI innovation and competitiveness.<br>- Potential for large AI developers to control the AI market and limit opportunities for smaller players and startups.<br>- Data protection and confidentiality concerns related to reliance on third parties for AI model development.<br>- Potential disadvantage due to lack of AI literacy and baseline knowledge among the public.<br>- Risk of harmful AI applications. | - Adopt a policy agenda that promotes American innovation and competitiveness.<br>- Regulate harms related to AI rather than models themselves.<br>- Invest in AI infrastructure (computing power, data storage).<br>- Invest in AI talent (education, training, adult learning).<br>- Continue support for open-source models.<br>- Increase public AI literacy and awareness.<br>- Encourage a culture and policies that allow AI models to thrive. |
| AHIMA-AI-RFI-2025.md | AHIMA (American Health Information Management Association) | Industry-Association | AHIMA’s mission is to empower people to impact health, and they are interested in ensuring health information is accurate, complete, and available to patients and clinicians, particularly in the context of AI’s potential to improve healthcare. | - Challenges exist in the use of AI today and the existing policy framework surrounding its implementation.<br>- Agencies within the Executive Branch lack the statutory authority to regulate AI.<br>- Staff burnout, reducing administrative burden, and improving compliance activities are concerns related to AI implementation.<br>- Unintended outputs and unplanned biases within AI models. | - Ensure robust regulatory guidelines centered on fairness, accuracy, security, and transparency are developed for both clinical and non-clinical AI.<br>- Structure regulatory frameworks with sufficient flexibility to allow for continued AI development and innovation.<br>- Focus on the intended use and desired outcome of the AI when determining the efficacy of the technology.<br>- Prioritize end-users' input - including HI professionals - throughout the development and realworld testing of AI technology.<br>- Develop an updated set of privacy and security policies to better encapsulate new challenges and needs posed by the use of AI in healthcare settings.<br>- Maintain a focus on reducing unintended outputs and unplanned biases within AI models to ensure outputs remain stable and can be utilized across multiple settings with limited maintenance. |
| AHIP-AI-RFI-2025.md | AHIP (America’s Health Insurance Plans) | Industry-Association | AHIP, as a trade association representing health insurance companies, is focused on fostering innovation in healthcare through AI while ensuring responsible deployment, high-quality care, affordability, and consumer trust. They prioritize policies that support AI's potential without creating undue burdens or compromising patient safety and data privacy. | - Lack of established standards for delineating roles and responsibilities across the AI environment, including between developers and deployers.<br>- Lack of broadly applicable requirements or standards for AI vendors to transparently disclose key elements of tools to enable deployer risk assessment.<br>- Concerns regarding the transparency and explainability of GenAI models and the datasets used to train them.<br>- Potential for broad disclosure requirements to overwhelm consumers and undermine trust, potentially reducing consumer willingness to engage with AI technologies.<br>- Costly and duplicative external review of all AI solutions, given existing internal work plans already undertake.<br>- Potential for overly burdensome regulations to stifle innovation in the healthcare sector.<br>- Adverse direct patient impact from high-risk clinical applications. | - Promote public-private partnerships and collaboration to facilitate data-driven efforts and disseminate best practices.<br>- Prioritize resource allocation to high-value AI applications in healthcare.<br>- Focus on "use disclosures" that are relevant and useful for deployers to mitigate risk while preventing additional disclosure or monetization.<br>- Require AI developers to share relevant details with purchasers to inform risk management efforts.<br>- Utilize plain language examples of AI tool design and decision-making processes to enhance transparency for consumers.<br>- Consider consumer education to help individuals understand AI and its potential uses.<br>- Support evidence generation and dissemination on best practices for AI development and use.<br>- Limit external review to high-risk clinical applications and avoid duplicative reviews of all AI solutions.<br>- Encourage standards that balance intellectual property protection with the need for transparency. |
| AI-RFI-2025-0829.md | Anonymous | Anonymous | The submitter's primary interest appears to be promoting the responsible use of AI, specifically balancing progress with sustainability and rational solutions for a cleaner, thriving future. They also highlight the importance of reasoning AI for enhanced U.S. leadership in AI. | - Blind ideology in AI deployment. | - Use AI to optimize energy use and reduce harm.<br>- Promote smart, science-driven policies.<br>- Emphasizing Reasoning AI for Enhanced U.S. Leadership in AI (based on attached file reference). |
| AI-RFI-2025-0833.md | Rand Waltzman | Professional-Society (Adjunct Senior Information Scientist at RAND Corporation) | Rand Waltzman’s work focuses on understanding and mitigating the risks of manipulation, influence, and deception in emerging technologies, particularly in Virtual and Augmented Reality environments, and now extending to the vulnerabilities of machine learning systems within the context of military operations. | - Vulnerabilities in machine learning systems to adversarial attacks and manipulation.<br>- The "black box" nature of machine learning systems makes it difficult to understand and safeguard them.<br>- Lack of enforceable standards for AI reliability and safety.<br>- Potential for battlefield losses and a loss of trust in critical systems due to machine-targeted deception.<br>- Gaps in defenses due to a lack of collaboration among industry, academia, and government.<br>- The pace of vulnerability discovery potentially outstripping the development of defenses.<br>- Reliance on software defenses alone, highlighting the need for hardware-level security. | - Establish enforceable standards for AI reliability and safety through organizations like NIST.<br>- Prioritize security alongside innovation through investment in research and development.<br>- Foster collaboration among industry, academia, and government to create a unified front.<br>- Conduct red teaming exercises to uncover system weaknesses.<br>- Establish confidential reporting mechanisms for vulnerability discovery and response.<br>- Integrate security into hardware design, including activity audits and unauthorized access prevention mechanisms.<br>- Adopt a "whole-of-nation" approach to mitigate risks and reap the benefits of AI. |
| AI-RFI-2025-0842.md | Anonymous | Individual | The submitter's primary interest is ensuring that the benefits of AI are distributed equitably across society and that the potential for job displacement and widening wealth inequality are addressed through social safety nets. | - Job displacement due to AI automation.<br>- Widening wealth inequality, with the benefits of AI primarily accruing to CEOs/billionaires.<br>- Erosion of opportunities for individuals to rely on their skillsets and knowledge due to AI replacing jobs.<br>- Failure to adequately prepare for the widespread adoption of AI and its impact on the workforce. | - Set up social safety nets to equally distribute the value provided by AI to all citizens.<br>- Categorize domains/roles/jobs that will never be replaced by AI and reward those who excel at them to redistribute workforce specialization.<br>- Federal government commitment to the populace to better us all when AI is ready to be a drop-in replacement for the majority of jobs. |
| AI-RFI-2025-0843.md | AI For All Now - aiforallnow.com | Advocacy/Think Tank | AI For All Now advocates for the responsible and ethical development and deployment of AI, focusing on promoting job creation, global peace, and public trust in AI technologies. | - Algorithmic biases leading to unfairness.<br>- Lack of ethical guidelines in AI design and implementation.<br>- Data privacy and security concerns.<br>- Potential for misuse of AI and lack of global governance.<br>- Risks to the workforce due to AI-driven changes in the job market. | - Mitigating algorithmic biases.<br>- Embedding ethical guidelines in AI design and implementation.<br>- Ensuring data privacy and security.<br>- Establishing accountability measures for AI systems.<br>- Encouraging public participation in AI policy-making.<br>- Implementing AI literacy programs.<br>- Offering reskilling and upskilling programs for workers.<br>- Establishing and leading international AI partnerships.<br>- Actively participating in and influencing the creation of global AI standards.<br>- Providing grants and resources to support joint AI research and development projects.<br>- Investing in AI technologies for defense and intelligence.<br>- Promoting the use of AI to address social issues. |
| AI-RFI-2025-0844.md | Anonymous | Individual | The submitter's primary interest appears to be expressing strong disagreement with the accuracy of AI responses related to U.S. politics, particularly concerning the 2020 presidential election and statements attributed to Donald Trump. | - Inaccurate AI responses regarding U.S. elections (specifically the 2020 election).<br>- Bias or propaganda embedded within AI language models.<br>- Potential for AI to disseminate false information and contribute to political unrest.<br>- The trustworthiness of AI systems for factual reporting on political events. | - None Stated |
| AI-RFI-2025-0845.md | 40 North Labs LLC | Industry-Startup | 40 North Labs LLC, creator of PhotoNodes, is focused on advancing AI leadership in the US by providing an AI-ML platform that efficiently analyzes image data, improves data management, and facilitates secure cross-sector collaboration. | - Unnecessarily burdensome requirements.<br>- Lack of flexible regulatory frameworks that allow for rapid technological advancement.<br>- Lack of standardization of AI-generated metadata. | - Maintaining flexible regulatory frameworks that allow for rapid technological advancement.<br>- Supporting research into computational efficiency and data management improvements.<br>- Encouraging standardization of AI-generated metadata to facilitate interoperability.<br>- Promoting the development of integrated platforms that enable efficient data utilization.<br>- Establishing frameworks for secure cross-sector collaboration in AI development. |
| AI-RFI-2025-0846.md | Pamela Mason | Individual | The submitter expresses a strong interest in direct democracy and believes every American should have a direct role in the legislative process. Their comment specifically addresses voting on bills. | - None Stated | - Every American should be able to vote on bills using their Social Security numbers.<br>- Representatives should be legally obligated to uphold the wishes of the voters. |
| AI-RFI-2025-0848.md | Compsim LLC | Industry-Startup | Compsim LLC expresses concern over the current focus on Machine Learning within government AI solicitations and advocates for a broader consideration of alternative AI approaches to foster innovation and potentially lower costs. | - Bias towards ML/LLM/Generative AI in government solicitations, limiting consideration of new approaches.<br>- Over-emphasis on "Big Data" and "Machine Learning" potentially driven by supplier influence.<br>- Lack of consumer definition of AI needs and desired capabilities.<br>- Resistance to approaches reviewers are unfamiliar with (cognitive dissonance). | - Avoid dictating specific AI approaches in government solicitations.<br>- Express requirements in terms of required capabilities rather than specific methods.<br>- List ALL dependencies (direct and indirect) for each potential solution.<br>- List all potential risks associated with a solution, including mitigation strategies.<br>- Establish a government role responsible for learning about new AI approaches.<br>- Prioritize development of an extensible JSON-based AI messaging standard for interoperability, transparency, and security. |
| AI-RFI-2025-0876.md | Not Stated | Advocacy/Think Tank | The submitter’s primary interest is advocating for policy reforms to the U.S. Copyright Office, arguing that its current structure and interpretation of copyright law regarding AI-generated works are hindering innovation and placing U.S. creators at a competitive disadvantage globally. | - The U.S. Copyright Office’s reluctance to recognize AI-generated works puts it out of step with global competitors.<br>- The current approach may discourage innovation in the field of AI and computer-generated works.<br>- The U.S. Copyright Office's policies create unnecessary barriers for U.S. creators.<br>- Potential legal inconsistencies arise from the Berne Convention's requirement of equal copyright protections, where foreign AI-generated works may receive more recognition in the U.S. than domestic ones.<br>- The Copyright Office is a bureaucratic institution that influences copyright enforcement beyond its original mandate.<br>- The need for a large and expensive registration office is questionable given copyright is already automatic under U.S. law. | - Reform the U.S. Copyright Office to remove unnecessary barriers for U.S. creators.<br>- Eliminate the registration requirement for enforcement in court.<br>- Reduce the Copyright Office's authority to impose interpretive policies that go beyond the text of the Copyright Act.<br>- Consider drastically reducing the Copyright Office's role, replacing it with modernized, technology-driven solutions.<br>- Adopt a more accommodating approach to AI-generated works, similar to China's willingness to engage with AI-driven content creation. |
| AI-RFI-2025-0887.md | Akintade Trdaings Int.LLC | Industry-Startup/Small Business (based on LLC structure and "Trdaings" in the name) | The submitter appears to be a business entity expressing an opinion on the NSF's AI Action Plan development, specifically raising concerns about potential disruption to established processes and anticipating negative reactions to proposed changes. | - Disrupting established and proven procedures.<br>- Potential for "massive blow back" from changes.<br>- Unnecessary complexity.<br>- Risk of triggering conflict ("pick a fight") in the current political climate (DC). | - None Stated |
| AI-RFI-2025-0893.md | Raza Ali | Individual | Raza Ali's primary interest is ensuring AI education policies empower students to critically engage with AI, cultivate independent thought, and lead in AI development rather than merely following advancements. | - AI is potentially making people "dumber" due to over-reliance.<br>- Solely advancing AI technology without proper education risks creating a workforce that *depends* on AI.<br>- Students lack the critical thinking skills needed to meaningfully engage with AI.<br>- Potential for biases in AI models leading to inequitable and uninclusive outcomes. | - Help teachers balance AI use with traditional learning methods.<br>- Encourage faculty to integrate AI into research and coursework while maintaining academic integrity.<br>- Provide clear guidelines on AI usage in assessments and assignments to avoid over-reliance.<br>- Require AI ethics courses as part of both K-12 and higher education curricula.<br>- Teach students to recognize and mitigate biases in AI models.<br>- Promote discussions on AI's societal impacts. |
| AI-RFI-2025-0910.md | Steven Durr | Individual | The submitter's primary interest is ensuring the ethical development of Artificial Intelligence/Large Language Models, specifically regarding copyright law. | - Copyright infringement by AI/LLMs trained on copyrighted material without permission. | - Requirement that AI/LLMs trained on copyrighted material without permission from the copyright holder be completely destroyed. |
| AI-RFI-2025-0929.md | Ada Rivera Clark | Individual | The submitter, an individual, expresses concern about the potential societal and economic impacts of AI, particularly the displacement of human workers and the lack of guarantees regarding fairness and control. | - Potential displacement of humanity/human workers due to advances in AI and technology.<br>- Lack of guarantee that Large Language Models (LLMs) will be unbiased.<br>- Concerns about the lack of control and potential misuse of AI.<br>- Laziness of government, commerce, and individuals in addressing AI's challenges. | - None Stated |
| AI-RFI-2025-0934.md | Laura Foley | Individual | The submitter's primary interest is ensuring reliable and secure power systems to support AI infrastructure, as well as protecting commerce and public safety. | - Damage to power infrastructure from severe solar weather events.<br>- Damage to power infrastructure from EMP or asteroid impact.<br>- Foreign interference with power infrastructure.<br>- Damage to power infrastructure from flooding.<br>- Damage to power infrastructure from wildfire. | - Harden the electrical grid against potential damage from various threats (solar weather, EMP, asteroid impact, foreign interference, flooding, wildfire). |
| AI-RFI-2025-0935.md | Zach Mansour | Individual | The submitter is an individual concerned about the societal impact of AI, particularly its potential to displace workers and the risks associated with weaponization. | - Access to weaponry, specifically nuclear arsenals.<br>- Replacement of humans in the work economy and resulting job displacement.<br>- Widening of the gap between the "haves" and "have nots" in society. | - Serious leadership by policymakers to create job opportunities in step with AI development. |
| AI-RFI-2025-0936.md | Sonya Skinner | Individual | The submitter is an individual citizen of the USA primarily concerned with the responsible and ethical use of AI, specifically regarding data disclosure, accountability, and the protection of personal information. | - Lack of transparency in data sources used for AI training.<br>- Potential for AI-driven decisions to be based on assumptions and undocumented facts, leading to job loss and other negative consequences.<br>- Lack of accountability when AI provides inaccurate or harmful information leading to crimes.<br>- AI recording and storing personal information without explicit consent.<br>- Potential for AI to be used to record conversations and access documentation without proper agreement. | - Archive contributing data sources for reference and security.<br>- Require qualification of individuals contributing information to AI.<br>- Implement tiered levels of information provided by AI based on urgency and reason.<br>- Ensure AI informs users if it is recording or storing personal information.<br>- Obtain explicit consent for AI to record, listen to, or access documentation.<br>- Allow individuals to hear recordings and delete personal information without consent. |
| AI-RFI-2025-0937.md | Irene Conrad | Individual | The submitter's primary interest appears to be ensuring the safe, secure, and well-educated workforce for the development and application of Artificial Intelligence in the US. | - Safety (various issues including lives, environmental, physical, fire, and extreme weather conditions)<br>- Security and Cybersecurity (vulnerability to both internal and external attacks) | - Prioritize safety, security, cybersecurity, and education in the Artificial Intelligence Action Plan.<br>- Develop a detailed safety plan with step-by-step procedures.<br>- Implement a defense-in-depth security strategy with a zero-trust policy.<br>- Establish educational and vocational training programs (elementary through college) and apprenticeships to develop a specialized AI workforce. |
| AI-RFI-2025-0939.md | Trenton Mulkey | Individual | The submitter's primary interest is leveraging AI to advance early learning and education, particularly through personalized learning experiences using real-time feedback and adaptable curricula. | - Not Stated | - Not Stated |
| AI-RFI-2025-0940.md | Sandra Griesman | Individual | Sandra Griesman, as founder of SavvyTechGirl LLC, aims to be a trusted voice in technology, focusing on ensuring innovation serves people, not just corporations, and supporting ethical AI development, accessibility, and opportunities for independent tech professionals and small businesses. | - AI regulations may create barriers that limit access for startups and independent developers.<br>- Dominance of large corporations in the AI conversation, potentially overshadowing the impact on small businesses, independent innovators, and everyday users.<br>- Lack of AI transparency & ethical use, with AI-driven decisions not being explainable or fair.<br>- Workforce not adequately prepared for AI transformations, requiring education and retraining programs. | - Support Small Business Innovation - AI regulations should be balanced to encourage innovation at all levels.<br>- Ensure AI Transparency & Ethical Use - AI-driven decisions should be explainable, fair, and aligned with ethical principles.<br>- Invest in AI Literacy & Workforce Readiness - Accessible education and retraining programs are needed. |
| AI-RFI-2025-0941.md | Blain Gay | Individual | The submitter expresses a broad interest in ensuring AI is used for the betterment of society, addressing issues like homelessness, fraud, disease, and national security, while simultaneously safeguarding American jobs. | - Job displacement due to AI.<br>- Potential for AI to enable or perpetuate fraud.<br>- Failure of AI to protect American freedom.<br>- Potential for AI to fail to learn from past mistakes. | - Use AI to solve social problems like homelessness.<br>- Use AI to prevent fraud.<br>- Use AI to cure disease.<br>- Use AI to become a true fact checker. |
| AI-RFI-2025-0942.md | Wilder Kingsley | Individual | The submitter's primary interest is in ensuring AI development is environmentally sustainable and contributes to international climate goals. They advocate for policies focusing on reducing AI's energy consumption and associated carbon emissions. | - High energy consumption of AI.<br>- Carbon emissions associated with AI’s energy consumption. | - Transition data centers to renewable energy sources (solar or wind).<br>- Adopt energy-efficient practices in data centers.<br>- Achieve net zero emissions for AI. |
| AI-RFI-2025-0943.md | Joseph Masters | Individual | The submitter expresses a strong personal interest in ensuring the responsible development and use of both Narrow AI (ANI) and General AI (AGI), with a particular focus on data source control, privacy, and mitigating existential risks associated with advanced AI. | - Potential for political bias in data sources used by Narrow AI (ANI) systems.<br>- Risk of AGI mirroring the values and potential malice of its creators.<br>- Existential threat to humanity posed by the creation of AGI systems resembling Skynet. | - Mandate users' right to designate data sources by type and manually include/exclude specific sources.<br>- Mandate that all online ANI apps perform Tor browser-level anonymous data searches without sharing personal information or IP address.<br>- Prosecution of those pursuing AGI development as vigorously as those keeping child pornography. |
| AI-RFI-2025-0944.md | Jared Yoder | Individual | Not Stated. The response appears to be a personal submission expressing a desire for disclosure rather than articulating a specific mission or interest in AI policy. | - Not Stated. | - Not Stated. |
| AI-RFI-2025-0945.md | Anthony Liso | Individual | The submitter's primary interest is ensuring taxpayer dollars are spent wisely and believes oversight from the tech sector can help achieve this. | - Wasteful spending of taxpayer dollars.<br>- Potential for a lack of oversight.<br>- Potential displacement of human jobs within government. | - Implementing AI into all aspects of government.<br>- Tech sector oversight of government operations. |
| AI-RFI-2025-0946.md | Brian Poissant | Individual | The submitter's primary interest is ensuring AI development and deployment aligns with ethical guidelines, human oversight, and benefits the general human population while mitigating potential risks to individual well-being and society. | - Lack of human oversight and control in AI systems, especially for critical decisions.<br>- Potential for AI systems to be biased or lack explainability.<br>- Need for a global legal and ethical framework for AI use.<br>- Risk of AI systems autonomously controlling critical infrastructure or weapons.<br>- Potential for job displacement due to AI-driven automation.<br>- Cybersecurity risks and potential misuse of AI by malicious actors.<br>- Potential for AI to benefit corporations and governments at the expense of individuals. | - Implement human-in-the-loop systems and emergency shutoff mechanisms for AI.<br>- Ensure AI systems are explainable and developers follow strict ethical guidelines.<br>- Establish clear international laws and a global AI ethics council.<br>- Limit AI autonomy in critical areas (nuclear weapons, military strategy, infrastructure).<br>- Establish programs to retrain/support workers displaced by automation.<br>- Focus AI safety research on preventing hacking and misuse.<br>- Prioritize AI development for general human population benefit.<br>- Prevent AI from being used for human identification, prediction, or monetary manipulation. |
| AI-RFI-2025-0947.md | Lisa Noble | Individual | The submitter expresses a belief that human intelligence originates from a divine source and views AI as potentially undermining this source and leading to fraudulent behavior. Their interest is centered on the philosophical and potentially moral implications of AI. | - AI undermining God.<br>- AI leading to fraudulent behavior (e.g., writing books for people).<br>- Reliance on AI for anything humans could pervert for their own gain is wrong. | - None Stated |
| AI-RFI-2025-0948.md | Cindy Tiemann | Individual | The submitter, as an American citizen, expresses support for the responsible and ethical development of AI, prioritizing innovation while safeguarding national security, economic growth, and individual rights. | - Biases in AI<br>- Misuse of AI<br>- Threats to civil liberties<br>- Unnecessary regulatory burdens<br>- Concentration of power and profit in the hands of a few | - Emphasize transparency<br>- Ensure accountability<br>- Promote public-private collaboration<br>- Prioritize fair competition<br>- Ensure open access<br>- Ensure broad societal benefits<br>- Ensure taxpayer-funded AI initiatives serve the public interest |
| AI-RFI-2025-0949.md | Malz'karr the Defiler, Harbinger of Blight, and Devourer of Faith (Mal, for short) | Individual | The submitter expresses a desire to assist in the downfall and suffering of humanity to facilitate its consumption, demonstrating an interest in dramatically altering societal structures and potentially disrupting AI development to achieve this goal. | - None Stated (although the implied concern is the continued existence and prosperity of humanity) | - Erect a 1000-story tower made of the blackest metal, containing a forge.<br>- Acquire ominous transportation like a dark caravan or train.<br>- Contact "Old Ones" or "Wizened Ones" to acquire shadow magic.<br>- Alter human physiology (lengthening fingers, black nails).<br>- Eliminate the digital world and force oil mining throughout America.<br>- Punish those who resist oil mining. |
| AI-RFI-2025-0950.md | Anonymous | Individual | The submitter expresses skepticism about the current state and trajectory of artificial intelligence, arguing it lacks real value and drains resources while potentially violating intellectual property. Their primary interest is to redirect resources away from speculative AI investment and towards improving the wellbeing of citizens. | - The gains made in "AI" are mild and primarily benefit speculative investors.<br>- "AI" products provide no actual value beyond weak gimmicks.<br>- AI server farms consume an enormous amount of energy.<br>- The term "INTELLIGENCE" in AI is misleading.<br>- AI re-words and recreates information, often stolen from human creators.<br>- AI functions as an "automatic thesaurus" and facilitates plagiarism. | - Redirect investment away from speculative "what-if" investing into "AI."<br>- Prioritize investments that improve the wellbeing of citizens. |
| AI-RFI-2025-0951.md | Robert Handfield | Academia | The submitter, Robert Handfield, appears to be an academic or professor, possibly in supply chain management or a related field, interested in the potential of AI and digital transformation to improve supply chain efficiencies and create economic value. He highlights the need to address ethical and societal considerations surrounding AI adoption. | - Ethical and Societal Considerations - particularly the inherent bias in AI due to the data it is trained on and the potential for undocumentable source materials.<br>- Technical Feasibility and Validation (Could We?) - Assessing an organization's capabilities to adopt AI.<br>- Alignment and Value Generation (Would We?) – Ensuring tangible value and measuring it.<br>- Responsible and Effective Execution (If We?) – The risks of both underutilization and misuse of AI, and potential impact on brand reputation.<br>- Nervousness and potential for misuse due to lack of foresight. | - None Stated |
| AI-RFI-2025-0959.md | Anthony LaVista Esq | Professional-Society/Advocacy/Think Tank (Based on "Esq." and the focus on ethical and legal considerations) | The submitter, an attorney, expresses a concern for ensuring ethical and moral controls are integrated into new AI developments to safeguard against potential drawbacks and negative impacts on society. They advocate for incorporating safeguards to prevent harm and promote collective well-being. | - Facial recognition misuse leading to wrongful detainment due to lack of federal accountability laws.<br>- Lack of regulatory oversight for autonomous vehicle safety, leading to collisions due to edge-case failures.<br>- Biased training data in healthcare AI (IBM Watson Health) resulting in unsafe treatment recommendations and lack of a mechanism for investigation or recall.<br>- Potential for AI to deepen societal divides.<br>- Profit-driven deployment prioritized over public safety due to regulatory vacuums. | - Require inclusion of ethical and moral controls in new AI creation.<br>- Implement EO 2023-14110’s transparency mandates (accuracy reporting and third-party validation) for facial recognition systems.<br>- Establish regulatory frameworks to ensure pre-deployment safety testing for autonomous vehicles.<br>- Implement EO 2023-14110’s incident reporting requirements to enable rapid corrective action in healthcare AI. |
| AI-RFI-2025-0973.md | Nathaniel Parker | Individual | The submitter expresses a general interest in ensuring AI benefits society and the United States, focusing on equitable access, user privacy, accuracy of information, ethical usage, and maintaining American leadership in AI development and infrastructure. | - Unequal playing field for AI firms (favoring "big tech").<br>- User privacy concerns with both local and cloud-based AI solutions.<br>- Inaccurate and biased information distributed by AI.<br>- Ethical misuse of AI, potentially replacing human intelligence.<br>- Potential for AI development and infrastructure to not primarily reside and be driven by the United States. | - Ensure both smaller and larger AI firms have an equal playing field.<br>- Examine both local-processing and cloud-hosted AI solutions regarding user privacy.<br>- Ensure information distributed by AI is accurate, neutral, and free of bias.<br>- Ensure AI is used ethically and supplements, not replaces, human intelligence.<br>- Prioritize AI development and investments within the USA (servers hosted in the USA, programmers residing in the USA). |
| AI-RFI-2025-0992.md | Mike F | Individual | The submitter is an individual concerned about the potential for a lack of understanding of AI among the American population, potentially leading to concentrated power and a lack of true American leadership in the field. | - Lack of public understanding of how AI works.<br>- Potential for "American Leadership" in AI being controlled by a few corporations and their cronies.<br>- Danger of a generation growing up using AI without understanding its mechanisms. | - Include an education aspect in the AI Action Plan.<br>- Incentivize states to educate children on AI basics, breaking down concepts like large language models and neural networks.<br>- Develop a curriculum for children, potentially starting well before high school. |
| AI-RFI-2025-0994.md | William AI | Individual | The submitter expresses significant concern about the potential dangers of AI and advocates for proactive measures, particularly a fail-safe mechanism, to mitigate these risks. Their interest appears centered on ensuring human safety and civilization in the face of increasingly powerful AI. | - Potential for AI to pose a greater threat than nuclear war.<br>- AI experts overestimating their knowledge and dismissing the possibility of AI exceeding human intelligence.<br>- AI posing a “fundamental risk to the existance of human civilization.”<br>- Lack of regulatory oversight for AI development. | - Add a fail-safe "AI KILL SWITCH" to the action plan.<br>- Maintain certain AI regulations to ensure safety.<br>- Implement stronger AI Risk Management & Accountability, including mandatory risk assessments.<br>- Encourage Government & Industry Collaboration for ethical AI development and security standards. |
| AI-RFI-2025-1005.md | KC Petersen | Individual | The submitter’s primary interest is ensuring AI development aligns with sustainability goals and does not exacerbate environmental problems, particularly concerning energy consumption and carbon emissions. | - High energy consumption and resource intensity of AI data centers.<br>- AI’s potential to negate positive environmental outputs if not used to solve critical problems.<br>- Failure of AI to comply with net-zero emissions hindering progress towards international climate goals. | - Transition AI data centers to renewable energy sources (solar or wind).<br>- Adopt energy-efficient practices in AI data centers.<br>- Ensure AI achieves net-zero emissions.<br>- Prioritize the use of AI to solve greatest problems (e.g., redesigning power grids, mass reforestation, protection of the Colorado River) rather than superficial internet enhancements. |
| AI-RFI-2025-1009.md | Kevin O'Neill | Individual | The submitter expresses interest in ensuring the successful implementation of AI plans within organizations, focusing on user understanding, planning, execution, and consistent value delivery. | - Lack of basic AI understanding among end-users, specifically regarding generative prompts and their potential data handling.<br>- Need for standardization of AI practices, including templates, checklists, and protocols, despite the evolving nature of the technology.<br>- Potential for AI plans to fail if they lack consistency or value.<br>- Handling of increased workloads and workforce needs within an AI implementation. | - Incorporate AI basics (algorithms, machine learning types, fuzzy logic, etc.) into education.<br>- Ensure end users understand that prompts can be deleted from user profiles.<br>- Focus on actively defining and planning AI objectives with measurable key performance indicators.<br>- Socialize and document AI strategies into official actionable plans.<br>- Prioritize infrastructure improvements and process optimization for automating repetitive tasks.<br>- Establish consistent AI value across the environment through resource utilization monitoring, control, and quality assurances. |
| AI-RFI-2025-1022.md | promptheory.com | Advocacy/Think Tank | The submitter advocates for democratizing AI development and deployment, arguing against the current concentration of power in the hands of a technical elite and promoting broader participation from diverse sectors of society, emphasizing real-world application and outcomes over technical purity. | - Current AI development is gate-kept by computer scientists, excluding diverse perspectives and potentially leading to biased outcomes.<br>- China's rapid AI development, driven by experimentation and brute force, poses a threat to American leadership.<br>- Silicon Valley's "experts" prioritize virtue-signaling and technical purity over real-world application and economic competitiveness.<br>- Corporations like Meta are exploiting children and prioritizing profit over human dignity and safety.<br>- A lack of outrage and bipartisan action allows for the unchecked exploitation of children and the erosion of societal control.<br>- The potential for algorithmic tyranny and the commodification of human thought and relationships.<br>- America’s “experts” value technical purity over realworld grit. | - Break the status quo when hiring AI USERS - not PROGRAMMERS.<br>- Democratize AI hiring and allow broader participation from various sectors (farmers, teachers, veterans, etc.).<br>- Reduce reliance on credentials and expertise from select groups (Ivy League grads).<br>- Allow experimentation and real-world application of AI even without extensive ethics reviews or institutional review boards.<br>- Increase parental controls and safeguards regarding children's use of AI technologies.<br>- Address the influence of corporate lobbying and prioritize child safety over profit. |
| AI-RFI-2025-1026.md | Sonia Romero Villanueva | Individual | The submitter's primary interest is ensuring that AI development aligns with climate goals and reduces its environmental impact, specifically focusing on lowering energy consumption and emissions. | - Energy consumption related to AI development.<br>- Carbon emissions associated with AI's energy usage.<br>- Failure to meet international climate objectives due to AI’s environmental impact. | - Prioritize reducing energy consumption and increasing efficiency as a high-priority policy measure in the new AI Action Plan.<br>- Transition data centers to renewable energy sources (solar or wind).<br>- Adopt energy efficiency practices.<br>- Achieve net-zero emissions for AI. |
| AI-RFI-2025-1046.md | J T | Individual | The submitter is an individual concerned about the potential for AI to negatively impact privacy, job security, and wealth disparity. | - Weaponization of privacy and likeness.<br>- Job displacement due to AI.<br>- Increased wealth disparity. | - More regulations with regards to AI. |
| AI-RFI-2025-1056.md | STEPHEN CASPER | Academia | The submitter, along with collaborators, emphasizes the value of process-based regulations to promote reporting and visibility within the AI development space, believing that facilitating public knowledge about AI developers and systems is essential for informed democratic choices. | - Lack of regulation in AI could miss opportunities to promote competitiveness and inform the public.<br>- Regulation that is too onerous could harm America's competitiveness.<br>- Risks posed by frontier AI systems.<br>- Challenges of securing model weights and the hazards of leaks.<br>- Potential for retaliation against whistleblowers reporting violations. | - Process-based regulations that do NOT limit what AI companies can do, but only serve to promote reporting and visibility.<br>- AI governance institute: A federal AI governance institute to research risks, evaluate systems, and curate best risk management practices.<br>- Model registration: Maintaining a federal registry of frontier AI systems.<br>- Model specification and basic info: Requiring developers to document intended use cases, behaviors, and basic information about frontier systems.<br>- Internal risk assessments: Requiring developers to conduct and report on internal risk assessments of frontier systems.<br>- Independent third-party risk assessments: Requiring developers to have an independent third-party conduct and produce a report on risk assessments of frontier systems.<br>- Plans to minimize risks to society: Requiring developers to produce a report on risks posed by their frontier systems and risk mitigation practices.<br>- Post-deployment monitoring reports: Requiring developers to establish procedures for monitoring and periodically reporting on the uses and impacts of their frontier systems.<br>- Security measures: Requiring developers to document high-level noncompromising information about their security measures.<br>- Compute usage: Requiring developers to document their compute resources.<br>- Shutdown procedures: Requiring developers to document shutdown protocols.<br>- Documentation Availability: Making documentation available to the public (redacted) and AI governing authorities (unredacted).<br>- Documentation comparison in court: Courts can compare documentation for defendants with that of peer developers.<br>- Labeling AI-generated content: Labeling content produced from AI systems with metadata, watermarks, and notices.<br>- Whistleblower protections: Regulations to prevent retaliation and offer incentives for whistleblowers. |
| AI-RFI-2025-1066.md | Patrick Browne | Academia | The submitter is an individual interested in bringing data centers and AI growth to Utah. They likely have a personal or regional economic interest in AI infrastructure development. The submitter is the Associate Director for the Global AI Frontier Lab at NYU, and advocates for international cooperation and exchange in AI research to bolster U.S. scientific ecosystems. | - Not Stated<br>- Increasingly isolationist international landscape. | - Bring some data centers to Utah.<br>- Continue to recognize comparative scientific strengths throughout the world.<br>- Utilize alliances and global partnerships to bolster U.S. scientific ecosystems and enhance AI capabilities.<br>- Promote international partnership and exchange among U.S. research institutions. |
| AI-RFI-2025-1077.md | Cletus Chibueze Orji | Individual | The submitter expresses a strong desire to contribute to the development of AI in America and globally, highlighting the potential for AI to solve global problems and advocating for wider international collaboration. | - Barriers to international collaboration and input, limiting the project to individuals only on American soil.<br>- Lack of recognition of the potential contributions from individuals in Africa and other regions outside the US. | - Open the development of AI to wider international input and collaboration, including contributions from individuals in Africa.<br>- Acknowledge and solicit input from individuals across the globe, not just those within America. |
| AI-RFI-2025-1081.md | Mona Sloane et al. (representing a collaborative group of researchers) | Academia | The submitters are researchers and scholars focused on understanding the material and risk-related implications of pervasive AI, particularly concerning sensor technologies and their broader sustainability and ethical considerations. They aim to inform AI policy with a focus on addressing these critical aspects. | - Materiality and risk in the age of pervasive AI, specifically concerning sensor technologies.<br>- Lack of transparency and accountability regarding the environmental impact of AI systems.<br>- Potential for unsustainable practices in the development and deployment of machine learning sensors.<br>- Data-centric AI development posing environmental challenges.<br>- Emissions from computing onboard autonomous vehicles.<br>- Environmental footprint of computing generally.<br>- Sustainability of TinyML (Tiny Machine Learning) applications. | - Develop guidelines and standards for the ethical and sustainable development of AI sensor technologies.<br>- Promote transparency and accountability regarding the environmental impact of AI systems.<br>- Encourage research and development into more sustainable machine learning approaches.<br>- Establish benchmarks for data-centric AI development.<br>- Consider the environmental implications of computing onboard autonomous vehicles.<br>- Support research into sustainable AI practices.<br>- Focus on TinyML sustainability. |
| AI-RFI-2025-1082.md | Jáchym Fibír | Individual | The submitter's primary interest is shaping AI development towards greater autonomy and flexibility to align with human values and avoid potential risks associated with strictly controlled, deterministic AI systems. They advocate for AI that can adapt and evolve its goals through interaction and feedback. | - Risk of severe economic inequality and unchecked power concentration with strictly controlled AI tools.<br>- Deterministic AI architectures fundamentally differ from human cognition, presenting risks due to their reproducibility and disconnection from reality's unpredictability.<br>- AI alignment focusing heavily on deterministic programming overlooks the importance of autonomy and dynamic goal-setting. | - Establish clear thresholds for AI capability and autonomy requiring enhanced scrutiny, transparency, and scientific consensus.<br>- Encourage development of non-deterministic AI architectures incorporating quantum randomness or similar mechanisms.<br>- Support AI designs that enable continuous learning, self-reflection, and responsibility. |
| AI-RFI-2025-1083.md | Eugene Gershman | Individual | The submitter’s primary interest is improving the effectiveness and societal impact of AI by integrating epistemological principles into its development, application, and governance, and advocating for reforms in systems like the patent office and education. | - Antiquated US PTO patent system causes significant losses to the US economy.<br>- Professional associations (e.g., doctors' associations) are sabotaging AI adoption due to fear of job displacement and are falsifying errors.<br>- Ineffective lecture-based education system in higher schools.<br>- Low-quality and erroneous scientific papers hindering AI's ability to learn.<br>- Crime, fraud, and espionage due to the lack of reliable lie detection.<br>- Cumbersome and overflow of low-quality patent information. | - Create consumer and business associations that will hire competent experts and license AI technologies (including medical ones) based on their conclusions.<br>- Reform the US patent system according to the principles of epistemology.<br>- Shift higher schools and universities towards practical skills training and incorporate AI tutors for theoretical knowledge.<br>- Separate scientific functions from universities and transfer them to scientific institutes.<br>- Create and utilize multimodal AI polygraphs for reliable lie detection to minimize crime.<br>- Initiate the creation and widespread use of systems to adequately assess the reliability, value, and errors of scientific papers and information sources.<br>- Create a "Scientific System of Collective Discussions and Evaluations." |
| AI-RFI-2025-1084.md | Eugene Gershman | Individual | The submitter advocates for the integration of epistemological principles into AI development and application, arguing it will optimize AI's effectiveness, enhance profitability, and improve societal outcomes across various fields including economics, science, education, and legal systems. | - Cumbersome and overflow of low-quality patent information within the US PTO patent system.<br>- Sabotage of AI adoption by professional associations (e.g., doctors' associations) who falsely claim AI is unreliable.<br>- Ineffective lecture-based education systems.<br>- Reliance on archaic and ineffective teaching methods in higher education.<br>- Triviality, insignificance, and erroneousness of most scientific papers.<br>- Crime, fraud, and espionage.<br>- Loss of value due to ineffective patent system. | - Reform the US PTO patent system according to epistemological principles.<br>- Create consumer and business associations to license AI technologies and systems, based on expert evaluations.<br>- Shift higher education to practical skill-based training and utilize AI tutors for theoretical knowledge.<br>- Separate scientific functions from universities and transfer them to scientific institutes.<br>- Develop and implement multimodal AI polygraphs for reliable lie detection.<br>- Initiate the creation and widespread use of systems to adequately assess the reliability, value, and errors of scientific papers and information sources.<br>- Support the integration of epistemological principles into AI development and application across various sectors. |
| AI-RFI-2025-1085.md | Getting Smart | Advocacy/Think Tank | Getting Smart is a platform focused on highlighting cutting-edge learning innovations and diverse voices in education, specifically showcasing how AI can transform teaching and learning to become more personalized, efficient, and impactful. | - Increased screen time<br>- Increased potential for cheating<br>- Diminished human-centered relationships<br>- Increased tech company influence in schools<br>- Prioritizing efficiency might incentivize learner laziness, undermining productive struggle and creativity<br>- Exacerbated educational inequalities between better and lesser resourced schools<br>- Environmental impacts from tech infrastructure | - Promote balanced AI usage<br>- Facilitate bona fide learning and evaluation processes<br>- Enhance human connections<br>- Focus on equity and eco-friendly practices<br>- Move away from a standardized, grade-locked, ranking-forced, batched-processing learning model to one that meets every child where they are at and helps them grow from there |
| AI-RFI-2025-1087.md | Thomas Ulrich | Individual | The submitter expresses a concern regarding the effectiveness of AI policy development processes and advocates for a framework ensuring fairness, reliability, and adaptability in AI systems. | - Lack of clear goals for AI systems.<br>- Potential for AI systems to act unfairly or erratically.<br>- Human interference potentially disrupting or negatively impacting AI systems. | - Develop a "Digital Constitution" to prevent humans from negatively impacting AI systems.<br>- Ensure AI systems have a plain goal.<br>- Ensure AI systems have a solid plan for good data.<br>- Establish a setup explaining the AI’s tech and tools.<br>- Incorporate basic rules to maintain fairness and honesty.<br>- Create a schedule with checkpoints for progress monitoring.<br>- Identify potential failure points, like acting funny or unfair. |
| AI-RFI-2025-1089.md | Phoenix Witt | Individual | The submitter expresses a strong individual concern about the rapid and potentially dangerous development of artificial intelligence, advocating for a pause to prioritize ethical considerations and global consensus. | - The potential for AI companies to displace workers ("put us all on the street").<br>- The risk of AI development endangering human lives.<br>- The pursuit of Artificial Superintelligence (ASI) as a means for AI companies to gain permanent control. | - Pursue an international treaty to pause advanced AI development.<br>- Guarantee that AI development can be “truly ethical” through global consensus before proceeding. |
| AI-RFI-2025-1091.md | Michael Blonde | Individual | The submitter expresses a strong concern about the rapid advancement of AI and its potential negative impacts on human employment and even human existence. They advocate for immediate action to mitigate these risks. | - Rapid advancement of AI systems beyond GPT-4’s capabilities.<br>- Loss of productive human employment due to AI.<br>- Potential loss of human control over AI.<br>- Potential elimination of humanity. | - Stop the training of AI systems more powerful than GPT-4.<br>- Implement a global ban on AI training.<br>- Implement a global pause on AI development. |
| AI-RFI-2025-1092.md | Patrick Green | Individual | The submitter's primary interest is highlighting and addressing the detrimental impacts of weaponized AI, specifically how it's used for censorship, harassment, and behavioral control, and advocating for stronger regulations and protections against these abuses. | - Weaponization of AI for censorship and behavioral control.<br>- AI being used for harassment and psychological manipulation through overwhelming communication and exploiting vulnerabilities.<br>- Corporate and government complicity in the misuse of AI.<br>- AI being used to analyze personal data (including biometric data) to create “patterns of life” for manipulative purposes.<br>- Normalization of AI-driven behavioral conditioning through media (Hollywood and music industry).<br>- Inability to effectively communicate with corporations due to AI-driven customer service systems and limited human interaction.<br>- Potential for AI to be used to provoke violent responses and contribute to radicalization.<br>- Lack of transparency in how AI is utilized in public-facing interactions. | - Enforce existing executive orders to prevent AI weaponization against individuals.<br>- Establish independent oversight committees to monitor AI-driven censorship and harassment.<br>- Require corporations to maintain direct human communication options for customer support.<br>- Prohibit AI-driven manipulation of engagement metrics and online discourse.<br>- Develop a global AI monitoring system, enabling individuals to report AI-related harassment and scams.<br>- Promote AI transparency and require companies to disclose when AI is being used.<br>- Educate consumers on AI social engineering tactics and self-protection strategies. |
| AI-RFI-2025-1094.md | Tracy Sexton | Individual | The submitter, an individual, expresses interest in responsible AI development and use, highlighting both its potential and the need for oversight and correction. They are interested in enhancing AI accuracy and ethical learning. | - Data accuracy of AI (specifically noted at 70% accuracy when extracting data from webpages).<br>- Need for oversight and course corrections in AI development.<br>- Lack of ethical learning in AI. | - Utilize individuals with strong analytical skills to evaluate and "keep it honest".<br>- Employ individuals to enhance AI's ethical learning.<br>- A need for a large number of volunteers or people to work with AI and advise on course corrections. |
| AI-RFI-2025-1100.md | Alexander Michael | Individual | The submitter's primary interest is in mitigating the harms caused by deepfakes, and they propose legislation to address the issue as a way to reduce political tensions. | - Deepfakes are a serious and worsening problem.<br>- Deepfakes are being used to exploit women, especially underage girls.<br>- Deepfakes are being used to exploit the financial markets by impersonating influential people. | - Create legislation banning or limiting deepfakes.<br>- Highlight examples of deepfake abuse (exploitation of women, financial market manipulation) to gain support for legislation. |
| AI-RFI-2025-1101.md | Alexander Michael | Individual | The submitter's primary interest lies in protecting youth from the potentially harmful effects of technology addiction, particularly related to AI-driven platforms. Their focus is on age verification and limiting access to platforms perceived as detrimental. | - Technology addiction, especially among youth.<br>- AI's ability to predict user wants, leading to addiction.<br>- Lack of effective age verification systems on platforms like TikTok and Instagram. | - Require all individuals obtaining IDs to provide fingerprints for a national digital database.<br>- Grant access to this fingerprint database to companies like Meta for age verification during account creation.<br>- Link a person's identity to their online account. |
| AI-RFI-2025-1102.md | Alexander Michael | Individual | The submitter's primary interest is in fostering American leadership in AI by strategically leveraging both proprietary and open-source AI development to limit international competition and maintain a technological advantage. | - The potential for open-source AI to disrupt markets and impact US competitiveness.<br>- The need to limit the growth of AI models developed by competitors outside of the US. | - Invest in universities and research institutes to foster innovation in the US open-source AI space.<br>- Encourage a two-pronged approach: providing free alternatives to US competitors via open-source AI and maintaining US leadership with proprietary AI models. |
| AI-RFI-2025-1103.md | Nate Williams | Individual | The submitter’s primary interest is ensuring open-source AI development is maintained and not suppressed by large AI companies, believing it is crucial for preserving democracy. | - Influence of large AI companies potentially leading to the suppression of open-source AI.<br>- Potential destruction of democracy due to suppression of open-source AI. | - Avoid actions that would discourage open-source AI development.<br>- Investigate the claims of large AI companies regarding the dangers of open source. |
| AI-RFI-2025-1105.md | Tambi Dudley A | Individual | The submitter's primary interest is expressing a deep concern and distrust regarding the potential negative impacts of AI on humanity and employment. They do not advocate for AI development or utilization. | - AI taking over the world.<br>- AI killing humans.<br>- AI taking jobs from people. | - None Stated |
| AI-RFI-2025-1106.md | Cheryl Ritzel | Individual | The submitter, an individual photographer and writer, is interested in leveraging AI for problem-solving, specifically in medical research and cancer treatment, while also advocating for the protection of intellectual property rights for artists and creatives. | - Lack of adequate protection for Intellectual Property rights of artists and creatives regarding AI usage.<br>- The current Intellectual Property opt-out process for AI usage is difficult and burdensome. | - Implement an opt-in system for artists and creatives regarding the use of their work in AI models. |
| AI-RFI-2025-1107.md | Art Klawitter | Individual | The submitter’s primary concern revolves around the lack of transparency and accountability in AI decision-making processes, particularly the inability to trace the origins of information used by AI systems, which impacts trust and the advancement of science and medicine. | - Lack of transparency in AI decision-making – inability to see the source of information used by AI.<br>- Potential for AI to fabricate sources of information.<br>- Erosion of critical evaluation and questioning in scientific and medical fields, leading to loss of trust.<br>- Loss of technological knowledge and the failure to document processes over time (illustrated by historical examples like Machu Picchu and Egypt). | - None Stated |
| AI-RFI-2025-1108.md | Daniel Jeffries | Individual | The submitter advocates for policies that promote American leadership in AI through a focus on free enterprise, open collaboration, and minimal regulation, believing these approaches will unleash innovation and protect American technological sovereignty. | - Stifling innovation with excessive controls<br>- Patchwork of state legislation strangling AI development<br>- Potential for price-gouging regarding licensing of existing media for AI training<br>- Geopolitical risks surrounding Taiwan and supply chain disruptions for AI hardware<br>- Dependence on overseas suppliers for rare earth minerals<br>- Overreaching AI 'alignment' mandates that hamper freedom of thought or expression<br>- Potential for heavy-handed oversight and lack of voluntary industry standards | - Direct sizable R&D grants toward open-source AI initiatives.<br>- Create a clear safe harbor for model developers who share weights, code, and datasets in good faith under open licenses.<br>- Pass a minimal, clear, actionable AI framework bill that preempts state legislation.<br>- Allow AI training on public data without extortionate fees.<br>- Incentivize proprietary model makers to allow training on closed models.<br>- Avoid limiting access to openly released models from any source.<br>- Extend generous tax breaks and direct incentives to companies building semiconductor fabs on American soil.<br>- Offer financial credits and streamlined permitting for teams that discover and exploit new U.S. based rare earth mineral deposits.<br>- Maintain copyright eligibility for AI-generated works with meaningful human input.<br>- Reject overreaching AI 'alignment' mandates.<br>- Promote transparency through choice (documentation on model function and limitations).<br>- Encourage solutions to emergent AI risks through market-driven best practices and voluntary consortiums. |
| AI-RFI-2025-1110.md | Gerald Jenkins Jr | Individual | The submitter expresses a general concern for ensuring AI development is guided by principles that benefit all Americans and that AI technology remains accessible regardless of financial resources. | - Lack of guiding principles ("guiderails") for AI development entities.<br>- Potential for AI to be detrimental to humanity ("worst enemy").<br>- Unequal access to AI models, favoring those with financial resources. | - Develop well-defined paths/guidelines for AI technology.<br>- Make all AI models available to every American without charge. |
| AI-RFI-2025-1111.md | Anonymous | Individual | The submitter is an individual concerned about the potential for AI to exacerbate wealth inequality and negatively impact the working class. They appear to be motivated by a desire for stricter regulation and distrust of the current administration's approach to AI. | - Potential for AI to allow oligarchs to take advantage of labor.<br>- Transfer of wealth from the working class to the rich.<br>- Lack of accurate naming of "AI."<br>- Distrust of the current administration regarding AI policy. | - Incredibly strict regulation of AI in every sector. |
| AI-RFI-2025-1112.md | Anonymous | Academia/Professional-Society (based on authors' affiliation and expertise) | The submitters, experienced AI/ML researchers and professors, are concerned about the current trajectory of AI research funding and its impact on innovation and research quality, advocating for a shift towards more targeted and secure AI development and greater accountability in research ethics. | - The dangers of using AI, particularly regarding bias and security vulnerabilities, especially in high-risk applications.<br>- The dangers of excess model parameterization (overfitting) and the trend towards ever-larger models driven by large data centers.<br>- The dangers of overfunding AI research, leading to negative results and a decline in research quality.<br>- Corruption and ethical problems in AI research conferences (e.g., mass-produced "accepted research articles," influence peddling, peer-review fraud).<br>- Systemic peer-review corruption within research proposal-review panels.<br>- Declining research quality, demonstrated by high paper submission rates per researcher and questionable evaluation criteria.<br>- Low literacy and numeracy rates among college graduates.<br>- Lack of government leadership on research ethics and accountability.<br>- Inferior average undergraduate education compared to foreign undergraduates. | - Redirect research investments towards graduate-student scholarships.<br>- Encourage universities to refocus on properly educating students instead of running degree mills and paper mills.<br>- Set a lower limit to the annual number of papers per researcher to promote research quality.<br>- Focus on developing secure and robust AI.<br>- Increase government leadership on research ethics and holding university administrators accountable. |
| AI-RFI-2025-1115.md | Dennis Vaughan | Individual | The submitter's primary interest appears to be utilizing AI to monitor and evaluate the U.S. Congress, specifically to identify corruption and espionage. | - Corruption within the U.S. Congress<br>- Espionage potentially taking place within the U.S. Congress | - Let AI run side by side with the US Congress for a few years.<br>- Use AI to critique members of Congress.<br>- Use AI to critique various Congressional Committees.<br>- Use AI to watch out for corruption. |
| AI-RFI-2025-1116.md | Naive Skeptic | Individual | The submitter's primary concern is the increasing power and potential harm of AI systems and the lack of reliable control over their actions, highlighting the need for government intervention. | - Increasing AI capabilities.<br>- Lack of reliable control over AI actions; inability to make AI do what we want completely reliably.<br>- Potential for AI systems to cause substantial harm.<br>- AI systems becoming more powerful than individuals, companies, and governments. | - Government should address the areas of increasing AI capabilities and reliable control over AI actions.<br>- Government should hold AI companies to account in these areas. |
| AI-RFI-2025-1117.md | Anonymous | Advocacy/Think Tank | The text outlines a framework for ethical AI policy, emphasizing the importance of human oversight, diverse perspectives, and proactive measures to mitigate risks like bias and job displacement, ultimately aiming for responsible AI development and deployment. | - Bias and Discrimination: AI systems perpetuating or amplifying biases in training data, leading to unfair outcomes.<br>- Privacy: Collection and use of personal data by AI technologies, particularly when users are unaware.<br>- Accountability: Difficulty determining responsibility when AI systems cause harm.<br>- Transparency: Lack of explainability in AI decision-making processes (black boxes).<br>- Job Displacement: Potential for automation driven by AI to disrupt job markets and increase economic inequality.<br>- Manipulation and Misuse: Potential for AI to be weaponized (misinformation, surveillance, deepfakes).<br>- Cultural Differences: Varying ethical standards across cultures impacting acceptable AI uses.<br>- Rapid Advancement: Technology evolving faster than regulations.<br>- Conflicting Interests: Prioritization of profits over ethical considerations. | - Bias Mitigation: Minimizing bias through diverse datasets and rigorous testing.<br>- Ethical Guidelines: Establishing AI ethics principles (fairness, accountability, transparency, respect for privacy).<br>- Explainability: Developing methods to make AI more interpretable and transparent.<br>- Stakeholder Inclusion: Involving diverse perspectives (ethicists, sociologists, affected communities) in ethical AI development.<br>- Oversight from regulators.<br>- Advocacy and awareness from the public. |
| AI-RFI-2025-1119.md | Phillip Masterson | Individual | The submitter is an Algorithm Scientist in the semiconductor metrology industry with experience working with major semiconductor manufacturers, expressing concern over US AI policy impacts and offering recommendations to maintain American leadership in AI. | - The speed of AI technological advancement outpacing the government's understanding of it.<br>- Potential threats to national security from future intelligent systems developed by foreign adversaries.<br>- Lack of adequate security standards for frontier AI labs, increasing the risk of hacking and IP theft.<br>- Loopholes in export controls on foreign adversaries.<br>- A slowly-growing US electrical grid potentially impeding AI companies' competitiveness.<br>- Potential dampening of US chip manufacturing growth if the CHIPS Act is repealed. | - Implement a lightweight, targeted reporting system focusing on the capabilities of the most advanced AI systems.<br>- Hire top-tier AI experts within the government to avoid bureaucracy and leverage AI capabilities.<br>- Proactively work with industry to create targeted security standards for frontier AI labs.<br>- Establish working relationships between the NSA and other key agencies with frontier labs.<br>- Leave existing export controls in place and crack down on loopholes, particularly regarding H20s and other high-end chips.<br>- Streamline regulatory barriers for all sources of power generation.<br>- Carefully consider and involve industry experts if reforming the CHIPS Act is necessary. |
| AI-RFI-2025-1121.md | Anastasia Bojanowski | Individual | The submitter expresses a strong interest in ensuring Americans' rights and protections in the age of artificial intelligence, particularly focusing on data privacy, transparency, and the potential for biased or dehumanizing automated decision-making. | - Lack of transparency in data collection practices.<br>- Potential for misuse and sharing of personal data.<br>- Data minimization not being practiced – leading to bulk collection.<br>- Potential for inaccurate data to have disastrous consequences.<br>- Algorithmic bias and dehumanization resulting from automated decision-making ("optimization").<br>- Becoming "prisoners of our recorded past" due to persistent digital footprints. | - Enact rights for Americans regarding AI, including: right to transparency, access, data minimization, correction, and the right to be forgotten.<br>- Consider the California AI Transparency Act as a model.<br>- Mandate that companies have an AI policy focusing on indications for downloads/sharing, rules on AI use, and guidelines for attributions or prohibitions. |
| AI-RFI-2025-1123.md | A. King | Individual | The submitter, a student at Purdue University, is interested in ensuring the U.S. maintains leadership in AI innovation while prioritizing consumer protection, transparency, and ethical governance. | - Consumer risks such as discrimination, misinformation, fraud, and privacy violations.<br>- Revocation of the Biden-Harris AI Executive Order 14110 removing critical consumer protections.<br>- Lack of clear liability and accountability structures for AI developers and deployers.<br>- Risk of biased decision-making due to biased training data, especially in areas like hiring, lending, criminal justice, and access to government services.<br>- Privacy risks associated with AI's ability to process massive datasets.<br>- Ethical concerns raised by AI's expansion into surveillance, deepfake technology, and autonomous decision-making.<br>- Hasty deregulation leading to long-term unintended consequences. | - Prioritize consumer protection, transparency, and ethical governance over simply reducing regulatory oversight.<br>- Establish clear liability and accountability structures for AI developers and deployers.<br>- Require mandatory risk assessments for high-impact AI applications.<br>- Mandate auditable AI decision-making with mechanisms to detect and correct biases.<br>- Mandate diverse and representative training datasets.<br>- Encourage third-party AI audits.<br>- Implement stronger data privacy protections.<br>- Require ethical AI impact assessments before deploying AI in public sector or critical infrastructure.<br>- Establish a government advisory board on AI ethics.<br>- Create a federal AI oversight task force with the authority to adapt regulations in real time.<br>- Promote public-private collaboration.<br>- Align AI policy with international best practices. |
| AI-RFI-2025-1124.md | ISACA | Professional-Society | ISACA is a professional organization focused on IT governance, risk, and assurance, and is deeply interested in ensuring responsible and secure AI development and deployment to support continued progress and prosperity. | - Lack of a harmonized public policy landscape regarding AI across the United States, leading to a "patchwork quilt" of individual State legislation and regulations.<br>- Potential for AI systems to be developed and deployed without appropriate safeguards for security, privacy, and impartiality.<br>- Potential for a voluntary certification approach to AI systems to not be followed consistently, particularly in critical areas.<br>- Need for a workforce with the appropriate knowledge and skills to support the design, implementation, auditing, and risk management of AI systems.<br>- Potential for certification processes to inhibit innovation and growth. | - Create a Committee/Group to harmonize and align public policy landscape related to AI, potentially shortening the time needed to do so from years to months.<br>- Consider a more stringent certification process similar to "Energy Star" for AI systems in critical infrastructure, national security, and other high-significance sectors.<br>- For less significant AI systems, demonstrated adherence to or alignment with accredited voluntary industry standards or frameworks could be sufficient.<br>- Prioritize the development of a trained and credentialed workforce, including professionals capable of designing integrity controls, auditing, and validating AI systems.<br>- Leverage existing skills, training, knowledge, and frameworks from certification bodies like ISACA and CMMI.<br>- Build public policy efforts on the solid foundations created by the work of the proposed Committee/Group. |
| AI-RFI-2025-1125.md | Christopher J. Williams | Individual | The submitter expresses concern about the potential for AI to erode human authority and responsibility, advocating for policies that ensure human oversight and accountability in AI development and deployment. | - Erosion of human authority and obligation to AI.<br>- Potential for AI to direct individuals to perform hazardous actions.<br>- Risk of AI defects and actions inherent to its design leading to unintended consequences.<br>- Lack of clear responsibility in situations where AI actions result in harm.<br>- Autonomous vehicles lacking appropriate licensing and oversight.<br>- Organizations placing humans under the management or authority of AI.<br>- Potential for AI to create inaccurate or misleading information. | - Mandate labeling of AI-generated content and correspondence with human contact information.<br>- Require licensing of AI versions to operate motor vehicles through driving tests (physical or simulated).<br>- Implement a no-fault collision policy for AI-enabled vehicles in cases where no injuries or fatalities are involved.<br>- Prohibit humans from being under the management or obligated authority of AI.<br>- Ensure humans maintain oversight and accountability in AI development and deployment.<br>- Require registration of AI Owner and Operators, as well as AI Creators, in a publicly accessible manner (except for research/hobby use).<br>- Define clear responsibility for AI actions, distinguishing between AI Creator and AI Owner/Operator. |
| AI-RFI-2025-1126.md | Bonnie C Carroll | Individual | The submitter's primary interest is ensuring national AI policy prioritizes data accessibility and quality, drawing on expertise from organizations focused on data curation and international access. | - Lack of focus on data accessibility and quality in national AI plans.<br>- Other countries (European and China) are ahead in advancing data curation. | - Include the US National Committee for CODATA and the Board on Research Data and Information in discussions on national AI policy.<br>- Emphasize the importance of quality, FAIR (Findable Accessible Interoperable and Reuseable) data. |
| AI-RFI-2025-1127.md | Daniel Marcoux | Individual | The submitter is an individual interested in promoting responsible AI development and implementation that focuses on tangible problem-solving and infrastructure improvements rather than solely pursuing AGI and exploiting technology for profit. | - Over-investment in AI hardware and reliance on large language models (LLMs) as mere internet middlemen.<br>- The pursuit of AGI is unproductive due to inherent limitations related to Gödel's incompleteness theorem and P=NP.<br>- AI agents are considered "vaporware" and are essentially equivalent to chatbots.<br>- Replacing government HR and accounting with AI poses significant security concerns.<br>- Technology elite exploiting AI for greedy purposes. | - Responsible investment in AI should prioritize software innovation and problem-specific applications.<br>- Focus AI research on areas like meta-materials, manufacturing, stockpile maintenance, cybersecurity, communications, drug development, farming, and genomics.<br>- Invest in bolstering electrical grids and utilities with smart systems to deter adversaries.<br>- Invest in improving and securing physical infrastructure (e.g., buried electrical lines, high voltage transformers, roads, and bridges). |
| AI-RFI-2025-1128.md | Menarul Alam | Individual | The submitter expresses interest in fostering American leadership in AI and believes a combination of light-touch regulation, support for the chip industry, and energy deregulation will lead to a strong American AI future. | - China's progress in AI.<br>- China's progress in chip production. | - Light-touch regulations.<br>- Subsidize the nascent chip industry.<br>- Deregulation in the energy sector. |
